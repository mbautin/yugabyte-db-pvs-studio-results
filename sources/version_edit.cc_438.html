
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
  <title>version_edit.cc</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">//  Copyright (c) 2011-present, Facebook, Inc.  All rights reserved.</a>
<a name="ln2">//  This source code is licensed under the BSD-style license found in the</a>
<a name="ln3">//  LICENSE file in the root directory of this source tree. An additional grant</a>
<a name="ln4">//  of patent rights can be found in the PATENTS file in the same directory.</a>
<a name="ln5">//</a>
<a name="ln6">// The following only applies to changes made to this file as part of YugaByte development.</a>
<a name="ln7">//</a>
<a name="ln8">// Portions Copyright (c) YugaByte, Inc.</a>
<a name="ln9">//</a>
<a name="ln10">// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except</a>
<a name="ln11">// in compliance with the License.  You may obtain a copy of the License at</a>
<a name="ln12">//</a>
<a name="ln13">// http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="ln14">//</a>
<a name="ln15">// Unless required by applicable law or agreed to in writing, software distributed under the License</a>
<a name="ln16">// is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express</a>
<a name="ln17">// or implied.  See the License for the specific language governing permissions and limitations</a>
<a name="ln18">// under the License.</a>
<a name="ln19">//</a>
<a name="ln20">// Copyright (c) 2011 The LevelDB Authors. All rights reserved.</a>
<a name="ln21">// Use of this source code is governed by a BSD-style license that can be</a>
<a name="ln22">// found in the LICENSE file. See the AUTHORS file for names of contributors.</a>
<a name="ln23"> </a>
<a name="ln24">#include &quot;yb/rocksdb/db/version_edit.h&quot;</a>
<a name="ln25"> </a>
<a name="ln26">#include &quot;yb/rocksdb/db/version_edit.pb.h&quot;</a>
<a name="ln27">#include &quot;yb/rocksdb/db/version_set.h&quot;</a>
<a name="ln28">#include &quot;yb/rocksdb/metadata.h&quot;</a>
<a name="ln29">#include &quot;yb/rocksdb/util/coding.h&quot;</a>
<a name="ln30">#include &quot;yb/rocksdb/util/event_logger.h&quot;</a>
<a name="ln31">#include &quot;yb/rocksdb/util/sync_point.h&quot;</a>
<a name="ln32">#include &quot;yb/util/logging.h&quot;</a>
<a name="ln33">#include &quot;yb/util/slice.h&quot;</a>
<a name="ln34">#include &quot;yb/util/debug-util.h&quot;</a>
<a name="ln35">#include &quot;yb/util/flag_tags.h&quot;</a>
<a name="ln36"> </a>
<a name="ln37">DEFINE_bool(use_per_file_metadata_for_flushed_frontier, false,</a>
<a name="ln38">            &quot;Allows taking per-file metadata in version edits into account when computing the &quot;</a>
<a name="ln39">            &quot;flushed frontier.&quot;);</a>
<a name="ln40">TAG_FLAG(use_per_file_metadata_for_flushed_frontier, hidden);</a>
<a name="ln41">TAG_FLAG(use_per_file_metadata_for_flushed_frontier, advanced);</a>
<a name="ln42"> </a>
<a name="ln43">namespace rocksdb {</a>
<a name="ln44"> </a>
<a name="ln45">uint64_t PackFileNumberAndPathId(uint64_t number, uint64_t path_id) {</a>
<a name="ln46">  assert(number &lt;= kFileNumberMask);</a>
<a name="ln47">  return number | (path_id * (kFileNumberMask + 1));</a>
<a name="ln48">}</a>
<a name="ln49"> </a>
<a name="ln50">FileMetaData::FileMetaData()</a>
<a name="ln51">    : refs(0),</a>
<a name="ln52">    being_compacted(false),</a>
<a name="ln53">    table_reader_handle(nullptr),</a>
<a name="ln54">    compensated_file_size(0),</a>
<a name="ln55">    num_entries(0),</a>
<a name="ln56">    num_deletions(0),</a>
<a name="ln57">    raw_key_size(0),</a>
<a name="ln58">    raw_value_size(0),</a>
<a name="ln59">    init_stats_from_file(false),</a>
<a name="ln60">    marked_for_compaction(false) {</a>
<a name="ln61">  smallest.seqno = kMaxSequenceNumber;</a>
<a name="ln62">  largest.seqno = 0;</a>
<a name="ln63">}</a>
<a name="ln64"> </a>
<a name="ln65">void FileMetaData::UpdateBoundaries(InternalKey key, const FileBoundaryValuesBase&amp; source) {</a>
<a name="ln66">  largest.key = std::move(key);</a>
<a name="ln67">  if (smallest.key.empty()) {</a>
<a name="ln68">    smallest.key = largest.key;</a>
<a name="ln69">  }</a>
<a name="ln70">  UpdateBoundariesExceptKey(source, UpdateBoundariesType::kAll);</a>
<a name="ln71">}</a>
<a name="ln72"> </a>
<a name="ln73">bool FileMetaData::Unref(TableCache* table_cache) {</a>
<a name="ln74">  refs--;</a>
<a name="ln75">  if (refs &lt;= 0) {</a>
<a name="ln76">    if (table_reader_handle) {</a>
<a name="ln77">      DCHECK_ONLY_NOTNULL(table_cache);</a>
<a name="ln78">      table_cache-&gt;ReleaseHandle(table_reader_handle);</a>
<a name="ln79">      table_reader_handle = nullptr;</a>
<a name="ln80">    }</a>
<a name="ln81">    return true;</a>
<a name="ln82">  } else {</a>
<a name="ln83">    return false;</a>
<a name="ln84">  }</a>
<a name="ln85">}</a>
<a name="ln86"> </a>
<a name="ln87">void FileMetaData::UpdateBoundariesExceptKey(const FileBoundaryValuesBase&amp; source,</a>
<a name="ln88">                                             UpdateBoundariesType type) {</a>
<a name="ln89">  if (type != UpdateBoundariesType::kLargest) {</a>
<a name="ln90">    smallest.seqno = std::min(smallest.seqno, source.seqno);</a>
<a name="ln91">    UserFrontier::Update(</a>
<a name="ln92">        source.user_frontier.get(), UpdateUserValueType::kSmallest, &amp;smallest.user_frontier);</a>
<a name="ln93"> </a>
<a name="ln94">    for (const auto&amp; user_value : source.user_values) {</a>
<a name="ln95">      UpdateUserValue(&amp;smallest.user_values, user_value, UpdateUserValueType::kSmallest);</a>
<a name="ln96">    }</a>
<a name="ln97">  }</a>
<a name="ln98">  if (type != UpdateBoundariesType::kSmallest) {</a>
<a name="ln99">    largest.seqno = std::max(largest.seqno, source.seqno);</a>
<a name="ln100">    UserFrontier::Update(</a>
<a name="ln101">        source.user_frontier.get(), UpdateUserValueType::kLargest, &amp;largest.user_frontier);</a>
<a name="ln102"> </a>
<a name="ln103">    for (const auto&amp; user_value : source.user_values) {</a>
<a name="ln104">      UpdateUserValue(&amp;largest.user_values, user_value, UpdateUserValueType::kLargest);</a>
<a name="ln105">    }</a>
<a name="ln106">  }</a>
<a name="ln107">}</a>
<a name="ln108"> </a>
<a name="ln109">Slice FileMetaData::UserFilter() const {</a>
<a name="ln110">  return largest.user_frontier ? largest.user_frontier-&gt;Filter() : Slice();</a>
<a name="ln111">}</a>
<a name="ln112"> </a>
<a name="ln113">std::string FileMetaData::ToString() const {</a>
<a name="ln114">  return yb::Format(&quot;{ number: $0 total_size: $1 base_size: $2 refs: $3 &quot;</a>
<a name="ln115">                    &quot;being_compacted: $4 smallest: $5 largest: $6 }&quot;,</a>
<a name="ln116">                    fd.GetNumber(), fd.GetTotalFileSize(), fd.GetBaseFileSize(), refs,</a>
<a name="ln117">                    being_compacted, smallest, largest);</a>
<a name="ln118">}</a>
<a name="ln119"> </a>
<a name="ln120">void VersionEdit::Clear() {</a>
<a name="ln121">  comparator_.reset();</a>
<a name="ln122">  max_level_ = 0;</a>
<a name="ln123">  log_number_.reset();</a>
<a name="ln124">  prev_log_number_.reset();</a>
<a name="ln125">  last_sequence_.reset();</a>
<a name="ln126">  next_file_number_.reset();</a>
<a name="ln127">  max_column_family_.reset();</a>
<a name="ln128">  deleted_files_.clear();</a>
<a name="ln129">  new_files_.clear();</a>
<a name="ln130">  column_family_ = 0;</a>
<a name="ln131">  column_family_name_.reset();</a>
<a name="ln132">  is_column_family_drop_ = false;</a>
<a name="ln133">  flushed_frontier_.reset();</a>
<a name="ln134">}</a>
<a name="ln135"> </a>
<a name="ln136">void EncodeBoundaryValues(const FileBoundaryValues&lt;InternalKey&gt;&amp; values, BoundaryValuesPB* out) {</a>
<a name="ln137">  auto key = values.key.Encode();</a>
<a name="ln138">  out-&gt;set_key(key.data(), key.size());</a>
<a name="ln139">  out-&gt;set_seqno(values.seqno);</a>
<a name="ln140">  if (values.user_frontier) {</a>
<a name="ln141">    values.user_frontier-&gt;ToPB(out-&gt;mutable_user_frontier());</a>
<a name="ln142">  }</a>
<a name="ln143"> </a>
<a name="ln144">  for (const auto&amp; user_value : values.user_values) {</a>
<a name="ln145">    auto* value = out-&gt;add_user_values();</a>
<a name="ln146">    value-&gt;set_tag(user_value-&gt;Tag());</a>
<a name="ln147">    auto encoded_user_value = user_value-&gt;Encode();</a>
<a name="ln148">    value-&gt;set_data(encoded_user_value.data(), encoded_user_value.size());</a>
<a name="ln149">  }</a>
<a name="ln150">}</a>
<a name="ln151"> </a>
<a name="ln152">Status DecodeBoundaryValues(BoundaryValuesExtractor* extractor,</a>
<a name="ln153">                            const BoundaryValuesPB&amp; values,</a>
<a name="ln154">                            FileBoundaryValues&lt;InternalKey&gt;* out) {</a>
<a name="ln155">  out-&gt;key = InternalKey::DecodeFrom(values.key());</a>
<a name="ln156">  out-&gt;seqno = values.seqno();</a>
<a name="ln157">  if (extractor != nullptr) {</a>
<a name="ln158">    if (values.has_user_frontier()) {</a>
<a name="ln159">      out-&gt;user_frontier = extractor-&gt;CreateFrontier();</a>
<a name="ln160">      out-&gt;user_frontier-&gt;FromPB(values.user_frontier());</a>
<a name="ln161">    }</a>
<a name="ln162">    for (const auto &amp;user_value : values.user_values()) {</a>
<a name="ln163">      UserBoundaryValuePtr decoded;</a>
<a name="ln164">      auto status = extractor-&gt;Decode(user_value.tag(), user_value.data(), &amp;decoded);</a>
<a name="ln165">      if (!status.ok()) {</a>
<a name="ln166">        return status;</a>
<a name="ln167">      }</a>
<a name="ln168">      if (decoded) {</a>
<a name="ln169">        out-&gt;user_values.push_back(std::move(decoded));</a>
<a name="ln170">      }</a>
<a name="ln171">    }</a>
<a name="ln172">  } else if (values.has_user_frontier()) {</a>
<a name="ln173">    return STATUS_FORMAT(</a>
<a name="ln174">        IllegalState, &quot;Boundary values contains user frontier but extractor is not specified: $0&quot;,</a>
<a name="ln175">        values);</a>
<a name="ln176">  }</a>
<a name="ln177">  return Status::OK();</a>
<a name="ln178">}</a>
<a name="ln179"> </a>
<a name="ln180">bool VersionEdit::AppendEncodedTo(std::string* dst) const {</a>
<a name="ln181">  VersionEditPB pb;</a>
<a name="ln182">  auto result = EncodeTo(&amp;pb);</a>
<a name="ln183">  if (result) {</a>
<a name="ln184">    pb.AppendToString(dst);</a>
<a name="ln185">  }</a>
<a name="ln186">  return result;</a>
<a name="ln187">}</a>
<a name="ln188"> </a>
<a name="ln189">bool VersionEdit::EncodeTo(VersionEditPB* dst) const {</a>
<a name="ln190">  VersionEditPB&amp; pb = *dst;</a>
<a name="ln191">  if (comparator_) {</a>
<a name="ln192">    pb.set_comparator(*comparator_);</a>
<a name="ln193">  }</a>
<a name="ln194">  if (log_number_) {</a>
<a name="ln195">    pb.set_log_number(*log_number_);</a>
<a name="ln196">  }</a>
<a name="ln197">  if (prev_log_number_) {</a>
<a name="ln198">    pb.set_prev_log_number(*prev_log_number_);</a>
<a name="ln199">  }</a>
<a name="ln200">  if (next_file_number_) {</a>
<a name="ln201">    pb.set_next_file_number(*next_file_number_);</a>
<a name="ln202">  }</a>
<a name="ln203">  if (last_sequence_) {</a>
<a name="ln204">    pb.set_last_sequence(*last_sequence_);</a>
<a name="ln205">  }</a>
<a name="ln206">  if (flushed_frontier_) {</a>
<a name="ln207">    flushed_frontier_-&gt;ToPB(pb.mutable_flushed_frontier());</a>
<a name="ln208">  }</a>
<a name="ln209">  if (max_column_family_) {</a>
<a name="ln210">    pb.set_max_column_family(*max_column_family_);</a>
<a name="ln211">  }</a>
<a name="ln212"> </a>
<a name="ln213">  for (const auto&amp; deleted : deleted_files_) {</a>
<a name="ln214">    auto&amp; deleted_file = *pb.add_deleted_files();</a>
<a name="ln215">    deleted_file.set_level(deleted.first);</a>
<a name="ln216">    deleted_file.set_file_number(deleted.second);</a>
<a name="ln217">  }</a>
<a name="ln218"> </a>
<a name="ln219">  for (size_t i = 0; i &lt; new_files_.size(); i++) {</a>
<a name="ln220">    const FileMetaData&amp; f = new_files_[i].second;</a>
<a name="ln221">    if (!f.smallest.key.Valid() || !f.largest.key.Valid()) {</a>
<a name="ln222">      return false;</a>
<a name="ln223">    }</a>
<a name="ln224">    auto&amp; new_file = *pb.add_new_files();</a>
<a name="ln225">    new_file.set_level(new_files_[i].first);</a>
<a name="ln226">    new_file.set_number(f.fd.GetNumber());</a>
<a name="ln227">    new_file.set_total_file_size(f.fd.GetTotalFileSize());</a>
<a name="ln228">    new_file.set_base_file_size(f.fd.GetBaseFileSize());</a>
<a name="ln229">    EncodeBoundaryValues(f.smallest, new_file.mutable_smallest());</a>
<a name="ln230">    EncodeBoundaryValues(f.largest, new_file.mutable_largest());</a>
<a name="ln231">    if (f.fd.GetPathId() != 0) {</a>
<a name="ln232">      new_file.set_path_id(f.fd.GetPathId());</a>
<a name="ln233">    }</a>
<a name="ln234">    if (f.marked_for_compaction) {</a>
<a name="ln235">      new_file.set_marked_for_compaction(true);</a>
<a name="ln236">    }</a>
<a name="ln237">    if (f.imported) {</a>
<a name="ln238">      new_file.set_imported(true);</a>
<a name="ln239">    }</a>
<a name="ln240">  }</a>
<a name="ln241"> </a>
<a name="ln242">  // 0 is default and does not need to be explicitly written</a>
<a name="ln243">  if (column_family_ != 0) {</a>
<a name="ln244">    pb.set_column_family(column_family_);</a>
<a name="ln245">  }</a>
<a name="ln246"> </a>
<a name="ln247">  if (column_family_name_) {</a>
<a name="ln248">    pb.set_column_family_name(*column_family_name_);</a>
<a name="ln249">  }</a>
<a name="ln250"> </a>
<a name="ln251">  if (is_column_family_drop_) {</a>
<a name="ln252">    pb.set_is_column_family_drop(true);</a>
<a name="ln253">  }</a>
<a name="ln254"> </a>
<a name="ln255">  return true;</a>
<a name="ln256">}</a>
<a name="ln257"> </a>
<a name="ln258">Status VersionEdit::DecodeFrom(BoundaryValuesExtractor* extractor, const Slice&amp; src) {</a>
<a name="ln259">  Clear();</a>
<a name="ln260">  VersionEditPB pb;</a>
<a name="ln261">  if (!pb.ParseFromArray(src.data(), static_cast&lt;int&gt;(src.size()))) {</a>
<a name="ln262">    return STATUS(Corruption, &quot;VersionEdit&quot;);</a>
<a name="ln263">  }</a>
<a name="ln264"> </a>
<a name="ln265">  VLOG(1) &lt;&lt; &quot;Parsed version edit: &quot; &lt;&lt; pb.ShortDebugString();</a>
<a name="ln266"> </a>
<a name="ln267">  if (pb.has_comparator()) {</a>
<a name="ln268">    comparator_ = std::move(*pb.mutable_comparator());</a>
<a name="ln269">  }</a>
<a name="ln270">  if (pb.has_log_number()) {</a>
<a name="ln271">    log_number_ = pb.log_number();</a>
<a name="ln272">  }</a>
<a name="ln273">  if (pb.has_prev_log_number()) {</a>
<a name="ln274">    prev_log_number_ = pb.prev_log_number();</a>
<a name="ln275">  }</a>
<a name="ln276">  if (pb.has_next_file_number()) {</a>
<a name="ln277">    next_file_number_ = pb.next_file_number();</a>
<a name="ln278">  }</a>
<a name="ln279">  if (pb.has_last_sequence()) {</a>
<a name="ln280">    last_sequence_ = pb.last_sequence();</a>
<a name="ln281">  }</a>
<a name="ln282">  if (extractor) {</a>
<a name="ln283">    // BoundaryValuesExtractor could be not set when running from internal RocksDB tools.</a>
<a name="ln284">    if (pb.has_obsolete_last_op_id()) {</a>
<a name="ln285">      flushed_frontier_ = extractor-&gt;CreateFrontier();</a>
<a name="ln286">      flushed_frontier_-&gt;FromOpIdPBDeprecated(pb.obsolete_last_op_id());</a>
<a name="ln287">    }</a>
<a name="ln288">    if (pb.has_flushed_frontier()) {</a>
<a name="ln289">      flushed_frontier_ = extractor-&gt;CreateFrontier();</a>
<a name="ln290">      flushed_frontier_-&gt;FromPB(pb.flushed_frontier());</a>
<a name="ln291">    }</a>
<a name="ln292">  }</a>
<a name="ln293">  if (pb.has_max_column_family()) {</a>
<a name="ln294">    max_column_family_ = pb.max_column_family();</a>
<a name="ln295">  }</a>
<a name="ln296"> </a>
<a name="ln297">  for (const auto&amp; deleted : pb.deleted_files()) {</a>
<a name="ln298">    deleted_files_.emplace(deleted.level(), deleted.file_number());</a>
<a name="ln299">  }</a>
<a name="ln300"> </a>
<a name="ln301">  const size_t new_files_size = static_cast&lt;size_t&gt;(pb.new_files_size());</a>
<a name="ln302">  new_files_.resize(new_files_size);</a>
<a name="ln303"> </a>
<a name="ln304">  for (size_t i = 0; i &lt; new_files_size; ++i) {</a>
<a name="ln305">    auto&amp; source = pb.new_files(static_cast&lt;int&gt;(i));</a>
<a name="ln306">    int level = source.level();</a>
<a name="ln307">    new_files_[i].first = level;</a>
<a name="ln308">    auto&amp; meta = new_files_[i].second;</a>
<a name="ln309">    meta.fd = FileDescriptor(source.number(),</a>
<a name="ln310">                             source.path_id(),</a>
<a name="ln311">                             source.total_file_size(),</a>
<a name="ln312">                             source.base_file_size());</a>
<a name="ln313">    if (source.has_obsolete_last_op_id() &amp;&amp; extractor) {</a>
<a name="ln314">      meta.largest.user_frontier = extractor-&gt;CreateFrontier();</a>
<a name="ln315">      meta.largest.user_frontier-&gt;FromOpIdPBDeprecated(source.obsolete_last_op_id());</a>
<a name="ln316">    }</a>
<a name="ln317">    auto status = DecodeBoundaryValues(extractor, source.smallest(), &amp;meta.smallest);</a>
<a name="ln318">    if (!status.ok()) {</a>
<a name="ln319">      return status;</a>
<a name="ln320">    }</a>
<a name="ln321">    status = DecodeBoundaryValues(extractor, source.largest(), &amp;meta.largest);</a>
<a name="ln322">    if (!status.ok()) {</a>
<a name="ln323">      return status;</a>
<a name="ln324">    }</a>
<a name="ln325">    meta.marked_for_compaction = source.marked_for_compaction();</a>
<a name="ln326">    max_level_ = std::max(max_level_, level);</a>
<a name="ln327">    meta.imported = source.imported();</a>
<a name="ln328"> </a>
<a name="ln329">    // Use the relevant fields in the &quot;largest&quot; frontier to update the &quot;flushed&quot; frontier for this</a>
<a name="ln330">    // version edit. In practice this will only look at OpId and will discard hybrid time and</a>
<a name="ln331">    // history cutoff (which probably won't be there anyway) coming from the boundary values.</a>
<a name="ln332">    //</a>
<a name="ln333">    // This is enabled only if --use_per_file_metadata_for_flushed_frontier is specified, until we</a>
<a name="ln334">    // know that we don't have any clusters with wrong per-file flushed frontier metadata in version</a>
<a name="ln335">    // edits, such as that restored from old backups from unrelated clusters.</a>
<a name="ln336">    if (FLAGS_use_per_file_metadata_for_flushed_frontier &amp;&amp; meta.largest.user_frontier) {</a>
<a name="ln337">      if (!flushed_frontier_) {</a>
<a name="ln338">        LOG(DFATAL) &lt;&lt; &quot;Flushed frontier not present but a file's largest user frontier present: &quot;</a>
<a name="ln339">                    &lt;&lt; meta.largest.user_frontier-&gt;ToString()</a>
<a name="ln340">                    &lt;&lt; &quot;, version edit protobuf:\n&quot; &lt;&lt; pb.DebugString();</a>
<a name="ln341">      } else if (!flushed_frontier_-&gt;Dominates(*meta.largest.user_frontier,</a>
<a name="ln342">                                               UpdateUserValueType::kLargest)) {</a>
<a name="ln343">        // The flushed frontier of this VersionEdit must already include the information provided</a>
<a name="ln344">        // by flushed frontiers of individual files.</a>
<a name="ln345">        LOG(DFATAL) &lt;&lt; &quot;Flushed frontier is present but has to be updated with data from &quot;</a>
<a name="ln346">                    &lt;&lt; &quot;file boundary: flushed_frontier=&quot; &lt;&lt; flushed_frontier_-&gt;ToString()</a>
<a name="ln347">                    &lt;&lt; &quot;, a file's larget user frontier: &quot;</a>
<a name="ln348">                    &lt;&lt; meta.largest.user_frontier-&gt;ToString()</a>
<a name="ln349">                    &lt;&lt; &quot;, version edit protobuf:\n&quot; &lt;&lt; pb.DebugString();</a>
<a name="ln350">      }</a>
<a name="ln351">      UpdateUserFrontier(</a>
<a name="ln352">          &amp;flushed_frontier_, meta.largest.user_frontier, UpdateUserValueType::kLargest);</a>
<a name="ln353">    }</a>
<a name="ln354">  }</a>
<a name="ln355"> </a>
<a name="ln356">  column_family_ = pb.column_family();</a>
<a name="ln357"> </a>
<a name="ln358">  if (!pb.column_family_name().empty()) {</a>
<a name="ln359">    column_family_name_ = pb.column_family_name();</a>
<a name="ln360">  }</a>
<a name="ln361"> </a>
<a name="ln362">  is_column_family_drop_ = pb.is_column_family_drop();</a>
<a name="ln363"> </a>
<a name="ln364">  return Status();</a>
<a name="ln365">}</a>
<a name="ln366"> </a>
<a name="ln367">std::string VersionEdit::DebugString(bool hex_key) const {</a>
<a name="ln368">  VersionEditPB pb;</a>
<a name="ln369">  EncodeTo(&amp;pb);</a>
<a name="ln370">  return pb.DebugString();</a>
<a name="ln371">}</a>
<a name="ln372"> </a>
<a name="ln373">void VersionEdit::InitNewDB() {</a>
<a name="ln374">  log_number_ = 0;</a>
<a name="ln375">  next_file_number_ = VersionSet::kInitialNextFileNumber;</a>
<a name="ln376">  last_sequence_ = 0;</a>
<a name="ln377">  flushed_frontier_.reset();</a>
<a name="ln378">}</a>
<a name="ln379"> </a>
<a name="ln380">void VersionEdit::UpdateFlushedFrontier(UserFrontierPtr value) {</a>
<a name="ln381">  ModifyFlushedFrontier(std::move(value), FrontierModificationMode::kUpdate);</a>
<a name="ln382">}</a>
<a name="ln383"> </a>
<a name="ln384">void VersionEdit::ModifyFlushedFrontier(UserFrontierPtr value, FrontierModificationMode mode) {</a>
<a name="ln385">  if (mode == FrontierModificationMode::kForce) {</a>
<a name="ln386">    flushed_frontier_ = std::move(value);</a>
<a name="ln387">    force_flushed_frontier_ = true;</a>
<a name="ln388">  } else {</a>
<a name="ln389">    UpdateUserFrontier(&amp;flushed_frontier_, std::move(value), UpdateUserValueType::kLargest);</a>
<a name="ln390">  }</a>
<a name="ln391">}</a>
<a name="ln392"> </a>
<a name="ln393">std::string FileDescriptor::ToString() const {</a>
<a name="ln394">  return yb::Format(&quot;{ number: $0 path_id: $1 total_file_size: $2 base_file_size: $3 }&quot;,</a>
<a name="ln395">                    GetNumber(), GetPathId(), total_file_size, base_file_size);</a>
<a name="ln396">}</a>
<a name="ln397"> </a>
<a name="ln398">}  // namespace rocksdb</a>

</code></pre>
<div class="balloon" rel="265"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
