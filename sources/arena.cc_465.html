
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
  <title>arena.cc</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">//  Copyright (c) 2011-present, Facebook, Inc.  All rights reserved.</a>
<a name="ln2">//  This source code is licensed under the BSD-style license found in the</a>
<a name="ln3">//  LICENSE file in the root directory of this source tree. An additional grant</a>
<a name="ln4">//  of patent rights can be found in the PATENTS file in the same directory.</a>
<a name="ln5">//</a>
<a name="ln6">// The following only applies to changes made to this file as part of YugaByte development.</a>
<a name="ln7">//</a>
<a name="ln8">// Portions Copyright (c) YugaByte, Inc.</a>
<a name="ln9">//</a>
<a name="ln10">// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except</a>
<a name="ln11">// in compliance with the License.  You may obtain a copy of the License at</a>
<a name="ln12">//</a>
<a name="ln13">// http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="ln14">//</a>
<a name="ln15">// Unless required by applicable law or agreed to in writing, software distributed under the License</a>
<a name="ln16">// is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express</a>
<a name="ln17">// or implied.  See the License for the specific language governing permissions and limitations</a>
<a name="ln18">// under the License.</a>
<a name="ln19">//</a>
<a name="ln20">// Copyright (c) 2011 The LevelDB Authors. All rights reserved.</a>
<a name="ln21">// Use of this source code is governed by a BSD-style license that can be</a>
<a name="ln22">// found in the LICENSE file. See the AUTHORS file for names of contributors.</a>
<a name="ln23"> </a>
<a name="ln24">#include &quot;yb/rocksdb/util/arena.h&quot;</a>
<a name="ln25"> </a>
<a name="ln26">#include &lt;algorithm&gt;</a>
<a name="ln27"> </a>
<a name="ln28">#ifdef ROCKSDB_MALLOC_USABLE_SIZE</a>
<a name="ln29">#include &lt;malloc.h&gt;</a>
<a name="ln30">#endif</a>
<a name="ln31">#ifndef OS_WIN</a>
<a name="ln32">#include &lt;sys/mman.h&gt;</a>
<a name="ln33">#endif</a>
<a name="ln34"> </a>
<a name="ln35">#include &quot;yb/rocksdb/port/port.h&quot;</a>
<a name="ln36">#include &quot;yb/rocksdb/env.h&quot;</a>
<a name="ln37"> </a>
<a name="ln38">#include &quot;yb/util/mem_tracker.h&quot;</a>
<a name="ln39"> </a>
<a name="ln40">namespace rocksdb {</a>
<a name="ln41"> </a>
<a name="ln42">// MSVC complains that it is already defined since it is static in the header.</a>
<a name="ln43">#ifndef OS_WIN</a>
<a name="ln44">const size_t Arena::kInlineSize;</a>
<a name="ln45">#endif</a>
<a name="ln46"> </a>
<a name="ln47">const size_t Arena::kMinBlockSize = 4096;</a>
<a name="ln48">const size_t Arena::kMaxBlockSize = 2 &lt;&lt; 30;</a>
<a name="ln49">static const int kAlignUnit = sizeof(void*);</a>
<a name="ln50"> </a>
<a name="ln51">size_t OptimizeBlockSize(size_t block_size) {</a>
<a name="ln52">  // Make sure block_size is in optimal range</a>
<a name="ln53">  block_size = std::max(Arena::kMinBlockSize, block_size);</a>
<a name="ln54">  block_size = std::min(Arena::kMaxBlockSize, block_size);</a>
<a name="ln55"> </a>
<a name="ln56">  // make sure block_size is the multiple of kAlignUnit</a>
<a name="ln57">  if (block_size % kAlignUnit != 0) {</a>
<a name="ln58">    block_size = (1 + block_size / kAlignUnit) * kAlignUnit;</a>
<a name="ln59">  }</a>
<a name="ln60"> </a>
<a name="ln61">  return block_size;</a>
<a name="ln62">}</a>
<a name="ln63"> </a>
<a name="ln64">Arena::Arena(size_t block_size, size_t huge_page_size)</a>
<a name="ln65">    : kBlockSize(OptimizeBlockSize(block_size)) {</a>
<a name="ln66">  assert(kBlockSize &gt;= kMinBlockSize &amp;&amp; kBlockSize &lt;= kMaxBlockSize &amp;&amp;</a>
<a name="ln67">         kBlockSize % kAlignUnit == 0);</a>
<a name="ln68">  alloc_bytes_remaining_ = sizeof(inline_block_);</a>
<a name="ln69">  blocks_memory_ += alloc_bytes_remaining_;</a>
<a name="ln70">  aligned_alloc_ptr_ = inline_block_;</a>
<a name="ln71">  unaligned_alloc_ptr_ = inline_block_ + alloc_bytes_remaining_;</a>
<a name="ln72">#ifdef MAP_HUGETLB</a>
<a name="ln73">  hugetlb_size_ = huge_page_size;</a>
<a name="ln74">  if (hugetlb_size_ &amp;&amp; kBlockSize &gt; hugetlb_size_) {</a>
<a name="ln75">    hugetlb_size_ = ((kBlockSize - 1U) / hugetlb_size_ + 1U) * hugetlb_size_;</a>
<a name="ln76">  }</a>
<a name="ln77">#endif</a>
<a name="ln78">}</a>
<a name="ln79"> </a>
<a name="ln80">Arena::~Arena() {</a>
<a name="ln81">  for (const auto&amp; block : blocks_) {</a>
<a name="ln82">    delete[] block;</a>
<a name="ln83">  }</a>
<a name="ln84"> </a>
<a name="ln85">#ifdef MAP_HUGETLB</a>
<a name="ln86">  for (const auto&amp; mmap_info : huge_blocks_) {</a>
<a name="ln87">    auto ret = munmap(mmap_info.addr_, mmap_info.length_);</a>
<a name="ln88">    if (ret != 0) {</a>
<a name="ln89">      // TODO(sdong): Better handling</a>
<a name="ln90">    }</a>
<a name="ln91">  }</a>
<a name="ln92">#endif</a>
<a name="ln93"> </a>
<a name="ln94">  if (mem_tracker_) {</a>
<a name="ln95">    mem_tracker_-&gt;Release(blocks_memory_);</a>
<a name="ln96">  }</a>
<a name="ln97">}</a>
<a name="ln98"> </a>
<a name="ln99">char* Arena::AllocateFallback(size_t bytes, bool aligned) {</a>
<a name="ln100">  if (bytes &gt; kBlockSize / 4) {</a>
<a name="ln101">    ++irregular_block_num;</a>
<a name="ln102">    // Object is more than a quarter of our block size.  Allocate it separately</a>
<a name="ln103">    // to avoid wasting too much space in leftover bytes.</a>
<a name="ln104">    return AllocateNewBlock(bytes);</a>
<a name="ln105">  }</a>
<a name="ln106"> </a>
<a name="ln107">  // We waste the remaining space in the current block.</a>
<a name="ln108">  size_t size = 0;</a>
<a name="ln109">  char* block_head = nullptr;</a>
<a name="ln110">#ifdef MAP_HUGETLB</a>
<a name="ln111">  if (hugetlb_size_) {</a>
<a name="ln112">    size = hugetlb_size_;</a>
<a name="ln113">    block_head = AllocateFromHugePage(size);</a>
<a name="ln114">  }</a>
<a name="ln115">#endif</a>
<a name="ln116">  if (!block_head) {</a>
<a name="ln117">    size = kBlockSize;</a>
<a name="ln118">    block_head = AllocateNewBlock(size);</a>
<a name="ln119">  }</a>
<a name="ln120">  alloc_bytes_remaining_ = size - bytes;</a>
<a name="ln121"> </a>
<a name="ln122">  if (aligned) {</a>
<a name="ln123">    aligned_alloc_ptr_ = block_head + bytes;</a>
<a name="ln124">    unaligned_alloc_ptr_ = block_head + size;</a>
<a name="ln125">    return block_head;</a>
<a name="ln126">  } else {</a>
<a name="ln127">    aligned_alloc_ptr_ = block_head;</a>
<a name="ln128">    unaligned_alloc_ptr_ = block_head + size - bytes;</a>
<a name="ln129">    return unaligned_alloc_ptr_;</a>
<a name="ln130">  }</a>
<a name="ln131">}</a>
<a name="ln132"> </a>
<a name="ln133">char* Arena::AllocateFromHugePage(size_t bytes) {</a>
<a name="ln134">#ifdef MAP_HUGETLB</a>
<a name="ln135">  if (hugetlb_size_ == 0) {</a>
<a name="ln136">    return nullptr;</a>
<a name="ln137">  }</a>
<a name="ln138">  // already reserve space in huge_blocks_ before calling mmap().</a>
<a name="ln139">  // this way the insertion into the vector below will not throw and we</a>
<a name="ln140">  // won't leak the mapping in that case. if reserve() throws, we</a>
<a name="ln141">  // won't leak either</a>
<a name="ln142">  huge_blocks_.reserve(huge_blocks_.size() + 1);</a>
<a name="ln143"> </a>
<a name="ln144">  void* addr = mmap(nullptr, bytes, (PROT_READ | PROT_WRITE),</a>
<a name="ln145">                    (MAP_PRIVATE | MAP_ANONYMOUS | MAP_HUGETLB), 0, 0);</a>
<a name="ln146"> </a>
<a name="ln147">  if (addr == MAP_FAILED) {</a>
<a name="ln148">    return nullptr;</a>
<a name="ln149">  }</a>
<a name="ln150">  // the following shouldn't throw because of the above reserve()</a>
<a name="ln151">  huge_blocks_.emplace_back(MmapInfo(addr, bytes));</a>
<a name="ln152">  return reinterpret_cast&lt;char*&gt;(addr);</a>
<a name="ln153">#else</a>
<a name="ln154">  return nullptr;</a>
<a name="ln155">#endif</a>
<a name="ln156">}</a>
<a name="ln157"> </a>
<a name="ln158">char* Arena::AllocateAligned(size_t bytes, size_t huge_page_size,</a>
<a name="ln159">                             Logger* logger) {</a>
<a name="ln160">  assert((kAlignUnit &amp; (kAlignUnit - 1)) ==</a>
<a name="ln161">         0);  // Pointer size should be a power of 2</a>
<a name="ln162"> </a>
<a name="ln163">#ifdef MAP_HUGETLB</a>
<a name="ln164">  if (huge_page_size &gt; 0 &amp;&amp; bytes &gt; 0) {</a>
<a name="ln165">    // Allocate from a huge page TBL table.</a>
<a name="ln166">    assert(logger != nullptr);  // logger need to be passed in.</a>
<a name="ln167">    size_t reserved_size =</a>
<a name="ln168">        ((bytes - 1U) / huge_page_size + 1U) * huge_page_size;</a>
<a name="ln169">    assert(reserved_size &gt;= bytes);</a>
<a name="ln170"> </a>
<a name="ln171">    char* addr = AllocateFromHugePage(reserved_size);</a>
<a name="ln172">    if (addr == nullptr) {</a>
<a name="ln173">      RWARN(logger, &quot;AllocateAligned fail to allocate huge TLB pages: %s&quot;,</a>
<a name="ln174">           strerror(errno));</a>
<a name="ln175">      // fail back to malloc</a>
<a name="ln176">    } else {</a>
<a name="ln177">      return addr;</a>
<a name="ln178">    }</a>
<a name="ln179">  }</a>
<a name="ln180">#endif</a>
<a name="ln181"> </a>
<a name="ln182">  size_t current_mod =</a>
<a name="ln183">      reinterpret_cast&lt;uintptr_t&gt;(aligned_alloc_ptr_) &amp; (kAlignUnit - 1);</a>
<a name="ln184">  size_t slop = (current_mod == 0 ? 0 : kAlignUnit - current_mod);</a>
<a name="ln185">  size_t needed = bytes + slop;</a>
<a name="ln186">  char* result;</a>
<a name="ln187">  if (needed &lt;= alloc_bytes_remaining_) {</a>
<a name="ln188">    result = aligned_alloc_ptr_ + slop;</a>
<a name="ln189">    aligned_alloc_ptr_ += needed;</a>
<a name="ln190">    alloc_bytes_remaining_ -= needed;</a>
<a name="ln191">  } else {</a>
<a name="ln192">    // AllocateFallback always returns aligned memory</a>
<a name="ln193">    result = AllocateFallback(bytes, true /* aligned */);</a>
<a name="ln194">  }</a>
<a name="ln195">  assert((reinterpret_cast&lt;uintptr_t&gt;(result) &amp; (kAlignUnit - 1)) == 0);</a>
<a name="ln196">  return result;</a>
<a name="ln197">}</a>
<a name="ln198"> </a>
<a name="ln199">char* Arena::AllocateNewBlock(size_t block_bytes) {</a>
<a name="ln200">  // already reserve space in blocks_ before allocating memory via new.</a>
<a name="ln201">  // this way the insertion into the vector below will not throw and we</a>
<a name="ln202">  // won't leak the allocated memory in that case. if reserve() throws,</a>
<a name="ln203">  // we won't leak either</a>
<a name="ln204">  blocks_.reserve(blocks_.size() + 1);</a>
<a name="ln205"> </a>
<a name="ln206">  char* block = new char[block_bytes];</a>
<a name="ln207"> </a>
<a name="ln208">#ifdef ROCKSDB_MALLOC_USABLE_SIZE</a>
<a name="ln209">  Consumed(malloc_usable_size(block));</a>
<a name="ln210">#else</a>
<a name="ln211">  Consumed(block_bytes);</a>
<a name="ln212">#endif  // ROCKSDB_MALLOC_USABLE_SIZE</a>
<a name="ln213">  // the following shouldn't throw because of the above reserve()</a>
<a name="ln214">  blocks_.push_back(block);</a>
<a name="ln215">  return block;</a>
<a name="ln216">}</a>
<a name="ln217"> </a>
<a name="ln218">void Arena::Consumed(size_t size) {</a>
<a name="ln219">  blocks_memory_ += size;</a>
<a name="ln220">  if (mem_tracker_) {</a>
<a name="ln221">    mem_tracker_-&gt;Consume(size);</a>
<a name="ln222">  }</a>
<a name="ln223">}</a>
<a name="ln224"> </a>
<a name="ln225">void Arena::SetMemTracker(yb::MemTrackerPtr mem_tracker) {</a>
<a name="ln226">  mem_tracker_ = std::move(mem_tracker);</a>
<a name="ln227">  mem_tracker_-&gt;Consume(blocks_memory_);</a>
<a name="ln228">}</a>
<a name="ln229"> </a>
<a name="ln230">}  // namespace rocksdb</a>

</code></pre>
<div class="balloon" rel="64"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v730/" target="_blank">V730</a> Not all members of a class are initialized inside the constructor. Consider inspecting: inline_block_.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
