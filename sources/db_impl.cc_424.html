
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
  <title>db_impl.cc</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">//  Copyright (c) 2011-present, Facebook, Inc.  All rights reserved.</a>
<a name="ln2">//  This source code is licensed under the BSD-style license found in the</a>
<a name="ln3">//  LICENSE file in the root directory of this source tree. An additional grant</a>
<a name="ln4">//  of patent rights can be found in the PATENTS file in the same directory.</a>
<a name="ln5">//</a>
<a name="ln6">// The following only applies to changes made to this file as part of YugaByte development.</a>
<a name="ln7">//</a>
<a name="ln8">// Portions Copyright (c) YugaByte, Inc.</a>
<a name="ln9">//</a>
<a name="ln10">// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except</a>
<a name="ln11">// in compliance with the License.  You may obtain a copy of the License at</a>
<a name="ln12">//</a>
<a name="ln13">// http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="ln14">//</a>
<a name="ln15">// Unless required by applicable law or agreed to in writing, software distributed under the License</a>
<a name="ln16">// is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express</a>
<a name="ln17">// or implied.  See the License for the specific language governing permissions and limitations</a>
<a name="ln18">// under the License.</a>
<a name="ln19">//</a>
<a name="ln20">// Copyright (c) 2011 The LevelDB Authors. All rights reserved.</a>
<a name="ln21">// Use of this source code is governed by a BSD-style license that can be</a>
<a name="ln22">// found in the LICENSE file. See the AUTHORS file for names of contributors.</a>
<a name="ln23"> </a>
<a name="ln24">#include &quot;yb/rocksdb/db/db_impl.h&quot;</a>
<a name="ln25"> </a>
<a name="ln26">#ifndef __STDC_FORMAT_MACROS</a>
<a name="ln27">#define __STDC_FORMAT_MACROS</a>
<a name="ln28">#endif</a>
<a name="ln29"> </a>
<a name="ln30">#include &lt;inttypes.h&gt;</a>
<a name="ln31">#include &lt;stdint.h&gt;</a>
<a name="ln32">#ifdef OS_SOLARIS</a>
<a name="ln33">#include &lt;alloca.h&gt;</a>
<a name="ln34">#endif</a>
<a name="ln35"> </a>
<a name="ln36">#include &lt;algorithm&gt;</a>
<a name="ln37">#include &lt;climits&gt;</a>
<a name="ln38">#include &lt;cstdio&gt;</a>
<a name="ln39">#include &lt;map&gt;</a>
<a name="ln40">#include &lt;set&gt;</a>
<a name="ln41">#include &lt;stdexcept&gt;</a>
<a name="ln42">#include &lt;string&gt;</a>
<a name="ln43">#include &lt;unordered_map&gt;</a>
<a name="ln44">#include &lt;unordered_set&gt;</a>
<a name="ln45">#include &lt;utility&gt;</a>
<a name="ln46">#include &lt;vector&gt;</a>
<a name="ln47"> </a>
<a name="ln48">#include &lt;boost/container/small_vector.hpp&gt;</a>
<a name="ln49"> </a>
<a name="ln50">#include &lt;gflags/gflags.h&gt;</a>
<a name="ln51"> </a>
<a name="ln52">#include &quot;yb/gutil/stringprintf.h&quot;</a>
<a name="ln53">#include &quot;yb/util/string_util.h&quot;</a>
<a name="ln54">#include &quot;yb/util/logging.h&quot;</a>
<a name="ln55">#include &quot;yb/util/debug-util.h&quot;</a>
<a name="ln56">#include &quot;yb/util/fault_injection.h&quot;</a>
<a name="ln57">#include &quot;yb/util/flag_tags.h&quot;</a>
<a name="ln58">#include &quot;yb/util/priority_thread_pool.h&quot;</a>
<a name="ln59">#include &quot;yb/util/atomic.h&quot;</a>
<a name="ln60"> </a>
<a name="ln61">#include &quot;yb/rocksdb/db/auto_roll_logger.h&quot;</a>
<a name="ln62">#include &quot;yb/rocksdb/db/builder.h&quot;</a>
<a name="ln63">#include &quot;yb/rocksdb/db/compaction_job.h&quot;</a>
<a name="ln64">#include &quot;yb/rocksdb/db/db_info_dumper.h&quot;</a>
<a name="ln65">#include &quot;yb/rocksdb/db/db_iter.h&quot;</a>
<a name="ln66">#include &quot;yb/rocksdb/db/dbformat.h&quot;</a>
<a name="ln67">#include &quot;yb/rocksdb/db/event_helpers.h&quot;</a>
<a name="ln68">#include &quot;yb/rocksdb/db/filename.h&quot;</a>
<a name="ln69">#include &quot;yb/rocksdb/db/file_numbers.h&quot;</a>
<a name="ln70">#include &quot;yb/rocksdb/db/flush_job.h&quot;</a>
<a name="ln71">#include &quot;yb/rocksdb/db/forward_iterator.h&quot;</a>
<a name="ln72">#include &quot;yb/rocksdb/db/job_context.h&quot;</a>
<a name="ln73">#include &quot;yb/rocksdb/db/log_reader.h&quot;</a>
<a name="ln74">#include &quot;yb/rocksdb/db/log_writer.h&quot;</a>
<a name="ln75">#include &quot;yb/rocksdb/db/managed_iterator.h&quot;</a>
<a name="ln76">#include &quot;yb/rocksdb/db/memtable.h&quot;</a>
<a name="ln77">#include &quot;yb/rocksdb/db/memtable_list.h&quot;</a>
<a name="ln78">#include &quot;yb/rocksdb/db/merge_context.h&quot;</a>
<a name="ln79">#include &quot;yb/rocksdb/db/merge_helper.h&quot;</a>
<a name="ln80">#include &quot;yb/rocksdb/db/table_cache.h&quot;</a>
<a name="ln81">#include &quot;yb/rocksdb/db/table_properties_collector.h&quot;</a>
<a name="ln82">#include &quot;yb/rocksdb/db/transaction_log_impl.h&quot;</a>
<a name="ln83">#include &quot;yb/rocksdb/db/version_set.h&quot;</a>
<a name="ln84">#include &quot;yb/rocksdb/db/write_batch_internal.h&quot;</a>
<a name="ln85">#include &quot;yb/rocksdb/db/write_callback.h&quot;</a>
<a name="ln86">#include &quot;yb/rocksdb/db/writebuffer.h&quot;</a>
<a name="ln87">#include &quot;yb/rocksdb/db/xfunc_test_points.h&quot;</a>
<a name="ln88">#include &quot;yb/rocksdb/memtable/hash_linklist_rep.h&quot;</a>
<a name="ln89">#include &quot;yb/rocksdb/memtable/hash_skiplist_rep.h&quot;</a>
<a name="ln90">#include &quot;yb/rocksdb/port/likely.h&quot;</a>
<a name="ln91">#include &quot;yb/rocksdb/port/port.h&quot;</a>
<a name="ln92">#include &quot;yb/rocksdb/cache.h&quot;</a>
<a name="ln93">#include &quot;yb/rocksdb/compaction_filter.h&quot;</a>
<a name="ln94">#include &quot;yb/rocksdb/db.h&quot;</a>
<a name="ln95">#include &quot;yb/rocksdb/env.h&quot;</a>
<a name="ln96">#include &quot;yb/rocksdb/merge_operator.h&quot;</a>
<a name="ln97">#include &quot;yb/rocksdb/sst_file_writer.h&quot;</a>
<a name="ln98">#include &quot;yb/rocksdb/statistics.h&quot;</a>
<a name="ln99">#include &quot;yb/rocksdb/status.h&quot;</a>
<a name="ln100">#include &quot;yb/rocksdb/table.h&quot;</a>
<a name="ln101">#include &quot;yb/rocksdb/wal_filter.h&quot;</a>
<a name="ln102">#include &quot;yb/rocksdb/table/block.h&quot;</a>
<a name="ln103">#include &quot;yb/rocksdb/table/block_based_table_factory.h&quot;</a>
<a name="ln104">#include &quot;yb/rocksdb/table/merger.h&quot;</a>
<a name="ln105">#include &quot;yb/rocksdb/table/table_builder.h&quot;</a>
<a name="ln106">#include &quot;yb/rocksdb/table/two_level_iterator.h&quot;</a>
<a name="ln107">#include &quot;yb/rocksdb/util/autovector.h&quot;</a>
<a name="ln108">#include &quot;yb/rocksdb/util/coding.h&quot;</a>
<a name="ln109">#include &quot;yb/rocksdb/util/compression.h&quot;</a>
<a name="ln110">#include &quot;yb/rocksdb/util/crc32c.h&quot;</a>
<a name="ln111">#include &quot;yb/rocksdb/util/file_reader_writer.h&quot;</a>
<a name="ln112">#include &quot;yb/rocksdb/util/file_util.h&quot;</a>
<a name="ln113">#include &quot;yb/rocksdb/util/log_buffer.h&quot;</a>
<a name="ln114">#include &quot;yb/rocksdb/util/logging.h&quot;</a>
<a name="ln115">#include &quot;yb/rocksdb/util/mutexlock.h&quot;</a>
<a name="ln116">#include &quot;yb/rocksdb/util/sst_file_manager_impl.h&quot;</a>
<a name="ln117">#include &quot;yb/rocksdb/util/options_helper.h&quot;</a>
<a name="ln118">#include &quot;yb/rocksdb/util/options_parser.h&quot;</a>
<a name="ln119">#include &quot;yb/rocksdb/util/perf_context_imp.h&quot;</a>
<a name="ln120">#include &quot;yb/rocksdb/util/stop_watch.h&quot;</a>
<a name="ln121">#include &quot;yb/rocksdb/util/sync_point.h&quot;</a>
<a name="ln122">#include &quot;yb/rocksdb/util/thread_status_updater.h&quot;</a>
<a name="ln123">#include &quot;yb/rocksdb/util/thread_status_util.h&quot;</a>
<a name="ln124">#include &quot;yb/rocksdb/util/xfunc.h&quot;</a>
<a name="ln125">#include &quot;yb/rocksdb/db/db_iterator_wrapper.h&quot;</a>
<a name="ln126"> </a>
<a name="ln127">#include &quot;yb/util/stats/iostats_context_imp.h&quot;</a>
<a name="ln128"> </a>
<a name="ln129">using namespace std::literals;</a>
<a name="ln130"> </a>
<a name="ln131">DEFINE_bool(dump_dbimpl_info, false, &quot;Dump RocksDB info during constructor.&quot;);</a>
<a name="ln132">DEFINE_bool(flush_rocksdb_on_shutdown, true,</a>
<a name="ln133">            &quot;Safely flush RocksDB when instance is destroyed, disabled for crash tests.&quot;);</a>
<a name="ln134">DEFINE_double(fault_crash_after_rocksdb_flush, 0.0,</a>
<a name="ln135">              &quot;Fraction of time to crash right after a successful RocksDB flush in tests.&quot;);</a>
<a name="ln136"> </a>
<a name="ln137">DEFINE_bool(use_priority_thread_pool_for_flushes, false,</a>
<a name="ln138">            &quot;When true priority thread pool will be used for flushes, otherwise &quot;</a>
<a name="ln139">            &quot;Env thread pool with Priority::HIGH will be used.&quot;);</a>
<a name="ln140">TAG_FLAG(use_priority_thread_pool_for_flushes, runtime);</a>
<a name="ln141"> </a>
<a name="ln142">DEFINE_bool(use_priority_thread_pool_for_compactions, true,</a>
<a name="ln143">            &quot;When true priority thread pool will be used for compactions, otherwise &quot;</a>
<a name="ln144">            &quot;Env thread pool with Priority::LOW will be used.&quot;);</a>
<a name="ln145">TAG_FLAG(use_priority_thread_pool_for_compactions, runtime);</a>
<a name="ln146"> </a>
<a name="ln147">DEFINE_int32(compaction_priority_start_bound, 10,</a>
<a name="ln148">             &quot;Compaction task of DB that has number of SST files less than specified will have &quot;</a>
<a name="ln149">             &quot;priority 0.&quot;);</a>
<a name="ln150"> </a>
<a name="ln151">DEFINE_int32(compaction_priority_step_size, 5,</a>
<a name="ln152">             &quot;Compaction task of DB that has number of SST files greater that &quot;</a>
<a name="ln153">             &quot;compaction_priority_start_bound will get 1 extra priority per every &quot;</a>
<a name="ln154">             &quot;compaction_priority_step_size files.&quot;);</a>
<a name="ln155"> </a>
<a name="ln156">DEFINE_int32(small_compaction_extra_priority, 1,</a>
<a name="ln157">             &quot;Small compaction will get small_compaction_extra_priority extra priority.&quot;);</a>
<a name="ln158"> </a>
<a name="ln159">DEFINE_bool(rocksdb_use_logging_iterator, false,</a>
<a name="ln160">            &quot;Wrap newly created RocksDB iterators in a logging wrapper&quot;);</a>
<a name="ln161"> </a>
<a name="ln162">DEFINE_test_flag(int32, max_write_waiters, std::numeric_limits&lt;int32_t&gt;::max(),</a>
<a name="ln163">                 &quot;Max allowed number of write waiters per RocksDB instance in tests.&quot;);</a>
<a name="ln164"> </a>
<a name="ln165">namespace rocksdb {</a>
<a name="ln166"> </a>
<a name="ln167">namespace {</a>
<a name="ln168"> </a>
<a name="ln169">std::unique_ptr&lt;Compaction&gt; PopFirstFromCompactionQueue(</a>
<a name="ln170">    std::deque&lt;std::unique_ptr&lt;Compaction&gt;&gt;* queue) {</a>
<a name="ln171">  DCHECK(!queue-&gt;empty());</a>
<a name="ln172">  auto c = std::move(queue-&gt;front());</a>
<a name="ln173">  ColumnFamilyData* cfd = c-&gt;column_family_data();</a>
<a name="ln174">  queue-&gt;pop_front();</a>
<a name="ln175">  DCHECK(cfd-&gt;pending_compaction());</a>
<a name="ln176">  cfd-&gt;set_pending_compaction(false);</a>
<a name="ln177">  return c;</a>
<a name="ln178">}</a>
<a name="ln179"> </a>
<a name="ln180">void ClearCompactionQueue(std::deque&lt;std::unique_ptr&lt;Compaction&gt;&gt;* queue) {</a>
<a name="ln181">  while (!queue-&gt;empty()) {</a>
<a name="ln182">    auto c = PopFirstFromCompactionQueue(queue);</a>
<a name="ln183">    c-&gt;ReleaseCompactionFiles(STATUS(Incomplete, &quot;DBImpl destroyed before compaction scheduled&quot;));</a>
<a name="ln184">    auto cfd = c-&gt;column_family_data();</a>
<a name="ln185">    c.reset();</a>
<a name="ln186">    if (cfd-&gt;Unref()) {</a>
<a name="ln187">      delete cfd;</a>
<a name="ln188">    }</a>
<a name="ln189">  }</a>
<a name="ln190">}</a>
<a name="ln191"> </a>
<a name="ln192">} // namespace</a>
<a name="ln193"> </a>
<a name="ln194">const char kDefaultColumnFamilyName[] = &quot;default&quot;;</a>
<a name="ln195"> </a>
<a name="ln196">struct DBImpl::WriteContext {</a>
<a name="ln197">  boost::container::small_vector&lt;std::unique_ptr&lt;SuperVersion&gt;, 8&gt; superversions_to_free_;</a>
<a name="ln198">  autovector&lt;MemTable*&gt; memtables_to_free_;</a>
<a name="ln199"> </a>
<a name="ln200">  ~WriteContext() {</a>
<a name="ln201">    for (auto&amp; m : memtables_to_free_) {</a>
<a name="ln202">      delete m;</a>
<a name="ln203">    }</a>
<a name="ln204">  }</a>
<a name="ln205">};</a>
<a name="ln206"> </a>
<a name="ln207">YB_DEFINE_ENUM(BgTaskType, (kFlush)(kCompaction));</a>
<a name="ln208"> </a>
<a name="ln209">class DBImpl::ThreadPoolTask : public yb::PriorityThreadPoolTask {</a>
<a name="ln210"> public:</a>
<a name="ln211">  explicit ThreadPoolTask(DBImpl* db_impl) : db_impl_(db_impl) {}</a>
<a name="ln212"> </a>
<a name="ln213">  bool BelongsTo(void* key) override {</a>
<a name="ln214">    return key == db_impl_;</a>
<a name="ln215">  }</a>
<a name="ln216"> </a>
<a name="ln217">  void Run(const Status&amp; status, yb::PriorityThreadPoolSuspender* suspender) override {</a>
<a name="ln218">    if (!status.ok()) {</a>
<a name="ln219">      LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Task cancelled &quot; &lt;&lt; ToString() &lt;&lt; &quot;: &quot; &lt;&lt; status;</a>
<a name="ln220">      InstrumentedMutexLock lock(&amp;db_impl_-&gt;mutex_);</a>
<a name="ln221">      AbortedUnlocked();</a>
<a name="ln222">      return; // Failed to schedule, could just drop compaction.</a>
<a name="ln223">    }</a>
<a name="ln224">    DoRun(suspender);</a>
<a name="ln225">  }</a>
<a name="ln226"> </a>
<a name="ln227">  virtual BgTaskType Type() const = 0;</a>
<a name="ln228"> </a>
<a name="ln229">  virtual int Priority() const = 0;</a>
<a name="ln230"> </a>
<a name="ln231">  virtual void AbortedUnlocked() = 0;</a>
<a name="ln232"> </a>
<a name="ln233">  virtual void DoRun(yb::PriorityThreadPoolSuspender* suspender) = 0;</a>
<a name="ln234"> </a>
<a name="ln235">  // Tries to recalculate and update task priority, returns true if priority was updated.</a>
<a name="ln236">  virtual bool UpdatePriority() = 0;</a>
<a name="ln237"> </a>
<a name="ln238">  const std::string&amp; LogPrefix() const {</a>
<a name="ln239">    return db_impl_-&gt;LogPrefix();</a>
<a name="ln240">  }</a>
<a name="ln241"> </a>
<a name="ln242"> protected:</a>
<a name="ln243">  DBImpl* const db_impl_;</a>
<a name="ln244">};</a>
<a name="ln245"> </a>
<a name="ln246">constexpr int kShuttingDownPriority = 200;</a>
<a name="ln247">constexpr int kFlushPriority = 100;</a>
<a name="ln248"> </a>
<a name="ln249">class DBImpl::CompactionTask : public ThreadPoolTask {</a>
<a name="ln250"> public:</a>
<a name="ln251">  CompactionTask(DBImpl* db_impl, DBImpl::ManualCompaction* manual_compaction)</a>
<a name="ln252">      : ThreadPoolTask(db_impl), manual_compaction_(manual_compaction),</a>
<a name="ln253">        compaction_(manual_compaction-&gt;compaction.get()), priority_(CalcPriority()) {</a>
<a name="ln254">    db_impl-&gt;mutex_.AssertHeld();</a>
<a name="ln255">  }</a>
<a name="ln256"> </a>
<a name="ln257">  CompactionTask(DBImpl* db_impl, std::unique_ptr&lt;Compaction&gt; compaction)</a>
<a name="ln258">      : ThreadPoolTask(db_impl), manual_compaction_(nullptr),</a>
<a name="ln259">        compaction_holder_(std::move(compaction)), compaction_(compaction_holder_.get()),</a>
<a name="ln260">        priority_(CalcPriority()) {</a>
<a name="ln261">    db_impl-&gt;mutex_.AssertHeld();</a>
<a name="ln262">  }</a>
<a name="ln263"> </a>
<a name="ln264">  void DoRun(yb::PriorityThreadPoolSuspender* suspender) override {</a>
<a name="ln265">    compaction_-&gt;SetSuspender(suspender);</a>
<a name="ln266">    db_impl_-&gt;BackgroundCallCompaction(manual_compaction_, std::move(compaction_holder_), this);</a>
<a name="ln267">  }</a>
<a name="ln268"> </a>
<a name="ln269">  void AbortedUnlocked() override {</a>
<a name="ln270">    db_impl_-&gt;mutex_.AssertHeld();</a>
<a name="ln271">    auto cfd = compaction_-&gt;column_family_data();</a>
<a name="ln272">    if (cfd-&gt;Unref()) {</a>
<a name="ln273">      delete cfd;</a>
<a name="ln274">    }</a>
<a name="ln275">    LOG_IF_WITH_PREFIX(DFATAL, db_impl_-&gt;compaction_tasks_.erase(this) != 1)</a>
<a name="ln276">        &lt;&lt; &quot;Aborted unknown compaction task: &quot; &lt;&lt; SerialNo();</a>
<a name="ln277">    if (db_impl_-&gt;compaction_tasks_.empty()) {</a>
<a name="ln278">      db_impl_-&gt;bg_cv_.SignalAll();</a>
<a name="ln279">    }</a>
<a name="ln280">  }</a>
<a name="ln281"> </a>
<a name="ln282">  BgTaskType Type() const override {</a>
<a name="ln283">    return BgTaskType::kCompaction;</a>
<a name="ln284">  }</a>
<a name="ln285"> </a>
<a name="ln286">  std::string ToString() const override {</a>
<a name="ln287">    return yb::Format(&quot;{ compact db: $0 }&quot;, db_impl_-&gt;GetName());</a>
<a name="ln288">  }</a>
<a name="ln289"> </a>
<a name="ln290">  bool UpdatePriority() override {</a>
<a name="ln291">    db_impl_-&gt;mutex_.AssertHeld();</a>
<a name="ln292"> </a>
<a name="ln293">    // Task already complete.</a>
<a name="ln294">    if (compaction_ == nullptr) {</a>
<a name="ln295">      return false;</a>
<a name="ln296">    }</a>
<a name="ln297"> </a>
<a name="ln298">    auto new_priority = CalcPriority();</a>
<a name="ln299">    if (new_priority != priority_) {</a>
<a name="ln300">      priority_ = new_priority;</a>
<a name="ln301">      return true;</a>
<a name="ln302">    }</a>
<a name="ln303">    return false;</a>
<a name="ln304">  }</a>
<a name="ln305"> </a>
<a name="ln306">  void Complete() {</a>
<a name="ln307">    db_impl_-&gt;mutex_.AssertHeld();</a>
<a name="ln308">    compaction_ = nullptr;</a>
<a name="ln309">  }</a>
<a name="ln310"> </a>
<a name="ln311">  int Priority() const override {</a>
<a name="ln312">    return priority_;</a>
<a name="ln313">  }</a>
<a name="ln314"> </a>
<a name="ln315"> private:</a>
<a name="ln316">  int CalcPriority() const {</a>
<a name="ln317">    db_impl_-&gt;mutex_.AssertHeld();</a>
<a name="ln318"> </a>
<a name="ln319">    if (db_impl_-&gt;shutting_down_.load(std::memory_order_acquire)) {</a>
<a name="ln320">      return kShuttingDownPriority;</a>
<a name="ln321">    }</a>
<a name="ln322"> </a>
<a name="ln323">    auto* current_version = compaction_-&gt;column_family_data()-&gt;GetSuperVersion()-&gt;current;</a>
<a name="ln324">    auto num_files = current_version-&gt;storage_info()-&gt;l0_delay_trigger_count();</a>
<a name="ln325"> </a>
<a name="ln326">    int result = 0;</a>
<a name="ln327">    if (num_files &gt;= FLAGS_compaction_priority_start_bound) {</a>
<a name="ln328">      result =</a>
<a name="ln329">          1 +</a>
<a name="ln330">          (num_files - FLAGS_compaction_priority_start_bound) / FLAGS_compaction_priority_step_size;</a>
<a name="ln331">    }</a>
<a name="ln332"> </a>
<a name="ln333">    if (!db_impl_-&gt;IsLargeCompaction(*compaction_)) {</a>
<a name="ln334">      result += FLAGS_small_compaction_extra_priority;</a>
<a name="ln335">    }</a>
<a name="ln336"> </a>
<a name="ln337">    return result;</a>
<a name="ln338">  }</a>
<a name="ln339"> </a>
<a name="ln340">  // Only one of manual_compaction_ and compaction_ could be non null.</a>
<a name="ln341">  DBImpl::ManualCompaction* const manual_compaction_;</a>
<a name="ln342">  std::unique_ptr&lt;Compaction&gt; compaction_holder_;</a>
<a name="ln343">  Compaction* compaction_;</a>
<a name="ln344">  int priority_;</a>
<a name="ln345">};</a>
<a name="ln346"> </a>
<a name="ln347">class DBImpl::FlushTask : public ThreadPoolTask {</a>
<a name="ln348"> public:</a>
<a name="ln349">  FlushTask(DBImpl* db_impl, ColumnFamilyData* cfd)</a>
<a name="ln350">      : ThreadPoolTask(db_impl), cfd_(cfd) {}</a>
<a name="ln351"> </a>
<a name="ln352">  void DoRun(yb::PriorityThreadPoolSuspender* suspender) override {</a>
<a name="ln353">    // Since flush tasks has highest priority we could don't use suspender for them.</a>
<a name="ln354">    db_impl_-&gt;BackgroundCallFlush(cfd_);</a>
<a name="ln355">  }</a>
<a name="ln356"> </a>
<a name="ln357">  int Priority() const override {</a>
<a name="ln358">    return kFlushPriority;</a>
<a name="ln359">  }</a>
<a name="ln360"> </a>
<a name="ln361">  void AbortedUnlocked() override {</a>
<a name="ln362">    db_impl_-&gt;mutex_.AssertHeld();</a>
<a name="ln363">    cfd_-&gt;set_pending_flush(false);</a>
<a name="ln364">    if (cfd_-&gt;Unref()) {</a>
<a name="ln365">      delete cfd_;</a>
<a name="ln366">    }</a>
<a name="ln367">    if (--db_impl_-&gt;bg_flush_scheduled_ == 0) {</a>
<a name="ln368">      db_impl_-&gt;bg_cv_.SignalAll();</a>
<a name="ln369">    }</a>
<a name="ln370">  }</a>
<a name="ln371"> </a>
<a name="ln372">  BgTaskType Type() const override {</a>
<a name="ln373">    return BgTaskType::kFlush;</a>
<a name="ln374">  }</a>
<a name="ln375"> </a>
<a name="ln376">  bool UpdatePriority() override {</a>
<a name="ln377">    return false;</a>
<a name="ln378">  }</a>
<a name="ln379"> </a>
<a name="ln380">  std::string ToString() const override {</a>
<a name="ln381">    return yb::Format(&quot;{ flush db: $0 }&quot;, db_impl_-&gt;GetName());</a>
<a name="ln382">  }</a>
<a name="ln383"> </a>
<a name="ln384"> private:</a>
<a name="ln385">  ColumnFamilyData* cfd_;</a>
<a name="ln386">};</a>
<a name="ln387"> </a>
<a name="ln388">// Utility class to update task priority.</a>
<a name="ln389">// We use two phase update to avoid calling thread pool while holding the mutex.</a>
<a name="ln390">class DBImpl::TaskPriorityUpdater {</a>
<a name="ln391"> public:</a>
<a name="ln392">  explicit TaskPriorityUpdater(DBImpl* db)</a>
<a name="ln393">      : db_(db),</a>
<a name="ln394">        priority_thread_pool_for_compactions_and_flushes_(</a>
<a name="ln395">            db_-&gt;db_options_.priority_thread_pool_for_compactions_and_flushes) {}</a>
<a name="ln396"> </a>
<a name="ln397">  void Prepare() {</a>
<a name="ln398">    db_-&gt;mutex_.AssertHeld();</a>
<a name="ln399">    for (auto* task : db_-&gt;compaction_tasks_) {</a>
<a name="ln400">      if (task-&gt;UpdatePriority()) {</a>
<a name="ln401">        update_priorities_request_.push_back({task-&gt;SerialNo(), task-&gt;Priority()});</a>
<a name="ln402">      }</a>
<a name="ln403">    }</a>
<a name="ln404">    db_ = nullptr;</a>
<a name="ln405">  }</a>
<a name="ln406"> </a>
<a name="ln407">  bool Empty() const {</a>
<a name="ln408">    return update_priorities_request_.empty();</a>
<a name="ln409">  }</a>
<a name="ln410"> </a>
<a name="ln411">  void Apply() {</a>
<a name="ln412">    for (const auto&amp; entry : update_priorities_request_) {</a>
<a name="ln413">      priority_thread_pool_for_compactions_and_flushes_-&gt;ChangeTaskPriority(</a>
<a name="ln414">          entry.task_serial_no, entry.new_priority);</a>
<a name="ln415">    }</a>
<a name="ln416">  }</a>
<a name="ln417"> </a>
<a name="ln418"> private:</a>
<a name="ln419">  DBImpl* db_;</a>
<a name="ln420">  yb::PriorityThreadPool* priority_thread_pool_for_compactions_and_flushes_;</a>
<a name="ln421">  boost::container::small_vector&lt;TaskPriorityChange, 8&gt; update_priorities_request_;</a>
<a name="ln422">};</a>
<a name="ln423"> </a>
<a name="ln424">Options SanitizeOptions(const std::string&amp; dbname,</a>
<a name="ln425">                        const InternalKeyComparator* icmp,</a>
<a name="ln426">                        const Options&amp; src) {</a>
<a name="ln427">  auto db_options = SanitizeOptions(dbname, DBOptions(src));</a>
<a name="ln428">  auto cf_options = SanitizeOptions(db_options, icmp, ColumnFamilyOptions(src));</a>
<a name="ln429">  return Options(db_options, cf_options);</a>
<a name="ln430">}</a>
<a name="ln431"> </a>
<a name="ln432">DBOptions SanitizeOptions(const std::string&amp; dbname, const DBOptions&amp; src) {</a>
<a name="ln433">  DBOptions result = src;</a>
<a name="ln434"> </a>
<a name="ln435">  // result.max_open_files means an &quot;infinite&quot; open files.</a>
<a name="ln436">  if (result.max_open_files != -1) {</a>
<a name="ln437">    int max_max_open_files = port::GetMaxOpenFiles();</a>
<a name="ln438">    if (max_max_open_files == -1) {</a>
<a name="ln439">      max_max_open_files = 1000000;</a>
<a name="ln440">    }</a>
<a name="ln441">    ClipToRange(&amp;result.max_open_files, 20, max_max_open_files);</a>
<a name="ln442">  }</a>
<a name="ln443"> </a>
<a name="ln444">  if (result.info_log == nullptr) {</a>
<a name="ln445">    Status s = CreateLoggerFromOptions(dbname, result, &amp;result.info_log);</a>
<a name="ln446">    if (!s.ok()) {</a>
<a name="ln447">      // No place suitable for logging</a>
<a name="ln448">      result.info_log = nullptr;</a>
<a name="ln449">    }</a>
<a name="ln450">  }</a>
<a name="ln451">  if (result.base_background_compactions == -1) {</a>
<a name="ln452">    result.base_background_compactions = result.max_background_compactions;</a>
<a name="ln453">  }</a>
<a name="ln454">  if (result.base_background_compactions &gt; result.max_background_compactions) {</a>
<a name="ln455">    result.base_background_compactions = result.max_background_compactions;</a>
<a name="ln456">  }</a>
<a name="ln457">  if (result.base_background_compactions == 1) {</a>
<a name="ln458">    result.num_reserved_small_compaction_threads = 0;</a>
<a name="ln459">  }</a>
<a name="ln460">  if (result.num_reserved_small_compaction_threads == -1 ||</a>
<a name="ln461">        result.num_reserved_small_compaction_threads &gt;= result.base_background_compactions) {</a>
<a name="ln462">    result.num_reserved_small_compaction_threads = result.base_background_compactions - 1;</a>
<a name="ln463">  }</a>
<a name="ln464">  result.env-&gt;IncBackgroundThreadsIfNeeded(</a>
<a name="ln465">      src.max_background_compactions, Env::Priority::LOW);</a>
<a name="ln466">  result.env-&gt;IncBackgroundThreadsIfNeeded(</a>
<a name="ln467">      src.max_background_flushes, Env::Priority::HIGH);</a>
<a name="ln468"> </a>
<a name="ln469">  if (result.rate_limiter.get() != nullptr) {</a>
<a name="ln470">    if (result.bytes_per_sync == 0) {</a>
<a name="ln471">      result.bytes_per_sync = 1024 * 1024;</a>
<a name="ln472">    }</a>
<a name="ln473">  }</a>
<a name="ln474"> </a>
<a name="ln475">  if (result.WAL_ttl_seconds &gt; 0 || result.WAL_size_limit_MB &gt; 0) {</a>
<a name="ln476">    result.recycle_log_file_num = false;</a>
<a name="ln477">  }</a>
<a name="ln478"> </a>
<a name="ln479">  if (result.wal_dir.empty()) {</a>
<a name="ln480">    // Use dbname as default</a>
<a name="ln481">    result.wal_dir = dbname;</a>
<a name="ln482">  }</a>
<a name="ln483">  if (result.wal_dir.back() == '/') {</a>
<a name="ln484">    result.wal_dir = result.wal_dir.substr(0, result.wal_dir.size() - 1);</a>
<a name="ln485">  }</a>
<a name="ln486"> </a>
<a name="ln487">  if (result.db_paths.size() == 0) {</a>
<a name="ln488">    result.db_paths.emplace_back(dbname, std::numeric_limits&lt;uint64_t&gt;::max());</a>
<a name="ln489">  }</a>
<a name="ln490"> </a>
<a name="ln491">  if (result.compaction_readahead_size &gt; 0) {</a>
<a name="ln492">    result.new_table_reader_for_compaction_inputs = true;</a>
<a name="ln493">  }</a>
<a name="ln494"> </a>
<a name="ln495">  return result;</a>
<a name="ln496">}</a>
<a name="ln497"> </a>
<a name="ln498">namespace {</a>
<a name="ln499"> </a>
<a name="ln500">Status SanitizeOptionsByTable(</a>
<a name="ln501">    const DBOptions&amp; db_opts,</a>
<a name="ln502">    const std::vector&lt;ColumnFamilyDescriptor&gt;&amp; column_families) {</a>
<a name="ln503">  Status s;</a>
<a name="ln504">  for (auto cf : column_families) {</a>
<a name="ln505">    s = cf.options.table_factory-&gt;SanitizeOptions(db_opts, cf.options);</a>
<a name="ln506">    if (!s.ok()) {</a>
<a name="ln507">      return s;</a>
<a name="ln508">    }</a>
<a name="ln509">  }</a>
<a name="ln510">  return Status::OK();</a>
<a name="ln511">}</a>
<a name="ln512"> </a>
<a name="ln513">CompressionType GetCompressionFlush(const ImmutableCFOptions&amp; ioptions) {</a>
<a name="ln514">  // Compressing memtable flushes might not help unless the sequential load</a>
<a name="ln515">  // optimization is used for leveled compaction. Otherwise the CPU and</a>
<a name="ln516">  // latency overhead is not offset by saving much space.</a>
<a name="ln517"> </a>
<a name="ln518">  bool can_compress;</a>
<a name="ln519"> </a>
<a name="ln520">  if (ioptions.compaction_style == kCompactionStyleUniversal) {</a>
<a name="ln521">    can_compress =</a>
<a name="ln522">        (ioptions.compaction_options_universal.compression_size_percent &lt; 0);</a>
<a name="ln523">  } else {</a>
<a name="ln524">    // For leveled compress when min_level_to_compress == 0.</a>
<a name="ln525">    can_compress = ioptions.compression_per_level.empty() ||</a>
<a name="ln526">                   ioptions.compression_per_level[0] != kNoCompression;</a>
<a name="ln527">  }</a>
<a name="ln528"> </a>
<a name="ln529">  if (can_compress) {</a>
<a name="ln530">    return ioptions.compression;</a>
<a name="ln531">  } else {</a>
<a name="ln532">    return kNoCompression;</a>
<a name="ln533">  }</a>
<a name="ln534">}</a>
<a name="ln535"> </a>
<a name="ln536">void DumpSupportInfo(Logger* logger) {</a>
<a name="ln537">  RLOG(InfoLogLevel::INFO_LEVEL, logger, &quot;Compression algorithms supported:&quot;);</a>
<a name="ln538">  RLOG(InfoLogLevel::INFO_LEVEL, logger, &quot;\tSnappy supported: %d&quot;,</a>
<a name="ln539">      Snappy_Supported());</a>
<a name="ln540">  RLOG(InfoLogLevel::INFO_LEVEL, logger, &quot;\tZlib supported: %d&quot;,</a>
<a name="ln541">      Zlib_Supported());</a>
<a name="ln542">  RLOG(InfoLogLevel::INFO_LEVEL, logger, &quot;\tBzip supported: %d&quot;,</a>
<a name="ln543">      BZip2_Supported());</a>
<a name="ln544">  RLOG(InfoLogLevel::INFO_LEVEL, logger, &quot;\tLZ4 supported: %d&quot;, LZ4_Supported());</a>
<a name="ln545">  RLOG(InfoLogLevel::INFO_LEVEL, logger, &quot;Fast CRC32 supported: %d&quot;,</a>
<a name="ln546">      crc32c::IsFastCrc32Supported());</a>
<a name="ln547">}</a>
<a name="ln548"> </a>
<a name="ln549">}  // namespace</a>
<a name="ln550"> </a>
<a name="ln551">DBImpl::DBImpl(const DBOptions&amp; options, const std::string&amp; dbname)</a>
<a name="ln552">    : env_(options.env),</a>
<a name="ln553">      checkpoint_env_(options.get_checkpoint_env()),</a>
<a name="ln554">      dbname_(dbname),</a>
<a name="ln555">      db_options_(SanitizeOptions(dbname, options)),</a>
<a name="ln556">      stats_(db_options_.statistics.get()),</a>
<a name="ln557">      db_lock_(nullptr),</a>
<a name="ln558">      mutex_(stats_, env_, DB_MUTEX_WAIT_MICROS, options.use_adaptive_mutex),</a>
<a name="ln559">      shutting_down_(false),</a>
<a name="ln560">      bg_cv_(&amp;mutex_),</a>
<a name="ln561">      logfile_number_(0),</a>
<a name="ln562">      log_dir_synced_(false),</a>
<a name="ln563">      log_empty_(true),</a>
<a name="ln564">      default_cf_handle_(nullptr),</a>
<a name="ln565">      log_sync_cv_(&amp;mutex_),</a>
<a name="ln566">      total_log_size_(0),</a>
<a name="ln567">      max_total_in_memory_state_(0),</a>
<a name="ln568">      is_snapshot_supported_(true),</a>
<a name="ln569">      write_buffer_(options.db_write_buffer_size, options.memory_monitor),</a>
<a name="ln570">      write_thread_(options.enable_write_thread_adaptive_yield</a>
<a name="ln571">                        ? options.write_thread_max_yield_usec</a>
<a name="ln572">                        : 0,</a>
<a name="ln573">                    options.write_thread_slow_yield_usec),</a>
<a name="ln574">      write_controller_(options.delayed_write_rate),</a>
<a name="ln575">      last_batch_group_size_(0),</a>
<a name="ln576">      unscheduled_flushes_(0),</a>
<a name="ln577">      unscheduled_compactions_(0),</a>
<a name="ln578">      bg_compaction_scheduled_(0),</a>
<a name="ln579">      num_total_running_compactions_(0),</a>
<a name="ln580">      num_running_large_compactions_(0),</a>
<a name="ln581">      bg_flush_scheduled_(0),</a>
<a name="ln582">      num_running_flushes_(0),</a>
<a name="ln583">      disable_delete_obsolete_files_(0),</a>
<a name="ln584">      delete_obsolete_files_next_run_(</a>
<a name="ln585">          options.env-&gt;NowMicros() +</a>
<a name="ln586">          db_options_.delete_obsolete_files_period_micros),</a>
<a name="ln587">      last_stats_dump_time_microsec_(0),</a>
<a name="ln588">      next_job_id_(1),</a>
<a name="ln589">      has_unpersisted_data_(false),</a>
<a name="ln590">      env_options_(db_options_),</a>
<a name="ln591">#ifndef ROCKSDB_LITE</a>
<a name="ln592">      wal_manager_(db_options_, env_options_),</a>
<a name="ln593">#endif  // ROCKSDB_LITE</a>
<a name="ln594">      event_logger_(db_options_.info_log.get()),</a>
<a name="ln595">      bg_work_paused_(0),</a>
<a name="ln596">      bg_compaction_paused_(0),</a>
<a name="ln597">      refitting_level_(false),</a>
<a name="ln598">      opened_successfully_(false) {</a>
<a name="ln599">  CHECK_OK(env_-&gt;GetAbsolutePath(dbname, &amp;db_absolute_path_));</a>
<a name="ln600"> </a>
<a name="ln601">  // Reserve ten files or so for other uses and give the rest to TableCache.</a>
<a name="ln602">  // Give a large number for setting of &quot;infinite&quot; open files.</a>
<a name="ln603">  const int table_cache_size = (db_options_.max_open_files == -1) ?</a>
<a name="ln604">        4194304 : db_options_.max_open_files - 10;</a>
<a name="ln605">  table_cache_ =</a>
<a name="ln606">      NewLRUCache(table_cache_size, db_options_.table_cache_numshardbits);</a>
<a name="ln607"> </a>
<a name="ln608">  versions_.reset(new VersionSet(dbname_, &amp;db_options_, env_options_,</a>
<a name="ln609">                                 table_cache_.get(), &amp;write_buffer_,</a>
<a name="ln610">                                 &amp;write_controller_));</a>
<a name="ln611">  pending_outputs_ = std::make_unique&lt;FileNumbersProvider&gt;(versions_.get());</a>
<a name="ln612">  column_family_memtables_.reset(</a>
<a name="ln613">      new ColumnFamilyMemTablesImpl(versions_-&gt;GetColumnFamilySet()));</a>
<a name="ln614"> </a>
<a name="ln615">  if (FLAGS_dump_dbimpl_info) {</a>
<a name="ln616">    DumpDBFileSummary(db_options_, dbname_);</a>
<a name="ln617">    db_options_.Dump(db_options_.info_log.get());</a>
<a name="ln618">    DumpSupportInfo(db_options_.info_log.get());</a>
<a name="ln619">  }</a>
<a name="ln620">}</a>
<a name="ln621"> </a>
<a name="ln622">// Will lock the mutex_,  will wait for completion if wait is true</a>
<a name="ln623">void DBImpl::CancelAllBackgroundWork(bool wait) {</a>
<a name="ln624">  InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln625">  shutting_down_.store(true, std::memory_order_release);</a>
<a name="ln626">  bg_cv_.SignalAll();</a>
<a name="ln627">  if (!wait) {</a>
<a name="ln628">    return;</a>
<a name="ln629">  }</a>
<a name="ln630">  // Wait for background work to finish</a>
<a name="ln631">  while (CheckBackgroundWorkAndLog(&quot;Cancel&quot;)) {</a>
<a name="ln632">    bg_cv_.Wait();</a>
<a name="ln633">  }</a>
<a name="ln634">}</a>
<a name="ln635"> </a>
<a name="ln636">bool DBImpl::CheckBackgroundWorkAndLog(const char* prefix) const {</a>
<a name="ln637">  if (bg_compaction_scheduled_ || bg_flush_scheduled_ || !compaction_tasks_.empty()) {</a>
<a name="ln638">    LOG_WITH_PREFIX(INFO)</a>
<a name="ln639">        &lt;&lt; prefix &lt;&lt; &quot; waiting for &quot; &lt;&lt; bg_compaction_scheduled_ &lt;&lt; &quot; scheduled compactions, &quot;</a>
<a name="ln640">        &lt;&lt; compaction_tasks_.size() &lt;&lt; &quot; compaction tasks and &quot;</a>
<a name="ln641">        &lt;&lt; bg_flush_scheduled_ &lt;&lt; &quot; flushes&quot;;</a>
<a name="ln642">    return true;</a>
<a name="ln643">  }</a>
<a name="ln644">  return false;</a>
<a name="ln645">}</a>
<a name="ln646"> </a>
<a name="ln647">DBImpl::~DBImpl() {</a>
<a name="ln648">  RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log, &quot;Shutting down RocksDB at: %s\n&quot;,</a>
<a name="ln649">       dbname_.c_str());</a>
<a name="ln650"> </a>
<a name="ln651">  TaskPriorityUpdater task_priority_updater(this);</a>
<a name="ln652">  {</a>
<a name="ln653">    InstrumentedMutexLock lock(&amp;mutex_);</a>
<a name="ln654"> </a>
<a name="ln655">    if (!shutting_down_.load(std::memory_order_acquire) &amp;&amp;</a>
<a name="ln656">        has_unpersisted_data_) {</a>
<a name="ln657">      for (auto cfd : *versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln658">        if (!cfd-&gt;IsDropped() &amp;&amp; !cfd-&gt;mem()-&gt;IsEmpty()) {</a>
<a name="ln659">          cfd-&gt;Ref();</a>
<a name="ln660">          mutex_.Unlock();</a>
<a name="ln661">          if (disable_flush_on_shutdown_) {</a>
<a name="ln662">            LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Skipping mem table flush - disable_flush_on_shutdown_ is set&quot;;</a>
<a name="ln663">          } else if (FLAGS_flush_rocksdb_on_shutdown) {</a>
<a name="ln664">            LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Flushing mem table on shutdown&quot;;</a>
<a name="ln665">            CHECK_OK(FlushMemTable(cfd, FlushOptions()));</a>
<a name="ln666">          } else {</a>
<a name="ln667">            RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln668">                &quot;Skipping mem table flush - flush_rocksdb_on_shutdown is unset&quot;);</a>
<a name="ln669">          }</a>
<a name="ln670">          mutex_.Lock();</a>
<a name="ln671">          cfd-&gt;Unref();</a>
<a name="ln672">        }</a>
<a name="ln673">      }</a>
<a name="ln674">      versions_-&gt;GetColumnFamilySet()-&gt;FreeDeadColumnFamilies();</a>
<a name="ln675">    }</a>
<a name="ln676">    shutting_down_.store(true, std::memory_order_release);</a>
<a name="ln677">    bg_cv_.SignalAll();</a>
<a name="ln678">    task_priority_updater.Prepare();</a>
<a name="ln679">  }</a>
<a name="ln680"> </a>
<a name="ln681">  task_priority_updater.Apply();</a>
<a name="ln682"> </a>
<a name="ln683">  if (db_options_.priority_thread_pool_for_compactions_and_flushes) {</a>
<a name="ln684">    db_options_.priority_thread_pool_for_compactions_and_flushes-&gt;Remove(this);</a>
<a name="ln685">  }</a>
<a name="ln686">  int compactions_unscheduled = env_-&gt;UnSchedule(this, Env::Priority::LOW);</a>
<a name="ln687">  int flushes_unscheduled = env_-&gt;UnSchedule(this, Env::Priority::HIGH);</a>
<a name="ln688"> </a>
<a name="ln689">  mutex_.Lock();</a>
<a name="ln690">  bg_compaction_scheduled_ -= compactions_unscheduled;</a>
<a name="ln691">  bg_flush_scheduled_ -= flushes_unscheduled;</a>
<a name="ln692"> </a>
<a name="ln693">  // Wait for background work to finish</a>
<a name="ln694">  while (CheckBackgroundWorkAndLog(&quot;Shutdown&quot;)) {</a>
<a name="ln695">    // Use timed wait for periodic status logging.</a>
<a name="ln696">    bg_cv_.TimedWait(env_-&gt;NowMicros() + yb::ToMicroseconds(5s));</a>
<a name="ln697">  }</a>
<a name="ln698">  EraseThreadStatusDbInfo();</a>
<a name="ln699">  flush_scheduler_.Clear();</a>
<a name="ln700"> </a>
<a name="ln701">  while (!flush_queue_.empty()) {</a>
<a name="ln702">    auto cfd = PopFirstFromFlushQueue();</a>
<a name="ln703">    if (cfd-&gt;Unref()) {</a>
<a name="ln704">      delete cfd;</a>
<a name="ln705">    }</a>
<a name="ln706">  }</a>
<a name="ln707"> </a>
<a name="ln708">  ClearCompactionQueue(&amp;small_compaction_queue_);</a>
<a name="ln709">  ClearCompactionQueue(&amp;large_compaction_queue_);</a>
<a name="ln710"> </a>
<a name="ln711">  if (default_cf_handle_ != nullptr) {</a>
<a name="ln712">    // we need to delete handle outside of lock because it does its own locking</a>
<a name="ln713">    mutex_.Unlock();</a>
<a name="ln714">    delete default_cf_handle_;</a>
<a name="ln715">    mutex_.Lock();</a>
<a name="ln716">  }</a>
<a name="ln717"> </a>
<a name="ln718">  // Clean up obsolete files due to SuperVersion release.</a>
<a name="ln719">  // (1) Need to delete to obsolete files before closing because RepairDB()</a>
<a name="ln720">  // scans all existing files in the file system and builds manifest file.</a>
<a name="ln721">  // Keeping obsolete files confuses the repair process.</a>
<a name="ln722">  // (2) Need to check if we Open()/Recover() the DB successfully before</a>
<a name="ln723">  // deleting because if VersionSet recover fails (may be due to corrupted</a>
<a name="ln724">  // manifest file), it is not able to identify live files correctly. As a</a>
<a name="ln725">  // result, all &quot;live&quot; files can get deleted by accident. However, corrupted</a>
<a name="ln726">  // manifest is recoverable by RepairDB().</a>
<a name="ln727">  if (opened_successfully_) {</a>
<a name="ln728">    JobContext job_context(next_job_id_.fetch_add(1));</a>
<a name="ln729">    FindObsoleteFiles(&amp;job_context, true);</a>
<a name="ln730"> </a>
<a name="ln731">    mutex_.Unlock();</a>
<a name="ln732">    // manifest number starting from 2</a>
<a name="ln733">    job_context.manifest_file_number = 1;</a>
<a name="ln734">    if (job_context.HaveSomethingToDelete()) {</a>
<a name="ln735">      PurgeObsoleteFiles(job_context);</a>
<a name="ln736">    }</a>
<a name="ln737">    job_context.Clean();</a>
<a name="ln738">    mutex_.Lock();</a>
<a name="ln739">  }</a>
<a name="ln740"> </a>
<a name="ln741">  for (auto l : logs_to_free_) {</a>
<a name="ln742">    delete l;</a>
<a name="ln743">  }</a>
<a name="ln744">  for (auto&amp; log : logs_) {</a>
<a name="ln745">    log.ClearWriter();</a>
<a name="ln746">  }</a>
<a name="ln747">  logs_.clear();</a>
<a name="ln748"> </a>
<a name="ln749">  // versions need to be destroyed before table_cache since it can hold</a>
<a name="ln750">  // references to table_cache.</a>
<a name="ln751">  versions_.reset();</a>
<a name="ln752">  mutex_.Unlock();</a>
<a name="ln753">  if (db_lock_ != nullptr) {</a>
<a name="ln754">    CHECK_OK(env_-&gt;UnlockFile(db_lock_));</a>
<a name="ln755">  }</a>
<a name="ln756"> </a>
<a name="ln757">  LogFlush(db_options_.info_log);</a>
<a name="ln758"> </a>
<a name="ln759">  LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Shutdown done&quot;;</a>
<a name="ln760">}</a>
<a name="ln761"> </a>
<a name="ln762">Status DBImpl::NewDB() {</a>
<a name="ln763">  VersionEdit new_db;</a>
<a name="ln764">  new_db.InitNewDB();</a>
<a name="ln765">  new_db.SetLastSequence(db_options_.initial_seqno);</a>
<a name="ln766"> </a>
<a name="ln767">  Status s;</a>
<a name="ln768"> </a>
<a name="ln769">  RLOG(InfoLogLevel::INFO_LEVEL,</a>
<a name="ln770">      db_options_.info_log, &quot;Creating manifest 1 \n&quot;);</a>
<a name="ln771">  const std::string manifest = DescriptorFileName(dbname_, 1);</a>
<a name="ln772">  {</a>
<a name="ln773">    unique_ptr&lt;WritableFile&gt; file;</a>
<a name="ln774">    EnvOptions env_options = env_-&gt;OptimizeForManifestWrite(env_options_);</a>
<a name="ln775">    s = NewWritableFile(env_, manifest, &amp;file, env_options);</a>
<a name="ln776">    if (!s.ok()) {</a>
<a name="ln777">      return s;</a>
<a name="ln778">    }</a>
<a name="ln779">    file-&gt;SetPreallocationBlockSize(db_options_.manifest_preallocation_size);</a>
<a name="ln780">    unique_ptr&lt;WritableFileWriter&gt; file_writer(</a>
<a name="ln781">        new WritableFileWriter(std::move(file), env_options));</a>
<a name="ln782">    log::Writer log(std::move(file_writer), 0, false);</a>
<a name="ln783">    std::string record;</a>
<a name="ln784">    new_db.AppendEncodedTo(&amp;record);</a>
<a name="ln785">    s = log.AddRecord(record);</a>
<a name="ln786">    if (s.ok()) {</a>
<a name="ln787">      s = SyncManifest(env_, &amp;db_options_, log.file());</a>
<a name="ln788">    }</a>
<a name="ln789">  }</a>
<a name="ln790">  if (s.ok()) {</a>
<a name="ln791">    // Make &quot;CURRENT&quot; file that points to the new manifest file.</a>
<a name="ln792">    s = SetCurrentFile(env_, dbname_, 1, directories_.GetDbDir(), db_options_.disableDataSync);</a>
<a name="ln793">  } else {</a>
<a name="ln794">    env_-&gt;CleanupFile(manifest);</a>
<a name="ln795">  }</a>
<a name="ln796">  return s;</a>
<a name="ln797">}</a>
<a name="ln798"> </a>
<a name="ln799">void DBImpl::MaybeIgnoreError(Status* s) const {</a>
<a name="ln800">  if (s-&gt;ok() || db_options_.paranoid_checks) {</a>
<a name="ln801">    // No change needed</a>
<a name="ln802">  } else {</a>
<a name="ln803">    RLOG(InfoLogLevel::WARN_LEVEL,</a>
<a name="ln804">        db_options_.info_log, &quot;Ignoring error %s&quot;, s-&gt;ToString().c_str());</a>
<a name="ln805">    *s = Status::OK();</a>
<a name="ln806">  }</a>
<a name="ln807">}</a>
<a name="ln808"> </a>
<a name="ln809">const Status DBImpl::CreateArchivalDirectory() {</a>
<a name="ln810">  if (db_options_.WAL_ttl_seconds &gt; 0 || db_options_.WAL_size_limit_MB &gt; 0) {</a>
<a name="ln811">    std::string archivalPath = ArchivalDirectory(db_options_.wal_dir);</a>
<a name="ln812">    return env_-&gt;CreateDirIfMissing(archivalPath);</a>
<a name="ln813">  }</a>
<a name="ln814">  return Status::OK();</a>
<a name="ln815">}</a>
<a name="ln816"> </a>
<a name="ln817">void DBImpl::PrintStatistics() {</a>
<a name="ln818">  auto dbstats = db_options_.statistics.get();</a>
<a name="ln819">  if (dbstats) {</a>
<a name="ln820">    RLOG(InfoLogLevel::WARN_LEVEL, db_options_.info_log,</a>
<a name="ln821">        &quot;STATISTICS:\n %s&quot;,</a>
<a name="ln822">        dbstats-&gt;ToString().c_str());</a>
<a name="ln823">  }</a>
<a name="ln824">}</a>
<a name="ln825"> </a>
<a name="ln826">void DBImpl::MaybeDumpStats() {</a>
<a name="ln827">  if (db_options_.stats_dump_period_sec == 0) return;</a>
<a name="ln828"> </a>
<a name="ln829">  const uint64_t now_micros = env_-&gt;NowMicros();</a>
<a name="ln830"> </a>
<a name="ln831">  if (last_stats_dump_time_microsec_ +</a>
<a name="ln832">      db_options_.stats_dump_period_sec * 1000000</a>
<a name="ln833">      &lt;= now_micros) {</a>
<a name="ln834">    // Multiple threads could race in here simultaneously.</a>
<a name="ln835">    // However, the last one will update last_stats_dump_time_microsec_</a>
<a name="ln836">    // atomically. We could see more than one dump during one dump</a>
<a name="ln837">    // period in rare cases.</a>
<a name="ln838">    last_stats_dump_time_microsec_ = now_micros;</a>
<a name="ln839"> </a>
<a name="ln840">#ifndef ROCKSDB_LITE</a>
<a name="ln841">    const DBPropertyInfo* cf_property_info =</a>
<a name="ln842">        GetPropertyInfo(DB::Properties::kCFStats);</a>
<a name="ln843">    assert(cf_property_info != nullptr);</a>
<a name="ln844">    const DBPropertyInfo* db_property_info =</a>
<a name="ln845">        GetPropertyInfo(DB::Properties::kDBStats);</a>
<a name="ln846">    assert(db_property_info != nullptr);</a>
<a name="ln847"> </a>
<a name="ln848">    std::string stats;</a>
<a name="ln849">    {</a>
<a name="ln850">      InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln851">      for (auto cfd : *versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln852">        cfd-&gt;internal_stats()-&gt;GetStringProperty(</a>
<a name="ln853">            *cf_property_info, DB::Properties::kCFStats, &amp;stats);</a>
<a name="ln854">      }</a>
<a name="ln855">      default_cf_internal_stats_-&gt;GetStringProperty(</a>
<a name="ln856">          *db_property_info, DB::Properties::kDBStats, &amp;stats);</a>
<a name="ln857">    }</a>
<a name="ln858">    RLOG(InfoLogLevel::WARN_LEVEL,</a>
<a name="ln859">        db_options_.info_log, &quot;------- DUMPING STATS -------&quot;);</a>
<a name="ln860">    RLOG(InfoLogLevel::WARN_LEVEL,</a>
<a name="ln861">        db_options_.info_log, &quot;%s&quot;, stats.c_str());</a>
<a name="ln862">#endif  // !ROCKSDB_LITE</a>
<a name="ln863"> </a>
<a name="ln864">    PrintStatistics();</a>
<a name="ln865">  }</a>
<a name="ln866">}</a>
<a name="ln867"> </a>
<a name="ln868">// * Returns the list of live files in 'sst_live'</a>
<a name="ln869">// If it's doing full scan:</a>
<a name="ln870">// * Returns the list of all files in the filesystem in</a>
<a name="ln871">// 'full_scan_candidate_files'.</a>
<a name="ln872">// Otherwise, gets obsolete files from VersionSet.</a>
<a name="ln873">// no_full_scan = true -- never do the full scan using GetChildren()</a>
<a name="ln874">// force = false -- don't force the full scan, except every</a>
<a name="ln875">//  db_options_.delete_obsolete_files_period_micros</a>
<a name="ln876">// force = true -- force the full scan</a>
<a name="ln877">void DBImpl::FindObsoleteFiles(JobContext* job_context, bool force,</a>
<a name="ln878">                               bool no_full_scan) {</a>
<a name="ln879">  mutex_.AssertHeld();</a>
<a name="ln880"> </a>
<a name="ln881">  // if deletion is disabled, do nothing</a>
<a name="ln882">  if (disable_delete_obsolete_files_ &gt; 0) {</a>
<a name="ln883">    return;</a>
<a name="ln884">  }</a>
<a name="ln885"> </a>
<a name="ln886">  bool doing_the_full_scan = false;</a>
<a name="ln887"> </a>
<a name="ln888">  // logic for figurint out if we're doing the full scan</a>
<a name="ln889">  if (no_full_scan) {</a>
<a name="ln890">    doing_the_full_scan = false;</a>
<a name="ln891">  } else if (force || db_options_.delete_obsolete_files_period_micros == 0) {</a>
<a name="ln892">    doing_the_full_scan = true;</a>
<a name="ln893">  } else {</a>
<a name="ln894">    const uint64_t now_micros = env_-&gt;NowMicros();</a>
<a name="ln895">    if (delete_obsolete_files_next_run_ &lt; now_micros) {</a>
<a name="ln896">      doing_the_full_scan = true;</a>
<a name="ln897">      delete_obsolete_files_next_run_ =</a>
<a name="ln898">          now_micros + db_options_.delete_obsolete_files_period_micros;</a>
<a name="ln899">    }</a>
<a name="ln900">  }</a>
<a name="ln901"> </a>
<a name="ln902">  // Get obsolete files.  This function will also update the list of</a>
<a name="ln903">  // pending files in VersionSet().</a>
<a name="ln904">  versions_-&gt;GetObsoleteFiles(*pending_outputs_,</a>
<a name="ln905">                              &amp;job_context-&gt;sst_delete_files,</a>
<a name="ln906">                              &amp;job_context-&gt;manifest_delete_files);</a>
<a name="ln907"> </a>
<a name="ln908">  // store the current filenum, lognum, etc</a>
<a name="ln909">  job_context-&gt;manifest_file_number = versions_-&gt;manifest_file_number();</a>
<a name="ln910">  job_context-&gt;pending_manifest_file_number =</a>
<a name="ln911">      versions_-&gt;pending_manifest_file_number();</a>
<a name="ln912">  job_context-&gt;log_number = versions_-&gt;MinLogNumber();</a>
<a name="ln913">  job_context-&gt;prev_log_number = versions_-&gt;prev_log_number();</a>
<a name="ln914"> </a>
<a name="ln915">  versions_-&gt;AddLiveFiles(&amp;job_context-&gt;sst_live);</a>
<a name="ln916">  if (doing_the_full_scan) {</a>
<a name="ln917">    InfoLogPrefix info_log_prefix(!db_options_.db_log_dir.empty(), dbname_);</a>
<a name="ln918">    for (size_t path_id = 0; path_id &lt; db_options_.db_paths.size(); path_id++) {</a>
<a name="ln919">      // set of all files in the directory. We'll exclude files that are still</a>
<a name="ln920">      // alive in the subsequent processings.</a>
<a name="ln921">      std::vector&lt;std::string&gt; files;</a>
<a name="ln922">      env_-&gt;GetChildrenWarnNotOk(db_options_.db_paths[path_id].path, &amp;files);</a>
<a name="ln923">      for (std::string file : files) {</a>
<a name="ln924">        uint64_t number;</a>
<a name="ln925">        FileType type;</a>
<a name="ln926">        if (!ParseFileName(file, &amp;number, info_log_prefix.prefix, &amp;type) ||</a>
<a name="ln927">            pending_outputs_-&gt;HasFileNumber(number)) {</a>
<a name="ln928">          continue;</a>
<a name="ln929">        }</a>
<a name="ln930">        // TODO(icanadi) clean up this mess to avoid having one-off &quot;/&quot; prefixes</a>
<a name="ln931">        job_context-&gt;full_scan_candidate_files.emplace_back(</a>
<a name="ln932">            &quot;/&quot; + file, static_cast&lt;uint32_t&gt;(path_id));</a>
<a name="ln933">      }</a>
<a name="ln934">    }</a>
<a name="ln935"> </a>
<a name="ln936">    // Add log files in wal_dir</a>
<a name="ln937">    if (db_options_.wal_dir != dbname_) {</a>
<a name="ln938">      std::vector&lt;std::string&gt; log_files;</a>
<a name="ln939">      env_-&gt;GetChildrenWarnNotOk(db_options_.wal_dir, &amp;log_files);</a>
<a name="ln940">      for (std::string log_file : log_files) {</a>
<a name="ln941">        job_context-&gt;full_scan_candidate_files.emplace_back(log_file, 0);</a>
<a name="ln942">      }</a>
<a name="ln943">    }</a>
<a name="ln944">    // Add info log files in db_log_dir</a>
<a name="ln945">    if (!db_options_.db_log_dir.empty() &amp;&amp; db_options_.db_log_dir != dbname_) {</a>
<a name="ln946">      std::vector&lt;std::string&gt; info_log_files;</a>
<a name="ln947">      // Ignore errors</a>
<a name="ln948">      env_-&gt;GetChildrenWarnNotOk(db_options_.db_log_dir, &amp;info_log_files);</a>
<a name="ln949">      for (std::string log_file : info_log_files) {</a>
<a name="ln950">        job_context-&gt;full_scan_candidate_files.emplace_back(log_file, 0);</a>
<a name="ln951">      }</a>
<a name="ln952">    }</a>
<a name="ln953">  }</a>
<a name="ln954"> </a>
<a name="ln955">  if (!alive_log_files_.empty()) {</a>
<a name="ln956">    uint64_t min_log_number = versions_-&gt;MinLogNumber();</a>
<a name="ln957">    // find newly obsoleted log files</a>
<a name="ln958">    while (alive_log_files_.begin()-&gt;number &lt; min_log_number) {</a>
<a name="ln959">      auto&amp; earliest = *alive_log_files_.begin();</a>
<a name="ln960">      if (db_options_.recycle_log_file_num &gt; log_recycle_files.size()) {</a>
<a name="ln961">        RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln962">            &quot;adding log %&quot; PRIu64 &quot; to recycle list\n&quot;, earliest.number);</a>
<a name="ln963">        log_recycle_files.push_back(earliest.number);</a>
<a name="ln964">      } else {</a>
<a name="ln965">        job_context-&gt;log_delete_files.push_back(earliest.number);</a>
<a name="ln966">      }</a>
<a name="ln967">      total_log_size_.fetch_sub(static_cast&lt;int64_t&gt;(earliest.size));</a>
<a name="ln968">      alive_log_files_.pop_front();</a>
<a name="ln969">      // Current log should always stay alive since it can't have</a>
<a name="ln970">      // number &lt; MinLogNumber().</a>
<a name="ln971">      assert(alive_log_files_.size());</a>
<a name="ln972">    }</a>
<a name="ln973">    while (!logs_.empty() &amp;&amp; logs_.front().number &lt; min_log_number) {</a>
<a name="ln974">      auto&amp; log = logs_.front();</a>
<a name="ln975">      if (log.getting_synced) {</a>
<a name="ln976">        log_sync_cv_.Wait();</a>
<a name="ln977">        // logs_ could have changed while we were waiting.</a>
<a name="ln978">        continue;</a>
<a name="ln979">      }</a>
<a name="ln980">      logs_to_free_.push_back(log.ReleaseWriter());</a>
<a name="ln981">      logs_.pop_front();</a>
<a name="ln982">    }</a>
<a name="ln983">    // Current log cannot be obsolete.</a>
<a name="ln984">    assert(!logs_.empty());</a>
<a name="ln985">  }</a>
<a name="ln986"> </a>
<a name="ln987">  // We're just cleaning up for DB::Write().</a>
<a name="ln988">  assert(job_context-&gt;logs_to_free.empty());</a>
<a name="ln989">  job_context-&gt;logs_to_free = logs_to_free_;</a>
<a name="ln990">  logs_to_free_.clear();</a>
<a name="ln991">}</a>
<a name="ln992"> </a>
<a name="ln993">namespace {</a>
<a name="ln994">bool CompareCandidateFile(const JobContext::CandidateFileInfo&amp; first,</a>
<a name="ln995">                          const JobContext::CandidateFileInfo&amp; second) {</a>
<a name="ln996">  if (first.file_name &gt; second.file_name) {</a>
<a name="ln997">    return true;</a>
<a name="ln998">  } else if (first.file_name &lt; second.file_name) {</a>
<a name="ln999">    return false;</a>
<a name="ln1000">  } else {</a>
<a name="ln1001">    return (first.path_id &gt; second.path_id);</a>
<a name="ln1002">  }</a>
<a name="ln1003">}</a>
<a name="ln1004">};  // namespace</a>
<a name="ln1005"> </a>
<a name="ln1006">// Diffs the files listed in filenames and those that do not</a>
<a name="ln1007">// belong to live files are posibly removed. Also, removes all the</a>
<a name="ln1008">// files in sst_delete_files and log_delete_files.</a>
<a name="ln1009">// It is not necessary to hold the mutex when invoking this method.</a>
<a name="ln1010">void DBImpl::PurgeObsoleteFiles(const JobContext&amp; state) {</a>
<a name="ln1011">  // we'd better have sth to delete</a>
<a name="ln1012">  assert(state.HaveSomethingToDelete());</a>
<a name="ln1013"> </a>
<a name="ln1014">  // this checks if FindObsoleteFiles() was run before. If not, don't do</a>
<a name="ln1015">  // PurgeObsoleteFiles(). If FindObsoleteFiles() was run, we need to also</a>
<a name="ln1016">  // run PurgeObsoleteFiles(), even if disable_delete_obsolete_files_ is true</a>
<a name="ln1017">  if (state.manifest_file_number == 0) {</a>
<a name="ln1018">    return;</a>
<a name="ln1019">  }</a>
<a name="ln1020"> </a>
<a name="ln1021">  // Now, convert live list to an unordered map, WITHOUT mutex held;</a>
<a name="ln1022">  // set is slow.</a>
<a name="ln1023">  std::unordered_map&lt;uint64_t, const FileDescriptor*&gt; sst_live_map;</a>
<a name="ln1024">  for (const FileDescriptor&amp; fd : state.sst_live) {</a>
<a name="ln1025">    sst_live_map[fd.GetNumber()] = &amp;fd;</a>
<a name="ln1026">  }</a>
<a name="ln1027"> </a>
<a name="ln1028">  auto candidate_files = state.full_scan_candidate_files;</a>
<a name="ln1029">  candidate_files.reserve(</a>
<a name="ln1030">      candidate_files.size() + state.sst_delete_files.size() +</a>
<a name="ln1031">      state.log_delete_files.size() + state.manifest_delete_files.size());</a>
<a name="ln1032">  // We may ignore the dbname when generating the file names.</a>
<a name="ln1033">  const char* kDumbDbName = &quot;&quot;;</a>
<a name="ln1034">  for (auto file : state.sst_delete_files) {</a>
<a name="ln1035">    // We only put base SST file in candidate_files</a>
<a name="ln1036">    candidate_files.emplace_back(</a>
<a name="ln1037">        MakeTableFileName(kDumbDbName, file-&gt;fd.GetNumber()),</a>
<a name="ln1038">        file-&gt;fd.GetPathId());</a>
<a name="ln1039">    delete file;</a>
<a name="ln1040">  }</a>
<a name="ln1041"> </a>
<a name="ln1042">  for (auto file_num : state.log_delete_files) {</a>
<a name="ln1043">    if (file_num &gt; 0) {</a>
<a name="ln1044">      candidate_files.emplace_back(LogFileName(kDumbDbName, file_num).substr(1),</a>
<a name="ln1045">                                   0);</a>
<a name="ln1046">    }</a>
<a name="ln1047">  }</a>
<a name="ln1048">  for (const auto&amp; filename : state.manifest_delete_files) {</a>
<a name="ln1049">    candidate_files.emplace_back(filename, 0);</a>
<a name="ln1050">  }</a>
<a name="ln1051"> </a>
<a name="ln1052">  // dedup state.candidate_files so we don't try to delete the same</a>
<a name="ln1053">  // file twice</a>
<a name="ln1054">  sort(candidate_files.begin(), candidate_files.end(), CompareCandidateFile);</a>
<a name="ln1055">  candidate_files.erase(unique(candidate_files.begin(), candidate_files.end()),</a>
<a name="ln1056">                        candidate_files.end());</a>
<a name="ln1057"> </a>
<a name="ln1058">  std::vector&lt;std::string&gt; old_info_log_files;</a>
<a name="ln1059">  InfoLogPrefix info_log_prefix(!db_options_.db_log_dir.empty(), dbname_);</a>
<a name="ln1060">  for (const auto&amp; candidate_file : candidate_files) {</a>
<a name="ln1061">    std::string to_delete = candidate_file.file_name;</a>
<a name="ln1062">    uint32_t path_id = candidate_file.path_id;</a>
<a name="ln1063">    uint64_t number;</a>
<a name="ln1064">    FileType type;</a>
<a name="ln1065">    // Ignore file if we cannot recognize it.</a>
<a name="ln1066">    if (!ParseFileName(to_delete, &amp;number, info_log_prefix.prefix, &amp;type)) {</a>
<a name="ln1067">      continue;</a>
<a name="ln1068">    }</a>
<a name="ln1069"> </a>
<a name="ln1070">    bool keep = true;</a>
<a name="ln1071">    switch (type) {</a>
<a name="ln1072">      case kLogFile:</a>
<a name="ln1073">        keep = ((number &gt;= state.log_number) ||</a>
<a name="ln1074">                (number == state.prev_log_number));</a>
<a name="ln1075">        break;</a>
<a name="ln1076">      case kDescriptorFile:</a>
<a name="ln1077">        // Keep my manifest file, and any newer incarnations'</a>
<a name="ln1078">        // (can happen during manifest roll)</a>
<a name="ln1079">        keep = (number &gt;= state.manifest_file_number);</a>
<a name="ln1080">        break;</a>
<a name="ln1081">      case kTableFile:</a>
<a name="ln1082">        // If the second condition is not there, this makes</a>
<a name="ln1083">        // DontDeletePendingOutputs fail</a>
<a name="ln1084">        keep = (sst_live_map.find(number) != sst_live_map.end()) ||</a>
<a name="ln1085">               pending_outputs_-&gt;HasFileNumber(number);</a>
<a name="ln1086">        break;</a>
<a name="ln1087">      case kTableSBlockFile:</a>
<a name="ln1088">        // Just skip, since we will process SST data file during processing of corresponding</a>
<a name="ln1089">        // SST base file.</a>
<a name="ln1090">        keep = true;</a>
<a name="ln1091">        break;</a>
<a name="ln1092">      case kTempFile:</a>
<a name="ln1093">        // Any temp files that are currently being written to must</a>
<a name="ln1094">        // be recorded in pending_outputs_, which is inserted into &quot;live&quot;.</a>
<a name="ln1095">        // Also, SetCurrentFile creates a temp file when writing out new</a>
<a name="ln1096">        // manifest, which is equal to state.pending_manifest_file_number. We</a>
<a name="ln1097">        // should not delete that file</a>
<a name="ln1098">        //</a>
<a name="ln1099">        // TODO(yhchiang): carefully modify the third condition to safely</a>
<a name="ln1100">        //                 remove the temp options files.</a>
<a name="ln1101">        keep = (sst_live_map.find(number) != sst_live_map.end()) ||</a>
<a name="ln1102">               (number == state.pending_manifest_file_number) ||</a>
<a name="ln1103">               (to_delete.find(kOptionsFileNamePrefix) != std::string::npos);</a>
<a name="ln1104">        break;</a>
<a name="ln1105">      case kInfoLogFile:</a>
<a name="ln1106">        keep = true;</a>
<a name="ln1107">        if (number != 0) {</a>
<a name="ln1108">          old_info_log_files.push_back(to_delete);</a>
<a name="ln1109">        }</a>
<a name="ln1110">        break;</a>
<a name="ln1111">      case kCurrentFile:</a>
<a name="ln1112">      case kDBLockFile:</a>
<a name="ln1113">      case kIdentityFile:</a>
<a name="ln1114">      case kMetaDatabase:</a>
<a name="ln1115">      case kOptionsFile:</a>
<a name="ln1116">        keep = true;</a>
<a name="ln1117">        break;</a>
<a name="ln1118">    }</a>
<a name="ln1119"> </a>
<a name="ln1120">    if (keep) {</a>
<a name="ln1121">      continue;</a>
<a name="ln1122">    }</a>
<a name="ln1123"> </a>
<a name="ln1124">    std::string fname;</a>
<a name="ln1125">    if (type == kTableFile) {</a>
<a name="ln1126">      // evict from cache</a>
<a name="ln1127">      TableCache::Evict(table_cache_.get(), number);</a>
<a name="ln1128">      fname = TableFileName(db_options_.db_paths, number, path_id);</a>
<a name="ln1129">    } else {</a>
<a name="ln1130">      fname = ((type == kLogFile) ?</a>
<a name="ln1131">          db_options_.wal_dir : dbname_) + &quot;/&quot; + to_delete;</a>
<a name="ln1132">    }</a>
<a name="ln1133"> </a>
<a name="ln1134">#ifndef ROCKSDB_LITE</a>
<a name="ln1135">    if (type == kLogFile &amp;&amp; (db_options_.WAL_ttl_seconds &gt; 0 ||</a>
<a name="ln1136">                              db_options_.WAL_size_limit_MB &gt; 0)) {</a>
<a name="ln1137">      wal_manager_.ArchiveWALFile(fname, number);</a>
<a name="ln1138">      continue;</a>
<a name="ln1139">    }</a>
<a name="ln1140">#endif  // !ROCKSDB_LITE</a>
<a name="ln1141">    Status file_deletion_status;</a>
<a name="ln1142">    if (type == kTableFile) {</a>
<a name="ln1143">      file_deletion_status = DeleteSSTFile(&amp;db_options_, fname, path_id);</a>
<a name="ln1144">      const std::string data_fname = TableBaseToDataFileName(fname);</a>
<a name="ln1145">      if (file_deletion_status.ok()) {</a>
<a name="ln1146">        // Delete corresponding data file if exists.</a>
<a name="ln1147">        Status s = db_options_.env-&gt;FileExists(data_fname);</a>
<a name="ln1148">        if (s.ok()) {</a>
<a name="ln1149">          file_deletion_status = DeleteSSTFile(&amp;db_options_, data_fname, path_id);</a>
<a name="ln1150">        } else if (!s.IsNotFound()) {</a>
<a name="ln1151">          file_deletion_status = s;</a>
<a name="ln1152">        }</a>
<a name="ln1153">      }</a>
<a name="ln1154">    } else {</a>
<a name="ln1155">      file_deletion_status = env_-&gt;DeleteFile(fname);</a>
<a name="ln1156">    }</a>
<a name="ln1157">    if (file_deletion_status.ok()) {</a>
<a name="ln1158">      RLOG(InfoLogLevel::DEBUG_LEVEL, db_options_.info_log,</a>
<a name="ln1159">          &quot;[JOB %d] Delete %s type=%d #%&quot; PRIu64 &quot; -- %s\n&quot;, state.job_id,</a>
<a name="ln1160">          fname.c_str(), type, number,</a>
<a name="ln1161">          file_deletion_status.ToString().c_str());</a>
<a name="ln1162">    } else if (env_-&gt;FileExists(fname).IsNotFound()) {</a>
<a name="ln1163">      RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln1164">          &quot;[JOB %d] Tried to delete a non-existing file %s type=%d #%&quot; PRIu64</a>
<a name="ln1165">          &quot; -- %s\n&quot;,</a>
<a name="ln1166">          state.job_id, fname.c_str(), type, number,</a>
<a name="ln1167">          file_deletion_status.ToString().c_str());</a>
<a name="ln1168">    } else {</a>
<a name="ln1169">      RLOG(InfoLogLevel::ERROR_LEVEL, db_options_.info_log,</a>
<a name="ln1170">          &quot;[JOB %d] Failed to delete %s type=%d #%&quot; PRIu64 &quot; -- %s\n&quot;,</a>
<a name="ln1171">          state.job_id, fname.c_str(), type, number,</a>
<a name="ln1172">          file_deletion_status.ToString().c_str());</a>
<a name="ln1173">    }</a>
<a name="ln1174">    if (type == kTableFile) {</a>
<a name="ln1175">      EventHelpers::LogAndNotifyTableFileDeletion(</a>
<a name="ln1176">          &amp;event_logger_, state.job_id, number, fname,</a>
<a name="ln1177">          file_deletion_status, GetName(),</a>
<a name="ln1178">          db_options_.listeners);</a>
<a name="ln1179">    }</a>
<a name="ln1180">  }</a>
<a name="ln1181"> </a>
<a name="ln1182">  // Delete old info log files.</a>
<a name="ln1183">  size_t old_info_log_file_count = old_info_log_files.size();</a>
<a name="ln1184">  if (old_info_log_file_count != 0 &amp;&amp;</a>
<a name="ln1185">      old_info_log_file_count &gt;= db_options_.keep_log_file_num) {</a>
<a name="ln1186">    std::sort(old_info_log_files.begin(), old_info_log_files.end());</a>
<a name="ln1187">    size_t end = old_info_log_file_count - db_options_.keep_log_file_num;</a>
<a name="ln1188">    for (unsigned int i = 0; i &lt;= end; i++) {</a>
<a name="ln1189">      std::string&amp; to_delete = old_info_log_files.at(i);</a>
<a name="ln1190">      std::string full_path_to_delete = (db_options_.db_log_dir.empty() ?</a>
<a name="ln1191">           dbname_ : db_options_.db_log_dir) + &quot;/&quot; + to_delete;</a>
<a name="ln1192">      RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln1193">          &quot;[JOB %d] Delete info log file %s\n&quot;, state.job_id,</a>
<a name="ln1194">          full_path_to_delete.c_str());</a>
<a name="ln1195">      Status s = env_-&gt;DeleteFile(full_path_to_delete);</a>
<a name="ln1196">      if (!s.ok()) {</a>
<a name="ln1197">        if (env_-&gt;FileExists(full_path_to_delete).IsNotFound()) {</a>
<a name="ln1198">          RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln1199">              &quot;[JOB %d] Tried to delete non-existing info log file %s FAILED &quot;</a>
<a name="ln1200">              &quot;-- %s\n&quot;,</a>
<a name="ln1201">              state.job_id, to_delete.c_str(), s.ToString().c_str());</a>
<a name="ln1202">        } else {</a>
<a name="ln1203">          RLOG(InfoLogLevel::ERROR_LEVEL, db_options_.info_log,</a>
<a name="ln1204">              &quot;[JOB %d] Delete info log file %s FAILED -- %s\n&quot;, state.job_id,</a>
<a name="ln1205">              to_delete.c_str(), s.ToString().c_str());</a>
<a name="ln1206">        }</a>
<a name="ln1207">      }</a>
<a name="ln1208">    }</a>
<a name="ln1209">  }</a>
<a name="ln1210">#ifndef ROCKSDB_LITE</a>
<a name="ln1211">  wal_manager_.PurgeObsoleteWALFiles();</a>
<a name="ln1212">#endif  // ROCKSDB_LITE</a>
<a name="ln1213">  LogFlush(db_options_.info_log);</a>
<a name="ln1214">}</a>
<a name="ln1215"> </a>
<a name="ln1216">void DBImpl::DeleteObsoleteFiles() {</a>
<a name="ln1217">  mutex_.AssertHeld();</a>
<a name="ln1218">  JobContext job_context(next_job_id_.fetch_add(1));</a>
<a name="ln1219">  FindObsoleteFiles(&amp;job_context, true);</a>
<a name="ln1220"> </a>
<a name="ln1221">  mutex_.Unlock();</a>
<a name="ln1222">  if (job_context.HaveSomethingToDelete()) {</a>
<a name="ln1223">    PurgeObsoleteFiles(job_context);</a>
<a name="ln1224">  }</a>
<a name="ln1225">  job_context.Clean();</a>
<a name="ln1226">  mutex_.Lock();</a>
<a name="ln1227">}</a>
<a name="ln1228"> </a>
<a name="ln1229">Status DBImpl::Directories::CreateAndNewDirectory(</a>
<a name="ln1230">    Env* env, const std::string&amp; dirname,</a>
<a name="ln1231">    std::unique_ptr&lt;Directory&gt;* directory) const {</a>
<a name="ln1232">  // We call CreateDirIfMissing() as the directory may already exist (if we</a>
<a name="ln1233">  // are reopening a DB), when this happens we don't want creating the</a>
<a name="ln1234">  // directory to cause an error. However, we need to check if creating the</a>
<a name="ln1235">  // directory fails or else we may get an obscure message about the lock</a>
<a name="ln1236">  // file not existing. One real-world example of this occurring is if</a>
<a name="ln1237">  // env-&gt;CreateDirIfMissing() doesn't create intermediate directories, e.g.</a>
<a name="ln1238">  // when dbname_ is &quot;dir/db&quot; but when &quot;dir&quot; doesn't exist.</a>
<a name="ln1239">  Status s = env-&gt;CreateDirIfMissing(dirname);</a>
<a name="ln1240">  if (!s.ok()) {</a>
<a name="ln1241">    return s;</a>
<a name="ln1242">  }</a>
<a name="ln1243">  return env-&gt;NewDirectory(dirname, directory);</a>
<a name="ln1244">}</a>
<a name="ln1245"> </a>
<a name="ln1246">Status DBImpl::Directories::SetDirectories(</a>
<a name="ln1247">    Env* env, const std::string&amp; dbname, const std::string&amp; wal_dir,</a>
<a name="ln1248">    const std::vector&lt;DbPath&gt;&amp; data_paths) {</a>
<a name="ln1249">  Status s = CreateAndNewDirectory(env, dbname, &amp;db_dir_);</a>
<a name="ln1250">  if (!s.ok()) {</a>
<a name="ln1251">    return s;</a>
<a name="ln1252">  }</a>
<a name="ln1253">  if (!wal_dir.empty() &amp;&amp; dbname != wal_dir) {</a>
<a name="ln1254">    s = CreateAndNewDirectory(env, wal_dir, &amp;wal_dir_);</a>
<a name="ln1255">    if (!s.ok()) {</a>
<a name="ln1256">      return s;</a>
<a name="ln1257">    }</a>
<a name="ln1258">  }</a>
<a name="ln1259"> </a>
<a name="ln1260">  data_dirs_.clear();</a>
<a name="ln1261">  for (auto&amp; p : data_paths) {</a>
<a name="ln1262">    const std::string db_path = p.path;</a>
<a name="ln1263">    if (db_path == dbname) {</a>
<a name="ln1264">      data_dirs_.emplace_back(nullptr);</a>
<a name="ln1265">    } else {</a>
<a name="ln1266">      std::unique_ptr&lt;Directory&gt; path_directory;</a>
<a name="ln1267">      s = CreateAndNewDirectory(env, db_path, &amp;path_directory);</a>
<a name="ln1268">      if (!s.ok()) {</a>
<a name="ln1269">        return s;</a>
<a name="ln1270">      }</a>
<a name="ln1271">      data_dirs_.emplace_back(path_directory.release());</a>
<a name="ln1272">    }</a>
<a name="ln1273">  }</a>
<a name="ln1274">  assert(data_dirs_.size() == data_paths.size());</a>
<a name="ln1275">  return Status::OK();</a>
<a name="ln1276">}</a>
<a name="ln1277"> </a>
<a name="ln1278">Directory* DBImpl::Directories::GetDataDir(size_t path_id) {</a>
<a name="ln1279">  assert(path_id &lt; data_dirs_.size());</a>
<a name="ln1280">  Directory* ret_dir = data_dirs_[path_id].get();</a>
<a name="ln1281">  if (ret_dir == nullptr) {</a>
<a name="ln1282">    // Should use db_dir_</a>
<a name="ln1283">    return db_dir_.get();</a>
<a name="ln1284">  }</a>
<a name="ln1285">  return ret_dir;</a>
<a name="ln1286">}</a>
<a name="ln1287"> </a>
<a name="ln1288">Status DBImpl::Recover(</a>
<a name="ln1289">    const std::vector&lt;ColumnFamilyDescriptor&gt;&amp; column_families, bool read_only,</a>
<a name="ln1290">    bool error_if_log_file_exist) {</a>
<a name="ln1291">  mutex_.AssertHeld();</a>
<a name="ln1292"> </a>
<a name="ln1293">  bool is_new_db = false;</a>
<a name="ln1294">  assert(db_lock_ == nullptr);</a>
<a name="ln1295">  if (!read_only) {</a>
<a name="ln1296">    Status s = directories_.SetDirectories(env_, dbname_, db_options_.wal_dir,</a>
<a name="ln1297">                                           db_options_.db_paths);</a>
<a name="ln1298">    if (!s.ok()) {</a>
<a name="ln1299">      return s;</a>
<a name="ln1300">    }</a>
<a name="ln1301"> </a>
<a name="ln1302">    s = env_-&gt;LockFile(LockFileName(dbname_), &amp;db_lock_);</a>
<a name="ln1303">    if (!s.ok()) {</a>
<a name="ln1304">      return s;</a>
<a name="ln1305">    }</a>
<a name="ln1306"> </a>
<a name="ln1307">    s = env_-&gt;FileExists(CurrentFileName(dbname_));</a>
<a name="ln1308">    if (s.IsNotFound()) {</a>
<a name="ln1309">      if (db_options_.create_if_missing) {</a>
<a name="ln1310">        s = NewDB();</a>
<a name="ln1311">        is_new_db = true;</a>
<a name="ln1312">        if (!s.ok()) {</a>
<a name="ln1313">          return s;</a>
<a name="ln1314">        }</a>
<a name="ln1315">      } else {</a>
<a name="ln1316">        return STATUS(InvalidArgument,</a>
<a name="ln1317">            dbname_, &quot;does not exist (create_if_missing is false)&quot;);</a>
<a name="ln1318">      }</a>
<a name="ln1319">    } else if (s.ok()) {</a>
<a name="ln1320">      if (db_options_.error_if_exists) {</a>
<a name="ln1321">        return STATUS(InvalidArgument,</a>
<a name="ln1322">            dbname_, &quot;exists (error_if_exists is true)&quot;);</a>
<a name="ln1323">      }</a>
<a name="ln1324">    } else {</a>
<a name="ln1325">      // Unexpected error reading file</a>
<a name="ln1326">      assert(s.IsIOError());</a>
<a name="ln1327">      return s;</a>
<a name="ln1328">    }</a>
<a name="ln1329">    // Check for the IDENTITY file and create it if not there</a>
<a name="ln1330">    s = env_-&gt;FileExists(IdentityFileName(dbname_));</a>
<a name="ln1331">    if (s.IsNotFound()) {</a>
<a name="ln1332">      s = SetIdentityFile(env_, dbname_);</a>
<a name="ln1333">      if (!s.ok()) {</a>
<a name="ln1334">        return s;</a>
<a name="ln1335">      }</a>
<a name="ln1336">    } else if (!s.ok()) {</a>
<a name="ln1337">      assert(s.IsIOError());</a>
<a name="ln1338">      return s;</a>
<a name="ln1339">    }</a>
<a name="ln1340">  }</a>
<a name="ln1341"> </a>
<a name="ln1342">  Status s = versions_-&gt;Recover(column_families, read_only);</a>
<a name="ln1343">  if (db_options_.paranoid_checks &amp;&amp; s.ok()) {</a>
<a name="ln1344">    s = CheckConsistency();</a>
<a name="ln1345">  }</a>
<a name="ln1346">  if (s.ok()) {</a>
<a name="ln1347">    SequenceNumber max_sequence(kMaxSequenceNumber);</a>
<a name="ln1348">    default_cf_handle_ = new ColumnFamilyHandleImpl(</a>
<a name="ln1349">        versions_-&gt;GetColumnFamilySet()-&gt;GetDefault(), this, &amp;mutex_);</a>
<a name="ln1350">    default_cf_internal_stats_ = default_cf_handle_-&gt;cfd()-&gt;internal_stats();</a>
<a name="ln1351">    single_column_family_mode_ =</a>
<a name="ln1352">        versions_-&gt;GetColumnFamilySet()-&gt;NumberOfColumnFamilies() == 1;</a>
<a name="ln1353"> </a>
<a name="ln1354">    // Recover from all newer log files than the ones named in the</a>
<a name="ln1355">    // descriptor (new log files may have been added by the previous</a>
<a name="ln1356">    // incarnation without registering them in the descriptor).</a>
<a name="ln1357">    //</a>
<a name="ln1358">    // Note that prev_log_number() is no longer used, but we pay</a>
<a name="ln1359">    // attention to it in case we are recovering a database</a>
<a name="ln1360">    // produced by an older version of rocksdb.</a>
<a name="ln1361">    const uint64_t min_log = versions_-&gt;MinLogNumber();</a>
<a name="ln1362">    const uint64_t prev_log = versions_-&gt;prev_log_number();</a>
<a name="ln1363">    std::vector&lt;std::string&gt; filenames;</a>
<a name="ln1364">    s = env_-&gt;GetChildren(db_options_.wal_dir, &amp;filenames);</a>
<a name="ln1365">    if (!s.ok()) {</a>
<a name="ln1366">      return s;</a>
<a name="ln1367">    }</a>
<a name="ln1368"> </a>
<a name="ln1369">    std::vector&lt;uint64_t&gt; logs;</a>
<a name="ln1370">    for (size_t i = 0; i &lt; filenames.size(); i++) {</a>
<a name="ln1371">      uint64_t number;</a>
<a name="ln1372">      FileType type;</a>
<a name="ln1373">      if (ParseFileName(filenames[i], &amp;number, &amp;type) &amp;&amp; type == kLogFile) {</a>
<a name="ln1374">        if (is_new_db) {</a>
<a name="ln1375">          return STATUS(Corruption,</a>
<a name="ln1376">              &quot;While creating a new Db, wal_dir contains &quot;</a>
<a name="ln1377">              &quot;existing log file: &quot;,</a>
<a name="ln1378">              filenames[i]);</a>
<a name="ln1379">        } else if ((number &gt;= min_log) || (number == prev_log)) {</a>
<a name="ln1380">          logs.push_back(number);</a>
<a name="ln1381">        }</a>
<a name="ln1382">      }</a>
<a name="ln1383">    }</a>
<a name="ln1384"> </a>
<a name="ln1385">    if (logs.size() &gt; 0 &amp;&amp; error_if_log_file_exist) {</a>
<a name="ln1386">      return STATUS(Corruption, &quot;&quot;</a>
<a name="ln1387">          &quot;The db was opened in readonly mode with error_if_log_file_exist&quot;</a>
<a name="ln1388">          &quot;flag but a log file already exists&quot;);</a>
<a name="ln1389">    }</a>
<a name="ln1390"> </a>
<a name="ln1391">    if (!logs.empty()) {</a>
<a name="ln1392">      // Recover in the order in which the logs were generated</a>
<a name="ln1393">      std::sort(logs.begin(), logs.end());</a>
<a name="ln1394">      s = RecoverLogFiles(logs, &amp;max_sequence, read_only);</a>
<a name="ln1395">      if (!s.ok()) {</a>
<a name="ln1396">        // Clear memtables if recovery failed</a>
<a name="ln1397">        for (auto cfd : *versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln1398">          cfd-&gt;CreateNewMemtable(*cfd-&gt;GetLatestMutableCFOptions(),</a>
<a name="ln1399">                                 kMaxSequenceNumber);</a>
<a name="ln1400">        }</a>
<a name="ln1401">      }</a>
<a name="ln1402">    }</a>
<a name="ln1403"> </a>
<a name="ln1404">    SetTickerCount(stats_, SEQUENCE_NUMBER, versions_-&gt;LastSequence());</a>
<a name="ln1405">  }</a>
<a name="ln1406"> </a>
<a name="ln1407">  // Initial value</a>
<a name="ln1408">  max_total_in_memory_state_ = 0;</a>
<a name="ln1409">  for (auto cfd : *versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln1410">    auto* mutable_cf_options = cfd-&gt;GetLatestMutableCFOptions();</a>
<a name="ln1411">    max_total_in_memory_state_ += mutable_cf_options-&gt;write_buffer_size *</a>
<a name="ln1412">                                  mutable_cf_options-&gt;max_write_buffer_number;</a>
<a name="ln1413">  }</a>
<a name="ln1414"> </a>
<a name="ln1415">  return s;</a>
<a name="ln1416">}</a>
<a name="ln1417"> </a>
<a name="ln1418">// REQUIRES: log_numbers are sorted in ascending order</a>
<a name="ln1419">Status DBImpl::RecoverLogFiles(const std::vector&lt;uint64_t&gt;&amp; log_numbers,</a>
<a name="ln1420">                               SequenceNumber* max_sequence, bool read_only) {</a>
<a name="ln1421">  struct LogReporter : public log::Reader::Reporter {</a>
<a name="ln1422">    Env* env;</a>
<a name="ln1423">    Logger* info_log;</a>
<a name="ln1424">    const char* fname;</a>
<a name="ln1425">    Status* status;  // nullptr if db_options_.paranoid_checks==false</a>
<a name="ln1426">    void Corruption(size_t bytes, const Status&amp; s) override {</a>
<a name="ln1427">      RLOG(InfoLogLevel::WARN_LEVEL,</a>
<a name="ln1428">          info_log, &quot;%s%s: dropping %d bytes; %s&quot;,</a>
<a name="ln1429">          (this-&gt;status == nullptr ? &quot;(ignoring error) &quot; : &quot;&quot;),</a>
<a name="ln1430">          fname, static_cast&lt;int&gt;(bytes), s.ToString().c_str());</a>
<a name="ln1431">      if (this-&gt;status != nullptr &amp;&amp; this-&gt;status-&gt;ok()) {</a>
<a name="ln1432">        *this-&gt;status = s;</a>
<a name="ln1433">      }</a>
<a name="ln1434">    }</a>
<a name="ln1435">  };</a>
<a name="ln1436"> </a>
<a name="ln1437">  mutex_.AssertHeld();</a>
<a name="ln1438">  Status status;</a>
<a name="ln1439">  std::unordered_map&lt;int, VersionEdit&gt; version_edits;</a>
<a name="ln1440">  // no need to refcount because iteration is under mutex</a>
<a name="ln1441">  for (auto cfd : *versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln1442">    VersionEdit edit;</a>
<a name="ln1443">    edit.SetColumnFamily(cfd-&gt;GetID());</a>
<a name="ln1444">    auto frontier = versions_-&gt;FlushedFrontier();</a>
<a name="ln1445">    if (frontier) {</a>
<a name="ln1446">      edit.UpdateFlushedFrontier(frontier-&gt;Clone());</a>
<a name="ln1447">    }</a>
<a name="ln1448">    version_edits.insert({cfd-&gt;GetID(), edit});</a>
<a name="ln1449">  }</a>
<a name="ln1450">  int job_id = next_job_id_.fetch_add(1);</a>
<a name="ln1451">  {</a>
<a name="ln1452">    auto stream = event_logger_.Log();</a>
<a name="ln1453">    stream &lt;&lt; &quot;job&quot; &lt;&lt; job_id &lt;&lt; &quot;event&quot;</a>
<a name="ln1454">           &lt;&lt; &quot;recovery_started&quot;;</a>
<a name="ln1455">    stream &lt;&lt; &quot;log_files&quot;;</a>
<a name="ln1456">    stream.StartArray();</a>
<a name="ln1457">    for (auto log_number : log_numbers) {</a>
<a name="ln1458">      stream &lt;&lt; log_number;</a>
<a name="ln1459">    }</a>
<a name="ln1460">    stream.EndArray();</a>
<a name="ln1461">  }</a>
<a name="ln1462"> </a>
<a name="ln1463">  bool continue_replay_log = true;</a>
<a name="ln1464">  for (auto log_number : log_numbers) {</a>
<a name="ln1465">    // The previous incarnation may not have written any MANIFEST</a>
<a name="ln1466">    // records after allocating this log number.  So we manually</a>
<a name="ln1467">    // update the file number allocation counter in VersionSet.</a>
<a name="ln1468">    versions_-&gt;MarkFileNumberUsedDuringRecovery(log_number);</a>
<a name="ln1469">    // Open the log file</a>
<a name="ln1470">    std::string fname = LogFileName(db_options_.wal_dir, log_number);</a>
<a name="ln1471">    unique_ptr&lt;SequentialFileReader&gt; file_reader;</a>
<a name="ln1472">    {</a>
<a name="ln1473">      unique_ptr&lt;SequentialFile&gt; file;</a>
<a name="ln1474">      status = env_-&gt;NewSequentialFile(fname, &amp;file, env_options_);</a>
<a name="ln1475">      if (!status.ok()) {</a>
<a name="ln1476">        MaybeIgnoreError(&amp;status);</a>
<a name="ln1477">        if (!status.ok()) {</a>
<a name="ln1478">          return status;</a>
<a name="ln1479">        } else {</a>
<a name="ln1480">          // Fail with one log file, but that's ok.</a>
<a name="ln1481">          // Try next one.</a>
<a name="ln1482">          continue;</a>
<a name="ln1483">        }</a>
<a name="ln1484">      }</a>
<a name="ln1485">      file_reader.reset(new SequentialFileReader(std::move(file)));</a>
<a name="ln1486">    }</a>
<a name="ln1487"> </a>
<a name="ln1488">    // Create the log reader.</a>
<a name="ln1489">    LogReporter reporter;</a>
<a name="ln1490">    reporter.env = env_;</a>
<a name="ln1491">    reporter.info_log = db_options_.info_log.get();</a>
<a name="ln1492">    reporter.fname = fname.c_str();</a>
<a name="ln1493">    if (!db_options_.paranoid_checks ||</a>
<a name="ln1494">        db_options_.wal_recovery_mode ==</a>
<a name="ln1495">            WALRecoveryMode::kSkipAnyCorruptedRecords) {</a>
<a name="ln1496">      reporter.status = nullptr;</a>
<a name="ln1497">    } else {</a>
<a name="ln1498">      reporter.status = &amp;status;</a>
<a name="ln1499">    }</a>
<a name="ln1500">    // We intentially make log::Reader do checksumming even if</a>
<a name="ln1501">    // paranoid_checks==false so that corruptions cause entire commits</a>
<a name="ln1502">    // to be skipped instead of propagating bad information (like overly</a>
<a name="ln1503">    // large sequence numbers).</a>
<a name="ln1504">    log::Reader reader(db_options_.info_log, std::move(file_reader), &amp;reporter,</a>
<a name="ln1505">                       true /*checksum*/, 0 /*initial_offset*/, log_number);</a>
<a name="ln1506">    RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln1507">        &quot;Recovering log #%&quot; PRIu64 &quot; mode %d skip-recovery %d&quot;, log_number,</a>
<a name="ln1508">        db_options_.wal_recovery_mode, !continue_replay_log);</a>
<a name="ln1509"> </a>
<a name="ln1510">    // Determine if we should tolerate incomplete records at the tail end of the</a>
<a name="ln1511">    // Read all the records and add to a memtable</a>
<a name="ln1512">    std::string scratch;</a>
<a name="ln1513">    Slice record;</a>
<a name="ln1514">    WriteBatch batch;</a>
<a name="ln1515"> </a>
<a name="ln1516">    if (!continue_replay_log) {</a>
<a name="ln1517">      uint64_t bytes;</a>
<a name="ln1518">      if (env_-&gt;GetFileSize(fname, &amp;bytes).ok()) {</a>
<a name="ln1519">        auto info_log = db_options_.info_log.get();</a>
<a name="ln1520">        RLOG(InfoLogLevel::WARN_LEVEL, info_log, &quot;%s: dropping %d bytes&quot;,</a>
<a name="ln1521">            fname.c_str(), static_cast&lt;int&gt;(bytes));</a>
<a name="ln1522">      }</a>
<a name="ln1523">    }</a>
<a name="ln1524"> </a>
<a name="ln1525">    while (</a>
<a name="ln1526">        continue_replay_log &amp;&amp;</a>
<a name="ln1527">        reader.ReadRecord(&amp;record, &amp;scratch, db_options_.wal_recovery_mode) &amp;&amp;</a>
<a name="ln1528">        status.ok()) {</a>
<a name="ln1529">      if (record.size() &lt; 12) {</a>
<a name="ln1530">        reporter.Corruption(record.size(),</a>
<a name="ln1531">                            STATUS(Corruption, &quot;log record too small&quot;));</a>
<a name="ln1532">        continue;</a>
<a name="ln1533">      }</a>
<a name="ln1534">      WriteBatchInternal::SetContents(&amp;batch, record);</a>
<a name="ln1535"> </a>
<a name="ln1536">#ifndef ROCKSDB_LITE</a>
<a name="ln1537">      if (db_options_.wal_filter != nullptr) {</a>
<a name="ln1538">        WriteBatch new_batch;</a>
<a name="ln1539">        bool batch_changed = false;</a>
<a name="ln1540"> </a>
<a name="ln1541">        WalFilter::WalProcessingOption wal_processing_option =</a>
<a name="ln1542">            db_options_.wal_filter-&gt;LogRecord(batch, &amp;new_batch,</a>
<a name="ln1543">                                              &amp;batch_changed);</a>
<a name="ln1544"> </a>
<a name="ln1545">        switch (wal_processing_option) {</a>
<a name="ln1546">          case WalFilter::WalProcessingOption::kContinueProcessing:</a>
<a name="ln1547">            // do nothing, proceeed normally</a>
<a name="ln1548">            break;</a>
<a name="ln1549">          case WalFilter::WalProcessingOption::kIgnoreCurrentRecord:</a>
<a name="ln1550">            // skip current record</a>
<a name="ln1551">            continue;</a>
<a name="ln1552">          case WalFilter::WalProcessingOption::kStopReplay:</a>
<a name="ln1553">            // skip current record and stop replay</a>
<a name="ln1554">            continue_replay_log = false;</a>
<a name="ln1555">            continue;</a>
<a name="ln1556">          case WalFilter::WalProcessingOption::kCorruptedRecord: {</a>
<a name="ln1557">            status = STATUS(Corruption, &quot;Corruption reported by Wal Filter &quot;,</a>
<a name="ln1558">                                        db_options_.wal_filter-&gt;Name());</a>
<a name="ln1559">            MaybeIgnoreError(&amp;status);</a>
<a name="ln1560">            if (!status.ok()) {</a>
<a name="ln1561">              reporter.Corruption(record.size(), status);</a>
<a name="ln1562">              continue;</a>
<a name="ln1563">            }</a>
<a name="ln1564">            break;</a>
<a name="ln1565">          }</a>
<a name="ln1566">          default: {</a>
<a name="ln1567">            assert(false);  // unhandled case</a>
<a name="ln1568">            status = STATUS(NotSupported,</a>
<a name="ln1569">                &quot;Unknown WalProcessingOption returned&quot;</a>
<a name="ln1570">                &quot; by Wal Filter &quot;,</a>
<a name="ln1571">                db_options_.wal_filter-&gt;Name());</a>
<a name="ln1572">            MaybeIgnoreError(&amp;status);</a>
<a name="ln1573">            if (!status.ok()) {</a>
<a name="ln1574">              return status;</a>
<a name="ln1575">            } else {</a>
<a name="ln1576">              // Ignore the error with current record processing.</a>
<a name="ln1577">              continue;</a>
<a name="ln1578">            }</a>
<a name="ln1579">          }</a>
<a name="ln1580">        }</a>
<a name="ln1581"> </a>
<a name="ln1582">        if (batch_changed) {</a>
<a name="ln1583">          // Make sure that the count in the new batch is</a>
<a name="ln1584">          // within the orignal count.</a>
<a name="ln1585">          int new_count = WriteBatchInternal::Count(&amp;new_batch);</a>
<a name="ln1586">          int original_count = WriteBatchInternal::Count(&amp;batch);</a>
<a name="ln1587">          if (new_count &gt; original_count) {</a>
<a name="ln1588">            RLOG(InfoLogLevel::FATAL_LEVEL, db_options_.info_log,</a>
<a name="ln1589">                &quot;Recovering log #%&quot; PRIu64</a>
<a name="ln1590">                &quot; mode %d log filter %s returned &quot;</a>
<a name="ln1591">                &quot;more records (%d) than original (%d) which is not allowed. &quot;</a>
<a name="ln1592">                &quot;Aborting recovery.&quot;,</a>
<a name="ln1593">                log_number, db_options_.wal_recovery_mode,</a>
<a name="ln1594">                db_options_.wal_filter-&gt;Name(), new_count, original_count);</a>
<a name="ln1595">            status = STATUS(NotSupported,</a>
<a name="ln1596">                &quot;More than original # of records &quot;</a>
<a name="ln1597">                &quot;returned by Wal Filter &quot;,</a>
<a name="ln1598">                db_options_.wal_filter-&gt;Name());</a>
<a name="ln1599">            return status;</a>
<a name="ln1600">          }</a>
<a name="ln1601">          // Set the same sequence number in the new_batch</a>
<a name="ln1602">          // as the original batch.</a>
<a name="ln1603">          WriteBatchInternal::SetSequence(&amp;new_batch,</a>
<a name="ln1604">                                          WriteBatchInternal::Sequence(&amp;batch));</a>
<a name="ln1605">          batch = new_batch;</a>
<a name="ln1606">        }</a>
<a name="ln1607">      }</a>
<a name="ln1608">#endif  // ROCKSDB_LITE</a>
<a name="ln1609"> </a>
<a name="ln1610">      // If column family was not found, it might mean that the WAL write</a>
<a name="ln1611">      // batch references to the column family that was dropped after the</a>
<a name="ln1612">      // insert. We don't want to fail the whole write batch in that case --</a>
<a name="ln1613">      // we just ignore the update.</a>
<a name="ln1614">      // That's why we set ignore missing column families to true</a>
<a name="ln1615">      status =</a>
<a name="ln1616">          WriteBatchInternal::InsertInto(&amp;batch, column_family_memtables_.get(),</a>
<a name="ln1617">                                         &amp;flush_scheduler_, true, log_number);</a>
<a name="ln1618"> </a>
<a name="ln1619">      MaybeIgnoreError(&amp;status);</a>
<a name="ln1620">      if (!status.ok()) {</a>
<a name="ln1621">        // We are treating this as a failure while reading since we read valid</a>
<a name="ln1622">        // blocks that do not form coherent data</a>
<a name="ln1623">        reporter.Corruption(record.size(), status);</a>
<a name="ln1624">        continue;</a>
<a name="ln1625">      }</a>
<a name="ln1626"> </a>
<a name="ln1627">      const SequenceNumber last_seq = WriteBatchInternal::Sequence(&amp;batch) +</a>
<a name="ln1628">                                      WriteBatchInternal::Count(&amp;batch) - 1;</a>
<a name="ln1629">      if ((*max_sequence == kMaxSequenceNumber) || (last_seq &gt; *max_sequence)) {</a>
<a name="ln1630">        *max_sequence = last_seq;</a>
<a name="ln1631">      }</a>
<a name="ln1632"> </a>
<a name="ln1633">      if (!read_only) {</a>
<a name="ln1634">        // we can do this because this is called before client has access to the</a>
<a name="ln1635">        // DB and there is only a single thread operating on DB</a>
<a name="ln1636">        ColumnFamilyData* cfd;</a>
<a name="ln1637"> </a>
<a name="ln1638">        while ((cfd = flush_scheduler_.TakeNextColumnFamily()) != nullptr) {</a>
<a name="ln1639">          cfd-&gt;Unref();</a>
<a name="ln1640">          // If this asserts, it means that InsertInto failed in</a>
<a name="ln1641">          // filtering updates to already-flushed column families</a>
<a name="ln1642">          assert(cfd-&gt;GetLogNumber() &lt;= log_number);</a>
<a name="ln1643">          auto iter = version_edits.find(cfd-&gt;GetID());</a>
<a name="ln1644">          assert(iter != version_edits.end());</a>
<a name="ln1645">          VersionEdit* edit = &amp;iter-&gt;second;</a>
<a name="ln1646">          status = WriteLevel0TableForRecovery(job_id, cfd, cfd-&gt;mem(), edit);</a>
<a name="ln1647">          if (!status.ok()) {</a>
<a name="ln1648">            // Reflect errors immediately so that conditions like full</a>
<a name="ln1649">            // file-systems cause the DB::Open() to fail.</a>
<a name="ln1650">            return status;</a>
<a name="ln1651">          }</a>
<a name="ln1652"> </a>
<a name="ln1653">          cfd-&gt;CreateNewMemtable(*cfd-&gt;GetLatestMutableCFOptions(),</a>
<a name="ln1654">                                 *max_sequence);</a>
<a name="ln1655">        }</a>
<a name="ln1656">      }</a>
<a name="ln1657">    }</a>
<a name="ln1658"> </a>
<a name="ln1659">    if (!status.ok()) {</a>
<a name="ln1660">      if (db_options_.wal_recovery_mode ==</a>
<a name="ln1661">             WALRecoveryMode::kSkipAnyCorruptedRecords) {</a>
<a name="ln1662">        // We should ignore all errors unconditionally</a>
<a name="ln1663">        status = Status::OK();</a>
<a name="ln1664">      } else if (db_options_.wal_recovery_mode ==</a>
<a name="ln1665">                 WALRecoveryMode::kPointInTimeRecovery) {</a>
<a name="ln1666">        // We should ignore the error but not continue replaying</a>
<a name="ln1667">        status = Status::OK();</a>
<a name="ln1668">        continue_replay_log = false;</a>
<a name="ln1669"> </a>
<a name="ln1670">        RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln1671">            &quot;Point in time recovered to log #%&quot; PRIu64 &quot; seq #%&quot; PRIu64,</a>
<a name="ln1672">            log_number, *max_sequence);</a>
<a name="ln1673">      } else {</a>
<a name="ln1674">        assert(db_options_.wal_recovery_mode ==</a>
<a name="ln1675">                  WALRecoveryMode::kTolerateCorruptedTailRecords</a>
<a name="ln1676">               || db_options_.wal_recovery_mode ==</a>
<a name="ln1677">                  WALRecoveryMode::kAbsoluteConsistency);</a>
<a name="ln1678">        return status;</a>
<a name="ln1679">      }</a>
<a name="ln1680">    }</a>
<a name="ln1681"> </a>
<a name="ln1682">    flush_scheduler_.Clear();</a>
<a name="ln1683">    if ((*max_sequence != kMaxSequenceNumber) &amp;&amp; (versions_-&gt;LastSequence() &lt; *max_sequence)) {</a>
<a name="ln1684">      versions_-&gt;SetLastSequence(*max_sequence);</a>
<a name="ln1685">    }</a>
<a name="ln1686">  }</a>
<a name="ln1687"> </a>
<a name="ln1688">  if (!read_only) {</a>
<a name="ln1689">    // no need to refcount since client still doesn't have access</a>
<a name="ln1690">    // to the DB and can not drop column families while we iterate</a>
<a name="ln1691">    auto max_log_number = log_numbers.back();</a>
<a name="ln1692">    for (auto cfd : *versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln1693">      auto iter = version_edits.find(cfd-&gt;GetID());</a>
<a name="ln1694">      assert(iter != version_edits.end());</a>
<a name="ln1695">      VersionEdit* edit = &amp;iter-&gt;second;</a>
<a name="ln1696"> </a>
<a name="ln1697">      if (cfd-&gt;GetLogNumber() &gt; max_log_number) {</a>
<a name="ln1698">        // Column family cfd has already flushed the data</a>
<a name="ln1699">        // from all logs. Memtable has to be empty because</a>
<a name="ln1700">        // we filter the updates based on log_number</a>
<a name="ln1701">        // (in WriteBatch::InsertInto)</a>
<a name="ln1702">        assert(cfd-&gt;mem()-&gt;GetFirstSequenceNumber() == 0);</a>
<a name="ln1703">        assert(edit-&gt;NumEntries() == 0);</a>
<a name="ln1704">        continue;</a>
<a name="ln1705">      }</a>
<a name="ln1706"> </a>
<a name="ln1707">      // flush the final memtable (if non-empty)</a>
<a name="ln1708">      if (cfd-&gt;mem()-&gt;GetFirstSequenceNumber() != 0) {</a>
<a name="ln1709">        status = WriteLevel0TableForRecovery(job_id, cfd, cfd-&gt;mem(), edit);</a>
<a name="ln1710">        if (!status.ok()) {</a>
<a name="ln1711">          // Recovery failed</a>
<a name="ln1712">          break;</a>
<a name="ln1713">        }</a>
<a name="ln1714"> </a>
<a name="ln1715">        cfd-&gt;CreateNewMemtable(*cfd-&gt;GetLatestMutableCFOptions(),</a>
<a name="ln1716">                               *max_sequence);</a>
<a name="ln1717">      }</a>
<a name="ln1718"> </a>
<a name="ln1719">      // write MANIFEST with update</a>
<a name="ln1720">      // writing log_number in the manifest means that any log file</a>
<a name="ln1721">      // with number strongly less than (log_number + 1) is already</a>
<a name="ln1722">      // recovered and should be ignored on next reincarnation.</a>
<a name="ln1723">      // Since we already recovered max_log_number, we want all logs</a>
<a name="ln1724">      // with numbers `&lt;= max_log_number` (includes this one) to be ignored</a>
<a name="ln1725">      edit-&gt;SetLogNumber(max_log_number + 1);</a>
<a name="ln1726">      // we must mark the next log number as used, even though it's</a>
<a name="ln1727">      // not actually used. that is because VersionSet assumes</a>
<a name="ln1728">      // VersionSet::next_file_number_ always to be strictly greater than any</a>
<a name="ln1729">      // log number</a>
<a name="ln1730">      versions_-&gt;MarkFileNumberUsedDuringRecovery(max_log_number + 1);</a>
<a name="ln1731">      status = versions_-&gt;LogAndApply(</a>
<a name="ln1732">          cfd, *cfd-&gt;GetLatestMutableCFOptions(), edit, &amp;mutex_);</a>
<a name="ln1733">      if (!status.ok()) {</a>
<a name="ln1734">        // Recovery failed</a>
<a name="ln1735">        break;</a>
<a name="ln1736">      }</a>
<a name="ln1737">    }</a>
<a name="ln1738">  }</a>
<a name="ln1739"> </a>
<a name="ln1740">  event_logger_.Log() &lt;&lt; &quot;job&quot; &lt;&lt; job_id &lt;&lt; &quot;event&quot;</a>
<a name="ln1741">                      &lt;&lt; &quot;recovery_finished&quot;;</a>
<a name="ln1742"> </a>
<a name="ln1743">  return status;</a>
<a name="ln1744">}</a>
<a name="ln1745"> </a>
<a name="ln1746">Status DBImpl::WriteLevel0TableForRecovery(int job_id, ColumnFamilyData* cfd,</a>
<a name="ln1747">                                           MemTable* mem, VersionEdit* edit) {</a>
<a name="ln1748">  mutex_.AssertHeld();</a>
<a name="ln1749">  const uint64_t start_micros = env_-&gt;NowMicros();</a>
<a name="ln1750">  FileMetaData meta;</a>
<a name="ln1751">  Status s;</a>
<a name="ln1752">  {</a>
<a name="ln1753">    auto file_number_holder = pending_outputs_-&gt;NewFileNumber();</a>
<a name="ln1754">    meta.fd = FileDescriptor(file_number_holder.Last(), 0, 0, 0);</a>
<a name="ln1755">    const auto* frontier = mem-&gt;Frontiers();</a>
<a name="ln1756">    if (frontier) {</a>
<a name="ln1757">      meta.smallest.user_frontier = frontier-&gt;Smallest().Clone();</a>
<a name="ln1758">      meta.largest.user_frontier = frontier-&gt;Largest().Clone();</a>
<a name="ln1759">    }</a>
<a name="ln1760">    ReadOptions ro;</a>
<a name="ln1761">    ro.total_order_seek = true;</a>
<a name="ln1762">    Arena arena;</a>
<a name="ln1763">    TableProperties table_properties;</a>
<a name="ln1764">    {</a>
<a name="ln1765">      ScopedArenaIterator iter(mem-&gt;NewIterator(ro, &amp;arena));</a>
<a name="ln1766">      RLOG(InfoLogLevel::DEBUG_LEVEL, db_options_.info_log,</a>
<a name="ln1767">          &quot;[%s] [WriteLevel0TableForRecovery]&quot;</a>
<a name="ln1768">          &quot; Level-0 table #%&quot; PRIu64 &quot;: started&quot;,</a>
<a name="ln1769">          cfd-&gt;GetName().c_str(), meta.fd.GetNumber());</a>
<a name="ln1770"> </a>
<a name="ln1771">      bool paranoid_file_checks =</a>
<a name="ln1772">          cfd-&gt;GetLatestMutableCFOptions()-&gt;paranoid_file_checks;</a>
<a name="ln1773">      {</a>
<a name="ln1774">        mutex_.Unlock();</a>
<a name="ln1775">        TableFileCreationInfo info;</a>
<a name="ln1776"> </a>
<a name="ln1777">        SequenceNumber earliest_write_conflict_snapshot;</a>
<a name="ln1778">        std::vector&lt;SequenceNumber&gt; snapshot_seqs =</a>
<a name="ln1779">            snapshots_.GetAll(&amp;earliest_write_conflict_snapshot);</a>
<a name="ln1780"> </a>
<a name="ln1781">        s = BuildTable(dbname_,</a>
<a name="ln1782">                       env_,</a>
<a name="ln1783">                       *cfd-&gt;ioptions(),</a>
<a name="ln1784">                       env_options_,</a>
<a name="ln1785">                       cfd-&gt;table_cache(),</a>
<a name="ln1786">                       iter.get(),</a>
<a name="ln1787">                       &amp;meta,</a>
<a name="ln1788">                       cfd-&gt;internal_comparator(),</a>
<a name="ln1789">                       cfd-&gt;int_tbl_prop_collector_factories(),</a>
<a name="ln1790">                       cfd-&gt;GetID(),</a>
<a name="ln1791">                       snapshot_seqs,</a>
<a name="ln1792">                       earliest_write_conflict_snapshot,</a>
<a name="ln1793">                       GetCompressionFlush(*cfd-&gt;ioptions()),</a>
<a name="ln1794">                       cfd-&gt;ioptions()-&gt;compression_opts,</a>
<a name="ln1795">                       paranoid_file_checks,</a>
<a name="ln1796">                       cfd-&gt;internal_stats(),</a>
<a name="ln1797">                       db_options_.boundary_extractor.get(),</a>
<a name="ln1798">                       Env::IO_HIGH,</a>
<a name="ln1799">                       &amp;info.table_properties);</a>
<a name="ln1800">        LogFlush(db_options_.info_log);</a>
<a name="ln1801">        RLOG(InfoLogLevel::DEBUG_LEVEL, db_options_.info_log,</a>
<a name="ln1802">            &quot;[%s] [WriteLevel0TableForRecovery]&quot;</a>
<a name="ln1803">            &quot; Level-0 table #%&quot; PRIu64 &quot;: %&quot; PRIu64 &quot; bytes %s&quot;,</a>
<a name="ln1804">            cfd-&gt;GetName().c_str(), meta.fd.GetNumber(), meta.fd.GetTotalFileSize(),</a>
<a name="ln1805">            s.ToString().c_str());</a>
<a name="ln1806"> </a>
<a name="ln1807">        // output to event logger</a>
<a name="ln1808">        if (s.ok()) {</a>
<a name="ln1809">          info.db_name = dbname_;</a>
<a name="ln1810">          info.cf_name = cfd-&gt;GetName();</a>
<a name="ln1811">          info.file_path = TableFileName(db_options_.db_paths,</a>
<a name="ln1812">                                         meta.fd.GetNumber(),</a>
<a name="ln1813">                                         meta.fd.GetPathId());</a>
<a name="ln1814">          info.file_size = meta.fd.GetTotalFileSize();</a>
<a name="ln1815">          info.job_id = job_id;</a>
<a name="ln1816">          EventHelpers::LogAndNotifyTableFileCreation(</a>
<a name="ln1817">              &amp;event_logger_, db_options_.listeners, meta.fd, info);</a>
<a name="ln1818">        }</a>
<a name="ln1819">        mutex_.Lock();</a>
<a name="ln1820">      }</a>
<a name="ln1821">    }</a>
<a name="ln1822">  }</a>
<a name="ln1823"> </a>
<a name="ln1824">  // Note that if file_size is zero, the file has been deleted and</a>
<a name="ln1825">  // should not be added to the manifest.</a>
<a name="ln1826">  int level = 0;</a>
<a name="ln1827">  if (s.ok() &amp;&amp; meta.fd.GetTotalFileSize() &gt; 0) {</a>
<a name="ln1828">    edit-&gt;AddCleanedFile(level, meta);</a>
<a name="ln1829">  }</a>
<a name="ln1830"> </a>
<a name="ln1831">  InternalStats::CompactionStats stats(1);</a>
<a name="ln1832">  stats.micros = env_-&gt;NowMicros() - start_micros;</a>
<a name="ln1833">  stats.bytes_written = meta.fd.GetTotalFileSize();</a>
<a name="ln1834">  stats.num_output_files = 1;</a>
<a name="ln1835">  cfd-&gt;internal_stats()-&gt;AddCompactionStats(level, stats);</a>
<a name="ln1836">  cfd-&gt;internal_stats()-&gt;AddCFStats(</a>
<a name="ln1837">      InternalStats::BYTES_FLUSHED, meta.fd.GetTotalFileSize());</a>
<a name="ln1838">  RecordTick(stats_, COMPACT_WRITE_BYTES, meta.fd.GetTotalFileSize());</a>
<a name="ln1839">  return s;</a>
<a name="ln1840">}</a>
<a name="ln1841"> </a>
<a name="ln1842">Result&lt;FileNumbersHolder&gt; DBImpl::FlushMemTableToOutputFile(</a>
<a name="ln1843">    ColumnFamilyData* cfd, const MutableCFOptions&amp; mutable_cf_options,</a>
<a name="ln1844">    bool* made_progress, JobContext* job_context, LogBuffer* log_buffer) {</a>
<a name="ln1845">  mutex_.AssertHeld();</a>
<a name="ln1846">  DCHECK_NE(cfd-&gt;imm()-&gt;NumNotFlushed(), 0);</a>
<a name="ln1847">  DCHECK(cfd-&gt;imm()-&gt;IsFlushPending());</a>
<a name="ln1848"> </a>
<a name="ln1849">  SequenceNumber earliest_write_conflict_snapshot;</a>
<a name="ln1850">  std::vector&lt;SequenceNumber&gt; snapshot_seqs =</a>
<a name="ln1851">      snapshots_.GetAll(&amp;earliest_write_conflict_snapshot);</a>
<a name="ln1852"> </a>
<a name="ln1853">  MemTableFilter mem_table_flush_filter;</a>
<a name="ln1854">  if (db_options_.mem_table_flush_filter_factory) {</a>
<a name="ln1855">    mem_table_flush_filter = (*db_options_.mem_table_flush_filter_factory)();</a>
<a name="ln1856">  }</a>
<a name="ln1857"> </a>
<a name="ln1858">  FlushJob flush_job(</a>
<a name="ln1859">      dbname_, cfd, db_options_, mutable_cf_options, env_options_,</a>
<a name="ln1860">      versions_.get(), &amp;mutex_, &amp;shutting_down_, snapshot_seqs,</a>
<a name="ln1861">      earliest_write_conflict_snapshot, mem_table_flush_filter, pending_outputs_.get(),</a>
<a name="ln1862">      job_context, log_buffer, directories_.GetDbDir(), directories_.GetDataDir(0U),</a>
<a name="ln1863">      GetCompressionFlush(*cfd-&gt;ioptions()), stats_, &amp;event_logger_);</a>
<a name="ln1864"> </a>
<a name="ln1865">  FileMetaData file_meta;</a>
<a name="ln1866"> </a>
<a name="ln1867">  // Within flush_job.Run, rocksdb may call event listener to notify</a>
<a name="ln1868">  // file creation and deletion.</a>
<a name="ln1869">  //</a>
<a name="ln1870">  // Note that flush_job.Run will unlock and lock the db_mutex,</a>
<a name="ln1871">  // and EventListener callback will be called when the db_mutex</a>
<a name="ln1872">  // is unlocked by the current thread.</a>
<a name="ln1873">  auto file_number_holder = flush_job.Run(&amp;file_meta);</a>
<a name="ln1874"> </a>
<a name="ln1875">  if (file_number_holder.ok()) {</a>
<a name="ln1876">    InstallSuperVersionAndScheduleWorkWrapper(cfd, job_context,</a>
<a name="ln1877">                                              mutable_cf_options);</a>
<a name="ln1878">    if (made_progress) {</a>
<a name="ln1879">      *made_progress = 1;</a>
<a name="ln1880">    }</a>
<a name="ln1881">    VersionStorageInfo::LevelSummaryStorage tmp;</a>
<a name="ln1882">    YB_LOG_EVERY_N_SECS(INFO, 1)</a>
<a name="ln1883">        &lt;&lt; &quot;[&quot; &lt;&lt; cfd-&gt;GetName() &lt;&lt; &quot;] Level summary: &quot;</a>
<a name="ln1884">        &lt;&lt; cfd-&gt;current()-&gt;storage_info()-&gt;LevelSummary(&amp;tmp);</a>
<a name="ln1885">  }</a>
<a name="ln1886"> </a>
<a name="ln1887">  if (!file_number_holder.ok() &amp;&amp; !file_number_holder.status().IsShutdownInProgress()</a>
<a name="ln1888">      &amp;&amp; db_options_.paranoid_checks &amp;&amp; bg_error_.ok()) {</a>
<a name="ln1889">    // if a bad error happened (not ShutdownInProgress) and paranoid_checks is</a>
<a name="ln1890">    // true, mark DB read-only</a>
<a name="ln1891">    bg_error_ = file_number_holder.status();</a>
<a name="ln1892">  }</a>
<a name="ln1893">  RecordFlushIOStats();</a>
<a name="ln1894">  RETURN_NOT_OK(file_number_holder);</a>
<a name="ln1895">  MAYBE_FAULT(FLAGS_fault_crash_after_rocksdb_flush);</a>
<a name="ln1896">#ifndef ROCKSDB_LITE</a>
<a name="ln1897">  // may temporarily unlock and lock the mutex.</a>
<a name="ln1898">  NotifyOnFlushCompleted(cfd, &amp;file_meta, mutable_cf_options,</a>
<a name="ln1899">                         job_context-&gt;job_id, flush_job.GetTableProperties());</a>
<a name="ln1900">#endif  // ROCKSDB_LITE</a>
<a name="ln1901">  auto sfm =</a>
<a name="ln1902">      static_cast&lt;SstFileManagerImpl*&gt;(db_options_.sst_file_manager.get());</a>
<a name="ln1903">  if (sfm) {</a>
<a name="ln1904">    // Notify sst_file_manager that a new file was added</a>
<a name="ln1905">    std::string file_path = MakeTableFileName(db_options_.db_paths[0].path,</a>
<a name="ln1906">                                              file_meta.fd.GetNumber());</a>
<a name="ln1907">    RETURN_NOT_OK(sfm-&gt;OnAddFile(file_path));</a>
<a name="ln1908">    if (cfd-&gt;ioptions()-&gt;table_factory-&gt;IsSplitSstForWriteSupported()) {</a>
<a name="ln1909">      RETURN_NOT_OK(sfm-&gt;OnAddFile(TableBaseToDataFileName(file_path)));</a>
<a name="ln1910">    }</a>
<a name="ln1911">    if (sfm-&gt;IsMaxAllowedSpaceReached() &amp;&amp; bg_error_.ok()) {</a>
<a name="ln1912">      bg_error_ = STATUS(IOError, &quot;Max allowed space was reached&quot;);</a>
<a name="ln1913">      TEST_SYNC_POINT(</a>
<a name="ln1914">          &quot;DBImpl::FlushMemTableToOutputFile:MaxAllowedSpaceReached&quot;);</a>
<a name="ln1915">    }</a>
<a name="ln1916">  }</a>
<a name="ln1917">  return file_number_holder;</a>
<a name="ln1918">}</a>
<a name="ln1919"> </a>
<a name="ln1920">uint64_t DBImpl::GetCurrentVersionSstFilesSize() {</a>
<a name="ln1921">  std::vector&lt;rocksdb::LiveFileMetaData&gt; file_metadata;</a>
<a name="ln1922">  GetLiveFilesMetaData(&amp;file_metadata);</a>
<a name="ln1923">  uint64_t total_sst_file_size = 0;</a>
<a name="ln1924">  for (const auto&amp; meta : file_metadata) {</a>
<a name="ln1925">    total_sst_file_size += meta.total_size;</a>
<a name="ln1926">  }</a>
<a name="ln1927">  return total_sst_file_size;</a>
<a name="ln1928">}</a>
<a name="ln1929"> </a>
<a name="ln1930">uint64_t DBImpl::GetCurrentVersionSstFilesUncompressedSize() {</a>
<a name="ln1931">  std::vector&lt;rocksdb::LiveFileMetaData&gt; file_metadata;</a>
<a name="ln1932">  GetLiveFilesMetaData(&amp;file_metadata);</a>
<a name="ln1933">  uint64_t total_uncompressed_file_size = 0;</a>
<a name="ln1934">  for (const auto &amp;meta : file_metadata) {</a>
<a name="ln1935">    total_uncompressed_file_size += meta.uncompressed_size;</a>
<a name="ln1936">  }</a>
<a name="ln1937">  return total_uncompressed_file_size;</a>
<a name="ln1938">}</a>
<a name="ln1939"> </a>
<a name="ln1940">uint64_t DBImpl::GetCurrentVersionNumSSTFiles() {</a>
<a name="ln1941">  InstrumentedMutexLock lock(&amp;mutex_);</a>
<a name="ln1942">  return default_cf_handle_-&gt;cfd()-&gt;current()-&gt;storage_info()-&gt;NumFiles();</a>
<a name="ln1943">}</a>
<a name="ln1944"> </a>
<a name="ln1945">void DBImpl::SetSSTFileTickers() {</a>
<a name="ln1946">  if (stats_) {</a>
<a name="ln1947">    auto sst_files_size = GetCurrentVersionSstFilesSize();</a>
<a name="ln1948">    SetTickerCount(stats_, CURRENT_VERSION_SST_FILES_SIZE, sst_files_size);</a>
<a name="ln1949">    auto uncompressed_sst_files_size = GetCurrentVersionSstFilesUncompressedSize();</a>
<a name="ln1950">    SetTickerCount(</a>
<a name="ln1951">        stats_, CURRENT_VERSION_SST_FILES_UNCOMPRESSED_SIZE, uncompressed_sst_files_size);</a>
<a name="ln1952">    auto num_sst_files = GetCurrentVersionNumSSTFiles();</a>
<a name="ln1953">    SetTickerCount(stats_, CURRENT_VERSION_NUM_SST_FILES, num_sst_files);</a>
<a name="ln1954">  }</a>
<a name="ln1955">}</a>
<a name="ln1956"> </a>
<a name="ln1957">uint64_t DBImpl::GetCurrentVersionDataSstFilesSize() {</a>
<a name="ln1958">  std::vector&lt;rocksdb::LiveFileMetaData&gt; file_metadata;</a>
<a name="ln1959">  GetLiveFilesMetaData(&amp;file_metadata);</a>
<a name="ln1960">  uint64_t data_sst_file_size = 0;</a>
<a name="ln1961">  for (const auto&amp; meta : file_metadata) {</a>
<a name="ln1962">    // Each SST has base/metadata SST file (&lt;number&gt;.sst) and at least one data SST file</a>
<a name="ln1963">    // (&lt;number&gt;.sst.sblock.0).</a>
<a name="ln1964">    // We subtract SST metadata file size from total SST size to get the SST data file(s) size.</a>
<a name="ln1965">    data_sst_file_size += meta.total_size - meta.base_size;</a>
<a name="ln1966">  }</a>
<a name="ln1967">  return data_sst_file_size;</a>
<a name="ln1968">}</a>
<a name="ln1969"> </a>
<a name="ln1970">void DBImpl::NotifyOnFlushCompleted(ColumnFamilyData* cfd,</a>
<a name="ln1971">                                    FileMetaData* file_meta,</a>
<a name="ln1972">                                    const MutableCFOptions&amp; mutable_cf_options,</a>
<a name="ln1973">                                    int job_id, TableProperties prop) {</a>
<a name="ln1974">#ifndef ROCKSDB_LITE</a>
<a name="ln1975">  mutex_.AssertHeld();</a>
<a name="ln1976">  if (shutting_down_.load(std::memory_order_acquire)) {</a>
<a name="ln1977">    return;</a>
<a name="ln1978">  }</a>
<a name="ln1979">  if (db_options_.listeners.size() &gt; 0) {</a>
<a name="ln1980">    bool triggered_writes_slowdown =</a>
<a name="ln1981">        (cfd-&gt;current()-&gt;storage_info()-&gt;NumLevelFiles(0) &gt;=</a>
<a name="ln1982">         mutable_cf_options.level0_slowdown_writes_trigger);</a>
<a name="ln1983">    bool triggered_writes_stop =</a>
<a name="ln1984">        (cfd-&gt;current()-&gt;storage_info()-&gt;NumLevelFiles(0) &gt;=</a>
<a name="ln1985">         mutable_cf_options.level0_stop_writes_trigger);</a>
<a name="ln1986">    if (triggered_writes_stop) {</a>
<a name="ln1987">      TEST_SYNC_POINT(&quot;DBImpl::NotifyOnFlushCompleted::TriggeredWriteStop&quot;);</a>
<a name="ln1988">    } else if (triggered_writes_slowdown) {</a>
<a name="ln1989">      TEST_SYNC_POINT(&quot;DBImpl::NotifyOnFlushCompleted::TriggeredWriteSlowdown&quot;);</a>
<a name="ln1990">    }</a>
<a name="ln1991"> </a>
<a name="ln1992">    // release lock while notifying events</a>
<a name="ln1993">    mutex_.Unlock();</a>
<a name="ln1994">    {</a>
<a name="ln1995">      FlushJobInfo info;</a>
<a name="ln1996">      info.cf_name = cfd-&gt;GetName();</a>
<a name="ln1997">      // TODO(yhchiang): make db_paths dynamic in case flush does not</a>
<a name="ln1998">      //                 go to L0 in the future.</a>
<a name="ln1999">      info.file_path = MakeTableFileName(db_options_.db_paths[0].path,</a>
<a name="ln2000">                                         file_meta-&gt;fd.GetNumber());</a>
<a name="ln2001">      info.thread_id = env_-&gt;GetThreadID();</a>
<a name="ln2002">      info.job_id = job_id;</a>
<a name="ln2003">      info.triggered_writes_slowdown = triggered_writes_slowdown;</a>
<a name="ln2004">      info.triggered_writes_stop = triggered_writes_stop;</a>
<a name="ln2005">      info.smallest_seqno = file_meta-&gt;smallest.seqno;</a>
<a name="ln2006">      info.largest_seqno = file_meta-&gt;largest.seqno;</a>
<a name="ln2007">      info.table_properties = prop;</a>
<a name="ln2008">      for (auto listener : db_options_.listeners) {</a>
<a name="ln2009">        listener-&gt;OnFlushCompleted(this, info);</a>
<a name="ln2010">      }</a>
<a name="ln2011">    }</a>
<a name="ln2012">  } else {</a>
<a name="ln2013">    mutex_.Unlock();</a>
<a name="ln2014">  }</a>
<a name="ln2015">  SetSSTFileTickers();</a>
<a name="ln2016">  mutex_.Lock();</a>
<a name="ln2017">  // no need to signal bg_cv_ as it will be signaled at the end of the</a>
<a name="ln2018">  // flush process.</a>
<a name="ln2019">#endif  // ROCKSDB_LITE</a>
<a name="ln2020">}</a>
<a name="ln2021"> </a>
<a name="ln2022">Status DBImpl::CompactRange(const CompactRangeOptions&amp; options,</a>
<a name="ln2023">                            ColumnFamilyHandle* column_family,</a>
<a name="ln2024">                            const Slice* begin, const Slice* end) {</a>
<a name="ln2025">  if (options.target_path_id &gt;= db_options_.db_paths.size()) {</a>
<a name="ln2026">    return STATUS(InvalidArgument, &quot;Invalid target path ID&quot;);</a>
<a name="ln2027">  }</a>
<a name="ln2028"> </a>
<a name="ln2029">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln2030">  auto cfd = cfh-&gt;cfd();</a>
<a name="ln2031">  bool exclusive = options.exclusive_manual_compaction;</a>
<a name="ln2032"> </a>
<a name="ln2033">  Status s = FlushMemTable(cfd, FlushOptions());</a>
<a name="ln2034">  if (!s.ok()) {</a>
<a name="ln2035">    LogFlush(db_options_.info_log);</a>
<a name="ln2036">    return s;</a>
<a name="ln2037">  }</a>
<a name="ln2038"> </a>
<a name="ln2039">  int max_level_with_files = 0;</a>
<a name="ln2040">  {</a>
<a name="ln2041">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln2042">    Version* base = cfd-&gt;current();</a>
<a name="ln2043">    for (int level = 1; level &lt; base-&gt;storage_info()-&gt;num_non_empty_levels();</a>
<a name="ln2044">         level++) {</a>
<a name="ln2045">      if (base-&gt;storage_info()-&gt;OverlapInLevel(level, begin, end)) {</a>
<a name="ln2046">        max_level_with_files = level;</a>
<a name="ln2047">      }</a>
<a name="ln2048">    }</a>
<a name="ln2049">  }</a>
<a name="ln2050"> </a>
<a name="ln2051">  int final_output_level = 0;</a>
<a name="ln2052">  if (cfd-&gt;ioptions()-&gt;compaction_style == kCompactionStyleUniversal &amp;&amp;</a>
<a name="ln2053">      cfd-&gt;NumberLevels() &gt; 1) {</a>
<a name="ln2054">    // Always compact all files together.</a>
<a name="ln2055">    s = RunManualCompaction(cfd, ColumnFamilyData::kCompactAllLevels,</a>
<a name="ln2056">                            cfd-&gt;NumberLevels() - 1, options.target_path_id,</a>
<a name="ln2057">                            begin, end, exclusive);</a>
<a name="ln2058">    final_output_level = cfd-&gt;NumberLevels() - 1;</a>
<a name="ln2059">  } else {</a>
<a name="ln2060">    for (int level = 0; level &lt;= max_level_with_files; level++) {</a>
<a name="ln2061">      int output_level;</a>
<a name="ln2062">      // in case the compaction is universal or if we're compacting the</a>
<a name="ln2063">      // bottom-most level, the output level will be the same as input one.</a>
<a name="ln2064">      // level 0 can never be the bottommost level (i.e. if all files are in</a>
<a name="ln2065">      // level 0, we will compact to level 1)</a>
<a name="ln2066">      if (cfd-&gt;ioptions()-&gt;compaction_style == kCompactionStyleUniversal ||</a>
<a name="ln2067">          cfd-&gt;ioptions()-&gt;compaction_style == kCompactionStyleFIFO) {</a>
<a name="ln2068">        output_level = level;</a>
<a name="ln2069">      } else if (level == max_level_with_files &amp;&amp; level &gt; 0) {</a>
<a name="ln2070">        if (options.bottommost_level_compaction ==</a>
<a name="ln2071">            BottommostLevelCompaction::kSkip) {</a>
<a name="ln2072">          // Skip bottommost level compaction</a>
<a name="ln2073">          continue;</a>
<a name="ln2074">        } else if (options.bottommost_level_compaction ==</a>
<a name="ln2075">                       BottommostLevelCompaction::kIfHaveCompactionFilter &amp;&amp;</a>
<a name="ln2076">                   cfd-&gt;ioptions()-&gt;compaction_filter == nullptr &amp;&amp;</a>
<a name="ln2077">                   cfd-&gt;ioptions()-&gt;compaction_filter_factory == nullptr) {</a>
<a name="ln2078">          // Skip bottommost level compaction since we don't have a compaction</a>
<a name="ln2079">          // filter</a>
<a name="ln2080">          continue;</a>
<a name="ln2081">        }</a>
<a name="ln2082">        output_level = level;</a>
<a name="ln2083">      } else {</a>
<a name="ln2084">        output_level = level + 1;</a>
<a name="ln2085">        if (cfd-&gt;ioptions()-&gt;compaction_style == kCompactionStyleLevel &amp;&amp;</a>
<a name="ln2086">            cfd-&gt;ioptions()-&gt;level_compaction_dynamic_level_bytes &amp;&amp;</a>
<a name="ln2087">            level == 0) {</a>
<a name="ln2088">          output_level = ColumnFamilyData::kCompactToBaseLevel;</a>
<a name="ln2089">        }</a>
<a name="ln2090">      }</a>
<a name="ln2091">      s = RunManualCompaction(cfd, level, output_level, options.target_path_id,</a>
<a name="ln2092">                              begin, end, exclusive);</a>
<a name="ln2093">      if (!s.ok()) {</a>
<a name="ln2094">        break;</a>
<a name="ln2095">      }</a>
<a name="ln2096">      if (output_level == ColumnFamilyData::kCompactToBaseLevel) {</a>
<a name="ln2097">        final_output_level = cfd-&gt;NumberLevels() - 1;</a>
<a name="ln2098">      } else if (output_level &gt; final_output_level) {</a>
<a name="ln2099">        final_output_level = output_level;</a>
<a name="ln2100">      }</a>
<a name="ln2101">      TEST_SYNC_POINT(&quot;DBImpl::RunManualCompaction()::1&quot;);</a>
<a name="ln2102">      TEST_SYNC_POINT(&quot;DBImpl::RunManualCompaction()::2&quot;);</a>
<a name="ln2103">    }</a>
<a name="ln2104">  }</a>
<a name="ln2105">  if (!s.ok()) {</a>
<a name="ln2106">    LogFlush(db_options_.info_log);</a>
<a name="ln2107">    return s;</a>
<a name="ln2108">  }</a>
<a name="ln2109"> </a>
<a name="ln2110">  if (options.change_level) {</a>
<a name="ln2111">    RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln2112">        &quot;[RefitLevel] waiting for background threads to stop&quot;);</a>
<a name="ln2113">    s = PauseBackgroundWork();</a>
<a name="ln2114">    if (s.ok()) {</a>
<a name="ln2115">      s = ReFitLevel(cfd, final_output_level, options.target_level);</a>
<a name="ln2116">    }</a>
<a name="ln2117">    CHECK_OK(ContinueBackgroundWork());</a>
<a name="ln2118">  }</a>
<a name="ln2119">  LogFlush(db_options_.info_log);</a>
<a name="ln2120"> </a>
<a name="ln2121">  {</a>
<a name="ln2122">    InstrumentedMutexLock lock(&amp;mutex_);</a>
<a name="ln2123">    // an automatic compaction that has been scheduled might have been</a>
<a name="ln2124">    // preempted by the manual compactions. Need to schedule it back.</a>
<a name="ln2125">    if (exclusive) {</a>
<a name="ln2126">      // all compaction scheduling was stopped so we reschedule for each cf</a>
<a name="ln2127">      ColumnFamilySet* columnFamilySet = versions_-&gt;GetColumnFamilySet();</a>
<a name="ln2128">      for (auto it = columnFamilySet-&gt;begin(); it != columnFamilySet-&gt;end(); ++it) {</a>
<a name="ln2129">        SchedulePendingCompaction(*it);</a>
<a name="ln2130">      }</a>
<a name="ln2131">    } else {</a>
<a name="ln2132">      // only compactions in this column family were stopped</a>
<a name="ln2133">      SchedulePendingCompaction(cfd);</a>
<a name="ln2134">    }</a>
<a name="ln2135">    MaybeScheduleFlushOrCompaction();</a>
<a name="ln2136">  }</a>
<a name="ln2137"> </a>
<a name="ln2138">  return s;</a>
<a name="ln2139">}</a>
<a name="ln2140"> </a>
<a name="ln2141">Status DBImpl::CompactFiles(</a>
<a name="ln2142">    const CompactionOptions&amp; compact_options,</a>
<a name="ln2143">    ColumnFamilyHandle* column_family,</a>
<a name="ln2144">    const std::vector&lt;std::string&gt;&amp; input_file_names,</a>
<a name="ln2145">    const int output_level, const int output_path_id) {</a>
<a name="ln2146">#ifdef ROCKSDB_LITE</a>
<a name="ln2147">    // not supported in lite version</a>
<a name="ln2148">  return STATUS(NotSupported, &quot;Not supported in ROCKSDB LITE&quot;);</a>
<a name="ln2149">#else</a>
<a name="ln2150">  if (column_family == nullptr) {</a>
<a name="ln2151">    return STATUS(InvalidArgument, &quot;ColumnFamilyHandle must be non-null.&quot;);</a>
<a name="ln2152">  }</a>
<a name="ln2153"> </a>
<a name="ln2154">  auto cfd = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family)-&gt;cfd();</a>
<a name="ln2155">  assert(cfd);</a>
<a name="ln2156"> </a>
<a name="ln2157">  Status s;</a>
<a name="ln2158">  JobContext job_context(0, true);</a>
<a name="ln2159">  LogBuffer log_buffer(InfoLogLevel::INFO_LEVEL,</a>
<a name="ln2160">                       db_options_.info_log.get());</a>
<a name="ln2161"> </a>
<a name="ln2162">  // Perform CompactFiles</a>
<a name="ln2163">  SuperVersion* sv = GetAndRefSuperVersion(cfd);</a>
<a name="ln2164">  {</a>
<a name="ln2165">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln2166"> </a>
<a name="ln2167">    s = CompactFilesImpl(compact_options, cfd, sv-&gt;current,</a>
<a name="ln2168">                         input_file_names, output_level,</a>
<a name="ln2169">                         output_path_id, &amp;job_context, &amp;log_buffer);</a>
<a name="ln2170">  }</a>
<a name="ln2171">  ReturnAndCleanupSuperVersion(cfd, sv);</a>
<a name="ln2172"> </a>
<a name="ln2173">  // Find and delete obsolete files</a>
<a name="ln2174">  {</a>
<a name="ln2175">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln2176">    // If !s.ok(), this means that Compaction failed. In that case, we want</a>
<a name="ln2177">    // to delete all obsolete files we might have created and we force</a>
<a name="ln2178">    // FindObsoleteFiles(). This is because job_context does not</a>
<a name="ln2179">    // catch all created files if compaction failed.</a>
<a name="ln2180">    FindObsoleteFiles(&amp;job_context, !s.ok());</a>
<a name="ln2181">  }  // release the mutex</a>
<a name="ln2182"> </a>
<a name="ln2183">  // delete unnecessary files if any, this is done outside the mutex</a>
<a name="ln2184">  if (job_context.HaveSomethingToDelete() || !log_buffer.IsEmpty()) {</a>
<a name="ln2185">    // Have to flush the info logs before bg_compaction_scheduled_--</a>
<a name="ln2186">    // because if bg_flush_scheduled_ becomes 0 and the lock is</a>
<a name="ln2187">    // released, the deconstructor of DB can kick in and destroy all the</a>
<a name="ln2188">    // states of DB so info_log might not be available after that point.</a>
<a name="ln2189">    // It also applies to access other states that DB owns.</a>
<a name="ln2190">    log_buffer.FlushBufferToLog();</a>
<a name="ln2191">    if (job_context.HaveSomethingToDelete()) {</a>
<a name="ln2192">      // no mutex is locked here.  No need to Unlock() and Lock() here.</a>
<a name="ln2193">      PurgeObsoleteFiles(job_context);</a>
<a name="ln2194">    }</a>
<a name="ln2195">    job_context.Clean();</a>
<a name="ln2196">  }</a>
<a name="ln2197"> </a>
<a name="ln2198">  return s;</a>
<a name="ln2199">#endif  // ROCKSDB_LITE</a>
<a name="ln2200">}</a>
<a name="ln2201"> </a>
<a name="ln2202">#ifndef ROCKSDB_LITE</a>
<a name="ln2203">Status DBImpl::CompactFilesImpl(</a>
<a name="ln2204">    const CompactionOptions&amp; compact_options, ColumnFamilyData* cfd,</a>
<a name="ln2205">    Version* version, const std::vector&lt;std::string&gt;&amp; input_file_names,</a>
<a name="ln2206">    const int output_level, int output_path_id, JobContext* job_context,</a>
<a name="ln2207">    LogBuffer* log_buffer) {</a>
<a name="ln2208">  mutex_.AssertHeld();</a>
<a name="ln2209"> </a>
<a name="ln2210">  if (shutting_down_.load(std::memory_order_acquire)) {</a>
<a name="ln2211">    return STATUS(ShutdownInProgress, &quot;&quot;);</a>
<a name="ln2212">  }</a>
<a name="ln2213"> </a>
<a name="ln2214">  std::unordered_set&lt;uint64_t&gt; input_set;</a>
<a name="ln2215">  for (auto file_name : input_file_names) {</a>
<a name="ln2216">    input_set.insert(TableFileNameToNumber(file_name));</a>
<a name="ln2217">  }</a>
<a name="ln2218"> </a>
<a name="ln2219">  ColumnFamilyMetaData cf_meta;</a>
<a name="ln2220">  // TODO(yhchiang): can directly use version here if none of the</a>
<a name="ln2221">  // following functions call is pluggable to external developers.</a>
<a name="ln2222">  version-&gt;GetColumnFamilyMetaData(&amp;cf_meta);</a>
<a name="ln2223"> </a>
<a name="ln2224">  if (output_path_id &lt; 0) {</a>
<a name="ln2225">    if (db_options_.db_paths.size() == 1U) {</a>
<a name="ln2226">      output_path_id = 0;</a>
<a name="ln2227">    } else {</a>
<a name="ln2228">      return STATUS(NotSupported,</a>
<a name="ln2229">          &quot;Automatic output path selection is not &quot;</a>
<a name="ln2230">          &quot;yet supported in CompactFiles()&quot;);</a>
<a name="ln2231">    }</a>
<a name="ln2232">  }</a>
<a name="ln2233"> </a>
<a name="ln2234">  Status s = cfd-&gt;compaction_picker()-&gt;SanitizeCompactionInputFiles(</a>
<a name="ln2235">      &amp;input_set, cf_meta, output_level);</a>
<a name="ln2236">  if (!s.ok()) {</a>
<a name="ln2237">    return s;</a>
<a name="ln2238">  }</a>
<a name="ln2239"> </a>
<a name="ln2240">  std::vector&lt;CompactionInputFiles&gt; input_files;</a>
<a name="ln2241">  s = cfd-&gt;compaction_picker()-&gt;GetCompactionInputsFromFileNumbers(</a>
<a name="ln2242">      &amp;input_files, &amp;input_set, version-&gt;storage_info(), compact_options);</a>
<a name="ln2243">  if (!s.ok()) {</a>
<a name="ln2244">    return s;</a>
<a name="ln2245">  }</a>
<a name="ln2246"> </a>
<a name="ln2247">  for (auto inputs : input_files) {</a>
<a name="ln2248">    if (cfd-&gt;compaction_picker()-&gt;FilesInCompaction(inputs.files)) {</a>
<a name="ln2249">      return STATUS(Aborted,</a>
<a name="ln2250">          &quot;Some of the necessary compaction input &quot;</a>
<a name="ln2251">          &quot;files are already being compacted&quot;);</a>
<a name="ln2252">    }</a>
<a name="ln2253">  }</a>
<a name="ln2254"> </a>
<a name="ln2255">  // At this point, CompactFiles will be run.</a>
<a name="ln2256">  bg_compaction_scheduled_++;</a>
<a name="ln2257"> </a>
<a name="ln2258">  assert(cfd-&gt;compaction_picker());</a>
<a name="ln2259">  unique_ptr&lt;Compaction&gt; c = cfd-&gt;compaction_picker()-&gt;FormCompaction(</a>
<a name="ln2260">      compact_options, input_files, output_level, version-&gt;storage_info(),</a>
<a name="ln2261">      *cfd-&gt;GetLatestMutableCFOptions(), output_path_id);</a>
<a name="ln2262">  if (!c) {</a>
<a name="ln2263">    return STATUS(Aborted, &quot;Another Level 0 compaction is running&quot;);</a>
<a name="ln2264">  }</a>
<a name="ln2265">  c-&gt;SetInputVersion(version);</a>
<a name="ln2266">  // deletion compaction currently not allowed in CompactFiles.</a>
<a name="ln2267">  assert(!c-&gt;deletion_compaction());</a>
<a name="ln2268"> </a>
<a name="ln2269">  SequenceNumber earliest_write_conflict_snapshot;</a>
<a name="ln2270">  std::vector&lt;SequenceNumber&gt; snapshot_seqs =</a>
<a name="ln2271">      snapshots_.GetAll(&amp;earliest_write_conflict_snapshot);</a>
<a name="ln2272"> </a>
<a name="ln2273">  assert(is_snapshot_supported_ || snapshots_.empty());</a>
<a name="ln2274">  CompactionJob compaction_job(</a>
<a name="ln2275">      job_context-&gt;job_id, c.get(), db_options_, env_options_, versions_.get(),</a>
<a name="ln2276">      &amp;shutting_down_, log_buffer, directories_.GetDbDir(),</a>
<a name="ln2277">      directories_.GetDataDir(c-&gt;output_path_id()), stats_, &amp;mutex_, &amp;bg_error_,</a>
<a name="ln2278">      snapshot_seqs, earliest_write_conflict_snapshot, pending_outputs_.get(), table_cache_,</a>
<a name="ln2279">      &amp;event_logger_, c-&gt;mutable_cf_options()-&gt;paranoid_file_checks,</a>
<a name="ln2280">      c-&gt;mutable_cf_options()-&gt;compaction_measure_io_stats, dbname_,</a>
<a name="ln2281">      nullptr);  // Here we pass a nullptr for CompactionJobStats because</a>
<a name="ln2282">                 // CompactFiles does not trigger OnCompactionCompleted(),</a>
<a name="ln2283">                 // which is the only place where CompactionJobStats is</a>
<a name="ln2284">                 // returned.  The idea of not triggering OnCompationCompleted()</a>
<a name="ln2285">                 // is that CompactFiles runs in the caller thread, so the user</a>
<a name="ln2286">                 // should always know when it completes.  As a result, it makes</a>
<a name="ln2287">                 // less sense to notify the users something they should already</a>
<a name="ln2288">                 // know.</a>
<a name="ln2289">                 //</a>
<a name="ln2290">                 // In the future, if we would like to add CompactionJobStats</a>
<a name="ln2291">                 // support for CompactFiles, we should have CompactFiles API</a>
<a name="ln2292">                 // pass a pointer of CompactionJobStats as the out-value</a>
<a name="ln2293">                 // instead of using EventListener.</a>
<a name="ln2294"> </a>
<a name="ln2295">  // Creating a compaction influences the compaction score because the score</a>
<a name="ln2296">  // takes running compactions into account (by skipping files that are already</a>
<a name="ln2297">  // being compacted). Since we just changed compaction score, we recalculate it</a>
<a name="ln2298">  // here.</a>
<a name="ln2299">  {</a>
<a name="ln2300">    CompactionOptionsFIFO dummy_compaction_options_fifo;</a>
<a name="ln2301">    version-&gt;storage_info()-&gt;ComputeCompactionScore(</a>
<a name="ln2302">        *c-&gt;mutable_cf_options(), dummy_compaction_options_fifo);</a>
<a name="ln2303">  }</a>
<a name="ln2304"> </a>
<a name="ln2305">  compaction_job.Prepare();</a>
<a name="ln2306"> </a>
<a name="ln2307">  Status status;</a>
<a name="ln2308">  {</a>
<a name="ln2309">    mutex_.Unlock();</a>
<a name="ln2310">    auto file_numbers_holder = compaction_job.Run();</a>
<a name="ln2311">    TEST_SYNC_POINT(&quot;CompactFilesImpl:2&quot;);</a>
<a name="ln2312">    TEST_SYNC_POINT(&quot;CompactFilesImpl:3&quot;);</a>
<a name="ln2313">    mutex_.Lock();</a>
<a name="ln2314"> </a>
<a name="ln2315">    status = compaction_job.Install(*c-&gt;mutable_cf_options());</a>
<a name="ln2316">    if (status.ok()) {</a>
<a name="ln2317">      InstallSuperVersionAndScheduleWorkWrapper(</a>
<a name="ln2318">          c-&gt;column_family_data(), job_context, *c-&gt;mutable_cf_options());</a>
<a name="ln2319">    }</a>
<a name="ln2320">    c-&gt;ReleaseCompactionFiles(s);</a>
<a name="ln2321">  }</a>
<a name="ln2322"> </a>
<a name="ln2323">  if (status.ok()) {</a>
<a name="ln2324">    // Done</a>
<a name="ln2325">  } else if (status.IsShutdownInProgress()) {</a>
<a name="ln2326">    // Ignore compaction errors found during shutting down</a>
<a name="ln2327">  } else {</a>
<a name="ln2328">    RLOG(InfoLogLevel::WARN_LEVEL, db_options_.info_log,</a>
<a name="ln2329">        &quot;[%s] [JOB %d] Compaction error: %s&quot;,</a>
<a name="ln2330">        c-&gt;column_family_data()-&gt;GetName().c_str(), job_context-&gt;job_id,</a>
<a name="ln2331">        status.ToString().c_str());</a>
<a name="ln2332">    if (db_options_.paranoid_checks &amp;&amp; bg_error_.ok()) {</a>
<a name="ln2333">      bg_error_ = status;</a>
<a name="ln2334">    }</a>
<a name="ln2335">  }</a>
<a name="ln2336"> </a>
<a name="ln2337">  c.reset();</a>
<a name="ln2338"> </a>
<a name="ln2339">  bg_compaction_scheduled_--;</a>
<a name="ln2340">  if (bg_compaction_scheduled_ == 0) {</a>
<a name="ln2341">    bg_cv_.SignalAll();</a>
<a name="ln2342">  }</a>
<a name="ln2343"> </a>
<a name="ln2344">  return status;</a>
<a name="ln2345">}</a>
<a name="ln2346">#endif  // ROCKSDB_LITE</a>
<a name="ln2347"> </a>
<a name="ln2348">Status DBImpl::PauseBackgroundWork() {</a>
<a name="ln2349">  InstrumentedMutexLock guard_lock(&amp;mutex_);</a>
<a name="ln2350">  bg_compaction_paused_++;</a>
<a name="ln2351">  while (CheckBackgroundWorkAndLog(&quot;Pause&quot;)) {</a>
<a name="ln2352">    bg_cv_.Wait();</a>
<a name="ln2353">  }</a>
<a name="ln2354">  bg_work_paused_++;</a>
<a name="ln2355">  return Status::OK();</a>
<a name="ln2356">}</a>
<a name="ln2357"> </a>
<a name="ln2358">Status DBImpl::ContinueBackgroundWork() {</a>
<a name="ln2359">  InstrumentedMutexLock guard_lock(&amp;mutex_);</a>
<a name="ln2360">  if (bg_work_paused_ == 0) {</a>
<a name="ln2361">    return STATUS(InvalidArgument, &quot;&quot;);</a>
<a name="ln2362">  }</a>
<a name="ln2363">  assert(bg_work_paused_ &gt; 0);</a>
<a name="ln2364">  assert(bg_compaction_paused_ &gt; 0);</a>
<a name="ln2365">  bg_compaction_paused_--;</a>
<a name="ln2366">  bg_work_paused_--;</a>
<a name="ln2367">  // It's sufficient to check just bg_work_paused_ here since</a>
<a name="ln2368">  // bg_work_paused_ is always no greater than bg_compaction_paused_</a>
<a name="ln2369">  if (bg_work_paused_ == 0) {</a>
<a name="ln2370">    MaybeScheduleFlushOrCompaction();</a>
<a name="ln2371">  }</a>
<a name="ln2372">  return Status::OK();</a>
<a name="ln2373">}</a>
<a name="ln2374"> </a>
<a name="ln2375">void DBImpl::NotifyOnCompactionCompleted(</a>
<a name="ln2376">    ColumnFamilyData* cfd, Compaction *c, const Status &amp;st,</a>
<a name="ln2377">    const CompactionJobStats&amp; compaction_job_stats,</a>
<a name="ln2378">    const int job_id) {</a>
<a name="ln2379">#ifndef ROCKSDB_LITE</a>
<a name="ln2380">  mutex_.AssertHeld();</a>
<a name="ln2381">  if (shutting_down_.load(std::memory_order_acquire)) {</a>
<a name="ln2382">    return;</a>
<a name="ln2383">  }</a>
<a name="ln2384">  VersionPtr current = cfd-&gt;current();</a>
<a name="ln2385">  // release lock while notifying events</a>
<a name="ln2386">  mutex_.Unlock();</a>
<a name="ln2387">  if (db_options_.listeners.size() &gt; 0) {</a>
<a name="ln2388">    CompactionJobInfo info;</a>
<a name="ln2389">    info.cf_name = cfd-&gt;GetName();</a>
<a name="ln2390">    info.status = st;</a>
<a name="ln2391">    info.thread_id = env_-&gt;GetThreadID();</a>
<a name="ln2392">    info.job_id = job_id;</a>
<a name="ln2393">    info.base_input_level = c-&gt;start_level();</a>
<a name="ln2394">    info.output_level = c-&gt;output_level();</a>
<a name="ln2395">    info.stats = compaction_job_stats;</a>
<a name="ln2396">    info.table_properties = c-&gt;GetOutputTableProperties();</a>
<a name="ln2397">    info.compaction_reason = c-&gt;compaction_reason();</a>
<a name="ln2398">    info.is_full_compaction = c-&gt;is_full_compaction();</a>
<a name="ln2399">    for (size_t i = 0; i &lt; c-&gt;num_input_levels(); ++i) {</a>
<a name="ln2400">      for (const auto fmd : *c-&gt;inputs(i)) {</a>
<a name="ln2401">        auto fn = TableFileName(db_options_.db_paths, fmd-&gt;fd.GetNumber(),</a>
<a name="ln2402">                                fmd-&gt;fd.GetPathId());</a>
<a name="ln2403">        info.input_files.push_back(fn);</a>
<a name="ln2404">        if (info.table_properties.count(fn) == 0) {</a>
<a name="ln2405">          std::shared_ptr&lt;const TableProperties&gt; tp;</a>
<a name="ln2406">          auto s = current-&gt;GetTableProperties(&amp;tp, fmd, &amp;fn);</a>
<a name="ln2407">          if (s.ok()) {</a>
<a name="ln2408">            info.table_properties[fn] = tp;</a>
<a name="ln2409">          }</a>
<a name="ln2410">        }</a>
<a name="ln2411">      }</a>
<a name="ln2412">    }</a>
<a name="ln2413">    for (const auto&amp; newf : c-&gt;edit()-&gt;GetNewFiles()) {</a>
<a name="ln2414">      info.output_files.push_back(</a>
<a name="ln2415">          TableFileName(db_options_.db_paths,</a>
<a name="ln2416">                        newf.second.fd.GetNumber(),</a>
<a name="ln2417">                        newf.second.fd.GetPathId()));</a>
<a name="ln2418">    }</a>
<a name="ln2419">    for (auto listener : db_options_.listeners) {</a>
<a name="ln2420">      listener-&gt;OnCompactionCompleted(this, info);</a>
<a name="ln2421">    }</a>
<a name="ln2422">  }</a>
<a name="ln2423">  SetSSTFileTickers();</a>
<a name="ln2424">  mutex_.Lock();</a>
<a name="ln2425">  // no need to signal bg_cv_ as it will be signaled at the end of the</a>
<a name="ln2426">  // flush process.</a>
<a name="ln2427">#endif  // ROCKSDB_LITE</a>
<a name="ln2428">}</a>
<a name="ln2429"> </a>
<a name="ln2430">void DBImpl::SetDisableFlushOnShutdown(bool disable_flush_on_shutdown) {</a>
<a name="ln2431">  // disable_flush_on_shutdown_ can only transition from false to true. This location</a>
<a name="ln2432">  // can be called multiple times with arg as false. It is only called once with arg</a>
<a name="ln2433">  // as true. Subsequently, the destructor reads this flag. Setting this flag</a>
<a name="ln2434">  // to true and the destructor are expected to run on the same thread and hence</a>
<a name="ln2435">  // it is not required for disable_flush_on_shutdown_ to be atomic.</a>
<a name="ln2436">  if (disable_flush_on_shutdown) {</a>
<a name="ln2437">    disable_flush_on_shutdown_ = disable_flush_on_shutdown;</a>
<a name="ln2438">  }</a>
<a name="ln2439">}</a>
<a name="ln2440"> </a>
<a name="ln2441">Status DBImpl::SetOptions(ColumnFamilyHandle* column_family,</a>
<a name="ln2442">    const std::unordered_map&lt;std::string, std::string&gt;&amp; options_map) {</a>
<a name="ln2443">#ifdef ROCKSDB_LITE</a>
<a name="ln2444">  return STATUS(NotSupported, &quot;Not supported in ROCKSDB LITE&quot;);</a>
<a name="ln2445">#else</a>
<a name="ln2446">  auto* cfd = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family)-&gt;cfd();</a>
<a name="ln2447">  if (options_map.empty()) {</a>
<a name="ln2448">    RLOG(InfoLogLevel::WARN_LEVEL,</a>
<a name="ln2449">        db_options_.info_log, &quot;SetOptions() on column family [%s], empty input&quot;,</a>
<a name="ln2450">        cfd-&gt;GetName().c_str());</a>
<a name="ln2451">    return STATUS(InvalidArgument, &quot;empty input&quot;);</a>
<a name="ln2452">  }</a>
<a name="ln2453"> </a>
<a name="ln2454">  MutableCFOptions new_options;</a>
<a name="ln2455">  Status s;</a>
<a name="ln2456">  Status persist_options_status;</a>
<a name="ln2457">  {</a>
<a name="ln2458">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln2459">    s = cfd-&gt;SetOptions(options_map);</a>
<a name="ln2460">    if (s.ok()) {</a>
<a name="ln2461">      new_options = *cfd-&gt;GetLatestMutableCFOptions();</a>
<a name="ln2462">    }</a>
<a name="ln2463">    if (s.ok()) {</a>
<a name="ln2464">      // Persist RocksDB options under the single write thread</a>
<a name="ln2465">      WriteThread::Writer w;</a>
<a name="ln2466">      write_thread_.EnterUnbatched(&amp;w, &amp;mutex_);</a>
<a name="ln2467"> </a>
<a name="ln2468">      persist_options_status = WriteOptionsFile();</a>
<a name="ln2469"> </a>
<a name="ln2470">      write_thread_.ExitUnbatched(&amp;w);</a>
<a name="ln2471">    }</a>
<a name="ln2472">  }</a>
<a name="ln2473"> </a>
<a name="ln2474">  RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln2475">      &quot;SetOptions() on column family [%s], inputs:&quot;,</a>
<a name="ln2476">      cfd-&gt;GetName().c_str());</a>
<a name="ln2477">  for (const auto&amp; o : options_map) {</a>
<a name="ln2478">    RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln2479">        &quot;%s: %s\n&quot;, o.first.c_str(), o.second.c_str());</a>
<a name="ln2480">  }</a>
<a name="ln2481">  if (s.ok()) {</a>
<a name="ln2482">    RLOG(InfoLogLevel::INFO_LEVEL,</a>
<a name="ln2483">        db_options_.info_log, &quot;[%s] SetOptions succeeded&quot;,</a>
<a name="ln2484">        cfd-&gt;GetName().c_str());</a>
<a name="ln2485">    new_options.Dump(db_options_.info_log.get());</a>
<a name="ln2486">    if (!persist_options_status.ok()) {</a>
<a name="ln2487">      if (db_options_.fail_if_options_file_error) {</a>
<a name="ln2488">        s = STATUS(IOError,</a>
<a name="ln2489">            &quot;SetOptions succeeded, but unable to persist options&quot;,</a>
<a name="ln2490">            persist_options_status.ToString());</a>
<a name="ln2491">      }</a>
<a name="ln2492">      RWARN(db_options_.info_log,</a>
<a name="ln2493">          &quot;Unable to persist options in SetOptions() -- %s&quot;,</a>
<a name="ln2494">          persist_options_status.ToString().c_str());</a>
<a name="ln2495">    }</a>
<a name="ln2496">  } else {</a>
<a name="ln2497">    RLOG(InfoLogLevel::WARN_LEVEL, db_options_.info_log,</a>
<a name="ln2498">        &quot;[%s] SetOptions failed&quot;, cfd-&gt;GetName().c_str());</a>
<a name="ln2499">  }</a>
<a name="ln2500">  LogFlush(db_options_.info_log);</a>
<a name="ln2501">  return s;</a>
<a name="ln2502">#endif  // ROCKSDB_LITE</a>
<a name="ln2503">}</a>
<a name="ln2504"> </a>
<a name="ln2505">// return the same level if it cannot be moved</a>
<a name="ln2506">int DBImpl::FindMinimumEmptyLevelFitting(ColumnFamilyData* cfd,</a>
<a name="ln2507">    const MutableCFOptions&amp; mutable_cf_options, int level) {</a>
<a name="ln2508">  mutex_.AssertHeld();</a>
<a name="ln2509">  const auto* vstorage = cfd-&gt;current()-&gt;storage_info();</a>
<a name="ln2510">  int minimum_level = level;</a>
<a name="ln2511">  for (int i = level - 1; i &gt; 0; --i) {</a>
<a name="ln2512">    // stop if level i is not empty</a>
<a name="ln2513">    if (vstorage-&gt;NumLevelFiles(i) &gt; 0) break;</a>
<a name="ln2514">    // stop if level i is too small (cannot fit the level files)</a>
<a name="ln2515">    if (vstorage-&gt;MaxBytesForLevel(i) &lt; vstorage-&gt;NumLevelBytes(level)) {</a>
<a name="ln2516">      break;</a>
<a name="ln2517">    }</a>
<a name="ln2518"> </a>
<a name="ln2519">    minimum_level = i;</a>
<a name="ln2520">  }</a>
<a name="ln2521">  return minimum_level;</a>
<a name="ln2522">}</a>
<a name="ln2523"> </a>
<a name="ln2524">// REQUIREMENT: block all background work by calling PauseBackgroundWork()</a>
<a name="ln2525">// before calling this function</a>
<a name="ln2526">Status DBImpl::ReFitLevel(ColumnFamilyData* cfd, int level, int target_level) {</a>
<a name="ln2527">  assert(level &lt; cfd-&gt;NumberLevels());</a>
<a name="ln2528">  if (target_level &gt;= cfd-&gt;NumberLevels()) {</a>
<a name="ln2529">    return STATUS(InvalidArgument, &quot;Target level exceeds number of levels&quot;);</a>
<a name="ln2530">  }</a>
<a name="ln2531"> </a>
<a name="ln2532">  std::unique_ptr&lt;SuperVersion&gt; superversion_to_free;</a>
<a name="ln2533">  std::unique_ptr&lt;SuperVersion&gt; new_superversion(new SuperVersion());</a>
<a name="ln2534"> </a>
<a name="ln2535">  Status status;</a>
<a name="ln2536"> </a>
<a name="ln2537">  InstrumentedMutexLock guard_lock(&amp;mutex_);</a>
<a name="ln2538"> </a>
<a name="ln2539">  // only allow one thread refitting</a>
<a name="ln2540">  if (refitting_level_) {</a>
<a name="ln2541">    RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln2542">        &quot;[ReFitLevel] another thread is refitting&quot;);</a>
<a name="ln2543">    return STATUS(NotSupported, &quot;another thread is refitting&quot;);</a>
<a name="ln2544">  }</a>
<a name="ln2545">  refitting_level_ = true;</a>
<a name="ln2546"> </a>
<a name="ln2547">  const MutableCFOptions mutable_cf_options = *cfd-&gt;GetLatestMutableCFOptions();</a>
<a name="ln2548">  // move to a smaller level</a>
<a name="ln2549">  int to_level = target_level;</a>
<a name="ln2550">  if (target_level &lt; 0) {</a>
<a name="ln2551">    to_level = FindMinimumEmptyLevelFitting(cfd, mutable_cf_options, level);</a>
<a name="ln2552">  }</a>
<a name="ln2553"> </a>
<a name="ln2554">  auto* vstorage = cfd-&gt;current()-&gt;storage_info();</a>
<a name="ln2555">  if (to_level &gt; level) {</a>
<a name="ln2556">    if (level == 0) {</a>
<a name="ln2557">      return STATUS(NotSupported,</a>
<a name="ln2558">          &quot;Cannot change from level 0 to other levels.&quot;);</a>
<a name="ln2559">    }</a>
<a name="ln2560">    // Check levels are empty for a trivial move</a>
<a name="ln2561">    for (int l = level + 1; l &lt;= to_level; l++) {</a>
<a name="ln2562">      if (vstorage-&gt;NumLevelFiles(l) &gt; 0) {</a>
<a name="ln2563">        return STATUS(NotSupported,</a>
<a name="ln2564">            &quot;Levels between source and target are not empty for a move.&quot;);</a>
<a name="ln2565">      }</a>
<a name="ln2566">    }</a>
<a name="ln2567">  }</a>
<a name="ln2568">  if (to_level != level) {</a>
<a name="ln2569">    RLOG(InfoLogLevel::DEBUG_LEVEL, db_options_.info_log,</a>
<a name="ln2570">        &quot;[%s] Before refitting:\n%s&quot;, cfd-&gt;GetName().c_str(),</a>
<a name="ln2571">        cfd-&gt;current()-&gt;DebugString().data());</a>
<a name="ln2572"> </a>
<a name="ln2573">    VersionEdit edit;</a>
<a name="ln2574">    edit.SetColumnFamily(cfd-&gt;GetID());</a>
<a name="ln2575">    for (const auto&amp; f : vstorage-&gt;LevelFiles(level)) {</a>
<a name="ln2576">      edit.DeleteFile(level, f-&gt;fd.GetNumber());</a>
<a name="ln2577">      edit.AddCleanedFile(to_level, *f);</a>
<a name="ln2578">    }</a>
<a name="ln2579">    RLOG(InfoLogLevel::DEBUG_LEVEL, db_options_.info_log,</a>
<a name="ln2580">        &quot;[%s] Apply version edit:\n%s&quot;, cfd-&gt;GetName().c_str(),</a>
<a name="ln2581">        edit.DebugString().data());</a>
<a name="ln2582"> </a>
<a name="ln2583">    status = versions_-&gt;LogAndApply(cfd, mutable_cf_options, &amp;edit, &amp;mutex_,</a>
<a name="ln2584">                                    directories_.GetDbDir());</a>
<a name="ln2585">    superversion_to_free = InstallSuperVersionAndScheduleWork(</a>
<a name="ln2586">       cfd, new_superversion.release(), mutable_cf_options);</a>
<a name="ln2587"> </a>
<a name="ln2588">    RLOG(InfoLogLevel::DEBUG_LEVEL, db_options_.info_log,</a>
<a name="ln2589">        &quot;[%s] LogAndApply: %s\n&quot;, cfd-&gt;GetName().c_str(),</a>
<a name="ln2590">        status.ToString().data());</a>
<a name="ln2591"> </a>
<a name="ln2592">    if (status.ok()) {</a>
<a name="ln2593">      RLOG(InfoLogLevel::DEBUG_LEVEL, db_options_.info_log,</a>
<a name="ln2594">          &quot;[%s] After refitting:\n%s&quot;, cfd-&gt;GetName().c_str(),</a>
<a name="ln2595">          cfd-&gt;current()-&gt;DebugString().data());</a>
<a name="ln2596">    }</a>
<a name="ln2597">  }</a>
<a name="ln2598"> </a>
<a name="ln2599">  refitting_level_ = false;</a>
<a name="ln2600"> </a>
<a name="ln2601">  return status;</a>
<a name="ln2602">}</a>
<a name="ln2603"> </a>
<a name="ln2604">int DBImpl::NumberLevels(ColumnFamilyHandle* column_family) {</a>
<a name="ln2605">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln2606">  return cfh-&gt;cfd()-&gt;NumberLevels();</a>
<a name="ln2607">}</a>
<a name="ln2608"> </a>
<a name="ln2609">int DBImpl::MaxMemCompactionLevel(ColumnFamilyHandle* column_family) {</a>
<a name="ln2610">  return 0;</a>
<a name="ln2611">}</a>
<a name="ln2612"> </a>
<a name="ln2613">int DBImpl::Level0StopWriteTrigger(ColumnFamilyHandle* column_family) {</a>
<a name="ln2614">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln2615">  InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln2616">  return cfh-&gt;cfd()-&gt;GetSuperVersion()-&gt;</a>
<a name="ln2617">      mutable_cf_options.level0_stop_writes_trigger;</a>
<a name="ln2618">}</a>
<a name="ln2619"> </a>
<a name="ln2620">Status DBImpl::Flush(const FlushOptions&amp; flush_options,</a>
<a name="ln2621">                     ColumnFamilyHandle* column_family) {</a>
<a name="ln2622">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln2623">  return FlushMemTable(cfh-&gt;cfd(), flush_options);</a>
<a name="ln2624">}</a>
<a name="ln2625"> </a>
<a name="ln2626">Status DBImpl::WaitForFlush(ColumnFamilyHandle* column_family) {</a>
<a name="ln2627">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln2628">  // Wait until the flush completes.</a>
<a name="ln2629">  return WaitForFlushMemTable(cfh-&gt;cfd());</a>
<a name="ln2630">}</a>
<a name="ln2631"> </a>
<a name="ln2632">Status DBImpl::SyncWAL() {</a>
<a name="ln2633">  autovector&lt;log::Writer*, 1&gt; logs_to_sync;</a>
<a name="ln2634">  bool need_log_dir_sync;</a>
<a name="ln2635">  uint64_t current_log_number;</a>
<a name="ln2636"> </a>
<a name="ln2637">  {</a>
<a name="ln2638">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln2639">    assert(!logs_.empty());</a>
<a name="ln2640"> </a>
<a name="ln2641">    // This SyncWAL() call only cares about logs up to this number.</a>
<a name="ln2642">    current_log_number = logfile_number_;</a>
<a name="ln2643"> </a>
<a name="ln2644">    while (logs_.front().number &lt;= current_log_number &amp;&amp;</a>
<a name="ln2645">           logs_.front().getting_synced) {</a>
<a name="ln2646">      log_sync_cv_.Wait();</a>
<a name="ln2647">    }</a>
<a name="ln2648">    // First check that logs are safe to sync in background.</a>
<a name="ln2649">    for (auto it = logs_.begin();</a>
<a name="ln2650">         it != logs_.end() &amp;&amp; it-&gt;number &lt;= current_log_number; ++it) {</a>
<a name="ln2651">      if (!it-&gt;writer-&gt;file()-&gt;writable_file()-&gt;IsSyncThreadSafe()) {</a>
<a name="ln2652">        return STATUS(NotSupported,</a>
<a name="ln2653">          &quot;SyncWAL() is not supported for this implementation of WAL file&quot;,</a>
<a name="ln2654">          db_options_.allow_mmap_writes</a>
<a name="ln2655">            ? &quot;try setting Options::allow_mmap_writes to false&quot;</a>
<a name="ln2656">            : yb::Slice());</a>
<a name="ln2657">      }</a>
<a name="ln2658">    }</a>
<a name="ln2659">    for (auto it = logs_.begin();</a>
<a name="ln2660">         it != logs_.end() &amp;&amp; it-&gt;number &lt;= current_log_number; ++it) {</a>
<a name="ln2661">      auto&amp; log = *it;</a>
<a name="ln2662">      assert(!log.getting_synced);</a>
<a name="ln2663">      log.getting_synced = true;</a>
<a name="ln2664">      logs_to_sync.push_back(log.writer);</a>
<a name="ln2665">    }</a>
<a name="ln2666"> </a>
<a name="ln2667">    need_log_dir_sync = !log_dir_synced_;</a>
<a name="ln2668">  }</a>
<a name="ln2669"> </a>
<a name="ln2670">  RecordTick(stats_, WAL_FILE_SYNCED);</a>
<a name="ln2671">  Status status;</a>
<a name="ln2672">  for (log::Writer* log : logs_to_sync) {</a>
<a name="ln2673">    status = log-&gt;file()-&gt;SyncWithoutFlush(db_options_.use_fsync);</a>
<a name="ln2674">    if (!status.ok()) {</a>
<a name="ln2675">      break;</a>
<a name="ln2676">    }</a>
<a name="ln2677">  }</a>
<a name="ln2678">  if (status.ok() &amp;&amp; need_log_dir_sync) {</a>
<a name="ln2679">    status = directories_.GetWalDir()-&gt;Fsync();</a>
<a name="ln2680">  }</a>
<a name="ln2681"> </a>
<a name="ln2682">  TEST_SYNC_POINT(&quot;DBImpl::SyncWAL:BeforeMarkLogsSynced:1&quot;);</a>
<a name="ln2683">  TEST_SYNC_POINT(&quot;DBImpl::SyncWAL:BeforeMarkLogsSynced:2&quot;);</a>
<a name="ln2684"> </a>
<a name="ln2685">  {</a>
<a name="ln2686">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln2687">    MarkLogsSynced(current_log_number, need_log_dir_sync, status);</a>
<a name="ln2688">  }</a>
<a name="ln2689"> </a>
<a name="ln2690">  return status;</a>
<a name="ln2691">}</a>
<a name="ln2692"> </a>
<a name="ln2693">void DBImpl::MarkLogsSynced(</a>
<a name="ln2694">    uint64_t up_to, bool synced_dir, const Status&amp; status) {</a>
<a name="ln2695">  mutex_.AssertHeld();</a>
<a name="ln2696">  if (synced_dir &amp;&amp;</a>
<a name="ln2697">      logfile_number_ == up_to &amp;&amp;</a>
<a name="ln2698">      status.ok()) {</a>
<a name="ln2699">    log_dir_synced_ = true;</a>
<a name="ln2700">  }</a>
<a name="ln2701">  for (auto it = logs_.begin(); it != logs_.end() &amp;&amp; it-&gt;number &lt;= up_to;) {</a>
<a name="ln2702">    auto&amp; log = *it;</a>
<a name="ln2703">    assert(log.getting_synced);</a>
<a name="ln2704">    if (status.ok() &amp;&amp; logs_.size() &gt; 1) {</a>
<a name="ln2705">      logs_to_free_.push_back(log.ReleaseWriter());</a>
<a name="ln2706">      it = logs_.erase(it);</a>
<a name="ln2707">    } else {</a>
<a name="ln2708">      log.getting_synced = false;</a>
<a name="ln2709">      ++it;</a>
<a name="ln2710">    }</a>
<a name="ln2711">  }</a>
<a name="ln2712">  assert(logs_.empty() || logs_[0].number &gt; up_to ||</a>
<a name="ln2713">         (logs_.size() == 1 &amp;&amp; !logs_[0].getting_synced));</a>
<a name="ln2714">  log_sync_cv_.SignalAll();</a>
<a name="ln2715">}</a>
<a name="ln2716"> </a>
<a name="ln2717">SequenceNumber DBImpl::GetLatestSequenceNumber() const {</a>
<a name="ln2718">  return versions_-&gt;LastSequence();</a>
<a name="ln2719">}</a>
<a name="ln2720"> </a>
<a name="ln2721">void DBImpl::SubmitCompactionOrFlushTask(std::unique_ptr&lt;ThreadPoolTask&gt; task) {</a>
<a name="ln2722">  mutex_.AssertHeld();</a>
<a name="ln2723">  if (task-&gt;Type() == BgTaskType::kCompaction) {</a>
<a name="ln2724">    compaction_tasks_.insert(down_cast&lt;CompactionTask*&gt;(task.get()));</a>
<a name="ln2725">  }</a>
<a name="ln2726">  auto status = db_options_.priority_thread_pool_for_compactions_and_flushes-&gt;Submit(</a>
<a name="ln2727">      task-&gt;Priority(), &amp;task);</a>
<a name="ln2728">  if (!status.ok()) {</a>
<a name="ln2729">    task-&gt;AbortedUnlocked();</a>
<a name="ln2730">  }</a>
<a name="ln2731">}</a>
<a name="ln2732"> </a>
<a name="ln2733">Status DBImpl::RunManualCompaction(ColumnFamilyData* cfd, int input_level,</a>
<a name="ln2734">                                   int output_level, uint32_t output_path_id,</a>
<a name="ln2735">                                   const Slice* begin, const Slice* end,</a>
<a name="ln2736">                                   bool exclusive, bool disallow_trivial_move) {</a>
<a name="ln2737">  assert(input_level == ColumnFamilyData::kCompactAllLevels ||</a>
<a name="ln2738">         input_level &gt;= 0);</a>
<a name="ln2739"> </a>
<a name="ln2740">  InternalKey begin_storage, end_storage;</a>
<a name="ln2741">  CompactionArg* ca;</a>
<a name="ln2742"> </a>
<a name="ln2743">  bool scheduled = false;</a>
<a name="ln2744">  bool manual_conflict = false;</a>
<a name="ln2745">  ManualCompaction manual_compaction;</a>
<a name="ln2746">  manual_compaction.cfd = cfd;</a>
<a name="ln2747">  manual_compaction.input_level = input_level;</a>
<a name="ln2748">  manual_compaction.output_level = output_level;</a>
<a name="ln2749">  manual_compaction.output_path_id = output_path_id;</a>
<a name="ln2750">  manual_compaction.done = false;</a>
<a name="ln2751">  manual_compaction.in_progress = false;</a>
<a name="ln2752">  manual_compaction.incomplete = false;</a>
<a name="ln2753">  manual_compaction.exclusive = exclusive;</a>
<a name="ln2754">  manual_compaction.disallow_trivial_move = disallow_trivial_move;</a>
<a name="ln2755">  // For universal compaction, we enforce every manual compaction to compact</a>
<a name="ln2756">  // all files.</a>
<a name="ln2757">  if (begin == nullptr ||</a>
<a name="ln2758">      cfd-&gt;ioptions()-&gt;compaction_style == kCompactionStyleUniversal ||</a>
<a name="ln2759">      cfd-&gt;ioptions()-&gt;compaction_style == kCompactionStyleFIFO) {</a>
<a name="ln2760">    manual_compaction.begin = nullptr;</a>
<a name="ln2761">  } else {</a>
<a name="ln2762">    begin_storage = InternalKey::MaxPossibleForUserKey(*begin);</a>
<a name="ln2763">    manual_compaction.begin = &amp;begin_storage;</a>
<a name="ln2764">  }</a>
<a name="ln2765">  if (end == nullptr ||</a>
<a name="ln2766">      cfd-&gt;ioptions()-&gt;compaction_style == kCompactionStyleUniversal ||</a>
<a name="ln2767">      cfd-&gt;ioptions()-&gt;compaction_style == kCompactionStyleFIFO) {</a>
<a name="ln2768">    manual_compaction.end = nullptr;</a>
<a name="ln2769">  } else {</a>
<a name="ln2770">    end_storage = InternalKey::MinPossibleForUserKey(*end);</a>
<a name="ln2771">    manual_compaction.end = &amp;end_storage;</a>
<a name="ln2772">  }</a>
<a name="ln2773"> </a>
<a name="ln2774">  InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln2775"> </a>
<a name="ln2776">  // When a manual compaction arrives, if it is exclusive, run all scheduled</a>
<a name="ln2777">  // and unscheduled compactions (from the queue) and then run the manual</a>
<a name="ln2778">  // one. This is to ensure that any key range can be compacted without</a>
<a name="ln2779">  // conflict. Otherwise, we let the manual compaction conflict until all</a>
<a name="ln2780">  // automatic compactions from the same column family have been scheduled</a>
<a name="ln2781">  // and run in the background.</a>
<a name="ln2782">  //</a>
<a name="ln2783">  // HasPendingManualCompaction() is true when at least one thread is inside</a>
<a name="ln2784">  // RunManualCompaction(), i.e. during that time no other compaction will</a>
<a name="ln2785">  // get scheduled (see MaybeScheduleFlushOrCompaction).</a>
<a name="ln2786">  //</a>
<a name="ln2787">  // Note that the following loop doesn't stop more that one thread calling</a>
<a name="ln2788">  // RunManualCompaction() from getting to the second while loop below.</a>
<a name="ln2789">  // However, only one of them will actually schedule compaction, while</a>
<a name="ln2790">  // others will wait on a condition variable until it completes.</a>
<a name="ln2791"> </a>
<a name="ln2792">  AddManualCompaction(&amp;manual_compaction);</a>
<a name="ln2793">  TEST_SYNC_POINT_CALLBACK(&quot;DBImpl::RunManualCompaction:NotScheduled&quot;, &amp;mutex_);</a>
<a name="ln2794">  if (exclusive) {</a>
<a name="ln2795">    while (unscheduled_compactions_ + bg_compaction_scheduled_ + compaction_tasks_.size() &gt; 0) {</a>
<a name="ln2796">      TEST_SYNC_POINT(&quot;DBImpl::RunManualCompaction()::Conflict&quot;);</a>
<a name="ln2797">      MaybeScheduleFlushOrCompaction();</a>
<a name="ln2798">      while (bg_compaction_scheduled_ + compaction_tasks_.size() &gt; 0) {</a>
<a name="ln2799">        RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln2800">             &quot;[%s] Manual compaction waiting for all other scheduled background &quot;</a>
<a name="ln2801">                 &quot;compactions to finish&quot;,</a>
<a name="ln2802">             cfd-&gt;GetName().c_str());</a>
<a name="ln2803">        bg_cv_.Wait();</a>
<a name="ln2804">      }</a>
<a name="ln2805">    }</a>
<a name="ln2806">  }</a>
<a name="ln2807"> </a>
<a name="ln2808">  RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln2809">      &quot;[%s] Manual compaction starting&quot;,</a>
<a name="ln2810">      cfd-&gt;GetName().c_str());</a>
<a name="ln2811"> </a>
<a name="ln2812">  // We don't check bg_error_ here, because if we get the error in compaction,</a>
<a name="ln2813">  // the compaction will set manual_compaction.status to bg_error_ and set manual_compaction.done to</a>
<a name="ln2814">  // true.</a>
<a name="ln2815">  while (!manual_compaction.done) {</a>
<a name="ln2816">    assert(HasPendingManualCompaction());</a>
<a name="ln2817">    manual_conflict = false;</a>
<a name="ln2818">    if (ShouldntRunManualCompaction(&amp;manual_compaction) || manual_compaction.in_progress ||</a>
<a name="ln2819">        scheduled ||</a>
<a name="ln2820">        ((manual_compaction.manual_end = &amp;manual_compaction.tmp_storage1) &amp;&amp; (</a>
<a name="ln2821">             (manual_compaction.compaction = manual_compaction.cfd-&gt;CompactRange(</a>
<a name="ln2822">                  *manual_compaction.cfd-&gt;GetLatestMutableCFOptions(),</a>
<a name="ln2823">                  manual_compaction.input_level, manual_compaction.output_level,</a>
<a name="ln2824">                  manual_compaction.output_path_id, manual_compaction.begin, manual_compaction.end,</a>
<a name="ln2825">                  &amp;manual_compaction.manual_end, &amp;manual_conflict)) ==</a>
<a name="ln2826">             nullptr) &amp;&amp;</a>
<a name="ln2827">         manual_conflict)) {</a>
<a name="ln2828">      // exclusive manual compactions should not see a conflict during</a>
<a name="ln2829">      // CompactRange</a>
<a name="ln2830">      assert(!exclusive || !manual_conflict);</a>
<a name="ln2831">      if (manual_conflict) {</a>
<a name="ln2832">        TEST_SYNC_POINT(&quot;DBImpl::RunManualCompaction()::Conflict&quot;);</a>
<a name="ln2833">      }</a>
<a name="ln2834">      // Running either this or some other manual compaction</a>
<a name="ln2835">      bg_cv_.Wait();</a>
<a name="ln2836">      if (scheduled &amp;&amp; manual_compaction.incomplete == true) {</a>
<a name="ln2837">        assert(!manual_compaction.in_progress);</a>
<a name="ln2838">        scheduled = false;</a>
<a name="ln2839">        manual_compaction.incomplete = false;</a>
<a name="ln2840">      }</a>
<a name="ln2841">    } else if (!scheduled) {</a>
<a name="ln2842">      if (manual_compaction.compaction == nullptr) {</a>
<a name="ln2843">        manual_compaction.done = true;</a>
<a name="ln2844">        bg_cv_.SignalAll();</a>
<a name="ln2845">        continue;</a>
<a name="ln2846">      }</a>
<a name="ln2847">      manual_compaction.incomplete = false;</a>
<a name="ln2848">      if (db_options_.priority_thread_pool_for_compactions_and_flushes &amp;&amp;</a>
<a name="ln2849">          FLAGS_use_priority_thread_pool_for_compactions) {</a>
<a name="ln2850">        SubmitCompactionOrFlushTask(std::make_unique&lt;CompactionTask&gt;(this, &amp;manual_compaction));</a>
<a name="ln2851">      } else {</a>
<a name="ln2852">        bg_compaction_scheduled_++;</a>
<a name="ln2853">        ca = new CompactionArg;</a>
<a name="ln2854">        ca-&gt;db = this;</a>
<a name="ln2855">        ca-&gt;m = &amp;manual_compaction;</a>
<a name="ln2856">        env_-&gt;Schedule(&amp;DBImpl::BGWorkCompaction, ca, Env::Priority::LOW, this,</a>
<a name="ln2857">                       &amp;DBImpl::UnscheduleCallback);</a>
<a name="ln2858">      }</a>
<a name="ln2859">      scheduled = true;</a>
<a name="ln2860">    }</a>
<a name="ln2861">  }</a>
<a name="ln2862"> </a>
<a name="ln2863">  assert(!manual_compaction.in_progress);</a>
<a name="ln2864">  assert(HasPendingManualCompaction());</a>
<a name="ln2865">  RemoveManualCompaction(&amp;manual_compaction);</a>
<a name="ln2866">  bg_cv_.SignalAll();</a>
<a name="ln2867">  return manual_compaction.status;</a>
<a name="ln2868">}</a>
<a name="ln2869"> </a>
<a name="ln2870">InternalIterator* DBImpl::NewInternalIterator(</a>
<a name="ln2871">    Arena* arena, ColumnFamilyHandle* column_family) {</a>
<a name="ln2872">  ColumnFamilyData* cfd;</a>
<a name="ln2873">  if (column_family == nullptr) {</a>
<a name="ln2874">    cfd = default_cf_handle_-&gt;cfd();</a>
<a name="ln2875">  } else {</a>
<a name="ln2876">    auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln2877">    cfd = cfh-&gt;cfd();</a>
<a name="ln2878">  }</a>
<a name="ln2879"> </a>
<a name="ln2880">  mutex_.Lock();</a>
<a name="ln2881">  SuperVersion* super_version = cfd-&gt;GetSuperVersion()-&gt;Ref();</a>
<a name="ln2882">  mutex_.Unlock();</a>
<a name="ln2883">  ReadOptions roptions;</a>
<a name="ln2884">  return NewInternalIterator(roptions, cfd, super_version, arena);</a>
<a name="ln2885">}</a>
<a name="ln2886"> </a>
<a name="ln2887">int DBImpl::GetCfdImmNumNotFlushed() {</a>
<a name="ln2888">  auto cfd = down_cast&lt;ColumnFamilyHandleImpl*&gt;(DefaultColumnFamily())-&gt;cfd();</a>
<a name="ln2889">  InstrumentedMutexLock guard_lock(&amp;mutex_);</a>
<a name="ln2890">  return cfd-&gt;imm()-&gt;NumNotFlushed();</a>
<a name="ln2891">}</a>
<a name="ln2892"> </a>
<a name="ln2893">FlushAbility DBImpl::GetFlushAbility() {</a>
<a name="ln2894">  auto cfd = down_cast&lt;ColumnFamilyHandleImpl*&gt;(DefaultColumnFamily())-&gt;cfd();</a>
<a name="ln2895">  InstrumentedMutexLock guard_lock(&amp;mutex_);</a>
<a name="ln2896">  if (cfd-&gt;imm()-&gt;NumNotFlushed() != 0) {</a>
<a name="ln2897">    return FlushAbility::kAlreadyFlushing;</a>
<a name="ln2898">  }</a>
<a name="ln2899">  return cfd-&gt;mem()-&gt;IsEmpty() ? FlushAbility::kNoNewData : FlushAbility::kHasNewData;</a>
<a name="ln2900">}</a>
<a name="ln2901"> </a>
<a name="ln2902">Status DBImpl::FlushMemTable(ColumnFamilyData* cfd,</a>
<a name="ln2903">                             const FlushOptions&amp; flush_options) {</a>
<a name="ln2904">  Status s;</a>
<a name="ln2905">  {</a>
<a name="ln2906">    WriteContext context;</a>
<a name="ln2907">    InstrumentedMutexLock guard_lock(&amp;mutex_);</a>
<a name="ln2908"> </a>
<a name="ln2909">    if (last_flush_at_tick_ &gt; flush_options.ignore_if_flushed_after_tick) {</a>
<a name="ln2910">      return STATUS(AlreadyPresent, &quot;Mem table already flushed&quot;);</a>
<a name="ln2911">    }</a>
<a name="ln2912"> </a>
<a name="ln2913">    if (cfd-&gt;imm()-&gt;NumNotFlushed() == 0 &amp;&amp; cfd-&gt;mem()-&gt;IsEmpty()) {</a>
<a name="ln2914">      // Nothing to flush</a>
<a name="ln2915">      return Status::OK();</a>
<a name="ln2916">    }</a>
<a name="ln2917"> </a>
<a name="ln2918">    last_flush_at_tick_ = FlushTick();</a>
<a name="ln2919"> </a>
<a name="ln2920">    WriteThread::Writer w;</a>
<a name="ln2921">    write_thread_.EnterUnbatched(&amp;w, &amp;mutex_);</a>
<a name="ln2922"> </a>
<a name="ln2923">    // SwitchMemtable() will release and reacquire mutex</a>
<a name="ln2924">    // during execution</a>
<a name="ln2925">    s = SwitchMemtable(cfd, &amp;context);</a>
<a name="ln2926">    write_thread_.ExitUnbatched(&amp;w);</a>
<a name="ln2927"> </a>
<a name="ln2928">    cfd-&gt;imm()-&gt;FlushRequested();</a>
<a name="ln2929"> </a>
<a name="ln2930">    // schedule flush</a>
<a name="ln2931">    SchedulePendingFlush(cfd);</a>
<a name="ln2932">    MaybeScheduleFlushOrCompaction();</a>
<a name="ln2933">  }</a>
<a name="ln2934"> </a>
<a name="ln2935">  if (s.ok() &amp;&amp; flush_options.wait) {</a>
<a name="ln2936">    // Wait until the compaction completes</a>
<a name="ln2937">    s = WaitForFlushMemTable(cfd);</a>
<a name="ln2938">  }</a>
<a name="ln2939">  return s;</a>
<a name="ln2940">}</a>
<a name="ln2941"> </a>
<a name="ln2942">Status DBImpl::WaitForFlushMemTable(ColumnFamilyData* cfd) {</a>
<a name="ln2943">  Status s;</a>
<a name="ln2944">  // Wait until the compaction completes</a>
<a name="ln2945">  InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln2946">  while (cfd-&gt;imm()-&gt;NumNotFlushed() &gt; 0 &amp;&amp; bg_error_.ok()) {</a>
<a name="ln2947">    if (shutting_down_.load(std::memory_order_acquire)) {</a>
<a name="ln2948">      return STATUS(ShutdownInProgress, &quot;&quot;);</a>
<a name="ln2949">    }</a>
<a name="ln2950">    bg_cv_.Wait();</a>
<a name="ln2951">  }</a>
<a name="ln2952">  if (!bg_error_.ok()) {</a>
<a name="ln2953">    s = bg_error_;</a>
<a name="ln2954">  }</a>
<a name="ln2955">  return s;</a>
<a name="ln2956">}</a>
<a name="ln2957"> </a>
<a name="ln2958">Status DBImpl::EnableAutoCompaction(</a>
<a name="ln2959">    const std::vector&lt;ColumnFamilyHandle*&gt;&amp; column_family_handles) {</a>
<a name="ln2960">  Status s;</a>
<a name="ln2961">  for (auto cf_ptr : column_family_handles) {</a>
<a name="ln2962">    Status status =</a>
<a name="ln2963">        this-&gt;SetOptions(cf_ptr, {{&quot;disable_auto_compactions&quot;, &quot;false&quot;}});</a>
<a name="ln2964">    if (status.ok()) {</a>
<a name="ln2965">      ColumnFamilyData* cfd = down_cast&lt;ColumnFamilyHandleImpl*&gt;(cf_ptr)-&gt;cfd();</a>
<a name="ln2966">      InstrumentedMutexLock guard_lock(&amp;mutex_);</a>
<a name="ln2967">      InstallSuperVersionAndScheduleWork(cfd, nullptr, *cfd-&gt;GetLatestMutableCFOptions());</a>
<a name="ln2968">    } else {</a>
<a name="ln2969">      s = status;</a>
<a name="ln2970">    }</a>
<a name="ln2971">  }</a>
<a name="ln2972"> </a>
<a name="ln2973">  return s;</a>
<a name="ln2974">}</a>
<a name="ln2975"> </a>
<a name="ln2976">void DBImpl::MaybeScheduleFlushOrCompaction() {</a>
<a name="ln2977">  mutex_.AssertHeld();</a>
<a name="ln2978">  if (!opened_successfully_) {</a>
<a name="ln2979">    // Compaction may introduce data race to DB open</a>
<a name="ln2980">    return;</a>
<a name="ln2981">  }</a>
<a name="ln2982">  if (bg_work_paused_ &gt; 0) {</a>
<a name="ln2983">    // we paused the background work</a>
<a name="ln2984">    return;</a>
<a name="ln2985">  } else if (shutting_down_.load(std::memory_order_acquire)) {</a>
<a name="ln2986">    // DB is being deleted; no more background compactions</a>
<a name="ln2987">    return;</a>
<a name="ln2988">  }</a>
<a name="ln2989"> </a>
<a name="ln2990">  while (unscheduled_flushes_ &gt; 0 &amp;&amp;</a>
<a name="ln2991">         bg_flush_scheduled_ &lt; db_options_.max_background_flushes) {</a>
<a name="ln2992">    unscheduled_flushes_--;</a>
<a name="ln2993">    bg_flush_scheduled_++;</a>
<a name="ln2994">    env_-&gt;Schedule(&amp;DBImpl::BGWorkFlush, this, Env::Priority::HIGH, this);</a>
<a name="ln2995">  }</a>
<a name="ln2996"> </a>
<a name="ln2997">  size_t bg_compactions_allowed = BGCompactionsAllowed();</a>
<a name="ln2998"> </a>
<a name="ln2999">  // special case -- if max_background_flushes == 0, then schedule flush on a</a>
<a name="ln3000">  // compaction thread</a>
<a name="ln3001">  if (db_options_.max_background_flushes == 0) {</a>
<a name="ln3002">    while (unscheduled_flushes_ &gt; 0 &amp;&amp;</a>
<a name="ln3003">           bg_flush_scheduled_ + bg_compaction_scheduled_ + compaction_tasks_.size() &lt;</a>
<a name="ln3004">               bg_compactions_allowed) {</a>
<a name="ln3005">      unscheduled_flushes_--;</a>
<a name="ln3006">      bg_flush_scheduled_++;</a>
<a name="ln3007">      env_-&gt;Schedule(&amp;DBImpl::BGWorkFlush, this, Env::Priority::LOW, this);</a>
<a name="ln3008">    }</a>
<a name="ln3009">  }</a>
<a name="ln3010"> </a>
<a name="ln3011">  if (bg_compaction_paused_ &gt; 0) {</a>
<a name="ln3012">    // we paused the background compaction</a>
<a name="ln3013">    return;</a>
<a name="ln3014">  }</a>
<a name="ln3015"> </a>
<a name="ln3016">  while (bg_compaction_scheduled_ + compaction_tasks_.size() &lt; bg_compactions_allowed &amp;&amp;</a>
<a name="ln3017">         unscheduled_compactions_ &gt; 0) {</a>
<a name="ln3018">    bg_compaction_scheduled_++;</a>
<a name="ln3019">    unscheduled_compactions_--;</a>
<a name="ln3020">    CompactionArg* ca = new CompactionArg;</a>
<a name="ln3021">    ca-&gt;db = this;</a>
<a name="ln3022">    ca-&gt;m = nullptr;</a>
<a name="ln3023">    env_-&gt;Schedule(&amp;DBImpl::BGWorkCompaction, ca, Env::Priority::LOW, this,</a>
<a name="ln3024">                   &amp;DBImpl::UnscheduleCallback);</a>
<a name="ln3025">  }</a>
<a name="ln3026">}</a>
<a name="ln3027"> </a>
<a name="ln3028">int DBImpl::BGCompactionsAllowed() const {</a>
<a name="ln3029">  if (write_controller_.NeedSpeedupCompaction()) {</a>
<a name="ln3030">    return db_options_.max_background_compactions;</a>
<a name="ln3031">  } else {</a>
<a name="ln3032">    return db_options_.base_background_compactions;</a>
<a name="ln3033">  }</a>
<a name="ln3034">}</a>
<a name="ln3035"> </a>
<a name="ln3036">bool DBImpl::IsEmptyCompactionQueue() {</a>
<a name="ln3037">  return small_compaction_queue_.empty() &amp;&amp; large_compaction_queue_.empty();</a>
<a name="ln3038">}</a>
<a name="ln3039"> </a>
<a name="ln3040">bool DBImpl::AddToCompactionQueue(ColumnFamilyData* cfd) {</a>
<a name="ln3041">  mutex_.AssertHeld();</a>
<a name="ln3042"> </a>
<a name="ln3043">  assert(!cfd-&gt;pending_compaction());</a>
<a name="ln3044"> </a>
<a name="ln3045">  const MutableCFOptions* mutable_cf_options = cfd-&gt;GetLatestMutableCFOptions();</a>
<a name="ln3046">  std::unique_ptr&lt;Compaction&gt; c;</a>
<a name="ln3047"> </a>
<a name="ln3048">  if (!mutable_cf_options-&gt;disable_auto_compactions &amp;&amp; !cfd-&gt;IsDropped()</a>
<a name="ln3049">        &amp;&amp; !(HasExclusiveManualCompaction() || HaveManualCompaction(cfd))) {</a>
<a name="ln3050">    LogBuffer log_buffer(InfoLogLevel::INFO_LEVEL, db_options_.info_log.get());</a>
<a name="ln3051">    c = cfd-&gt;PickCompaction(*cfd-&gt;GetLatestMutableCFOptions(), &amp;log_buffer);</a>
<a name="ln3052">    log_buffer.FlushBufferToLog();</a>
<a name="ln3053">    if (c) {</a>
<a name="ln3054">      cfd-&gt;Ref();</a>
<a name="ln3055">      if (db_options_.priority_thread_pool_for_compactions_and_flushes &amp;&amp;</a>
<a name="ln3056">          FLAGS_use_priority_thread_pool_for_compactions) {</a>
<a name="ln3057">        SubmitCompactionOrFlushTask(std::make_unique&lt;CompactionTask&gt;(this, std::move(c)));</a>
<a name="ln3058">        // True means that we need to schedule one more compaction, since it is already scheduled</a>
<a name="ln3059">        // one line above we return false.</a>
<a name="ln3060">        return false;</a>
<a name="ln3061">      } else if (!IsLargeCompaction(*c)) {</a>
<a name="ln3062">        small_compaction_queue_.push_back(std::move(c));</a>
<a name="ln3063">      } else {</a>
<a name="ln3064">        large_compaction_queue_.push_back(std::move(c));</a>
<a name="ln3065">      }</a>
<a name="ln3066">      cfd-&gt;set_pending_compaction(true);</a>
<a name="ln3067">      return true;</a>
<a name="ln3068">    }</a>
<a name="ln3069">  }</a>
<a name="ln3070"> </a>
<a name="ln3071">  return false;</a>
<a name="ln3072">}</a>
<a name="ln3073"> </a>
<a name="ln3074">std::unique_ptr&lt;Compaction&gt; DBImpl::PopFirstFromSmallCompactionQueue() {</a>
<a name="ln3075">  return PopFirstFromCompactionQueue(&amp;small_compaction_queue_);</a>
<a name="ln3076">}</a>
<a name="ln3077"> </a>
<a name="ln3078">std::unique_ptr&lt;Compaction&gt; DBImpl::PopFirstFromLargeCompactionQueue() {</a>
<a name="ln3079">  return PopFirstFromCompactionQueue(&amp;large_compaction_queue_);</a>
<a name="ln3080">}</a>
<a name="ln3081"> </a>
<a name="ln3082">bool DBImpl::IsLargeCompaction(const Compaction&amp; compaction) {</a>
<a name="ln3083">  return compaction.CalculateTotalInputSize() &gt;= db_options_.compaction_size_threshold_bytes;</a>
<a name="ln3084">}</a>
<a name="ln3085"> </a>
<a name="ln3086">void DBImpl::AddToFlushQueue(ColumnFamilyData* cfd) {</a>
<a name="ln3087">  assert(!cfd-&gt;pending_flush());</a>
<a name="ln3088">  cfd-&gt;Ref();</a>
<a name="ln3089">  flush_queue_.push_back(cfd);</a>
<a name="ln3090">  cfd-&gt;set_pending_flush(true);</a>
<a name="ln3091">}</a>
<a name="ln3092"> </a>
<a name="ln3093">ColumnFamilyData* DBImpl::PopFirstFromFlushQueue() {</a>
<a name="ln3094">  assert(!flush_queue_.empty());</a>
<a name="ln3095">  auto cfd = *flush_queue_.begin();</a>
<a name="ln3096">  flush_queue_.pop_front();</a>
<a name="ln3097">  assert(cfd-&gt;pending_flush());</a>
<a name="ln3098">  cfd-&gt;set_pending_flush(false);</a>
<a name="ln3099">  return cfd;</a>
<a name="ln3100">}</a>
<a name="ln3101"> </a>
<a name="ln3102">void DBImpl::SchedulePendingFlush(ColumnFamilyData* cfd) {</a>
<a name="ln3103">  if (!cfd-&gt;pending_flush() &amp;&amp; cfd-&gt;imm()-&gt;IsFlushPending()) {</a>
<a name="ln3104">    for (auto listener : db_options_.listeners) {</a>
<a name="ln3105">      listener-&gt;OnFlushScheduled(this);</a>
<a name="ln3106">    }</a>
<a name="ln3107">    if (db_options_.priority_thread_pool_for_compactions_and_flushes &amp;&amp;</a>
<a name="ln3108">        FLAGS_use_priority_thread_pool_for_flushes) {</a>
<a name="ln3109">      ++bg_flush_scheduled_;</a>
<a name="ln3110">      cfd-&gt;Ref();</a>
<a name="ln3111">      cfd-&gt;set_pending_flush(true);</a>
<a name="ln3112">      SubmitCompactionOrFlushTask(std::make_unique&lt;FlushTask&gt;(this, cfd));</a>
<a name="ln3113">    } else {</a>
<a name="ln3114">      AddToFlushQueue(cfd);</a>
<a name="ln3115">      ++unscheduled_flushes_;</a>
<a name="ln3116">    }</a>
<a name="ln3117">  }</a>
<a name="ln3118">}</a>
<a name="ln3119"> </a>
<a name="ln3120">void DBImpl::SchedulePendingCompaction(ColumnFamilyData* cfd) {</a>
<a name="ln3121">  mutex_.AssertHeld();</a>
<a name="ln3122"> </a>
<a name="ln3123">  if (!cfd-&gt;pending_compaction() &amp;&amp; cfd-&gt;NeedsCompaction() &amp;&amp;</a>
<a name="ln3124">      !shutting_down_.load(std::memory_order_acquire)) {</a>
<a name="ln3125">    if (AddToCompactionQueue(cfd)) {</a>
<a name="ln3126">      ++unscheduled_compactions_;</a>
<a name="ln3127">    }</a>
<a name="ln3128">  }</a>
<a name="ln3129">}</a>
<a name="ln3130"> </a>
<a name="ln3131">void DBImpl::RecordFlushIOStats() {</a>
<a name="ln3132">  RecordTick(stats_, FLUSH_WRITE_BYTES, IOSTATS(bytes_written));</a>
<a name="ln3133">  IOSTATS_RESET(bytes_written);</a>
<a name="ln3134">}</a>
<a name="ln3135"> </a>
<a name="ln3136">void DBImpl::BGWorkFlush(void* db) {</a>
<a name="ln3137">  IOSTATS_SET_THREAD_POOL_ID(Env::Priority::HIGH);</a>
<a name="ln3138">  TEST_SYNC_POINT(&quot;DBImpl::BGWorkFlush&quot;);</a>
<a name="ln3139">  reinterpret_cast&lt;DBImpl*&gt;(db)-&gt;BackgroundCallFlush(nullptr /* cfd */);</a>
<a name="ln3140">  TEST_SYNC_POINT(&quot;DBImpl::BGWorkFlush:done&quot;);</a>
<a name="ln3141">}</a>
<a name="ln3142"> </a>
<a name="ln3143">void DBImpl::BGWorkCompaction(void* arg) {</a>
<a name="ln3144">  CompactionArg ca = *(reinterpret_cast&lt;CompactionArg*&gt;(arg));</a>
<a name="ln3145">  delete reinterpret_cast&lt;CompactionArg*&gt;(arg);</a>
<a name="ln3146">  IOSTATS_SET_THREAD_POOL_ID(Env::Priority::LOW);</a>
<a name="ln3147">  TEST_SYNC_POINT(&quot;DBImpl::BGWorkCompaction&quot;);</a>
<a name="ln3148">  reinterpret_cast&lt;DBImpl*&gt;(ca.db)-&gt;BackgroundCallCompaction(ca.m);</a>
<a name="ln3149">}</a>
<a name="ln3150"> </a>
<a name="ln3151">void DBImpl::UnscheduleCallback(void* arg) {</a>
<a name="ln3152">  CompactionArg ca = *(reinterpret_cast&lt;CompactionArg*&gt;(arg));</a>
<a name="ln3153">  delete reinterpret_cast&lt;CompactionArg*&gt;(arg);</a>
<a name="ln3154">  if (ca.m != nullptr) {</a>
<a name="ln3155">    ca.m-&gt;compaction.reset();</a>
<a name="ln3156">  }</a>
<a name="ln3157">  TEST_SYNC_POINT(&quot;DBImpl::UnscheduleCallback&quot;);</a>
<a name="ln3158">}</a>
<a name="ln3159"> </a>
<a name="ln3160">Result&lt;FileNumbersHolder&gt; DBImpl::BackgroundFlush(</a>
<a name="ln3161">    bool* made_progress, JobContext* job_context, LogBuffer* log_buffer, ColumnFamilyData* cfd) {</a>
<a name="ln3162">  mutex_.AssertHeld();</a>
<a name="ln3163"> </a>
<a name="ln3164">  Status status = bg_error_;</a>
<a name="ln3165">  if (status.ok() &amp;&amp; shutting_down_.load(std::memory_order_acquire)) {</a>
<a name="ln3166">    status = STATUS(ShutdownInProgress, &quot;&quot;);</a>
<a name="ln3167">  }</a>
<a name="ln3168"> </a>
<a name="ln3169">  if (!status.ok()) {</a>
<a name="ln3170">    return status;</a>
<a name="ln3171">  }</a>
<a name="ln3172"> </a>
<a name="ln3173">  if (cfd == nullptr) {</a>
<a name="ln3174">    while (!flush_queue_.empty()) {</a>
<a name="ln3175">      // This cfd is already referenced</a>
<a name="ln3176">      auto first_cfd = PopFirstFromFlushQueue();</a>
<a name="ln3177"> </a>
<a name="ln3178">      if (first_cfd-&gt;IsDropped() || !first_cfd-&gt;imm()-&gt;IsFlushPending()) {</a>
<a name="ln3179">        // can't flush this CF, try next one</a>
<a name="ln3180">        if (first_cfd-&gt;Unref()) {</a>
<a name="ln3181">          delete first_cfd;</a>
<a name="ln3182">        }</a>
<a name="ln3183">        continue;</a>
<a name="ln3184">      }</a>
<a name="ln3185"> </a>
<a name="ln3186">      // found a flush!</a>
<a name="ln3187">      cfd = first_cfd;</a>
<a name="ln3188">      break;</a>
<a name="ln3189">    }</a>
<a name="ln3190">  } else {</a>
<a name="ln3191">    DCHECK(cfd-&gt;pending_flush());</a>
<a name="ln3192">    cfd-&gt;set_pending_flush(false);</a>
<a name="ln3193">  }</a>
<a name="ln3194"> </a>
<a name="ln3195">  if (cfd == nullptr) {</a>
<a name="ln3196">    return FileNumbersHolder();</a>
<a name="ln3197">  }</a>
<a name="ln3198">  const MutableCFOptions mutable_cf_options =</a>
<a name="ln3199">      *cfd-&gt;GetLatestMutableCFOptions();</a>
<a name="ln3200">  YB_LOG_WITH_PREFIX_EVERY_N_SECS(INFO, 1)</a>
<a name="ln3201">      &lt;&lt; &quot;Calling FlushMemTableToOutputFile with column &quot;</a>
<a name="ln3202">      &lt;&lt; &quot;family [&quot; &lt;&lt; cfd-&gt;GetName() &lt;&lt; &quot;], &quot;</a>
<a name="ln3203">      &lt;&lt; &quot;flush slots scheduled &quot; &lt;&lt; bg_flush_scheduled_ &lt;&lt; &quot;, &quot;</a>
<a name="ln3204">      &lt;&lt; &quot;total flush slots &quot; &lt;&lt; db_options_.max_background_flushes &lt;&lt; &quot;, &quot;</a>
<a name="ln3205">      &lt;&lt; &quot;compaction slots scheduled &quot; &lt;&lt; bg_compaction_scheduled_ &lt;&lt; &quot;, &quot;</a>
<a name="ln3206">      &lt;&lt; &quot;compaction tasks &quot; &lt;&lt; yb::ToString(compaction_tasks_) &lt;&lt; &quot;, &quot;</a>
<a name="ln3207">      &lt;&lt; &quot;total compaction slots &quot; &lt;&lt; BGCompactionsAllowed();</a>
<a name="ln3208">  auto result = FlushMemTableToOutputFile(cfd, mutable_cf_options, made_progress,</a>
<a name="ln3209">                                          job_context, log_buffer);</a>
<a name="ln3210">  if (cfd-&gt;Unref()) {</a>
<a name="ln3211">    delete cfd;</a>
<a name="ln3212">  }</a>
<a name="ln3213">  return result;</a>
<a name="ln3214">}</a>
<a name="ln3215"> </a>
<a name="ln3216">void DBImpl::WaitAfterBackgroundError(</a>
<a name="ln3217">    const Status&amp; s, const char* job_name, LogBuffer* log_buffer) {</a>
<a name="ln3218">  if (!s.ok() &amp;&amp; !s.IsShutdownInProgress()) {</a>
<a name="ln3219">    // Wait a little bit before retrying background job in</a>
<a name="ln3220">    // case this is an environmental problem and we do not want to</a>
<a name="ln3221">    // chew up resources for failed jobs for the duration of</a>
<a name="ln3222">    // the problem.</a>
<a name="ln3223">    uint64_t error_cnt = default_cf_internal_stats_-&gt;BumpAndGetBackgroundErrorCount();</a>
<a name="ln3224">    bg_cv_.SignalAll();  // In case a waiter can proceed despite the error</a>
<a name="ln3225">    mutex_.Unlock();</a>
<a name="ln3226">    log_buffer-&gt;FlushBufferToLog();</a>
<a name="ln3227">    RLOG(</a>
<a name="ln3228">        InfoLogLevel::ERROR_LEVEL, db_options_.info_log, Format(</a>
<a name="ln3229">            &quot;Waiting after background $0 error: $1, Accumulated background error counts: $2&quot;,</a>
<a name="ln3230">            job_name, s, error_cnt).c_str());</a>
<a name="ln3231">    LogFlush(db_options_.info_log);</a>
<a name="ln3232">    env_-&gt;SleepForMicroseconds(1000000);</a>
<a name="ln3233">    mutex_.Lock();</a>
<a name="ln3234">  }</a>
<a name="ln3235">}</a>
<a name="ln3236"> </a>
<a name="ln3237">void DBImpl::BackgroundJobComplete(</a>
<a name="ln3238">    const Status&amp; s, JobContext* job_context, LogBuffer* log_buffer) {</a>
<a name="ln3239">  mutex_.AssertHeld();</a>
<a name="ln3240"> </a>
<a name="ln3241">  TaskPriorityUpdater task_priority_updater(this);</a>
<a name="ln3242">  task_priority_updater.Prepare();</a>
<a name="ln3243"> </a>
<a name="ln3244">  // If flush or compaction failed, we want to delete all temporary files that we might have</a>
<a name="ln3245">  // created. Thus, we force full scan in FindObsoleteFiles()</a>
<a name="ln3246">  FindObsoleteFiles(job_context, !s.ok() &amp;&amp; !s.IsShutdownInProgress());</a>
<a name="ln3247"> </a>
<a name="ln3248">  // delete unnecessary files if any, this is done outside the mutex</a>
<a name="ln3249">  if (job_context-&gt;HaveSomethingToDelete() || !log_buffer-&gt;IsEmpty() ||</a>
<a name="ln3250">      !task_priority_updater.Empty() || HasFilesChangedListener()) {</a>
<a name="ln3251">    mutex_.Unlock();</a>
<a name="ln3252">    // Have to flush the info logs before bg_flush_scheduled_--</a>
<a name="ln3253">    // because if bg_flush_scheduled_ becomes 0 and the lock is</a>
<a name="ln3254">    // released, the destructor of DB can kick in and destroy all the</a>
<a name="ln3255">    // state of DB so info_log might not be available after that point.</a>
<a name="ln3256">    // It also applies to access to other state that DB owns.</a>
<a name="ln3257">    log_buffer-&gt;FlushBufferToLog();</a>
<a name="ln3258">    if (job_context-&gt;HaveSomethingToDelete()) {</a>
<a name="ln3259">      PurgeObsoleteFiles(*job_context);</a>
<a name="ln3260">    }</a>
<a name="ln3261">    job_context-&gt;Clean();</a>
<a name="ln3262"> </a>
<a name="ln3263">    task_priority_updater.Apply();</a>
<a name="ln3264"> </a>
<a name="ln3265">    FilesChanged();</a>
<a name="ln3266"> </a>
<a name="ln3267">    mutex_.Lock();</a>
<a name="ln3268">  }</a>
<a name="ln3269">}</a>
<a name="ln3270"> </a>
<a name="ln3271">void DBImpl::BackgroundCallFlush(ColumnFamilyData* cfd) {</a>
<a name="ln3272">  bool made_progress = false;</a>
<a name="ln3273">  JobContext job_context(next_job_id_.fetch_add(1), true);</a>
<a name="ln3274"> </a>
<a name="ln3275">  LogBuffer log_buffer(InfoLogLevel::INFO_LEVEL, db_options_.info_log.get());</a>
<a name="ln3276"> </a>
<a name="ln3277">  InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln3278">  assert(bg_flush_scheduled_);</a>
<a name="ln3279">  num_running_flushes_++;</a>
<a name="ln3280"> </a>
<a name="ln3281">  Status s;</a>
<a name="ln3282">  {</a>
<a name="ln3283">    auto file_number_holder = BackgroundFlush(&amp;made_progress, &amp;job_context, &amp;log_buffer, cfd);</a>
<a name="ln3284">    s = yb::ResultToStatus(file_number_holder);</a>
<a name="ln3285">    WaitAfterBackgroundError(s, &quot;flush&quot;, &amp;log_buffer);</a>
<a name="ln3286">  }</a>
<a name="ln3287"> </a>
<a name="ln3288">  BackgroundJobComplete(s, &amp;job_context, &amp;log_buffer);</a>
<a name="ln3289"> </a>
<a name="ln3290">  assert(num_running_flushes_ &gt; 0);</a>
<a name="ln3291">  num_running_flushes_--;</a>
<a name="ln3292">  bg_flush_scheduled_--;</a>
<a name="ln3293">  // See if there's more work to be done</a>
<a name="ln3294">  MaybeScheduleFlushOrCompaction();</a>
<a name="ln3295">  RecordFlushIOStats();</a>
<a name="ln3296">  bg_cv_.SignalAll();</a>
<a name="ln3297">  // IMPORTANT: there should be no code after calling SignalAll. This call may</a>
<a name="ln3298">  // signal the DB destructor that it's OK to proceed with destruction. In</a>
<a name="ln3299">  // that case, all DB variables will be dealloacated and referencing them</a>
<a name="ln3300">  // will cause trouble.</a>
<a name="ln3301">}</a>
<a name="ln3302"> </a>
<a name="ln3303">void DBImpl::BackgroundCallCompaction(ManualCompaction* m, std::unique_ptr&lt;Compaction&gt; compaction,</a>
<a name="ln3304">                                      CompactionTask* compaction_task) {</a>
<a name="ln3305">  bool made_progress = false;</a>
<a name="ln3306">  JobContext job_context(next_job_id_.fetch_add(1), true);</a>
<a name="ln3307">  MaybeDumpStats();</a>
<a name="ln3308">  LogBuffer log_buffer(InfoLogLevel::INFO_LEVEL, db_options_.info_log.get());</a>
<a name="ln3309"> </a>
<a name="ln3310">  InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln3311">  num_total_running_compactions_++;</a>
<a name="ln3312"> </a>
<a name="ln3313">  if (compaction_task) {</a>
<a name="ln3314">    LOG_IF_WITH_PREFIX(DFATAL, compaction_tasks_.count(compaction_task) != 1)</a>
<a name="ln3315">        &lt;&lt; &quot;Running compaction for unknown task: &quot; &lt;&lt; compaction_task;</a>
<a name="ln3316">  } else {</a>
<a name="ln3317">    LOG_IF_WITH_PREFIX(DFATAL, bg_compaction_scheduled_ == 0)</a>
<a name="ln3318">        &lt;&lt; &quot;Running compaction while no compactions were scheduled&quot;;</a>
<a name="ln3319">  }</a>
<a name="ln3320"> </a>
<a name="ln3321">  Status s;</a>
<a name="ln3322">  {</a>
<a name="ln3323">    auto file_numbers_holder = BackgroundCompaction(</a>
<a name="ln3324">        &amp;made_progress, &amp;job_context, &amp;log_buffer, m, std::move(compaction));</a>
<a name="ln3325"> </a>
<a name="ln3326">    if (compaction_task) {</a>
<a name="ln3327">      compaction_task-&gt;Complete();</a>
<a name="ln3328">    }</a>
<a name="ln3329"> </a>
<a name="ln3330">    s = yb::ResultToStatus(file_numbers_holder);</a>
<a name="ln3331">    TEST_SYNC_POINT(&quot;BackgroundCallCompaction:1&quot;);</a>
<a name="ln3332">    WaitAfterBackgroundError(s, &quot;compaction&quot;, &amp;log_buffer);</a>
<a name="ln3333">  }</a>
<a name="ln3334"> </a>
<a name="ln3335">  BackgroundJobComplete(s, &amp;job_context, &amp;log_buffer);</a>
<a name="ln3336"> </a>
<a name="ln3337">  assert(num_total_running_compactions_ &gt; 0);</a>
<a name="ln3338">  num_total_running_compactions_--;</a>
<a name="ln3339">  if (compaction_task) {</a>
<a name="ln3340">      LOG_IF_WITH_PREFIX(DFATAL, compaction_tasks_.erase(compaction_task) != 1)</a>
<a name="ln3341">          &lt;&lt; &quot;Finished compaction with unknown task serial no: &quot; &lt;&lt; yb::ToString(compaction_task);</a>
<a name="ln3342">  } else {</a>
<a name="ln3343">    bg_compaction_scheduled_--;</a>
<a name="ln3344">  }</a>
<a name="ln3345"> </a>
<a name="ln3346">  versions_-&gt;GetColumnFamilySet()-&gt;FreeDeadColumnFamilies();</a>
<a name="ln3347"> </a>
<a name="ln3348">  // See if there's more work to be done</a>
<a name="ln3349">  MaybeScheduleFlushOrCompaction();</a>
<a name="ln3350">  if (made_progress || (bg_compaction_scheduled_ + compaction_tasks_.size()) == 0 ||</a>
<a name="ln3351">      HasPendingManualCompaction()) {</a>
<a name="ln3352">    // signal if</a>
<a name="ln3353">    // * made_progress -- need to wakeup DelayWrite</a>
<a name="ln3354">    // * bg_compaction_scheduled_ == 0 -- need to wakeup ~DBImpl</a>
<a name="ln3355">    // * HasPendingManualCompaction -- need to wakeup RunManualCompaction</a>
<a name="ln3356">    // If none of this is true, there is no need to signal since nobody is</a>
<a name="ln3357">    // waiting for it</a>
<a name="ln3358">    bg_cv_.SignalAll();</a>
<a name="ln3359">  }</a>
<a name="ln3360">  // IMPORTANT: there should be no code after calling SignalAll. This call may</a>
<a name="ln3361">  // signal the DB destructor that it's OK to proceed with destruction. In</a>
<a name="ln3362">  // that case, all DB variables will be dealloacated and referencing them</a>
<a name="ln3363">  // will cause trouble.</a>
<a name="ln3364">}</a>
<a name="ln3365"> </a>
<a name="ln3366">Result&lt;FileNumbersHolder&gt; DBImpl::BackgroundCompaction(</a>
<a name="ln3367">    bool* made_progress, JobContext* job_context, LogBuffer* log_buffer,</a>
<a name="ln3368">    ManualCompaction* manual_compaction, std::unique_ptr&lt;Compaction&gt; compaction) {</a>
<a name="ln3369">  *made_progress = false;</a>
<a name="ln3370">  mutex_.AssertHeld();</a>
<a name="ln3371"> </a>
<a name="ln3372">  bool is_manual = (manual_compaction != nullptr);</a>
<a name="ln3373">  if (is_manual &amp;&amp; compaction) {</a>
<a name="ln3374">    return STATUS(</a>
<a name="ln3375">        InvalidArgument,</a>
<a name="ln3376">        &quot;Both is_manual and compaction are specified in BackgroundCompaction, only one of them is &quot;</a>
<a name="ln3377">            &quot;allowed&quot;);</a>
<a name="ln3378">  }</a>
<a name="ln3379">  DCHECK(!is_manual || !compaction);</a>
<a name="ln3380">  bool is_large_compaction = false;</a>
<a name="ln3381"> </a>
<a name="ln3382">  // (manual_compaction-&gt;in_progress == false);</a>
<a name="ln3383">  bool trivial_move_disallowed =</a>
<a name="ln3384">      is_manual &amp;&amp; manual_compaction-&gt;disallow_trivial_move;</a>
<a name="ln3385"> </a>
<a name="ln3386">  CompactionJobStats compaction_job_stats;</a>
<a name="ln3387">  Status status = bg_error_;</a>
<a name="ln3388">  if (status.ok() &amp;&amp; shutting_down_.load(std::memory_order_acquire)) {</a>
<a name="ln3389">    status = STATUS(ShutdownInProgress, &quot;&quot;);</a>
<a name="ln3390">  }</a>
<a name="ln3391"> </a>
<a name="ln3392">  if (!status.ok()) {</a>
<a name="ln3393">    if (is_manual) {</a>
<a name="ln3394">      manual_compaction-&gt;status = status;</a>
<a name="ln3395">      manual_compaction-&gt;done = true;</a>
<a name="ln3396">      manual_compaction-&gt;in_progress = false;</a>
<a name="ln3397">      manual_compaction-&gt;compaction.reset();</a>
<a name="ln3398">      manual_compaction = nullptr;</a>
<a name="ln3399">    }</a>
<a name="ln3400">    if (compaction &amp;&amp; compaction-&gt;column_family_data()-&gt;Unref()) {</a>
<a name="ln3401">      delete compaction-&gt;column_family_data();</a>
<a name="ln3402">    }</a>
<a name="ln3403">    return status;</a>
<a name="ln3404">  }</a>
<a name="ln3405"> </a>
<a name="ln3406">  if (is_manual) {</a>
<a name="ln3407">    // another thread cannot pick up the same work</a>
<a name="ln3408">    manual_compaction-&gt;in_progress = true;</a>
<a name="ln3409">  }</a>
<a name="ln3410"> </a>
<a name="ln3411">  unique_ptr&lt;Compaction&gt; c;</a>
<a name="ln3412">  // InternalKey manual_end_storage;</a>
<a name="ln3413">  // InternalKey* manual_end = &amp;manual_end_storage;</a>
<a name="ln3414">  if (is_manual) {</a>
<a name="ln3415">    ManualCompaction* m = manual_compaction;</a>
<a name="ln3416">    assert(m-&gt;in_progress);</a>
<a name="ln3417">    c = std::move(m-&gt;compaction);</a>
<a name="ln3418">    if (!c) {</a>
<a name="ln3419">      m-&gt;done = true;</a>
<a name="ln3420">      m-&gt;manual_end = nullptr;</a>
<a name="ln3421">      LOG_TO_BUFFER(log_buffer,</a>
<a name="ln3422">                  &quot;[%s] Manual compaction from level-%d from %s .. &quot;</a>
<a name="ln3423">                  &quot;%s; nothing to do\n&quot;,</a>
<a name="ln3424">                  m-&gt;cfd-&gt;GetName().c_str(), m-&gt;input_level,</a>
<a name="ln3425">                  (m-&gt;begin ? m-&gt;begin-&gt;DebugString().c_str() : &quot;(begin)&quot;),</a>
<a name="ln3426">                  (m-&gt;end ? m-&gt;end-&gt;DebugString().c_str() : &quot;(end)&quot;));</a>
<a name="ln3427">    } else {</a>
<a name="ln3428">      LOG_TO_BUFFER(log_buffer,</a>
<a name="ln3429">                  &quot;[%s] Manual compaction from level-%d to level-%d from %s .. &quot;</a>
<a name="ln3430">                  &quot;%s; will stop at %s\n&quot;,</a>
<a name="ln3431">                  m-&gt;cfd-&gt;GetName().c_str(), m-&gt;input_level, c-&gt;output_level(),</a>
<a name="ln3432">                  (m-&gt;begin ? m-&gt;begin-&gt;DebugString().c_str() : &quot;(begin)&quot;),</a>
<a name="ln3433">                  (m-&gt;end ? m-&gt;end-&gt;DebugString().c_str() : &quot;(end)&quot;),</a>
<a name="ln3434">                  ((m-&gt;done || m-&gt;manual_end == nullptr)</a>
<a name="ln3435">                       ? &quot;(end)&quot;</a>
<a name="ln3436">                       : m-&gt;manual_end-&gt;DebugString().c_str()));</a>
<a name="ln3437">    }</a>
<a name="ln3438">  } else {</a>
<a name="ln3439">    // cfd is referenced here</a>
<a name="ln3440">    if (compaction) {</a>
<a name="ln3441">      c = std::move(compaction);</a>
<a name="ln3442">      is_large_compaction = IsLargeCompaction(*c);</a>
<a name="ln3443">    } else if (!large_compaction_queue_.empty() &amp;&amp; BGCompactionsAllowed() &gt;</a>
<a name="ln3444">          num_running_large_compactions() + db_options_.num_reserved_small_compaction_threads) {</a>
<a name="ln3445">      c = PopFirstFromLargeCompactionQueue();</a>
<a name="ln3446">      is_large_compaction = true;</a>
<a name="ln3447">    } else if (!small_compaction_queue_.empty()) {</a>
<a name="ln3448">      c = PopFirstFromSmallCompactionQueue();</a>
<a name="ln3449">      is_large_compaction = false;</a>
<a name="ln3450">    } else {</a>
<a name="ln3451">      LOG_IF(DFATAL, large_compaction_queue_.empty())</a>
<a name="ln3452">          &lt;&lt; &quot;Don't have compactions in BackgroundCompaction&quot;;</a>
<a name="ln3453">      LOG_TO_BUFFER(log_buffer, &quot;No small compactions in queue. Large compaction threads busy.&quot;);</a>
<a name="ln3454">      unscheduled_compactions_++;</a>
<a name="ln3455">      return FileNumbersHolder();</a>
<a name="ln3456">    }</a>
<a name="ln3457"> </a>
<a name="ln3458">    ColumnFamilyData* cfd = c-&gt;column_family_data();</a>
<a name="ln3459"> </a>
<a name="ln3460">    // We unreference here because the following code will take a Ref() on</a>
<a name="ln3461">    // this cfd if it is going to use it (Compaction class holds a</a>
<a name="ln3462">    // reference).</a>
<a name="ln3463">    // This will all happen under a mutex so we don't have to be afraid of</a>
<a name="ln3464">    // somebody else deleting it.</a>
<a name="ln3465">    if (cfd-&gt;Unref()) {</a>
<a name="ln3466">      delete cfd;</a>
<a name="ln3467">      // This was the last reference of the column family, so no need to</a>
<a name="ln3468">      // compact.</a>
<a name="ln3469">      return FileNumbersHolder();</a>
<a name="ln3470">    }</a>
<a name="ln3471"> </a>
<a name="ln3472">    if (is_large_compaction) {</a>
<a name="ln3473">      num_running_large_compactions_++;</a>
<a name="ln3474">      TEST_SYNC_POINT(&quot;DBImpl:BackgroundCompaction:LargeCompaction&quot;);</a>
<a name="ln3475">    } else {</a>
<a name="ln3476">      TEST_SYNC_POINT(&quot;DBImpl:BackgroundCompaction:SmallCompaction&quot;);</a>
<a name="ln3477">    }</a>
<a name="ln3478"> </a>
<a name="ln3479">    if (c != nullptr) {</a>
<a name="ln3480">      // update statistics</a>
<a name="ln3481">      MeasureTime(stats_, NUM_FILES_IN_SINGLE_COMPACTION,</a>
<a name="ln3482">                  c-&gt;inputs(0)-&gt;size());</a>
<a name="ln3483">      // There are three things that can change compaction score:</a>
<a name="ln3484">      // 1) When flush or compaction finish. This case is covered by</a>
<a name="ln3485">      // InstallSuperVersionAndScheduleWork</a>
<a name="ln3486">      // 2) When MutableCFOptions changes. This case is also covered by</a>
<a name="ln3487">      // InstallSuperVersionAndScheduleWork, because this is when the new</a>
<a name="ln3488">      // options take effect.</a>
<a name="ln3489">      // 3) When we Pick a new compaction, we &quot;remove&quot; those files being</a>
<a name="ln3490">      // compacted from the calculation, which then influences compaction</a>
<a name="ln3491">      // score. Here we check if we need the new compaction even without the</a>
<a name="ln3492">      // files that are currently being compacted. If we need another</a>
<a name="ln3493">      // compaction, we might be able to execute it in parallel, so we add it</a>
<a name="ln3494">      // to the queue and schedule a new thread.</a>
<a name="ln3495"> </a>
<a name="ln3496">      SchedulePendingCompaction(cfd);</a>
<a name="ln3497">      MaybeScheduleFlushOrCompaction();</a>
<a name="ln3498">    }</a>
<a name="ln3499">  }</a>
<a name="ln3500"> </a>
<a name="ln3501">  Result&lt;FileNumbersHolder&gt; result = FileNumbersHolder();</a>
<a name="ln3502">  if (c-&gt;deletion_compaction()) {</a>
<a name="ln3503">    // TODO(icanadi) Do we want to honor snapshots here? i.e. not delete old</a>
<a name="ln3504">    // file if there is alive snapshot pointing to it</a>
<a name="ln3505">    assert(c-&gt;num_input_files(1) == 0);</a>
<a name="ln3506">    assert(c-&gt;level() == 0);</a>
<a name="ln3507">    assert(c-&gt;column_family_data()-&gt;ioptions()-&gt;compaction_style ==</a>
<a name="ln3508">           kCompactionStyleFIFO);</a>
<a name="ln3509"> </a>
<a name="ln3510">    compaction_job_stats.num_input_files = c-&gt;num_input_files(0);</a>
<a name="ln3511"> </a>
<a name="ln3512">    for (const auto&amp; f : *c-&gt;inputs(0)) {</a>
<a name="ln3513">      c-&gt;edit()-&gt;DeleteFile(c-&gt;level(), f-&gt;fd.GetNumber());</a>
<a name="ln3514">    }</a>
<a name="ln3515">    status = versions_-&gt;LogAndApply(c-&gt;column_family_data(),</a>
<a name="ln3516">                                    *c-&gt;mutable_cf_options(), c-&gt;edit(),</a>
<a name="ln3517">                                    &amp;mutex_, directories_.GetDbDir());</a>
<a name="ln3518">    InstallSuperVersionAndScheduleWorkWrapper(</a>
<a name="ln3519">        c-&gt;column_family_data(), job_context, *c-&gt;mutable_cf_options());</a>
<a name="ln3520">    LOG_TO_BUFFER(log_buffer, &quot;[%s] Deleted %d files\n&quot;,</a>
<a name="ln3521">                c-&gt;column_family_data()-&gt;GetName().c_str(),</a>
<a name="ln3522">                c-&gt;num_input_files(0));</a>
<a name="ln3523">    *made_progress = true;</a>
<a name="ln3524">  } else if (!trivial_move_disallowed &amp;&amp; c-&gt;IsTrivialMove()) {</a>
<a name="ln3525">    TEST_SYNC_POINT(&quot;DBImpl::BackgroundCompaction:TrivialMove&quot;);</a>
<a name="ln3526">    // Instrument for event update</a>
<a name="ln3527">    // TODO(yhchiang): add op details for showing trivial-move.</a>
<a name="ln3528">    ThreadStatusUtil::SetColumnFamily(</a>
<a name="ln3529">        c-&gt;column_family_data(), c-&gt;column_family_data()-&gt;ioptions()-&gt;env,</a>
<a name="ln3530">        c-&gt;column_family_data()-&gt;options()-&gt;enable_thread_tracking);</a>
<a name="ln3531">    ThreadStatusUtil::SetThreadOperation(ThreadStatus::OP_COMPACTION);</a>
<a name="ln3532"> </a>
<a name="ln3533">    compaction_job_stats.num_input_files = c-&gt;num_input_files(0);</a>
<a name="ln3534"> </a>
<a name="ln3535">    // Move files to next level</a>
<a name="ln3536">    int32_t moved_files = 0;</a>
<a name="ln3537">    int64_t moved_bytes = 0;</a>
<a name="ln3538">    for (unsigned int l = 0; l &lt; c-&gt;num_input_levels(); l++) {</a>
<a name="ln3539">      if (c-&gt;level(l) == c-&gt;output_level()) {</a>
<a name="ln3540">        continue;</a>
<a name="ln3541">      }</a>
<a name="ln3542">      for (size_t i = 0; i &lt; c-&gt;num_input_files(l); i++) {</a>
<a name="ln3543">        FileMetaData* f = c-&gt;input(l, i);</a>
<a name="ln3544">        c-&gt;edit()-&gt;DeleteFile(c-&gt;level(l), f-&gt;fd.GetNumber());</a>
<a name="ln3545">        c-&gt;edit()-&gt;AddCleanedFile(c-&gt;output_level(), *f);</a>
<a name="ln3546"> </a>
<a name="ln3547">        LOG_TO_BUFFER(log_buffer,</a>
<a name="ln3548">                    &quot;[%s] Moving #%&quot; PRIu64 &quot; to level-%d %&quot; PRIu64 &quot; bytes\n&quot;,</a>
<a name="ln3549">                    c-&gt;column_family_data()-&gt;GetName().c_str(),</a>
<a name="ln3550">                    f-&gt;fd.GetNumber(), c-&gt;output_level(), f-&gt;fd.GetTotalFileSize());</a>
<a name="ln3551">        ++moved_files;</a>
<a name="ln3552">        moved_bytes += f-&gt;fd.GetTotalFileSize();</a>
<a name="ln3553">      }</a>
<a name="ln3554">    }</a>
<a name="ln3555"> </a>
<a name="ln3556">    status = versions_-&gt;LogAndApply(c-&gt;column_family_data(),</a>
<a name="ln3557">                                    *c-&gt;mutable_cf_options(), c-&gt;edit(),</a>
<a name="ln3558">                                    &amp;mutex_, directories_.GetDbDir());</a>
<a name="ln3559">    // Use latest MutableCFOptions</a>
<a name="ln3560">    InstallSuperVersionAndScheduleWorkWrapper(</a>
<a name="ln3561">        c-&gt;column_family_data(), job_context, *c-&gt;mutable_cf_options());</a>
<a name="ln3562"> </a>
<a name="ln3563">    VersionStorageInfo::LevelSummaryStorage tmp;</a>
<a name="ln3564">    c-&gt;column_family_data()-&gt;internal_stats()-&gt;IncBytesMoved(c-&gt;output_level(),</a>
<a name="ln3565">                                                             moved_bytes);</a>
<a name="ln3566">    {</a>
<a name="ln3567">      event_logger_.LogToBuffer(log_buffer)</a>
<a name="ln3568">          &lt;&lt; &quot;job&quot; &lt;&lt; job_context-&gt;job_id &lt;&lt; &quot;event&quot;</a>
<a name="ln3569">          &lt;&lt; &quot;trivial_move&quot;</a>
<a name="ln3570">          &lt;&lt; &quot;destination_level&quot; &lt;&lt; c-&gt;output_level() &lt;&lt; &quot;files&quot; &lt;&lt; moved_files</a>
<a name="ln3571">          &lt;&lt; &quot;total_files_size&quot; &lt;&lt; moved_bytes;</a>
<a name="ln3572">    }</a>
<a name="ln3573">    LOG_TO_BUFFER(</a>
<a name="ln3574">        log_buffer,</a>
<a name="ln3575">        &quot;[%s] Moved #%d files to level-%d %&quot; PRIu64 &quot; bytes %s: %s\n&quot;,</a>
<a name="ln3576">        c-&gt;column_family_data()-&gt;GetName().c_str(), moved_files,</a>
<a name="ln3577">        c-&gt;output_level(), moved_bytes, status.ToString().c_str(),</a>
<a name="ln3578">        c-&gt;column_family_data()-&gt;current()-&gt;storage_info()-&gt;LevelSummary(&amp;tmp));</a>
<a name="ln3579">    *made_progress = true;</a>
<a name="ln3580"> </a>
<a name="ln3581">    // Clear Instrument</a>
<a name="ln3582">    ThreadStatusUtil::ResetThreadStatus();</a>
<a name="ln3583">  } else {</a>
<a name="ln3584">    int output_level  __attribute__((unused)) = c-&gt;output_level();</a>
<a name="ln3585">    TEST_SYNC_POINT_CALLBACK(&quot;DBImpl::BackgroundCompaction:NonTrivial&quot;,</a>
<a name="ln3586">                             &amp;output_level);</a>
<a name="ln3587"> </a>
<a name="ln3588">    SequenceNumber earliest_write_conflict_snapshot;</a>
<a name="ln3589">    std::vector&lt;SequenceNumber&gt; snapshot_seqs =</a>
<a name="ln3590">        snapshots_.GetAll(&amp;earliest_write_conflict_snapshot);</a>
<a name="ln3591"> </a>
<a name="ln3592">    assert(is_snapshot_supported_ || snapshots_.empty());</a>
<a name="ln3593">    CompactionJob compaction_job(</a>
<a name="ln3594">        job_context-&gt;job_id, c.get(), db_options_, env_options_,</a>
<a name="ln3595">        versions_.get(), &amp;shutting_down_, log_buffer, directories_.GetDbDir(),</a>
<a name="ln3596">        directories_.GetDataDir(c-&gt;output_path_id()), stats_, &amp;mutex_,</a>
<a name="ln3597">        &amp;bg_error_, snapshot_seqs, earliest_write_conflict_snapshot,</a>
<a name="ln3598">        pending_outputs_.get(), table_cache_, &amp;event_logger_,</a>
<a name="ln3599">        c-&gt;mutable_cf_options()-&gt;paranoid_file_checks,</a>
<a name="ln3600">        c-&gt;mutable_cf_options()-&gt;compaction_measure_io_stats, dbname_,</a>
<a name="ln3601">        &amp;compaction_job_stats);</a>
<a name="ln3602">    compaction_job.Prepare();</a>
<a name="ln3603"> </a>
<a name="ln3604">    mutex_.Unlock();</a>
<a name="ln3605">    result = compaction_job.Run();</a>
<a name="ln3606">    TEST_SYNC_POINT(&quot;DBImpl::BackgroundCompaction:NonTrivial:AfterRun&quot;);</a>
<a name="ln3607">    mutex_.Lock();</a>
<a name="ln3608"> </a>
<a name="ln3609">    status = compaction_job.Install(*c-&gt;mutable_cf_options());</a>
<a name="ln3610">    if (status.ok()) {</a>
<a name="ln3611">      InstallSuperVersionAndScheduleWorkWrapper(</a>
<a name="ln3612">          c-&gt;column_family_data(), job_context, *c-&gt;mutable_cf_options());</a>
<a name="ln3613">    }</a>
<a name="ln3614">    *made_progress = true;</a>
<a name="ln3615">  }</a>
<a name="ln3616"> </a>
<a name="ln3617">  NotifyOnCompactionCompleted(</a>
<a name="ln3618">      c-&gt;column_family_data(), c.get(), status,</a>
<a name="ln3619">      compaction_job_stats, job_context-&gt;job_id);</a>
<a name="ln3620"> </a>
<a name="ln3621">  c-&gt;ReleaseCompactionFiles(status);</a>
<a name="ln3622"> </a>
<a name="ln3623">  // It is possible that a compaction was needed in the column family but we could not</a>
<a name="ln3624">  // add it to the queue when this compaction was popped because of L0 conflicts</a>
<a name="ln3625">  // or other picker internals, so we try to schedule again.</a>
<a name="ln3626">  SchedulePendingCompaction(c-&gt;column_family_data());</a>
<a name="ln3627"> </a>
<a name="ln3628">  *made_progress = true;</a>
<a name="ln3629">  // this will unref its input_version and column_family_data</a>
<a name="ln3630">  c.reset();</a>
<a name="ln3631"> </a>
<a name="ln3632">  if (status.ok()) {</a>
<a name="ln3633">    // Done</a>
<a name="ln3634">  } else if (status.IsShutdownInProgress()) {</a>
<a name="ln3635">    // Ignore compaction errors found during shutting down</a>
<a name="ln3636">  } else {</a>
<a name="ln3637">    RLOG(InfoLogLevel::WARN_LEVEL, db_options_.info_log, &quot;Compaction error: %s&quot;,</a>
<a name="ln3638">        status.ToString().c_str());</a>
<a name="ln3639">    if (db_options_.paranoid_checks &amp;&amp; bg_error_.ok()) {</a>
<a name="ln3640">      bg_error_ = status;</a>
<a name="ln3641">    }</a>
<a name="ln3642">  }</a>
<a name="ln3643"> </a>
<a name="ln3644">  if (is_manual) {</a>
<a name="ln3645">    ManualCompaction* m = manual_compaction;</a>
<a name="ln3646">    if (!status.ok()) {</a>
<a name="ln3647">      m-&gt;status = status;</a>
<a name="ln3648">      m-&gt;done = true;</a>
<a name="ln3649">    }</a>
<a name="ln3650">    // For universal compaction:</a>
<a name="ln3651">    //   Because universal compaction always happens at level 0, so one</a>
<a name="ln3652">    //   compaction will pick up all overlapped files. No files will be</a>
<a name="ln3653">    //   filtered out due to size limit and left for a successive compaction.</a>
<a name="ln3654">    //   So we can safely conclude the current compaction.</a>
<a name="ln3655">    //</a>
<a name="ln3656">    //   Also note that, if we don't stop here, then the current compaction</a>
<a name="ln3657">    //   writes a new file back to level 0, which will be used in successive</a>
<a name="ln3658">    //   compaction. Hence the manual compaction will never finish.</a>
<a name="ln3659">    //</a>
<a name="ln3660">    // Stop the compaction if manual_end points to nullptr -- this means</a>
<a name="ln3661">    // that we compacted the whole range. manual_end should always point</a>
<a name="ln3662">    // to nullptr in case of universal compaction</a>
<a name="ln3663">    if (m-&gt;manual_end == nullptr) {</a>
<a name="ln3664">      m-&gt;done = true;</a>
<a name="ln3665">    }</a>
<a name="ln3666">    if (!m-&gt;done) {</a>
<a name="ln3667">      // We only compacted part of the requested range.  Update *m</a>
<a name="ln3668">      // to the range that is left to be compacted.</a>
<a name="ln3669">      // Universal and FIFO compactions should always compact the whole range</a>
<a name="ln3670">      assert(m-&gt;cfd-&gt;ioptions()-&gt;compaction_style !=</a>
<a name="ln3671">                 kCompactionStyleUniversal ||</a>
<a name="ln3672">             m-&gt;cfd-&gt;ioptions()-&gt;num_levels &gt; 1);</a>
<a name="ln3673">      assert(m-&gt;cfd-&gt;ioptions()-&gt;compaction_style != kCompactionStyleFIFO);</a>
<a name="ln3674">      m-&gt;tmp_storage = *m-&gt;manual_end;</a>
<a name="ln3675">      m-&gt;begin = &amp;m-&gt;tmp_storage;</a>
<a name="ln3676">      m-&gt;incomplete = true;</a>
<a name="ln3677">    }</a>
<a name="ln3678">    m-&gt;in_progress = false; // not being processed anymore</a>
<a name="ln3679">  }</a>
<a name="ln3680"> </a>
<a name="ln3681">  if (is_large_compaction) {</a>
<a name="ln3682">    num_running_large_compactions_--;</a>
<a name="ln3683">  }</a>
<a name="ln3684"> </a>
<a name="ln3685">  RETURN_NOT_OK(status);</a>
<a name="ln3686"> </a>
<a name="ln3687">  return result;</a>
<a name="ln3688">}</a>
<a name="ln3689"> </a>
<a name="ln3690">bool DBImpl::HasPendingManualCompaction() {</a>
<a name="ln3691">  return (!manual_compaction_dequeue_.empty());</a>
<a name="ln3692">}</a>
<a name="ln3693"> </a>
<a name="ln3694">void DBImpl::AddManualCompaction(DBImpl::ManualCompaction* m) {</a>
<a name="ln3695">  manual_compaction_dequeue_.push_back(m);</a>
<a name="ln3696">}</a>
<a name="ln3697"> </a>
<a name="ln3698">void DBImpl::RemoveManualCompaction(DBImpl::ManualCompaction* m) {</a>
<a name="ln3699">  // Remove from queue</a>
<a name="ln3700">  std::deque&lt;ManualCompaction*&gt;::iterator it =</a>
<a name="ln3701">      manual_compaction_dequeue_.begin();</a>
<a name="ln3702">  while (it != manual_compaction_dequeue_.end()) {</a>
<a name="ln3703">    if (m == (*it)) {</a>
<a name="ln3704">      it = manual_compaction_dequeue_.erase(it);</a>
<a name="ln3705">      return;</a>
<a name="ln3706">    }</a>
<a name="ln3707">    it++;</a>
<a name="ln3708">  }</a>
<a name="ln3709">  assert(false);</a>
<a name="ln3710">  return;</a>
<a name="ln3711">}</a>
<a name="ln3712"> </a>
<a name="ln3713">bool DBImpl::ShouldntRunManualCompaction(ManualCompaction* m) {</a>
<a name="ln3714">  if (m-&gt;exclusive) {</a>
<a name="ln3715">    return (bg_compaction_scheduled_ + compaction_tasks_.size() &gt; 0);</a>
<a name="ln3716">  }</a>
<a name="ln3717">  std::deque&lt;ManualCompaction*&gt;::iterator it =</a>
<a name="ln3718">      manual_compaction_dequeue_.begin();</a>
<a name="ln3719">  bool seen = false;</a>
<a name="ln3720">  while (it != manual_compaction_dequeue_.end()) {</a>
<a name="ln3721">    if (m == (*it)) {</a>
<a name="ln3722">      it++;</a>
<a name="ln3723">      seen = true;</a>
<a name="ln3724">      continue;</a>
<a name="ln3725">    } else if (MCOverlap(m, (*it)) &amp;&amp; (!seen &amp;&amp; !(*it)-&gt;in_progress)) {</a>
<a name="ln3726">      // Consider the other manual compaction *it, conflicts if:</a>
<a name="ln3727">      // overlaps with m</a>
<a name="ln3728">      // and (*it) is ahead in the queue and is not yet in progress</a>
<a name="ln3729">      return true;</a>
<a name="ln3730">    }</a>
<a name="ln3731">    it++;</a>
<a name="ln3732">  }</a>
<a name="ln3733">  return false;</a>
<a name="ln3734">}</a>
<a name="ln3735"> </a>
<a name="ln3736">bool DBImpl::HaveManualCompaction(ColumnFamilyData* cfd) {</a>
<a name="ln3737">  // Remove from priority queue</a>
<a name="ln3738">  std::deque&lt;ManualCompaction*&gt;::iterator it =</a>
<a name="ln3739">      manual_compaction_dequeue_.begin();</a>
<a name="ln3740">  while (it != manual_compaction_dequeue_.end()) {</a>
<a name="ln3741">    if ((*it)-&gt;exclusive) {</a>
<a name="ln3742">      return true;</a>
<a name="ln3743">    }</a>
<a name="ln3744">    if ((cfd == (*it)-&gt;cfd) &amp;&amp; (!((*it)-&gt;in_progress || (*it)-&gt;done))) {</a>
<a name="ln3745">      // Allow automatic compaction if manual compaction is</a>
<a name="ln3746">      // is in progress</a>
<a name="ln3747">      return true;</a>
<a name="ln3748">    }</a>
<a name="ln3749">    it++;</a>
<a name="ln3750">  }</a>
<a name="ln3751">  return false;</a>
<a name="ln3752">}</a>
<a name="ln3753"> </a>
<a name="ln3754">bool DBImpl::HasExclusiveManualCompaction() {</a>
<a name="ln3755">  // Remove from priority queue</a>
<a name="ln3756">  std::deque&lt;ManualCompaction*&gt;::iterator it =</a>
<a name="ln3757">      manual_compaction_dequeue_.begin();</a>
<a name="ln3758">  while (it != manual_compaction_dequeue_.end()) {</a>
<a name="ln3759">    if ((*it)-&gt;exclusive) {</a>
<a name="ln3760">      return true;</a>
<a name="ln3761">    }</a>
<a name="ln3762">    it++;</a>
<a name="ln3763">  }</a>
<a name="ln3764">  return false;</a>
<a name="ln3765">}</a>
<a name="ln3766"> </a>
<a name="ln3767">bool DBImpl::MCOverlap(ManualCompaction* m, ManualCompaction* m1) {</a>
<a name="ln3768">  if ((m-&gt;exclusive) || (m1-&gt;exclusive)) {</a>
<a name="ln3769">    return true;</a>
<a name="ln3770">  }</a>
<a name="ln3771">  if (m-&gt;cfd != m1-&gt;cfd) {</a>
<a name="ln3772">    return false;</a>
<a name="ln3773">  }</a>
<a name="ln3774">  return true;</a>
<a name="ln3775">}</a>
<a name="ln3776"> </a>
<a name="ln3777">namespace {</a>
<a name="ln3778">struct IterState {</a>
<a name="ln3779">  IterState(DBImpl* _db, InstrumentedMutex* _mu, SuperVersion* _super_version)</a>
<a name="ln3780">      : db(_db), mu(_mu), super_version(_super_version) {}</a>
<a name="ln3781"> </a>
<a name="ln3782">  DBImpl* db;</a>
<a name="ln3783">  InstrumentedMutex* mu;</a>
<a name="ln3784">  SuperVersion* super_version;</a>
<a name="ln3785">};</a>
<a name="ln3786"> </a>
<a name="ln3787">static void CleanupIteratorState(void* arg1, void* arg2) {</a>
<a name="ln3788">  IterState* state = reinterpret_cast&lt;IterState*&gt;(arg1);</a>
<a name="ln3789"> </a>
<a name="ln3790">  if (state-&gt;super_version-&gt;Unref()) {</a>
<a name="ln3791">    // Job id == 0 means that this is not our background process, but rather</a>
<a name="ln3792">    // user thread</a>
<a name="ln3793">    JobContext job_context(0);</a>
<a name="ln3794"> </a>
<a name="ln3795">    state-&gt;mu-&gt;Lock();</a>
<a name="ln3796">    state-&gt;super_version-&gt;Cleanup();</a>
<a name="ln3797">    state-&gt;db-&gt;FindObsoleteFiles(&amp;job_context, false, true);</a>
<a name="ln3798">    state-&gt;mu-&gt;Unlock();</a>
<a name="ln3799"> </a>
<a name="ln3800">    delete state-&gt;super_version;</a>
<a name="ln3801">    if (job_context.HaveSomethingToDelete()) {</a>
<a name="ln3802">      state-&gt;db-&gt;PurgeObsoleteFiles(job_context);</a>
<a name="ln3803">    }</a>
<a name="ln3804">    job_context.Clean();</a>
<a name="ln3805">  }</a>
<a name="ln3806"> </a>
<a name="ln3807">  delete state;</a>
<a name="ln3808">}</a>
<a name="ln3809">}  // namespace</a>
<a name="ln3810"> </a>
<a name="ln3811">InternalIterator* DBImpl::NewInternalIterator(const ReadOptions&amp; read_options,</a>
<a name="ln3812">                                              ColumnFamilyData* cfd,</a>
<a name="ln3813">                                              SuperVersion* super_version,</a>
<a name="ln3814">                                              Arena* arena) {</a>
<a name="ln3815">  InternalIterator* internal_iter;</a>
<a name="ln3816">  assert(arena != nullptr);</a>
<a name="ln3817">  // Need to create internal iterator from the arena.</a>
<a name="ln3818">  MergeIteratorBuilder merge_iter_builder(cfd-&gt;internal_comparator().get(), arena);</a>
<a name="ln3819">  // Collect iterator for mutable mem</a>
<a name="ln3820">  merge_iter_builder.AddIterator(</a>
<a name="ln3821">      super_version-&gt;mem-&gt;NewIterator(read_options, arena));</a>
<a name="ln3822">  // Collect all needed child iterators for immutable memtables</a>
<a name="ln3823">  super_version-&gt;imm-&gt;AddIterators(read_options, &amp;merge_iter_builder);</a>
<a name="ln3824">  // Collect iterators for files in L0 - Ln</a>
<a name="ln3825">  super_version-&gt;current-&gt;AddIterators(read_options, env_options_,</a>
<a name="ln3826">                                       &amp;merge_iter_builder);</a>
<a name="ln3827">  internal_iter = merge_iter_builder.Finish();</a>
<a name="ln3828">  IterState* cleanup = new IterState(this, &amp;mutex_, super_version);</a>
<a name="ln3829">  internal_iter-&gt;RegisterCleanup(CleanupIteratorState, cleanup, nullptr);</a>
<a name="ln3830"> </a>
<a name="ln3831">  return internal_iter;</a>
<a name="ln3832">}</a>
<a name="ln3833"> </a>
<a name="ln3834">ColumnFamilyHandle* DBImpl::DefaultColumnFamily() const {</a>
<a name="ln3835">  return default_cf_handle_;</a>
<a name="ln3836">}</a>
<a name="ln3837"> </a>
<a name="ln3838">Status DBImpl::Get(const ReadOptions&amp; read_options,</a>
<a name="ln3839">                   ColumnFamilyHandle* column_family, const Slice&amp; key,</a>
<a name="ln3840">                   std::string* value) {</a>
<a name="ln3841">  return GetImpl(read_options, column_family, key, value);</a>
<a name="ln3842">}</a>
<a name="ln3843"> </a>
<a name="ln3844">// JobContext gets created and destructed outside of the lock --</a>
<a name="ln3845">// we</a>
<a name="ln3846">// use this convinently to:</a>
<a name="ln3847">// * malloc one SuperVersion() outside of the lock -- new_superversion</a>
<a name="ln3848">// * delete SuperVersion()s outside of the lock -- superversions_to_free</a>
<a name="ln3849">//</a>
<a name="ln3850">// However, if InstallSuperVersionAndScheduleWork() gets called twice with the</a>
<a name="ln3851">// same job_context, we can't reuse the SuperVersion() that got</a>
<a name="ln3852">// malloced because</a>
<a name="ln3853">// first call already used it. In that rare case, we take a hit and create a</a>
<a name="ln3854">// new SuperVersion() inside of the mutex. We do similar thing</a>
<a name="ln3855">// for superversion_to_free</a>
<a name="ln3856">void DBImpl::InstallSuperVersionAndScheduleWorkWrapper(</a>
<a name="ln3857">    ColumnFamilyData* cfd, JobContext* job_context,</a>
<a name="ln3858">    const MutableCFOptions&amp; mutable_cf_options) {</a>
<a name="ln3859">  mutex_.AssertHeld();</a>
<a name="ln3860">  auto old_superversion = InstallSuperVersionAndScheduleWork(</a>
<a name="ln3861">      cfd, job_context-&gt;new_superversion, mutable_cf_options);</a>
<a name="ln3862">  job_context-&gt;new_superversion = nullptr;</a>
<a name="ln3863">  job_context-&gt;superversions_to_free.push_back(old_superversion.release());</a>
<a name="ln3864">}</a>
<a name="ln3865"> </a>
<a name="ln3866">std::unique_ptr&lt;SuperVersion&gt; DBImpl::InstallSuperVersionAndScheduleWork(</a>
<a name="ln3867">    ColumnFamilyData* cfd, SuperVersion* new_sv,</a>
<a name="ln3868">    const MutableCFOptions&amp; mutable_cf_options) {</a>
<a name="ln3869">  mutex_.AssertHeld();</a>
<a name="ln3870"> </a>
<a name="ln3871">  // Update max_total_in_memory_state_</a>
<a name="ln3872">  size_t old_memtable_size = 0;</a>
<a name="ln3873">  auto* old_sv = cfd-&gt;GetSuperVersion();</a>
<a name="ln3874">  if (old_sv) {</a>
<a name="ln3875">    old_memtable_size = old_sv-&gt;mutable_cf_options.write_buffer_size *</a>
<a name="ln3876">                        old_sv-&gt;mutable_cf_options.max_write_buffer_number;</a>
<a name="ln3877">  }</a>
<a name="ln3878"> </a>
<a name="ln3879">  auto old = cfd-&gt;InstallSuperVersion(</a>
<a name="ln3880">      new_sv ? new_sv : new SuperVersion(), &amp;mutex_, mutable_cf_options);</a>
<a name="ln3881"> </a>
<a name="ln3882">  // Whenever we install new SuperVersion, we might need to issue new flushes or</a>
<a name="ln3883">  // compactions.</a>
<a name="ln3884">  SchedulePendingFlush(cfd);</a>
<a name="ln3885">  SchedulePendingCompaction(cfd);</a>
<a name="ln3886">  MaybeScheduleFlushOrCompaction();</a>
<a name="ln3887"> </a>
<a name="ln3888">  // Update max_total_in_memory_state_</a>
<a name="ln3889">  max_total_in_memory_state_ =</a>
<a name="ln3890">      max_total_in_memory_state_ - old_memtable_size +</a>
<a name="ln3891">      mutable_cf_options.write_buffer_size *</a>
<a name="ln3892">      mutable_cf_options.max_write_buffer_number;</a>
<a name="ln3893">  return old;</a>
<a name="ln3894">}</a>
<a name="ln3895"> </a>
<a name="ln3896">Status DBImpl::GetImpl(const ReadOptions&amp; read_options,</a>
<a name="ln3897">                       ColumnFamilyHandle* column_family, const Slice&amp; key,</a>
<a name="ln3898">                       std::string* value, bool* value_found) {</a>
<a name="ln3899">  StopWatch sw(env_, stats_, DB_GET);</a>
<a name="ln3900">  PERF_TIMER_GUARD(get_snapshot_time);</a>
<a name="ln3901"> </a>
<a name="ln3902">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln3903">  auto cfd = cfh-&gt;cfd();</a>
<a name="ln3904"> </a>
<a name="ln3905">  SequenceNumber snapshot;</a>
<a name="ln3906">  if (read_options.snapshot != nullptr) {</a>
<a name="ln3907">    snapshot = reinterpret_cast&lt;const SnapshotImpl*&gt;(</a>
<a name="ln3908">        read_options.snapshot)-&gt;number_;</a>
<a name="ln3909">  } else {</a>
<a name="ln3910">    snapshot = versions_-&gt;LastSequence();</a>
<a name="ln3911">  }</a>
<a name="ln3912">  // Acquire SuperVersion</a>
<a name="ln3913">  SuperVersion* sv = GetAndRefSuperVersion(cfd);</a>
<a name="ln3914">  // Prepare to store a list of merge operations if merge occurs.</a>
<a name="ln3915">  MergeContext merge_context;</a>
<a name="ln3916"> </a>
<a name="ln3917">  Status s;</a>
<a name="ln3918">  // First look in the memtable, then in the immutable memtable (if any).</a>
<a name="ln3919">  // s is both in/out. When in, s could either be OK or MergeInProgress.</a>
<a name="ln3920">  // merge_operands will contain the sequence of merges in the latter case.</a>
<a name="ln3921">  LookupKey lkey(key, snapshot);</a>
<a name="ln3922">  PERF_TIMER_STOP(get_snapshot_time);</a>
<a name="ln3923"> </a>
<a name="ln3924">  bool skip_memtable =</a>
<a name="ln3925">      (read_options.read_tier == kPersistedTier &amp;&amp; has_unpersisted_data_);</a>
<a name="ln3926">  bool done = false;</a>
<a name="ln3927">  if (!skip_memtable) {</a>
<a name="ln3928">    if (sv-&gt;mem-&gt;Get(lkey, value, &amp;s, &amp;merge_context)) {</a>
<a name="ln3929">      done = true;</a>
<a name="ln3930">      RecordTick(stats_, MEMTABLE_HIT);</a>
<a name="ln3931">    } else if (sv-&gt;imm-&gt;Get(lkey, value, &amp;s, &amp;merge_context)) {</a>
<a name="ln3932">      done = true;</a>
<a name="ln3933">      RecordTick(stats_, MEMTABLE_HIT);</a>
<a name="ln3934">    }</a>
<a name="ln3935">  }</a>
<a name="ln3936">  if (!done) {</a>
<a name="ln3937">    PERF_TIMER_GUARD(get_from_output_files_time);</a>
<a name="ln3938">    sv-&gt;current-&gt;Get(read_options, lkey, value, &amp;s, &amp;merge_context,</a>
<a name="ln3939">                     value_found);</a>
<a name="ln3940">    RecordTick(stats_, MEMTABLE_MISS);</a>
<a name="ln3941">  }</a>
<a name="ln3942"> </a>
<a name="ln3943">  {</a>
<a name="ln3944">    PERF_TIMER_GUARD(get_post_process_time);</a>
<a name="ln3945"> </a>
<a name="ln3946">    ReturnAndCleanupSuperVersion(cfd, sv);</a>
<a name="ln3947"> </a>
<a name="ln3948">    RecordTick(stats_, NUMBER_KEYS_READ);</a>
<a name="ln3949">    RecordTick(stats_, BYTES_READ, value-&gt;size());</a>
<a name="ln3950">    MeasureTime(stats_, BYTES_PER_READ, value-&gt;size());</a>
<a name="ln3951">  }</a>
<a name="ln3952">  return s;</a>
<a name="ln3953">}</a>
<a name="ln3954"> </a>
<a name="ln3955">std::vector&lt;Status&gt; DBImpl::MultiGet(</a>
<a name="ln3956">    const ReadOptions&amp; read_options,</a>
<a name="ln3957">    const std::vector&lt;ColumnFamilyHandle*&gt;&amp; column_family,</a>
<a name="ln3958">    const std::vector&lt;Slice&gt;&amp; keys, std::vector&lt;std::string&gt;* values) {</a>
<a name="ln3959"> </a>
<a name="ln3960">  StopWatch sw(env_, stats_, DB_MULTIGET);</a>
<a name="ln3961">  PERF_TIMER_GUARD(get_snapshot_time);</a>
<a name="ln3962"> </a>
<a name="ln3963">  struct MultiGetColumnFamilyData {</a>
<a name="ln3964">    ColumnFamilyData* cfd;</a>
<a name="ln3965">    SuperVersion* super_version;</a>
<a name="ln3966">  };</a>
<a name="ln3967">  std::unordered_map&lt;uint32_t, MultiGetColumnFamilyData*&gt; multiget_cf_data;</a>
<a name="ln3968">  // fill up and allocate outside of mutex</a>
<a name="ln3969">  for (auto cf : column_family) {</a>
<a name="ln3970">    auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(cf);</a>
<a name="ln3971">    auto cfd = cfh-&gt;cfd();</a>
<a name="ln3972">    if (multiget_cf_data.find(cfd-&gt;GetID()) == multiget_cf_data.end()) {</a>
<a name="ln3973">      auto mgcfd = new MultiGetColumnFamilyData();</a>
<a name="ln3974">      mgcfd-&gt;cfd = cfd;</a>
<a name="ln3975">      multiget_cf_data.insert({cfd-&gt;GetID(), mgcfd});</a>
<a name="ln3976">    }</a>
<a name="ln3977">  }</a>
<a name="ln3978"> </a>
<a name="ln3979">  mutex_.Lock();</a>
<a name="ln3980">  SequenceNumber snapshot;</a>
<a name="ln3981">  if (read_options.snapshot != nullptr) {</a>
<a name="ln3982">    snapshot = reinterpret_cast&lt;const SnapshotImpl*&gt;(</a>
<a name="ln3983">        read_options.snapshot)-&gt;number_;</a>
<a name="ln3984">  } else {</a>
<a name="ln3985">    snapshot = versions_-&gt;LastSequence();</a>
<a name="ln3986">  }</a>
<a name="ln3987">  for (auto mgd_iter : multiget_cf_data) {</a>
<a name="ln3988">    mgd_iter.second-&gt;super_version =</a>
<a name="ln3989">        mgd_iter.second-&gt;cfd-&gt;GetSuperVersion()-&gt;Ref();</a>
<a name="ln3990">  }</a>
<a name="ln3991">  mutex_.Unlock();</a>
<a name="ln3992"> </a>
<a name="ln3993">  // Contain a list of merge operations if merge occurs.</a>
<a name="ln3994">  MergeContext merge_context;</a>
<a name="ln3995"> </a>
<a name="ln3996">  // Note: this always resizes the values array</a>
<a name="ln3997">  size_t num_keys = keys.size();</a>
<a name="ln3998">  std::vector&lt;Status&gt; stat_list(num_keys);</a>
<a name="ln3999">  values-&gt;resize(num_keys);</a>
<a name="ln4000"> </a>
<a name="ln4001">  // Keep track of bytes that we read for statistics-recording later</a>
<a name="ln4002">  uint64_t bytes_read = 0;</a>
<a name="ln4003">  PERF_TIMER_STOP(get_snapshot_time);</a>
<a name="ln4004"> </a>
<a name="ln4005">  // For each of the given keys, apply the entire &quot;get&quot; process as follows:</a>
<a name="ln4006">  // First look in the memtable, then in the immutable memtable (if any).</a>
<a name="ln4007">  // s is both in/out. When in, s could either be OK or MergeInProgress.</a>
<a name="ln4008">  // merge_operands will contain the sequence of merges in the latter case.</a>
<a name="ln4009">  for (size_t i = 0; i &lt; num_keys; ++i) {</a>
<a name="ln4010">    merge_context.Clear();</a>
<a name="ln4011">    Status&amp; s = stat_list[i];</a>
<a name="ln4012">    std::string* value = &amp;(*values)[i];</a>
<a name="ln4013"> </a>
<a name="ln4014">    LookupKey lkey(keys[i], snapshot);</a>
<a name="ln4015">    auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family[i]);</a>
<a name="ln4016">    auto mgd_iter = multiget_cf_data.find(cfh-&gt;cfd()-&gt;GetID());</a>
<a name="ln4017">    assert(mgd_iter != multiget_cf_data.end());</a>
<a name="ln4018">    auto mgd = mgd_iter-&gt;second;</a>
<a name="ln4019">    auto super_version = mgd-&gt;super_version;</a>
<a name="ln4020">    bool skip_memtable =</a>
<a name="ln4021">        (read_options.read_tier == kPersistedTier &amp;&amp; has_unpersisted_data_);</a>
<a name="ln4022">    bool done = false;</a>
<a name="ln4023">    if (!skip_memtable) {</a>
<a name="ln4024">      if (super_version-&gt;mem-&gt;Get(lkey, value, &amp;s, &amp;merge_context)) {</a>
<a name="ln4025">        done = true;</a>
<a name="ln4026">        // TODO(?): RecordTick(stats_, MEMTABLE_HIT)?</a>
<a name="ln4027">      } else if (super_version-&gt;imm-&gt;Get(lkey, value, &amp;s, &amp;merge_context)) {</a>
<a name="ln4028">        done = true;</a>
<a name="ln4029">        // TODO(?): RecordTick(stats_, MEMTABLE_HIT)?</a>
<a name="ln4030">      }</a>
<a name="ln4031">    }</a>
<a name="ln4032">    if (!done) {</a>
<a name="ln4033">      PERF_TIMER_GUARD(get_from_output_files_time);</a>
<a name="ln4034">      super_version-&gt;current-&gt;Get(read_options, lkey, value, &amp;s,</a>
<a name="ln4035">                                  &amp;merge_context);</a>
<a name="ln4036">      // TODO(?): RecordTick(stats_, MEMTABLE_MISS)?</a>
<a name="ln4037">    }</a>
<a name="ln4038"> </a>
<a name="ln4039">    if (s.ok()) {</a>
<a name="ln4040">      bytes_read += value-&gt;size();</a>
<a name="ln4041">    }</a>
<a name="ln4042">  }</a>
<a name="ln4043"> </a>
<a name="ln4044">  // Post processing (decrement reference counts and record statistics)</a>
<a name="ln4045">  PERF_TIMER_GUARD(get_post_process_time);</a>
<a name="ln4046">  autovector&lt;SuperVersion*&gt; superversions_to_delete;</a>
<a name="ln4047"> </a>
<a name="ln4048">  // TODO(icanadi) do we need lock here or just around Cleanup()?</a>
<a name="ln4049">  mutex_.Lock();</a>
<a name="ln4050">  for (auto mgd_iter : multiget_cf_data) {</a>
<a name="ln4051">    auto mgd = mgd_iter.second;</a>
<a name="ln4052">    if (mgd-&gt;super_version-&gt;Unref()) {</a>
<a name="ln4053">      mgd-&gt;super_version-&gt;Cleanup();</a>
<a name="ln4054">      superversions_to_delete.push_back(mgd-&gt;super_version);</a>
<a name="ln4055">    }</a>
<a name="ln4056">  }</a>
<a name="ln4057">  mutex_.Unlock();</a>
<a name="ln4058"> </a>
<a name="ln4059">  for (auto td : superversions_to_delete) {</a>
<a name="ln4060">    delete td;</a>
<a name="ln4061">  }</a>
<a name="ln4062">  for (auto mgd : multiget_cf_data) {</a>
<a name="ln4063">    delete mgd.second;</a>
<a name="ln4064">  }</a>
<a name="ln4065"> </a>
<a name="ln4066">  RecordTick(stats_, NUMBER_MULTIGET_CALLS);</a>
<a name="ln4067">  RecordTick(stats_, NUMBER_MULTIGET_KEYS_READ, num_keys);</a>
<a name="ln4068">  RecordTick(stats_, NUMBER_MULTIGET_BYTES_READ, bytes_read);</a>
<a name="ln4069">  MeasureTime(stats_, BYTES_PER_MULTIGET, bytes_read);</a>
<a name="ln4070">  PERF_TIMER_STOP(get_post_process_time);</a>
<a name="ln4071"> </a>
<a name="ln4072">  return stat_list;</a>
<a name="ln4073">}</a>
<a name="ln4074"> </a>
<a name="ln4075">#ifndef ROCKSDB_LITE</a>
<a name="ln4076">Status DBImpl::AddFile(ColumnFamilyHandle* column_family,</a>
<a name="ln4077">                       const std::string&amp; file_path, bool move_file) {</a>
<a name="ln4078">  Status status;</a>
<a name="ln4079">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln4080">  ColumnFamilyData* cfd = cfh-&gt;cfd();</a>
<a name="ln4081"> </a>
<a name="ln4082">  ExternalSstFileInfo file_info;</a>
<a name="ln4083">  file_info.file_path = file_path;</a>
<a name="ln4084">  status = env_-&gt;GetFileSize(file_path, &amp;file_info.base_file_size);</a>
<a name="ln4085">  if (!status.ok()) {</a>
<a name="ln4086">    return status;</a>
<a name="ln4087">  }</a>
<a name="ln4088"> </a>
<a name="ln4089">  // Access the file using TableReader to extract</a>
<a name="ln4090">  // version, number of entries, smallest user key, largest user key</a>
<a name="ln4091">  std::unique_ptr&lt;RandomAccessFile&gt; base_sst_file;</a>
<a name="ln4092">  status = env_-&gt;NewRandomAccessFile(file_path, &amp;base_sst_file, env_options_);</a>
<a name="ln4093">  if (!status.ok()) {</a>
<a name="ln4094">    return status;</a>
<a name="ln4095">  }</a>
<a name="ln4096">  std::unique_ptr&lt;RandomAccessFileReader&gt; base_sst_file_reader;</a>
<a name="ln4097">  base_sst_file_reader.reset(new RandomAccessFileReader(std::move(base_sst_file)));</a>
<a name="ln4098"> </a>
<a name="ln4099">  std::unique_ptr&lt;TableReader&gt; table_reader;</a>
<a name="ln4100">  status = cfd-&gt;ioptions()-&gt;table_factory-&gt;NewTableReader(</a>
<a name="ln4101">      TableReaderOptions(*cfd-&gt;ioptions(), env_options_,</a>
<a name="ln4102">                         cfd-&gt;internal_comparator()),</a>
<a name="ln4103">      std::move(base_sst_file_reader), file_info.base_file_size,</a>
<a name="ln4104">      &amp;table_reader);</a>
<a name="ln4105">  if (!status.ok()) {</a>
<a name="ln4106">    return status;</a>
<a name="ln4107">  }</a>
<a name="ln4108"> </a>
<a name="ln4109">  // Get the external sst file version from table properties</a>
<a name="ln4110">  const UserCollectedProperties&amp; user_collected_properties =</a>
<a name="ln4111">      table_reader-&gt;GetTableProperties()-&gt;user_collected_properties;</a>
<a name="ln4112">  UserCollectedProperties::const_iterator external_sst_file_version_iter =</a>
<a name="ln4113">      user_collected_properties.find(ExternalSstFilePropertyNames::kVersion);</a>
<a name="ln4114">  if (external_sst_file_version_iter == user_collected_properties.end()) {</a>
<a name="ln4115">    return STATUS(InvalidArgument, &quot;Generated table version not found&quot;);</a>
<a name="ln4116">  }</a>
<a name="ln4117"> </a>
<a name="ln4118">  file_info.is_split_sst = table_reader-&gt;IsSplitSst();</a>
<a name="ln4119">  if (file_info.is_split_sst) {</a>
<a name="ln4120">    std::unique_ptr&lt;RandomAccessFile&gt; data_sst_file;</a>
<a name="ln4121">    status = env_-&gt;NewRandomAccessFile(TableBaseToDataFileName(file_path), &amp;data_sst_file,</a>
<a name="ln4122">        env_options_);</a>
<a name="ln4123">    if (!status.ok()) {</a>
<a name="ln4124">      return status;</a>
<a name="ln4125">    }</a>
<a name="ln4126">    std::unique_ptr&lt;RandomAccessFileReader&gt; data_sst_file_reader;</a>
<a name="ln4127">    data_sst_file_reader.reset(new RandomAccessFileReader(std::move(data_sst_file)));</a>
<a name="ln4128">    table_reader-&gt;SetDataFileReader(std::move(data_sst_file_reader));</a>
<a name="ln4129">  }</a>
<a name="ln4130"> </a>
<a name="ln4131">  file_info.file_size = file_info.base_file_size +</a>
<a name="ln4132">      (file_info.is_split_sst ? table_reader-&gt;GetTableProperties()-&gt;data_size : 0);</a>
<a name="ln4133"> </a>
<a name="ln4134">  file_info.version =</a>
<a name="ln4135">      DecodeFixed32(external_sst_file_version_iter-&gt;second.c_str());</a>
<a name="ln4136">  if (file_info.version == 1) {</a>
<a name="ln4137">    // version 1 imply that all sequence numbers in table equal 0</a>
<a name="ln4138">    file_info.sequence_number = 0;</a>
<a name="ln4139">  } else {</a>
<a name="ln4140">    return STATUS(InvalidArgument, &quot;Generated table version is not supported&quot;);</a>
<a name="ln4141">  }</a>
<a name="ln4142"> </a>
<a name="ln4143">  // Get number of entries in table</a>
<a name="ln4144">  file_info.num_entries = table_reader-&gt;GetTableProperties()-&gt;num_entries;</a>
<a name="ln4145"> </a>
<a name="ln4146">  ParsedInternalKey key;</a>
<a name="ln4147">  std::unique_ptr&lt;InternalIterator&gt; iter(</a>
<a name="ln4148">      table_reader-&gt;NewIterator(ReadOptions()));</a>
<a name="ln4149"> </a>
<a name="ln4150">  // Get first (smallest) key from file</a>
<a name="ln4151">  iter-&gt;SeekToFirst();</a>
<a name="ln4152">  if (!ParseInternalKey(iter-&gt;key(), &amp;key)) {</a>
<a name="ln4153">    return STATUS(Corruption, &quot;Generated table have corrupted keys&quot;);</a>
<a name="ln4154">  }</a>
<a name="ln4155">  if (key.sequence != 0) {</a>
<a name="ln4156">    return STATUS(Corruption, &quot;Generated table have non zero sequence number&quot;);</a>
<a name="ln4157">  }</a>
<a name="ln4158">  file_info.smallest_key = key.user_key.ToString();</a>
<a name="ln4159"> </a>
<a name="ln4160">  // Get last (largest) key from file</a>
<a name="ln4161">  iter-&gt;SeekToLast();</a>
<a name="ln4162">  if (!ParseInternalKey(iter-&gt;key(), &amp;key)) {</a>
<a name="ln4163">    return STATUS(Corruption, &quot;Generated table have corrupted keys&quot;);</a>
<a name="ln4164">  }</a>
<a name="ln4165">  if (key.sequence != 0) {</a>
<a name="ln4166">    return STATUS(Corruption, &quot;Generated table have non zero sequence number&quot;);</a>
<a name="ln4167">  }</a>
<a name="ln4168">  file_info.largest_key = key.user_key.ToString();</a>
<a name="ln4169"> </a>
<a name="ln4170">  return AddFile(column_family, &amp;file_info, move_file);</a>
<a name="ln4171">}</a>
<a name="ln4172"> </a>
<a name="ln4173">namespace {</a>
<a name="ln4174"> </a>
<a name="ln4175">// Helper function for copying file from src_path to dst_path. If try_hard_link is true it tries</a>
<a name="ln4176">// to make a hard link instead of copyging if possible.</a>
<a name="ln4177">Status AddFile(Env* env, const std::string&amp; src_path, const std::string&amp; dst_path,</a>
<a name="ln4178">    bool try_hard_link) {</a>
<a name="ln4179">  Status status;</a>
<a name="ln4180">  if (try_hard_link) {</a>
<a name="ln4181">    status = env-&gt;LinkFile(src_path, dst_path);</a>
<a name="ln4182">    if (status.IsNotSupported()) {</a>
<a name="ln4183">      // Original file is on a different FS, use copy instead of hard linking</a>
<a name="ln4184">      status = CopyFile(env, src_path, dst_path, 0);</a>
<a name="ln4185">    }</a>
<a name="ln4186">  } else {</a>
<a name="ln4187">    status = CopyFile(env, src_path, dst_path, 0);</a>
<a name="ln4188">  }</a>
<a name="ln4189">  return status;</a>
<a name="ln4190">}</a>
<a name="ln4191"> </a>
<a name="ln4192">// Deletes file and logs error message in case of failure. error_format should have format</a>
<a name="ln4193">// specifications exactly for 2 string arguments: path and status.</a>
<a name="ln4194">void DeleteFile(Env* env, const std::string&amp; path, const shared_ptr&lt;Logger&gt;&amp; info_log,</a>
<a name="ln4195">    const char* error_format) {</a>
<a name="ln4196">  Status s = env-&gt;DeleteFile(path);</a>
<a name="ln4197">  if (!s.ok()) {</a>
<a name="ln4198">    RLOG(InfoLogLevel::WARN_LEVEL, info_log, error_format, path.c_str(), s.ToString().c_str());</a>
<a name="ln4199">  }</a>
<a name="ln4200">}</a>
<a name="ln4201"> </a>
<a name="ln4202">} // namespace</a>
<a name="ln4203"> </a>
<a name="ln4204">Status DBImpl::AddFile(ColumnFamilyHandle* column_family,</a>
<a name="ln4205">                       const ExternalSstFileInfo* file_info, bool move_file) {</a>
<a name="ln4206">  Status status;</a>
<a name="ln4207">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln4208">  ColumnFamilyData* cfd = cfh-&gt;cfd();</a>
<a name="ln4209"> </a>
<a name="ln4210">  if (file_info-&gt;num_entries == 0) {</a>
<a name="ln4211">    return STATUS(InvalidArgument, &quot;File contain no entries&quot;);</a>
<a name="ln4212">  }</a>
<a name="ln4213">  if (file_info-&gt;version != 1) {</a>
<a name="ln4214">    return STATUS(InvalidArgument, &quot;Generated table version is not supported&quot;);</a>
<a name="ln4215">  }</a>
<a name="ln4216">  // version 1 imply that file have only Put Operations with Sequence Number = 0</a>
<a name="ln4217"> </a>
<a name="ln4218">  FileMetaData meta;</a>
<a name="ln4219">  meta.smallest.key = InternalKey(file_info-&gt;smallest_key,</a>
<a name="ln4220">                                  file_info-&gt;sequence_number,</a>
<a name="ln4221">                                  ValueType::kTypeValue);</a>
<a name="ln4222">  meta.largest.key = InternalKey(file_info-&gt;largest_key,</a>
<a name="ln4223">                                 file_info-&gt;sequence_number,</a>
<a name="ln4224">                                 ValueType::kTypeValue);</a>
<a name="ln4225">  if (!meta.smallest.key.Valid() || !meta.largest.key.Valid()) {</a>
<a name="ln4226">    return STATUS(Corruption, &quot;Generated table have corrupted keys&quot;);</a>
<a name="ln4227">  }</a>
<a name="ln4228">  meta.smallest.seqno = file_info-&gt;sequence_number;</a>
<a name="ln4229">  meta.largest.seqno = file_info-&gt;sequence_number;</a>
<a name="ln4230">  if (meta.smallest.seqno != 0 || meta.largest.seqno != 0) {</a>
<a name="ln4231">    return STATUS(InvalidArgument,</a>
<a name="ln4232">        &quot;Non zero sequence numbers are not supported&quot;);</a>
<a name="ln4233">  }</a>
<a name="ln4234"> </a>
<a name="ln4235">  std::string db_base_fname;</a>
<a name="ln4236">  std::string db_data_fname;</a>
<a name="ln4237">  std::string data_file_path;</a>
<a name="ln4238">  {</a>
<a name="ln4239">    // Generate a location for the new table</a>
<a name="ln4240">    auto file_number_holder = pending_outputs_-&gt;NewFileNumber();</a>
<a name="ln4241">    meta.fd = FileDescriptor(file_number_holder.Last(), 0, file_info-&gt;file_size,</a>
<a name="ln4242">        file_info-&gt;base_file_size);</a>
<a name="ln4243"> </a>
<a name="ln4244">    db_base_fname = TableFileName(</a>
<a name="ln4245">        db_options_.db_paths, meta.fd.GetNumber(), meta.fd.GetPathId());</a>
<a name="ln4246">    status = ::rocksdb::AddFile(env_, file_info-&gt;file_path, db_base_fname, move_file);</a>
<a name="ln4247"> </a>
<a name="ln4248">    if (status.ok() &amp;&amp; file_info-&gt;is_split_sst) {</a>
<a name="ln4249">      data_file_path = TableBaseToDataFileName(file_info-&gt;file_path);</a>
<a name="ln4250">      db_data_fname = TableBaseToDataFileName(db_base_fname);</a>
<a name="ln4251">      status = ::rocksdb::AddFile(env_, data_file_path, db_data_fname, move_file);</a>
<a name="ln4252">      if (!status.ok()) {</a>
<a name="ln4253">        ::rocksdb::DeleteFile(env_, db_base_fname, db_options_.info_log,</a>
<a name="ln4254">            &quot;AddFile() clean up for file %s failed : %s&quot;);</a>
<a name="ln4255">      }</a>
<a name="ln4256">    }</a>
<a name="ln4257"> </a>
<a name="ln4258">    TEST_SYNC_POINT(&quot;DBImpl::AddFile:FileCopied&quot;);</a>
<a name="ln4259">    if (!status.ok()) {</a>
<a name="ln4260">      return status;</a>
<a name="ln4261">    }</a>
<a name="ln4262"> </a>
<a name="ln4263">    {</a>
<a name="ln4264">      InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln4265">      const MutableCFOptions mutable_cf_options =</a>
<a name="ln4266">          *cfd-&gt;GetLatestMutableCFOptions();</a>
<a name="ln4267"> </a>
<a name="ln4268">      WriteThread::Writer w;</a>
<a name="ln4269">      write_thread_.EnterUnbatched(&amp;w, &amp;mutex_);</a>
<a name="ln4270"> </a>
<a name="ln4271">      if (!snapshots_.empty()) {</a>
<a name="ln4272">        // Check that no snapshots are being held</a>
<a name="ln4273">        status =</a>
<a name="ln4274">            STATUS(NotSupported, &quot;Cannot add a file while holding snapshots&quot;);</a>
<a name="ln4275">      }</a>
<a name="ln4276"> </a>
<a name="ln4277">      if (status.ok()) {</a>
<a name="ln4278">        // Verify that added file key range dont overlap with any keys in DB</a>
<a name="ln4279">        SuperVersion* sv = cfd-&gt;GetSuperVersion()-&gt;Ref();</a>
<a name="ln4280">        Arena arena;</a>
<a name="ln4281">        ReadOptions ro;</a>
<a name="ln4282">        ro.total_order_seek = true;</a>
<a name="ln4283">        ScopedArenaIterator iter(NewInternalIterator(ro, cfd, sv, &amp;arena));</a>
<a name="ln4284"> </a>
<a name="ln4285">        InternalKey range_start(file_info-&gt;smallest_key, kMaxSequenceNumber, kTypeValue);</a>
<a name="ln4286">        iter-&gt;Seek(range_start.Encode());</a>
<a name="ln4287">        status = iter-&gt;status();</a>
<a name="ln4288"> </a>
<a name="ln4289">        if (status.ok() &amp;&amp; iter-&gt;Valid()) {</a>
<a name="ln4290">          ParsedInternalKey seek_result;</a>
<a name="ln4291">          if (ParseInternalKey(iter-&gt;key(), &amp;seek_result)) {</a>
<a name="ln4292">            auto* vstorage = cfd-&gt;current()-&gt;storage_info();</a>
<a name="ln4293">            if (vstorage-&gt;InternalComparator()-&gt;user_comparator()-&gt;Compare(</a>
<a name="ln4294">                seek_result.user_key, file_info-&gt;largest_key) &lt;= 0) {</a>
<a name="ln4295">              status = STATUS(NotSupported, &quot;Cannot add overlapping range&quot;);</a>
<a name="ln4296">            }</a>
<a name="ln4297">          } else {</a>
<a name="ln4298">            status = STATUS(Corruption, &quot;DB have corrupted keys&quot;);</a>
<a name="ln4299">          }</a>
<a name="ln4300">        }</a>
<a name="ln4301">      }</a>
<a name="ln4302"> </a>
<a name="ln4303">      if (status.ok()) {</a>
<a name="ln4304">        // Add file to L0</a>
<a name="ln4305">        VersionEdit edit;</a>
<a name="ln4306">        edit.SetColumnFamily(cfd-&gt;GetID());</a>
<a name="ln4307">        edit.AddCleanedFile(0, meta);</a>
<a name="ln4308"> </a>
<a name="ln4309">        status = versions_-&gt;LogAndApply(</a>
<a name="ln4310">            cfd, mutable_cf_options, &amp;edit, &amp;mutex_, directories_.GetDbDir());</a>
<a name="ln4311">      }</a>
<a name="ln4312">      write_thread_.ExitUnbatched(&amp;w);</a>
<a name="ln4313"> </a>
<a name="ln4314">      if (status.ok()) {</a>
<a name="ln4315">        InstallSuperVersionAndScheduleWork(cfd, nullptr, mutable_cf_options);</a>
<a name="ln4316">      }</a>
<a name="ln4317">    }</a>
<a name="ln4318">  }</a>
<a name="ln4319"> </a>
<a name="ln4320">  if (!status.ok()) {</a>
<a name="ln4321">    // We failed to add the file to the database</a>
<a name="ln4322">    const char* error_format = &quot;AddFile() clean up for file %s failed : %s&quot;;</a>
<a name="ln4323">    ::rocksdb::DeleteFile(env_, db_base_fname, db_options_.info_log, error_format);</a>
<a name="ln4324">    if (file_info-&gt;is_split_sst) {</a>
<a name="ln4325">      ::rocksdb::DeleteFile(env_, db_data_fname, db_options_.info_log, error_format);</a>
<a name="ln4326">    }</a>
<a name="ln4327">  } else if (status.ok()) {</a>
<a name="ln4328">    if (move_file) {</a>
<a name="ln4329">      // The file was moved and added successfully, remove original file link</a>
<a name="ln4330">      const char* error_format =</a>
<a name="ln4331">          &quot;%s was added to DB successfully but failed to remove original file link : %s&quot;;</a>
<a name="ln4332">      ::rocksdb::DeleteFile(env_, file_info-&gt;file_path, db_options_.info_log, error_format);</a>
<a name="ln4333">      if (file_info-&gt;is_split_sst) {</a>
<a name="ln4334">        ::rocksdb::DeleteFile(env_, data_file_path, db_options_.info_log, error_format);</a>
<a name="ln4335">      }</a>
<a name="ln4336">    }</a>
<a name="ln4337">    FilesChanged();</a>
<a name="ln4338">  }</a>
<a name="ln4339">  return status;</a>
<a name="ln4340">}</a>
<a name="ln4341">#endif  // ROCKSDB_LITE</a>
<a name="ln4342"> </a>
<a name="ln4343">std::function&lt;void()&gt; DBImpl::GetFilesChangedListener() const {</a>
<a name="ln4344">  std::lock_guard&lt;std::mutex&gt; lock(files_changed_listener_mutex_);</a>
<a name="ln4345">  return files_changed_listener_;</a>
<a name="ln4346">}</a>
<a name="ln4347"> </a>
<a name="ln4348">bool DBImpl::HasFilesChangedListener() const {</a>
<a name="ln4349">  std::lock_guard&lt;std::mutex&gt; lock(files_changed_listener_mutex_);</a>
<a name="ln4350">  return files_changed_listener_ != nullptr;</a>
<a name="ln4351">}</a>
<a name="ln4352"> </a>
<a name="ln4353">void DBImpl::ListenFilesChanged(std::function&lt;void()&gt; files_changed_listener) {</a>
<a name="ln4354">  std::lock_guard&lt;std::mutex&gt; lock(files_changed_listener_mutex_);</a>
<a name="ln4355">  files_changed_listener_ = std::move(files_changed_listener);</a>
<a name="ln4356">}</a>
<a name="ln4357"> </a>
<a name="ln4358">void DBImpl::FilesChanged() {</a>
<a name="ln4359">  auto files_changed_listener = GetFilesChangedListener();</a>
<a name="ln4360">  if (files_changed_listener) {</a>
<a name="ln4361">    files_changed_listener();</a>
<a name="ln4362">  }</a>
<a name="ln4363">}</a>
<a name="ln4364"> </a>
<a name="ln4365">Status DBImpl::CreateColumnFamily(const ColumnFamilyOptions&amp; cf_options,</a>
<a name="ln4366">                                  const std::string&amp; column_family_name,</a>
<a name="ln4367">                                  ColumnFamilyHandle** handle) {</a>
<a name="ln4368">  Status s;</a>
<a name="ln4369">  Status persist_options_status;</a>
<a name="ln4370">  *handle = nullptr;</a>
<a name="ln4371"> </a>
<a name="ln4372">  s = CheckCompressionSupported(cf_options);</a>
<a name="ln4373">  if (s.ok() &amp;&amp; db_options_.allow_concurrent_memtable_write) {</a>
<a name="ln4374">    s = CheckConcurrentWritesSupported(cf_options);</a>
<a name="ln4375">  }</a>
<a name="ln4376">  if (!s.ok()) {</a>
<a name="ln4377">    return s;</a>
<a name="ln4378">  }</a>
<a name="ln4379"> </a>
<a name="ln4380">  {</a>
<a name="ln4381">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln4382"> </a>
<a name="ln4383">    if (versions_-&gt;GetColumnFamilySet()-&gt;GetColumnFamily(column_family_name) !=</a>
<a name="ln4384">        nullptr) {</a>
<a name="ln4385">      return STATUS(InvalidArgument, &quot;Column family already exists&quot;);</a>
<a name="ln4386">    }</a>
<a name="ln4387">    VersionEdit edit;</a>
<a name="ln4388">    edit.AddColumnFamily(column_family_name);</a>
<a name="ln4389">    uint32_t new_id = versions_-&gt;GetColumnFamilySet()-&gt;GetNextColumnFamilyID();</a>
<a name="ln4390">    edit.SetColumnFamily(new_id);</a>
<a name="ln4391">    edit.SetLogNumber(logfile_number_);</a>
<a name="ln4392">    edit.SetComparatorName(cf_options.comparator-&gt;Name());</a>
<a name="ln4393"> </a>
<a name="ln4394">    // LogAndApply will both write the creation in MANIFEST and create</a>
<a name="ln4395">    // ColumnFamilyData object</a>
<a name="ln4396">    Options opt(db_options_, cf_options);</a>
<a name="ln4397">    {  // write thread</a>
<a name="ln4398">      WriteThread::Writer w;</a>
<a name="ln4399">      write_thread_.EnterUnbatched(&amp;w, &amp;mutex_);</a>
<a name="ln4400">      // LogAndApply will both write the creation in MANIFEST and create</a>
<a name="ln4401">      // ColumnFamilyData object</a>
<a name="ln4402">      s = versions_-&gt;LogAndApply(</a>
<a name="ln4403">          nullptr, MutableCFOptions(opt, ImmutableCFOptions(opt)), &amp;edit,</a>
<a name="ln4404">          &amp;mutex_, directories_.GetDbDir(), false, &amp;cf_options);</a>
<a name="ln4405"> </a>
<a name="ln4406">      if (s.ok()) {</a>
<a name="ln4407">        // If the column family was created successfully, we then persist</a>
<a name="ln4408">        // the updated RocksDB options under the same single write thread</a>
<a name="ln4409">        persist_options_status = WriteOptionsFile();</a>
<a name="ln4410">      }</a>
<a name="ln4411">      write_thread_.ExitUnbatched(&amp;w);</a>
<a name="ln4412">    }</a>
<a name="ln4413">    if (s.ok()) {</a>
<a name="ln4414">      single_column_family_mode_ = false;</a>
<a name="ln4415">      auto* cfd =</a>
<a name="ln4416">          versions_-&gt;GetColumnFamilySet()-&gt;GetColumnFamily(column_family_name);</a>
<a name="ln4417">      assert(cfd != nullptr);</a>
<a name="ln4418">      InstallSuperVersionAndScheduleWork(cfd, nullptr, *cfd-&gt;GetLatestMutableCFOptions());</a>
<a name="ln4419"> </a>
<a name="ln4420">      if (!cfd-&gt;mem()-&gt;IsSnapshotSupported()) {</a>
<a name="ln4421">        is_snapshot_supported_ = false;</a>
<a name="ln4422">      }</a>
<a name="ln4423"> </a>
<a name="ln4424">      *handle = new ColumnFamilyHandleImpl(cfd, this, &amp;mutex_);</a>
<a name="ln4425">      RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln4426">          &quot;Created column family [%s] (ID %u)&quot;,</a>
<a name="ln4427">          column_family_name.c_str(), (unsigned)cfd-&gt;GetID());</a>
<a name="ln4428">    } else {</a>
<a name="ln4429">      RLOG(InfoLogLevel::ERROR_LEVEL, db_options_.info_log,</a>
<a name="ln4430">          &quot;Creating column family [%s] FAILED -- %s&quot;,</a>
<a name="ln4431">          column_family_name.c_str(), s.ToString().c_str());</a>
<a name="ln4432">    }</a>
<a name="ln4433">  }  // InstrumentedMutexLock l(&amp;mutex_)</a>
<a name="ln4434"> </a>
<a name="ln4435">  // this is outside the mutex</a>
<a name="ln4436">  if (s.ok()) {</a>
<a name="ln4437">    NewThreadStatusCfInfo(down_cast&lt;ColumnFamilyHandleImpl*&gt;(*handle)-&gt;cfd());</a>
<a name="ln4438">    if (!persist_options_status.ok()) {</a>
<a name="ln4439">      if (db_options_.fail_if_options_file_error) {</a>
<a name="ln4440">        s = STATUS(IOError,</a>
<a name="ln4441">            &quot;ColumnFamily has been created, but unable to persist&quot;</a>
<a name="ln4442">            &quot;options in CreateColumnFamily()&quot;,</a>
<a name="ln4443">            persist_options_status.ToString().c_str());</a>
<a name="ln4444">      }</a>
<a name="ln4445">      RWARN(db_options_.info_log,</a>
<a name="ln4446">          &quot;Unable to persist options in CreateColumnFamily() -- %s&quot;,</a>
<a name="ln4447">          persist_options_status.ToString().c_str());</a>
<a name="ln4448">    }</a>
<a name="ln4449">  }</a>
<a name="ln4450">  return s;</a>
<a name="ln4451">}</a>
<a name="ln4452"> </a>
<a name="ln4453">Status DBImpl::DropColumnFamily(ColumnFamilyHandle* column_family) {</a>
<a name="ln4454">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln4455">  auto cfd = cfh-&gt;cfd();</a>
<a name="ln4456">  if (cfd-&gt;GetID() == 0) {</a>
<a name="ln4457">    return STATUS(InvalidArgument, &quot;Can't drop default column family&quot;);</a>
<a name="ln4458">  }</a>
<a name="ln4459"> </a>
<a name="ln4460">  bool cf_support_snapshot = cfd-&gt;mem()-&gt;IsSnapshotSupported();</a>
<a name="ln4461"> </a>
<a name="ln4462">  VersionEdit edit;</a>
<a name="ln4463">  edit.DropColumnFamily();</a>
<a name="ln4464">  edit.SetColumnFamily(cfd-&gt;GetID());</a>
<a name="ln4465"> </a>
<a name="ln4466">  Status s;</a>
<a name="ln4467">  Status options_persist_status;</a>
<a name="ln4468">  {</a>
<a name="ln4469">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln4470">    if (cfd-&gt;IsDropped()) {</a>
<a name="ln4471">      s = STATUS(InvalidArgument, &quot;Column family already dropped!\n&quot;);</a>
<a name="ln4472">    }</a>
<a name="ln4473">    if (s.ok()) {</a>
<a name="ln4474">      // we drop column family from a single write thread</a>
<a name="ln4475">      WriteThread::Writer w;</a>
<a name="ln4476">      write_thread_.EnterUnbatched(&amp;w, &amp;mutex_);</a>
<a name="ln4477">      s = versions_-&gt;LogAndApply(cfd, *cfd-&gt;GetLatestMutableCFOptions(),</a>
<a name="ln4478">                                 &amp;edit, &amp;mutex_);</a>
<a name="ln4479">      if (s.ok()) {</a>
<a name="ln4480">        // If the column family was dropped successfully, we then persist</a>
<a name="ln4481">        // the updated RocksDB options under the same single write thread</a>
<a name="ln4482">        options_persist_status = WriteOptionsFile();</a>
<a name="ln4483">      }</a>
<a name="ln4484">      write_thread_.ExitUnbatched(&amp;w);</a>
<a name="ln4485">    }</a>
<a name="ln4486"> </a>
<a name="ln4487">    if (!cf_support_snapshot) {</a>
<a name="ln4488">      // Dropped Column Family doesn't support snapshot. Need to recalculate</a>
<a name="ln4489">      // is_snapshot_supported_.</a>
<a name="ln4490">      bool new_is_snapshot_supported = true;</a>
<a name="ln4491">      for (auto c : *versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln4492">        if (!c-&gt;IsDropped() &amp;&amp; !c-&gt;mem()-&gt;IsSnapshotSupported()) {</a>
<a name="ln4493">          new_is_snapshot_supported = false;</a>
<a name="ln4494">          break;</a>
<a name="ln4495">        }</a>
<a name="ln4496">      }</a>
<a name="ln4497">      is_snapshot_supported_ = new_is_snapshot_supported;</a>
<a name="ln4498">    }</a>
<a name="ln4499">  }</a>
<a name="ln4500"> </a>
<a name="ln4501">  if (s.ok()) {</a>
<a name="ln4502">    // Note that here we erase the associated cf_info of the to-be-dropped</a>
<a name="ln4503">    // cfd before its ref-count goes to zero to avoid having to erase cf_info</a>
<a name="ln4504">    // later inside db_mutex.</a>
<a name="ln4505">    EraseThreadStatusCfInfo(cfd);</a>
<a name="ln4506">    assert(cfd-&gt;IsDropped());</a>
<a name="ln4507">    auto* mutable_cf_options = cfd-&gt;GetLatestMutableCFOptions();</a>
<a name="ln4508">    max_total_in_memory_state_ -= mutable_cf_options-&gt;write_buffer_size *</a>
<a name="ln4509">                                  mutable_cf_options-&gt;max_write_buffer_number;</a>
<a name="ln4510">    RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln4511">        &quot;Dropped column family with id %u\n&quot;, cfd-&gt;GetID());</a>
<a name="ln4512"> </a>
<a name="ln4513">    if (!options_persist_status.ok()) {</a>
<a name="ln4514">      if (db_options_.fail_if_options_file_error) {</a>
<a name="ln4515">        s = STATUS(IOError,</a>
<a name="ln4516">            &quot;ColumnFamily has been dropped, but unable to persist &quot;</a>
<a name="ln4517">            &quot;options in DropColumnFamily()&quot;,</a>
<a name="ln4518">            options_persist_status.ToString().c_str());</a>
<a name="ln4519">      }</a>
<a name="ln4520">      RWARN(db_options_.info_log,</a>
<a name="ln4521">          &quot;Unable to persist options in DropColumnFamily() -- %s&quot;,</a>
<a name="ln4522">          options_persist_status.ToString().c_str());</a>
<a name="ln4523">    }</a>
<a name="ln4524">  } else {</a>
<a name="ln4525">    RLOG(InfoLogLevel::ERROR_LEVEL, db_options_.info_log,</a>
<a name="ln4526">        &quot;Dropping column family with id %u FAILED -- %s\n&quot;,</a>
<a name="ln4527">        cfd-&gt;GetID(), s.ToString().c_str());</a>
<a name="ln4528">  }</a>
<a name="ln4529"> </a>
<a name="ln4530">  return s;</a>
<a name="ln4531">}</a>
<a name="ln4532"> </a>
<a name="ln4533">bool DBImpl::KeyMayExist(const ReadOptions&amp; read_options,</a>
<a name="ln4534">                         ColumnFamilyHandle* column_family, const Slice&amp; key,</a>
<a name="ln4535">                         std::string* value, bool* value_found) {</a>
<a name="ln4536">  if (value_found != nullptr) {</a>
<a name="ln4537">    // falsify later if key-may-exist but can't fetch value</a>
<a name="ln4538">    *value_found = true;</a>
<a name="ln4539">  }</a>
<a name="ln4540">  ReadOptions roptions = read_options;</a>
<a name="ln4541">  roptions.read_tier = kBlockCacheTier; // read from block cache only</a>
<a name="ln4542">  auto s = GetImpl(roptions, column_family, key, value, value_found);</a>
<a name="ln4543"> </a>
<a name="ln4544">  // If block_cache is enabled and the index block of the table was</a>
<a name="ln4545">  // not present in block_cache, the return value will be Status::Incomplete.</a>
<a name="ln4546">  // In this case, key may still exist in the table.</a>
<a name="ln4547">  return s.ok() || s.IsIncomplete();</a>
<a name="ln4548">}</a>
<a name="ln4549"> </a>
<a name="ln4550">Iterator* DBImpl::NewIterator(const ReadOptions&amp; read_options,</a>
<a name="ln4551">                              ColumnFamilyHandle* column_family) {</a>
<a name="ln4552">  if (read_options.read_tier == kPersistedTier) {</a>
<a name="ln4553">    return NewErrorIterator(STATUS(NotSupported,</a>
<a name="ln4554">        &quot;ReadTier::kPersistedData is not yet supported in iterators.&quot;));</a>
<a name="ln4555">  }</a>
<a name="ln4556">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln4557">  auto cfd = cfh-&gt;cfd();</a>
<a name="ln4558"> </a>
<a name="ln4559">  XFUNC_TEST(&quot;&quot;, &quot;managed_new&quot;, managed_new1, xf_manage_new,</a>
<a name="ln4560">             reinterpret_cast&lt;DBImpl*&gt;(this),</a>
<a name="ln4561">             const_cast&lt;ReadOptions*&gt;(&amp;read_options), is_snapshot_supported_);</a>
<a name="ln4562">  if (read_options.managed) {</a>
<a name="ln4563">#ifdef ROCKSDB_LITE</a>
<a name="ln4564">    // not supported in lite version</a>
<a name="ln4565">    return NewErrorIterator(STATUS(InvalidArgument,</a>
<a name="ln4566">        &quot;Managed Iterators not supported in RocksDBLite.&quot;));</a>
<a name="ln4567">#else</a>
<a name="ln4568">    if ((read_options.tailing) || (read_options.snapshot != nullptr) ||</a>
<a name="ln4569">        (is_snapshot_supported_)) {</a>
<a name="ln4570">      return new ManagedIterator(this, read_options, cfd);</a>
<a name="ln4571">    }</a>
<a name="ln4572">    // Managed iter not supported</a>
<a name="ln4573">    return NewErrorIterator(STATUS(InvalidArgument,</a>
<a name="ln4574">        &quot;Managed Iterators not supported without snapshots.&quot;));</a>
<a name="ln4575">#endif</a>
<a name="ln4576">  } else if (read_options.tailing) {</a>
<a name="ln4577">#ifdef ROCKSDB_LITE</a>
<a name="ln4578">    // not supported in lite version</a>
<a name="ln4579">    return nullptr;</a>
<a name="ln4580">#else</a>
<a name="ln4581">    SuperVersion* sv = cfd-&gt;GetReferencedSuperVersion(&amp;mutex_);</a>
<a name="ln4582">    auto iter = new ForwardIterator(this, read_options, cfd, sv);</a>
<a name="ln4583">    return NewDBIterator(</a>
<a name="ln4584">        env_, *cfd-&gt;ioptions(), cfd-&gt;user_comparator(), iter,</a>
<a name="ln4585">        kMaxSequenceNumber,</a>
<a name="ln4586">        sv-&gt;mutable_cf_options.max_sequential_skip_in_iterations,</a>
<a name="ln4587">        sv-&gt;version_number, read_options.iterate_upper_bound,</a>
<a name="ln4588">        read_options.prefix_same_as_start, read_options.pin_data);</a>
<a name="ln4589">#endif</a>
<a name="ln4590">  } else {</a>
<a name="ln4591">    SequenceNumber latest_snapshot = versions_-&gt;LastSequence();</a>
<a name="ln4592">    SuperVersion* sv = cfd-&gt;GetReferencedSuperVersion(&amp;mutex_);</a>
<a name="ln4593"> </a>
<a name="ln4594">    auto snapshot =</a>
<a name="ln4595">        read_options.snapshot != nullptr</a>
<a name="ln4596">            ? reinterpret_cast&lt;const SnapshotImpl*&gt;(</a>
<a name="ln4597">                read_options.snapshot)-&gt;number_</a>
<a name="ln4598">            : latest_snapshot;</a>
<a name="ln4599"> </a>
<a name="ln4600">    // Try to generate a DB iterator tree in continuous memory area to be</a>
<a name="ln4601">    // cache friendly. Here is an example of result:</a>
<a name="ln4602">    // +-------------------------------+</a>
<a name="ln4603">    // |                               |</a>
<a name="ln4604">    // | ArenaWrappedDBIter            |</a>
<a name="ln4605">    // |  +                            |</a>
<a name="ln4606">    // |  +---&gt; Inner Iterator   ------------+</a>
<a name="ln4607">    // |  |                            |     |</a>
<a name="ln4608">    // |  |    +-- -- -- -- -- -- -- --+     |</a>
<a name="ln4609">    // |  +--- | Arena                 |     |</a>
<a name="ln4610">    // |       |                       |     |</a>
<a name="ln4611">    // |          Allocated Memory:    |     |</a>
<a name="ln4612">    // |       |   +-------------------+     |</a>
<a name="ln4613">    // |       |   | DBIter            | &lt;---+</a>
<a name="ln4614">    // |           |  +                |</a>
<a name="ln4615">    // |       |   |  +-&gt; iter_  ------------+</a>
<a name="ln4616">    // |       |   |                   |     |</a>
<a name="ln4617">    // |       |   +-------------------+     |</a>
<a name="ln4618">    // |       |   | MergingIterator   | &lt;---+</a>
<a name="ln4619">    // |           |  +                |</a>
<a name="ln4620">    // |       |   |  +-&gt;child iter1  ------------+</a>
<a name="ln4621">    // |       |   |  |                |          |</a>
<a name="ln4622">    // |           |  +-&gt;child iter2  ----------+ |</a>
<a name="ln4623">    // |       |   |  |                |        | |</a>
<a name="ln4624">    // |       |   |  +-&gt;child iter3  --------+ | |</a>
<a name="ln4625">    // |           |                   |      | | |</a>
<a name="ln4626">    // |       |   +-------------------+      | | |</a>
<a name="ln4627">    // |       |   | Iterator1         | &lt;--------+</a>
<a name="ln4628">    // |       |   +-------------------+      | |</a>
<a name="ln4629">    // |       |   | Iterator2         | &lt;------+</a>
<a name="ln4630">    // |       |   +-------------------+      |</a>
<a name="ln4631">    // |       |   | Iterator3         | &lt;----+</a>
<a name="ln4632">    // |       |   +-------------------+</a>
<a name="ln4633">    // |       |                       |</a>
<a name="ln4634">    // +-------+-----------------------+</a>
<a name="ln4635">    //</a>
<a name="ln4636">    // ArenaWrappedDBIter inlines an arena area where all the iterators in</a>
<a name="ln4637">    // the iterator tree are allocated in the order of being accessed when</a>
<a name="ln4638">    // querying.</a>
<a name="ln4639">    // Laying out the iterators in the order of being accessed makes it more</a>
<a name="ln4640">    // likely that any iterator pointer is close to the iterator it points to so</a>
<a name="ln4641">    // that they are likely to be in the same cache line and/or page.</a>
<a name="ln4642">    ArenaWrappedDBIter* db_iter = NewArenaWrappedDbIterator(</a>
<a name="ln4643">        env_, *cfd-&gt;ioptions(), cfd-&gt;user_comparator(), snapshot,</a>
<a name="ln4644">        sv-&gt;mutable_cf_options.max_sequential_skip_in_iterations,</a>
<a name="ln4645">        sv-&gt;version_number, read_options.iterate_upper_bound,</a>
<a name="ln4646">        read_options.prefix_same_as_start, read_options.pin_data);</a>
<a name="ln4647"> </a>
<a name="ln4648">    InternalIterator* internal_iter =</a>
<a name="ln4649">        NewInternalIterator(read_options, cfd, sv, db_iter-&gt;GetArena());</a>
<a name="ln4650">    db_iter-&gt;SetIterUnderDBIter(internal_iter);</a>
<a name="ln4651"> </a>
<a name="ln4652">    if (yb::GetAtomicFlag(&amp;FLAGS_rocksdb_use_logging_iterator)) {</a>
<a name="ln4653">      return new TransitionLoggingIteratorWrapper(db_iter, LogPrefix());</a>
<a name="ln4654">    }</a>
<a name="ln4655">    return db_iter;</a>
<a name="ln4656">  }</a>
<a name="ln4657">  // To stop compiler from complaining</a>
<a name="ln4658">  return nullptr;</a>
<a name="ln4659">}</a>
<a name="ln4660"> </a>
<a name="ln4661">Status DBImpl::NewIterators(</a>
<a name="ln4662">    const ReadOptions&amp; read_options,</a>
<a name="ln4663">    const std::vector&lt;ColumnFamilyHandle*&gt;&amp; column_families,</a>
<a name="ln4664">    std::vector&lt;Iterator*&gt;* iterators) {</a>
<a name="ln4665">  if (read_options.read_tier == kPersistedTier) {</a>
<a name="ln4666">    return STATUS(NotSupported,</a>
<a name="ln4667">        &quot;ReadTier::kPersistedData is not yet supported in iterators.&quot;);</a>
<a name="ln4668">  }</a>
<a name="ln4669">  iterators-&gt;clear();</a>
<a name="ln4670">  iterators-&gt;reserve(column_families.size());</a>
<a name="ln4671">  XFUNC_TEST(&quot;&quot;, &quot;managed_new&quot;, managed_new1, xf_manage_new,</a>
<a name="ln4672">             reinterpret_cast&lt;DBImpl*&gt;(this),</a>
<a name="ln4673">             const_cast&lt;ReadOptions*&gt;(&amp;read_options), is_snapshot_supported_);</a>
<a name="ln4674">  if (read_options.managed) {</a>
<a name="ln4675">#ifdef ROCKSDB_LITE</a>
<a name="ln4676">    return STATUS(InvalidArgument,</a>
<a name="ln4677">        &quot;Managed interator not supported in RocksDB lite&quot;);</a>
<a name="ln4678">#else</a>
<a name="ln4679">    if ((!read_options.tailing) &amp;&amp; (read_options.snapshot == nullptr) &amp;&amp;</a>
<a name="ln4680">        (!is_snapshot_supported_)) {</a>
<a name="ln4681">      return STATUS(InvalidArgument,</a>
<a name="ln4682">          &quot;Managed interator not supported without snapshots&quot;);</a>
<a name="ln4683">    }</a>
<a name="ln4684">    for (auto cfh : column_families) {</a>
<a name="ln4685">      auto cfd = down_cast&lt;ColumnFamilyHandleImpl*&gt;(cfh)-&gt;cfd();</a>
<a name="ln4686">      auto iter = new ManagedIterator(this, read_options, cfd);</a>
<a name="ln4687">      iterators-&gt;push_back(iter);</a>
<a name="ln4688">    }</a>
<a name="ln4689">#endif</a>
<a name="ln4690">  } else if (read_options.tailing) {</a>
<a name="ln4691">#ifdef ROCKSDB_LITE</a>
<a name="ln4692">    return STATUS(InvalidArgument,</a>
<a name="ln4693">        &quot;Tailing interator not supported in RocksDB lite&quot;);</a>
<a name="ln4694">#else</a>
<a name="ln4695">    for (auto cfh : column_families) {</a>
<a name="ln4696">      auto cfd = down_cast&lt;ColumnFamilyHandleImpl*&gt;(cfh)-&gt;cfd();</a>
<a name="ln4697">      SuperVersion* sv = cfd-&gt;GetReferencedSuperVersion(&amp;mutex_);</a>
<a name="ln4698">      auto iter = new ForwardIterator(this, read_options, cfd, sv);</a>
<a name="ln4699">      iterators-&gt;push_back(NewDBIterator(</a>
<a name="ln4700">          env_, *cfd-&gt;ioptions(), cfd-&gt;user_comparator(), iter,</a>
<a name="ln4701">          kMaxSequenceNumber,</a>
<a name="ln4702">          sv-&gt;mutable_cf_options.max_sequential_skip_in_iterations,</a>
<a name="ln4703">          sv-&gt;version_number, nullptr, false, read_options.pin_data));</a>
<a name="ln4704">    }</a>
<a name="ln4705">#endif</a>
<a name="ln4706">  } else {</a>
<a name="ln4707">    SequenceNumber latest_snapshot = versions_-&gt;LastSequence();</a>
<a name="ln4708"> </a>
<a name="ln4709">    for (size_t i = 0; i &lt; column_families.size(); ++i) {</a>
<a name="ln4710">      auto* cfd = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_families[i])-&gt;cfd();</a>
<a name="ln4711">      SuperVersion* sv = cfd-&gt;GetReferencedSuperVersion(&amp;mutex_);</a>
<a name="ln4712"> </a>
<a name="ln4713">      auto snapshot =</a>
<a name="ln4714">          read_options.snapshot != nullptr</a>
<a name="ln4715">              ? reinterpret_cast&lt;const SnapshotImpl*&gt;(</a>
<a name="ln4716">                  read_options.snapshot)-&gt;number_</a>
<a name="ln4717">              : latest_snapshot;</a>
<a name="ln4718"> </a>
<a name="ln4719">      ArenaWrappedDBIter* db_iter = NewArenaWrappedDbIterator(</a>
<a name="ln4720">          env_, *cfd-&gt;ioptions(), cfd-&gt;user_comparator(), snapshot,</a>
<a name="ln4721">          sv-&gt;mutable_cf_options.max_sequential_skip_in_iterations,</a>
<a name="ln4722">          sv-&gt;version_number, nullptr, false, read_options.pin_data);</a>
<a name="ln4723">      InternalIterator* internal_iter =</a>
<a name="ln4724">          NewInternalIterator(read_options, cfd, sv, db_iter-&gt;GetArena());</a>
<a name="ln4725">      db_iter-&gt;SetIterUnderDBIter(internal_iter);</a>
<a name="ln4726">      iterators-&gt;push_back(db_iter);</a>
<a name="ln4727">    }</a>
<a name="ln4728">  }</a>
<a name="ln4729"> </a>
<a name="ln4730">  return Status::OK();</a>
<a name="ln4731">}</a>
<a name="ln4732"> </a>
<a name="ln4733">const Snapshot* DBImpl::GetSnapshot() { return GetSnapshotImpl(false); }</a>
<a name="ln4734"> </a>
<a name="ln4735">#ifndef ROCKSDB_LITE</a>
<a name="ln4736">const Snapshot* DBImpl::GetSnapshotForWriteConflictBoundary() {</a>
<a name="ln4737">  return GetSnapshotImpl(true);</a>
<a name="ln4738">}</a>
<a name="ln4739">#endif  // ROCKSDB_LITE</a>
<a name="ln4740"> </a>
<a name="ln4741">const Snapshot* DBImpl::GetSnapshotImpl(bool is_write_conflict_boundary) {</a>
<a name="ln4742">  int64_t unix_time = 0;</a>
<a name="ln4743">  WARN_NOT_OK(env_-&gt;GetCurrentTime(&amp;unix_time), &quot;Failed to get current time&quot;);</a>
<a name="ln4744">  SnapshotImpl* s = new SnapshotImpl;</a>
<a name="ln4745"> </a>
<a name="ln4746">  InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln4747">  // returns null if the underlying memtable does not support snapshot.</a>
<a name="ln4748">  if (!is_snapshot_supported_) {</a>
<a name="ln4749">    delete s;</a>
<a name="ln4750">    return nullptr;</a>
<a name="ln4751">  }</a>
<a name="ln4752">  return snapshots_.New(s, versions_-&gt;LastSequence(), unix_time,</a>
<a name="ln4753">                        is_write_conflict_boundary);</a>
<a name="ln4754">}</a>
<a name="ln4755"> </a>
<a name="ln4756">void DBImpl::ReleaseSnapshot(const Snapshot* s) {</a>
<a name="ln4757">  const SnapshotImpl* casted_s = reinterpret_cast&lt;const SnapshotImpl*&gt;(s);</a>
<a name="ln4758">  {</a>
<a name="ln4759">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln4760">    snapshots_.Delete(casted_s);</a>
<a name="ln4761">  }</a>
<a name="ln4762">  delete casted_s;</a>
<a name="ln4763">}</a>
<a name="ln4764"> </a>
<a name="ln4765">// Convenience methods</a>
<a name="ln4766">Status DBImpl::Put(const WriteOptions&amp; o, ColumnFamilyHandle* column_family,</a>
<a name="ln4767">                   const Slice&amp; key, const Slice&amp; val) {</a>
<a name="ln4768">  return DB::Put(o, column_family, key, val);</a>
<a name="ln4769">}</a>
<a name="ln4770"> </a>
<a name="ln4771">Status DBImpl::Merge(const WriteOptions&amp; o, ColumnFamilyHandle* column_family,</a>
<a name="ln4772">                     const Slice&amp; key, const Slice&amp; val) {</a>
<a name="ln4773">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln4774">  if (!cfh-&gt;cfd()-&gt;ioptions()-&gt;merge_operator) {</a>
<a name="ln4775">    return STATUS(NotSupported, &quot;Provide a merge_operator when opening DB&quot;);</a>
<a name="ln4776">  } else {</a>
<a name="ln4777">    return DB::Merge(o, column_family, key, val);</a>
<a name="ln4778">  }</a>
<a name="ln4779">}</a>
<a name="ln4780"> </a>
<a name="ln4781">Status DBImpl::Delete(const WriteOptions&amp; write_options,</a>
<a name="ln4782">                      ColumnFamilyHandle* column_family, const Slice&amp; key) {</a>
<a name="ln4783">  return DB::Delete(write_options, column_family, key);</a>
<a name="ln4784">}</a>
<a name="ln4785"> </a>
<a name="ln4786">Status DBImpl::SingleDelete(const WriteOptions&amp; write_options,</a>
<a name="ln4787">                            ColumnFamilyHandle* column_family,</a>
<a name="ln4788">                            const Slice&amp; key) {</a>
<a name="ln4789">  return DB::SingleDelete(write_options, column_family, key);</a>
<a name="ln4790">}</a>
<a name="ln4791"> </a>
<a name="ln4792">Status DBImpl::Write(const WriteOptions&amp; write_options, WriteBatch* my_batch) {</a>
<a name="ln4793">  return WriteImpl(write_options, my_batch, nullptr);</a>
<a name="ln4794">}</a>
<a name="ln4795"> </a>
<a name="ln4796">#ifndef ROCKSDB_LITE</a>
<a name="ln4797">Status DBImpl::WriteWithCallback(const WriteOptions&amp; write_options,</a>
<a name="ln4798">                                 WriteBatch* my_batch,</a>
<a name="ln4799">                                 WriteCallback* callback) {</a>
<a name="ln4800">  return WriteImpl(write_options, my_batch, callback);</a>
<a name="ln4801">}</a>
<a name="ln4802">#endif  // ROCKSDB_LITE</a>
<a name="ln4803"> </a>
<a name="ln4804">Status DBImpl::WriteImpl(const WriteOptions&amp; write_options,</a>
<a name="ln4805">                         WriteBatch* my_batch, WriteCallback* callback) {</a>
<a name="ln4806"> </a>
<a name="ln4807">  if (my_batch == nullptr) {</a>
<a name="ln4808">    return STATUS(Corruption, &quot;Batch is nullptr!&quot;);</a>
<a name="ln4809">  }</a>
<a name="ln4810">  if (write_options.timeout_hint_us != 0) {</a>
<a name="ln4811">    return STATUS(InvalidArgument, &quot;timeout_hint_us is deprecated&quot;);</a>
<a name="ln4812">  }</a>
<a name="ln4813"> </a>
<a name="ln4814">  Status status;</a>
<a name="ln4815"> </a>
<a name="ln4816">  bool xfunc_attempted_write = false;</a>
<a name="ln4817">  XFUNC_TEST(&quot;transaction&quot;, &quot;transaction_xftest_write_impl&quot;,</a>
<a name="ln4818">             xf_transaction_write1, xf_transaction_write, write_options,</a>
<a name="ln4819">             db_options_, my_batch, callback, this, &amp;status,</a>
<a name="ln4820">             &amp;xfunc_attempted_write);</a>
<a name="ln4821">  if (xfunc_attempted_write) {</a>
<a name="ln4822">    // Test already did the write</a>
<a name="ln4823">    return status;</a>
<a name="ln4824">  }</a>
<a name="ln4825"> </a>
<a name="ln4826">  PERF_TIMER_GUARD(write_pre_and_post_process_time);</a>
<a name="ln4827">  WriteThread::Writer w;</a>
<a name="ln4828">  w.batch = my_batch;</a>
<a name="ln4829">  w.sync = write_options.sync;</a>
<a name="ln4830">  w.disableWAL = write_options.disableWAL;</a>
<a name="ln4831">  w.in_batch_group = false;</a>
<a name="ln4832">  w.callback = callback;</a>
<a name="ln4833"> </a>
<a name="ln4834">  if (!write_options.disableWAL) {</a>
<a name="ln4835">    RecordTick(stats_, WRITE_WITH_WAL);</a>
<a name="ln4836">  }</a>
<a name="ln4837"> </a>
<a name="ln4838">  StopWatch write_sw(env_, db_options_.statistics.get(), DB_WRITE);</a>
<a name="ln4839"> </a>
<a name="ln4840">#ifndef NDEBUG</a>
<a name="ln4841">  auto num_write_waiters = write_waiters_.fetch_add(1, std::memory_order_acq_rel);</a>
<a name="ln4842">#endif</a>
<a name="ln4843"> </a>
<a name="ln4844">  write_thread_.JoinBatchGroup(&amp;w);</a>
<a name="ln4845"> </a>
<a name="ln4846">#ifndef NDEBUG</a>
<a name="ln4847">  write_waiters_.fetch_sub(1, std::memory_order_acq_rel);</a>
<a name="ln4848">  DCHECK_LE(num_write_waiters, FLAGS_TEST_max_write_waiters);</a>
<a name="ln4849">#endif</a>
<a name="ln4850"> </a>
<a name="ln4851">  if (w.state == WriteThread::STATE_PARALLEL_FOLLOWER) {</a>
<a name="ln4852">    // we are a non-leader in a parallel group</a>
<a name="ln4853">    PERF_TIMER_GUARD(write_memtable_time);</a>
<a name="ln4854"> </a>
<a name="ln4855">    if (!w.CallbackFailed()) {</a>
<a name="ln4856">      ColumnFamilyMemTablesImpl column_family_memtables(</a>
<a name="ln4857">          versions_-&gt;GetColumnFamilySet());</a>
<a name="ln4858">      WriteBatchInternal::SetSequence(w.batch, w.sequence);</a>
<a name="ln4859">      InsertFlags insert_flags{InsertFlag::kConcurrentMemtableWrites};</a>
<a name="ln4860">      w.status = WriteBatchInternal::InsertInto(</a>
<a name="ln4861">          w.batch, &amp;column_family_memtables, &amp;flush_scheduler_,</a>
<a name="ln4862">          write_options.ignore_missing_column_families, 0 /*log_number*/, this, insert_flags);</a>
<a name="ln4863">    }</a>
<a name="ln4864"> </a>
<a name="ln4865">    if (write_thread_.CompleteParallelWorker(&amp;w)) {</a>
<a name="ln4866">      // we're responsible for early exit</a>
<a name="ln4867">      auto last_sequence = w.parallel_group-&gt;last_sequence;</a>
<a name="ln4868">      SetTickerCount(stats_, SEQUENCE_NUMBER, last_sequence);</a>
<a name="ln4869">      versions_-&gt;SetLastSequence(last_sequence);</a>
<a name="ln4870">      write_thread_.EarlyExitParallelGroup(&amp;w);</a>
<a name="ln4871">    }</a>
<a name="ln4872">    assert(w.state == WriteThread::STATE_COMPLETED);</a>
<a name="ln4873">    // STATE_COMPLETED conditional below handles exit</a>
<a name="ln4874"> </a>
<a name="ln4875">    status = w.FinalStatus();</a>
<a name="ln4876">  }</a>
<a name="ln4877">  if (w.state == WriteThread::STATE_COMPLETED) {</a>
<a name="ln4878">    // write is complete and leader has updated sequence</a>
<a name="ln4879">    RecordTick(stats_, WRITE_DONE_BY_OTHER);</a>
<a name="ln4880">    return w.FinalStatus();</a>
<a name="ln4881">  }</a>
<a name="ln4882">  // else we are the leader of the write batch group</a>
<a name="ln4883">  assert(w.state == WriteThread::STATE_GROUP_LEADER);</a>
<a name="ln4884"> </a>
<a name="ln4885">  WriteContext context;</a>
<a name="ln4886">  mutex_.Lock();</a>
<a name="ln4887"> </a>
<a name="ln4888">  if (!write_options.disableWAL) {</a>
<a name="ln4889">    default_cf_internal_stats_-&gt;AddDBStats(InternalDBStatsType::WRITE_WITH_WAL, 1);</a>
<a name="ln4890">  }</a>
<a name="ln4891"> </a>
<a name="ln4892">  RecordTick(stats_, WRITE_DONE_BY_SELF);</a>
<a name="ln4893">  default_cf_internal_stats_-&gt;AddDBStats(InternalDBStatsType::WRITE_DONE_BY_SELF, 1);</a>
<a name="ln4894"> </a>
<a name="ln4895">  // Once reaches this point, the current writer &quot;w&quot; will try to do its write</a>
<a name="ln4896">  // job.  It may also pick up some of the remaining writers in the &quot;writers_&quot;</a>
<a name="ln4897">  // when it finds suitable, and finish them in the same write batch.</a>
<a name="ln4898">  // This is how a write job could be done by the other writer.</a>
<a name="ln4899">  assert(!single_column_family_mode_ ||</a>
<a name="ln4900">         versions_-&gt;GetColumnFamilySet()-&gt;NumberOfColumnFamilies() == 1);</a>
<a name="ln4901"> </a>
<a name="ln4902">  uint64_t max_total_wal_size = (db_options_.max_total_wal_size == 0)</a>
<a name="ln4903">                                    ? 4 * max_total_in_memory_state_</a>
<a name="ln4904">                                    : db_options_.max_total_wal_size;</a>
<a name="ln4905">  if (UNLIKELY(!single_column_family_mode_ &amp;&amp;</a>
<a name="ln4906">               alive_log_files_.begin()-&gt;getting_flushed == false &amp;&amp;</a>
<a name="ln4907">               total_log_size() &gt; max_total_wal_size)) {</a>
<a name="ln4908">    uint64_t flush_column_family_if_log_file = alive_log_files_.begin()-&gt;number;</a>
<a name="ln4909">    alive_log_files_.begin()-&gt;getting_flushed = true;</a>
<a name="ln4910">    RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln4911">        &quot;Flushing all column families with data in WAL number %&quot; PRIu64</a>
<a name="ln4912">        &quot;. Total log size is %&quot; PRIu64 &quot; while max_total_wal_size is %&quot; PRIu64,</a>
<a name="ln4913">        flush_column_family_if_log_file, total_log_size(), max_total_wal_size);</a>
<a name="ln4914">    // no need to refcount because drop is happening in write thread, so can't</a>
<a name="ln4915">    // happen while we're in the write thread</a>
<a name="ln4916">    for (auto cfd : *versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln4917">      if (cfd-&gt;IsDropped()) {</a>
<a name="ln4918">        continue;</a>
<a name="ln4919">      }</a>
<a name="ln4920">      if (cfd-&gt;GetLogNumber() &lt;= flush_column_family_if_log_file) {</a>
<a name="ln4921">        status = SwitchMemtable(cfd, &amp;context);</a>
<a name="ln4922">        if (!status.ok()) {</a>
<a name="ln4923">          break;</a>
<a name="ln4924">        }</a>
<a name="ln4925">        cfd-&gt;imm()-&gt;FlushRequested();</a>
<a name="ln4926">        SchedulePendingFlush(cfd);</a>
<a name="ln4927">      }</a>
<a name="ln4928">    }</a>
<a name="ln4929">    MaybeScheduleFlushOrCompaction();</a>
<a name="ln4930">  } else if (UNLIKELY(write_buffer_.ShouldFlush())) {</a>
<a name="ln4931">    RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln4932">        &quot;Flushing column family with largest mem table size. Write buffer is &quot;</a>
<a name="ln4933">        &quot;using %&quot; PRIu64 &quot; bytes out of a total of %&quot; PRIu64 &quot;.&quot;,</a>
<a name="ln4934">        write_buffer_.memory_usage(), write_buffer_.buffer_size());</a>
<a name="ln4935">    // no need to refcount because drop is happening in write thread, so can't</a>
<a name="ln4936">    // happen while we're in the write thread</a>
<a name="ln4937">    ColumnFamilyData* largest_cfd = nullptr;</a>
<a name="ln4938">    size_t largest_cfd_size = 0;</a>
<a name="ln4939"> </a>
<a name="ln4940">    for (auto cfd : *versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln4941">      if (cfd-&gt;IsDropped()) {</a>
<a name="ln4942">        continue;</a>
<a name="ln4943">      }</a>
<a name="ln4944">      if (!cfd-&gt;mem()-&gt;IsEmpty()) {</a>
<a name="ln4945">        // We only consider active mem table, hoping immutable memtable is</a>
<a name="ln4946">        // already in the process of flushing.</a>
<a name="ln4947">        size_t cfd_size = cfd-&gt;mem()-&gt;ApproximateMemoryUsage();</a>
<a name="ln4948">        if (largest_cfd == nullptr || cfd_size &gt; largest_cfd_size) {</a>
<a name="ln4949">          largest_cfd = cfd;</a>
<a name="ln4950">          largest_cfd_size = cfd_size;</a>
<a name="ln4951">        }</a>
<a name="ln4952">      }</a>
<a name="ln4953">    }</a>
<a name="ln4954">    if (largest_cfd != nullptr) {</a>
<a name="ln4955">      status = SwitchMemtable(largest_cfd, &amp;context);</a>
<a name="ln4956">      if (status.ok()) {</a>
<a name="ln4957">        largest_cfd-&gt;imm()-&gt;FlushRequested();</a>
<a name="ln4958">        SchedulePendingFlush(largest_cfd);</a>
<a name="ln4959">        MaybeScheduleFlushOrCompaction();</a>
<a name="ln4960">      }</a>
<a name="ln4961">    }</a>
<a name="ln4962">  }</a>
<a name="ln4963"> </a>
<a name="ln4964">  if (UNLIKELY(status.ok() &amp;&amp; !bg_error_.ok())) {</a>
<a name="ln4965">    status = bg_error_;</a>
<a name="ln4966">  }</a>
<a name="ln4967"> </a>
<a name="ln4968">  if (UNLIKELY(status.ok() &amp;&amp; !flush_scheduler_.Empty())) {</a>
<a name="ln4969">    status = ScheduleFlushes(&amp;context);</a>
<a name="ln4970">  }</a>
<a name="ln4971"> </a>
<a name="ln4972">  if (UNLIKELY(status.ok() &amp;&amp; (write_controller_.IsStopped() ||</a>
<a name="ln4973">                               write_controller_.NeedsDelay()))) {</a>
<a name="ln4974">    PERF_TIMER_STOP(write_pre_and_post_process_time);</a>
<a name="ln4975">    PERF_TIMER_GUARD(write_delay_time);</a>
<a name="ln4976">    // We don't know size of curent batch so that we always use the size</a>
<a name="ln4977">    // for previous one. It might create a fairness issue that expiration</a>
<a name="ln4978">    // might happen for smaller writes but larger writes can go through.</a>
<a name="ln4979">    // Can optimize it if it is an issue.</a>
<a name="ln4980">    status = DelayWrite(last_batch_group_size_);</a>
<a name="ln4981">    PERF_TIMER_START(write_pre_and_post_process_time);</a>
<a name="ln4982">  }</a>
<a name="ln4983"> </a>
<a name="ln4984">  uint64_t last_sequence = versions_-&gt;LastSequence();</a>
<a name="ln4985">  WriteThread::Writer* last_writer = &amp;w;</a>
<a name="ln4986">  autovector&lt;WriteThread::Writer*&gt; write_group;</a>
<a name="ln4987">  bool need_log_sync = !write_options.disableWAL &amp;&amp; write_options.sync;</a>
<a name="ln4988">  bool need_log_dir_sync = need_log_sync &amp;&amp; !log_dir_synced_;</a>
<a name="ln4989"> </a>
<a name="ln4990">  if (status.ok()) {</a>
<a name="ln4991">    if (need_log_sync) {</a>
<a name="ln4992">      while (logs_.front().getting_synced) {</a>
<a name="ln4993">        log_sync_cv_.Wait();</a>
<a name="ln4994">      }</a>
<a name="ln4995">      for (auto&amp; log : logs_) {</a>
<a name="ln4996">        assert(!log.getting_synced);</a>
<a name="ln4997">        log.getting_synced = true;</a>
<a name="ln4998">      }</a>
<a name="ln4999">    }</a>
<a name="ln5000"> </a>
<a name="ln5001">    // Add to log and apply to memtable.  We can release the lock</a>
<a name="ln5002">    // during this phase since &amp;w is currently responsible for logging</a>
<a name="ln5003">    // and protects against concurrent loggers and concurrent writes</a>
<a name="ln5004">    // into memtables</a>
<a name="ln5005">  }</a>
<a name="ln5006"> </a>
<a name="ln5007">  mutex_.Unlock();</a>
<a name="ln5008"> </a>
<a name="ln5009">  // At this point the mutex is unlocked</a>
<a name="ln5010"> </a>
<a name="ln5011">  bool exit_completed_early = false;</a>
<a name="ln5012">  last_batch_group_size_ =</a>
<a name="ln5013">      write_thread_.EnterAsBatchGroupLeader(&amp;w, &amp;last_writer, &amp;write_group);</a>
<a name="ln5014"> </a>
<a name="ln5015">  if (status.ok()) {</a>
<a name="ln5016">    // Rules for when we can update the memtable concurrently</a>
<a name="ln5017">    // 1. supported by memtable</a>
<a name="ln5018">    // 2. Puts are not okay if inplace_update_support</a>
<a name="ln5019">    // 3. Deletes or SingleDeletes are not okay if filtering deletes</a>
<a name="ln5020">    //    (controlled by both batch and memtable setting)</a>
<a name="ln5021">    // 4. Merges are not okay</a>
<a name="ln5022">    // 5. YugaByte-specific user-specified sequence numbers are currently not compatible with</a>
<a name="ln5023">    //    parallel memtable writes.</a>
<a name="ln5024">    //</a>
<a name="ln5025">    // Rules 1..3 are enforced by checking the options</a>
<a name="ln5026">    // during startup (CheckConcurrentWritesSupported), so if</a>
<a name="ln5027">    // options.allow_concurrent_memtable_write is true then they can be</a>
<a name="ln5028">    // assumed to be true.  Rule 4 is checked for each batch.  We could</a>
<a name="ln5029">    // relax rules 2 and 3 if we could prevent write batches from referring</a>
<a name="ln5030">    // more than once to a particular key.</a>
<a name="ln5031">    bool parallel =</a>
<a name="ln5032">        db_options_.allow_concurrent_memtable_write &amp;&amp; write_group.size() &gt; 1;</a>
<a name="ln5033">    size_t total_count = 0;</a>
<a name="ln5034">    uint64_t total_byte_size = 0;</a>
<a name="ln5035">    for (auto writer : write_group) {</a>
<a name="ln5036">      if (writer-&gt;CheckCallback(this)) {</a>
<a name="ln5037">        total_count += WriteBatchInternal::Count(writer-&gt;batch);</a>
<a name="ln5038">        total_byte_size = WriteBatchInternal::AppendedByteSize(</a>
<a name="ln5039">            total_byte_size, WriteBatchInternal::ByteSize(writer-&gt;batch));</a>
<a name="ln5040">        parallel = parallel &amp;&amp; !writer-&gt;batch-&gt;HasMerge();</a>
<a name="ln5041">      }</a>
<a name="ln5042">    }</a>
<a name="ln5043"> </a>
<a name="ln5044">    const SequenceNumber current_sequence = last_sequence + 1;</a>
<a name="ln5045"> </a>
<a name="ln5046">#ifndef NDEBUG</a>
<a name="ln5047">    if (current_sequence &lt;= last_sequence) {</a>
<a name="ln5048">      RLOG(InfoLogLevel::FATAL_LEVEL, db_options_.info_log,</a>
<a name="ln5049">        &quot;Current sequence number %&quot; PRIu64 &quot; is &lt;= last sequence number %&quot; PRIu64,</a>
<a name="ln5050">        current_sequence, last_sequence);</a>
<a name="ln5051">    }</a>
<a name="ln5052">#endif</a>
<a name="ln5053"> </a>
<a name="ln5054">    // Reserve sequence numbers for all individual updates in this batch group.</a>
<a name="ln5055">    last_sequence += total_count;</a>
<a name="ln5056"> </a>
<a name="ln5057">    // Record statistics</a>
<a name="ln5058">    RecordTick(stats_, NUMBER_KEYS_WRITTEN, total_count);</a>
<a name="ln5059">    RecordTick(stats_, BYTES_WRITTEN, total_byte_size);</a>
<a name="ln5060">    MeasureTime(stats_, BYTES_PER_WRITE, total_byte_size);</a>
<a name="ln5061">    PERF_TIMER_STOP(write_pre_and_post_process_time);</a>
<a name="ln5062"> </a>
<a name="ln5063">    if (write_options.disableWAL) {</a>
<a name="ln5064">      has_unpersisted_data_ = true;</a>
<a name="ln5065">    }</a>
<a name="ln5066"> </a>
<a name="ln5067">    uint64_t log_size = 0;</a>
<a name="ln5068">    if (!write_options.disableWAL) {</a>
<a name="ln5069">      PERF_TIMER_GUARD(write_wal_time);</a>
<a name="ln5070"> </a>
<a name="ln5071">      WriteBatch* merged_batch = nullptr;</a>
<a name="ln5072">      if (write_group.size() == 1 &amp;&amp; !write_group[0]-&gt;CallbackFailed()) {</a>
<a name="ln5073">        merged_batch = write_group[0]-&gt;batch;</a>
<a name="ln5074">      } else {</a>
<a name="ln5075">        // WAL needs all of the batches flattened into a single batch.</a>
<a name="ln5076">        // We could avoid copying here with an iov-like AddRecord</a>
<a name="ln5077">        // interface</a>
<a name="ln5078">        merged_batch = &amp;tmp_batch_;</a>
<a name="ln5079">        for (auto writer : write_group) {</a>
<a name="ln5080">          if (!writer-&gt;CallbackFailed()) {</a>
<a name="ln5081">            WriteBatchInternal::Append(merged_batch, writer-&gt;batch);</a>
<a name="ln5082">          }</a>
<a name="ln5083">        }</a>
<a name="ln5084">      }</a>
<a name="ln5085">      WriteBatchInternal::SetSequence(merged_batch, current_sequence);</a>
<a name="ln5086"> </a>
<a name="ln5087">      CHECK_EQ(WriteBatchInternal::Count(merged_batch), total_count);</a>
<a name="ln5088"> </a>
<a name="ln5089">      Slice log_entry = WriteBatchInternal::Contents(merged_batch);</a>
<a name="ln5090">      log::Writer* log_writer;</a>
<a name="ln5091">      LogFileNumberSize* last_alive_log_file;</a>
<a name="ln5092">      {</a>
<a name="ln5093">        InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln5094">        log_writer = logs_.back().writer;</a>
<a name="ln5095">        last_alive_log_file = &amp;alive_log_files_.back();</a>
<a name="ln5096">      }</a>
<a name="ln5097">      status = log_writer-&gt;AddRecord(log_entry);</a>
<a name="ln5098">      total_log_size_.fetch_add(static_cast&lt;int64_t&gt;(log_entry.size()));</a>
<a name="ln5099">      last_alive_log_file-&gt;AddSize(log_entry.size());</a>
<a name="ln5100">      log_empty_ = false;</a>
<a name="ln5101">      log_size = log_entry.size();</a>
<a name="ln5102">      RecordTick(stats_, WAL_FILE_BYTES, log_size);</a>
<a name="ln5103">      if (status.ok() &amp;&amp; need_log_sync) {</a>
<a name="ln5104">        RecordTick(stats_, WAL_FILE_SYNCED);</a>
<a name="ln5105">        StopWatch sw(env_, stats_, WAL_FILE_SYNC_MICROS);</a>
<a name="ln5106">        // It's safe to access logs_ with unlocked mutex_ here because:</a>
<a name="ln5107">        //  - we've set getting_synced=true for all logs,</a>
<a name="ln5108">        //    so other threads won't pop from logs_ while we're here,</a>
<a name="ln5109">        //  - only writer thread can push to logs_, and we're in</a>
<a name="ln5110">        //    writer thread, so no one will push to logs_,</a>
<a name="ln5111">        //  - as long as other threads don't modify it, it's safe to read</a>
<a name="ln5112">        //    from std::deque from multiple threads concurrently.</a>
<a name="ln5113">        for (auto&amp; log : logs_) {</a>
<a name="ln5114">          status = log.writer-&gt;file()-&gt;Sync(db_options_.use_fsync);</a>
<a name="ln5115">          if (!status.ok()) {</a>
<a name="ln5116">            break;</a>
<a name="ln5117">          }</a>
<a name="ln5118">        }</a>
<a name="ln5119">        if (status.ok() &amp;&amp; need_log_dir_sync) {</a>
<a name="ln5120">          // We only sync WAL directory the first time WAL syncing is</a>
<a name="ln5121">          // requested, so that in case users never turn on WAL sync,</a>
<a name="ln5122">          // we can avoid the disk I/O in the write code path.</a>
<a name="ln5123">          status = directories_.GetWalDir()-&gt;Fsync();</a>
<a name="ln5124">        }</a>
<a name="ln5125">      }</a>
<a name="ln5126"> </a>
<a name="ln5127">      if (merged_batch == &amp;tmp_batch_) {</a>
<a name="ln5128">        tmp_batch_.Clear();</a>
<a name="ln5129">      }</a>
<a name="ln5130">    }</a>
<a name="ln5131">    if (status.ok()) {</a>
<a name="ln5132">      PERF_TIMER_GUARD(write_memtable_time);</a>
<a name="ln5133"> </a>
<a name="ln5134">      {</a>
<a name="ln5135">        // Update stats while we are an exclusive group leader, so we know</a>
<a name="ln5136">        // that nobody else can be writing to these particular stats.</a>
<a name="ln5137">        // We're optimistic, updating the stats before we successfully</a>
<a name="ln5138">        // commit.  That lets us release our leader status early in</a>
<a name="ln5139">        // some cases.</a>
<a name="ln5140">        auto stats = default_cf_internal_stats_;</a>
<a name="ln5141">        stats-&gt;AddDBStats(InternalDBStatsType::BYTES_WRITTEN, total_byte_size);</a>
<a name="ln5142">        stats-&gt;AddDBStats(InternalDBStatsType::NUMBER_KEYS_WRITTEN, total_count);</a>
<a name="ln5143">        if (!write_options.disableWAL) {</a>
<a name="ln5144">          if (write_options.sync) {</a>
<a name="ln5145">            stats-&gt;AddDBStats(InternalDBStatsType::WAL_FILE_SYNCED, 1);</a>
<a name="ln5146">          }</a>
<a name="ln5147">          stats-&gt;AddDBStats(InternalDBStatsType::WAL_FILE_BYTES, log_size);</a>
<a name="ln5148">        }</a>
<a name="ln5149">        uint64_t for_other = write_group.size() - 1;</a>
<a name="ln5150">        if (for_other &gt; 0) {</a>
<a name="ln5151">          stats-&gt;AddDBStats(InternalDBStatsType::WRITE_DONE_BY_OTHER, for_other);</a>
<a name="ln5152">          if (!write_options.disableWAL) {</a>
<a name="ln5153">            stats-&gt;AddDBStats(InternalDBStatsType::WRITE_WITH_WAL, for_other);</a>
<a name="ln5154">          }</a>
<a name="ln5155">        }</a>
<a name="ln5156">      }</a>
<a name="ln5157"> </a>
<a name="ln5158">      if (!parallel) {</a>
<a name="ln5159">        InsertFlags insert_flags{InsertFlag::kFilterDeletes};</a>
<a name="ln5160">        status = WriteBatchInternal::InsertInto(</a>
<a name="ln5161">            write_group, current_sequence, column_family_memtables_.get(),</a>
<a name="ln5162">            &amp;flush_scheduler_, write_options.ignore_missing_column_families,</a>
<a name="ln5163">            0 /*log_number*/, this, insert_flags);</a>
<a name="ln5164"> </a>
<a name="ln5165">        if (status.ok()) {</a>
<a name="ln5166">          // There were no write failures. Set leader's status</a>
<a name="ln5167">          // in case the write callback returned a non-ok status.</a>
<a name="ln5168">          status = w.FinalStatus();</a>
<a name="ln5169">        }</a>
<a name="ln5170"> </a>
<a name="ln5171">      } else {</a>
<a name="ln5172">        WriteThread::ParallelGroup pg;</a>
<a name="ln5173">        pg.leader = &amp;w;</a>
<a name="ln5174">        pg.last_writer = last_writer;</a>
<a name="ln5175">        pg.last_sequence = last_sequence;</a>
<a name="ln5176">        pg.early_exit_allowed = !need_log_sync;</a>
<a name="ln5177">        pg.running.store(static_cast&lt;uint32_t&gt;(write_group.size()),</a>
<a name="ln5178">                         std::memory_order_relaxed);</a>
<a name="ln5179">        write_thread_.LaunchParallelFollowers(&amp;pg, current_sequence);</a>
<a name="ln5180"> </a>
<a name="ln5181">        if (!w.CallbackFailed()) {</a>
<a name="ln5182">          // do leader write</a>
<a name="ln5183">          ColumnFamilyMemTablesImpl column_family_memtables(</a>
<a name="ln5184">              versions_-&gt;GetColumnFamilySet());</a>
<a name="ln5185">          assert(w.sequence == current_sequence);</a>
<a name="ln5186">          WriteBatchInternal::SetSequence(w.batch, w.sequence);</a>
<a name="ln5187">          InsertFlags insert_flags{InsertFlag::kConcurrentMemtableWrites};</a>
<a name="ln5188">          w.status = WriteBatchInternal::InsertInto(</a>
<a name="ln5189">              w.batch, &amp;column_family_memtables, &amp;flush_scheduler_,</a>
<a name="ln5190">              write_options.ignore_missing_column_families, 0 /*log_number*/,</a>
<a name="ln5191">              this, insert_flags);</a>
<a name="ln5192">        }</a>
<a name="ln5193"> </a>
<a name="ln5194">        // CompleteParallelWorker returns true if this thread should</a>
<a name="ln5195">        // handle exit, false means somebody else did</a>
<a name="ln5196">        exit_completed_early = !write_thread_.CompleteParallelWorker(&amp;w);</a>
<a name="ln5197">        status = w.FinalStatus();</a>
<a name="ln5198">      }</a>
<a name="ln5199"> </a>
<a name="ln5200">      if (!exit_completed_early &amp;&amp; w.status.ok()) {</a>
<a name="ln5201">        SetTickerCount(stats_, SEQUENCE_NUMBER, last_sequence);</a>
<a name="ln5202">        versions_-&gt;SetLastSequence(last_sequence);</a>
<a name="ln5203">        if (!need_log_sync) {</a>
<a name="ln5204">          write_thread_.ExitAsBatchGroupLeader(&amp;w, last_writer, w.status);</a>
<a name="ln5205">          exit_completed_early = true;</a>
<a name="ln5206">        }</a>
<a name="ln5207">      }</a>
<a name="ln5208"> </a>
<a name="ln5209">      // A non-OK status here indicates that the state implied by the</a>
<a name="ln5210">      // WAL has diverged from the in-memory state.  This could be</a>
<a name="ln5211">      // because of a corrupt write_batch (very bad), or because the</a>
<a name="ln5212">      // client specified an invalid column family and didn't specify</a>
<a name="ln5213">      // ignore_missing_column_families.</a>
<a name="ln5214">      //</a>
<a name="ln5215">      // Is setting bg_error_ enough here?  This will at least stop</a>
<a name="ln5216">      // compaction and fail any further writes.</a>
<a name="ln5217">      if (!status.ok() &amp;&amp; bg_error_.ok() &amp;&amp; !w.CallbackFailed()) {</a>
<a name="ln5218">        bg_error_ = status;</a>
<a name="ln5219">      }</a>
<a name="ln5220">    }</a>
<a name="ln5221">  }</a>
<a name="ln5222">  PERF_TIMER_START(write_pre_and_post_process_time);</a>
<a name="ln5223"> </a>
<a name="ln5224">  if (db_options_.paranoid_checks &amp;&amp; !status.ok() &amp;&amp; !w.CallbackFailed() &amp;&amp; !status.IsBusy()) {</a>
<a name="ln5225">    mutex_.Lock();</a>
<a name="ln5226">    if (bg_error_.ok()) {</a>
<a name="ln5227">      bg_error_ = status;  // stop compaction &amp; fail any further writes</a>
<a name="ln5228">    }</a>
<a name="ln5229">    mutex_.Unlock();</a>
<a name="ln5230">  }</a>
<a name="ln5231"> </a>
<a name="ln5232">  if (need_log_sync) {</a>
<a name="ln5233">    mutex_.Lock();</a>
<a name="ln5234">    MarkLogsSynced(logfile_number_, need_log_dir_sync, status);</a>
<a name="ln5235">    mutex_.Unlock();</a>
<a name="ln5236">  }</a>
<a name="ln5237"> </a>
<a name="ln5238">  if (!exit_completed_early) {</a>
<a name="ln5239">    write_thread_.ExitAsBatchGroupLeader(&amp;w, last_writer, w.status);</a>
<a name="ln5240">  }</a>
<a name="ln5241"> </a>
<a name="ln5242">  return status;</a>
<a name="ln5243">}</a>
<a name="ln5244"> </a>
<a name="ln5245">// REQUIRES: mutex_ is held</a>
<a name="ln5246">// REQUIRES: this thread is currently at the front of the writer queue</a>
<a name="ln5247">Status DBImpl::DelayWrite(uint64_t num_bytes) {</a>
<a name="ln5248">  uint64_t time_delayed = 0;</a>
<a name="ln5249">  bool delayed = false;</a>
<a name="ln5250">  {</a>
<a name="ln5251">    StopWatch sw(env_, stats_, WRITE_STALL, &amp;time_delayed);</a>
<a name="ln5252">    auto delay = write_controller_.GetDelay(env_, num_bytes);</a>
<a name="ln5253">    if (delay &gt; 0) {</a>
<a name="ln5254">      mutex_.Unlock();</a>
<a name="ln5255">      delayed = true;</a>
<a name="ln5256">      TEST_SYNC_POINT(&quot;DBImpl::DelayWrite:Sleep&quot;);</a>
<a name="ln5257">      // hopefully we don't have to sleep more than 2 billion microseconds</a>
<a name="ln5258">      env_-&gt;SleepForMicroseconds(static_cast&lt;int&gt;(delay));</a>
<a name="ln5259">      mutex_.Lock();</a>
<a name="ln5260">    }</a>
<a name="ln5261"> </a>
<a name="ln5262">    while (bg_error_.ok() &amp;&amp; write_controller_.IsStopped()) {</a>
<a name="ln5263">      delayed = true;</a>
<a name="ln5264">      TEST_SYNC_POINT(&quot;DBImpl::DelayWrite:Wait&quot;);</a>
<a name="ln5265">      bg_cv_.Wait();</a>
<a name="ln5266">    }</a>
<a name="ln5267">  }</a>
<a name="ln5268">  if (delayed) {</a>
<a name="ln5269">    default_cf_internal_stats_-&gt;AddDBStats(InternalDBStatsType::WRITE_STALL_MICROS,</a>
<a name="ln5270">                                           time_delayed);</a>
<a name="ln5271">    RecordTick(stats_, STALL_MICROS, time_delayed);</a>
<a name="ln5272">  }</a>
<a name="ln5273"> </a>
<a name="ln5274">  return bg_error_;</a>
<a name="ln5275">}</a>
<a name="ln5276"> </a>
<a name="ln5277">Status DBImpl::ScheduleFlushes(WriteContext* context) {</a>
<a name="ln5278">  ColumnFamilyData* cfd;</a>
<a name="ln5279">  while ((cfd = flush_scheduler_.TakeNextColumnFamily()) != nullptr) {</a>
<a name="ln5280">    auto status = SwitchMemtable(cfd, context);</a>
<a name="ln5281">    if (cfd-&gt;Unref()) {</a>
<a name="ln5282">      delete cfd;</a>
<a name="ln5283">    }</a>
<a name="ln5284">    if (!status.ok()) {</a>
<a name="ln5285">      return status;</a>
<a name="ln5286">    }</a>
<a name="ln5287">  }</a>
<a name="ln5288">  return Status::OK();</a>
<a name="ln5289">}</a>
<a name="ln5290"> </a>
<a name="ln5291">// REQUIRES: mutex_ is held</a>
<a name="ln5292">// REQUIRES: this thread is currently at the front of the writer queue</a>
<a name="ln5293">Status DBImpl::SwitchMemtable(ColumnFamilyData* cfd, WriteContext* context) {</a>
<a name="ln5294">  mutex_.AssertHeld();</a>
<a name="ln5295">  unique_ptr&lt;WritableFile&gt; lfile;</a>
<a name="ln5296">  log::Writer* new_log = nullptr;</a>
<a name="ln5297">  MemTable* new_mem = nullptr;</a>
<a name="ln5298"> </a>
<a name="ln5299">  // Attempt to switch to a new memtable and trigger flush of old.</a>
<a name="ln5300">  // Do this without holding the dbmutex lock.</a>
<a name="ln5301">  assert(versions_-&gt;prev_log_number() == 0);</a>
<a name="ln5302">  bool creating_new_log = !log_empty_;</a>
<a name="ln5303">  uint64_t recycle_log_number = 0;</a>
<a name="ln5304">  if (creating_new_log &amp;&amp; db_options_.recycle_log_file_num &amp;&amp;</a>
<a name="ln5305">      !log_recycle_files.empty()) {</a>
<a name="ln5306">    recycle_log_number = log_recycle_files.front();</a>
<a name="ln5307">    log_recycle_files.pop_front();</a>
<a name="ln5308">  }</a>
<a name="ln5309">  uint64_t new_log_number =</a>
<a name="ln5310">      creating_new_log ? versions_-&gt;NewFileNumber() : logfile_number_;</a>
<a name="ln5311">  SuperVersion* new_superversion = nullptr;</a>
<a name="ln5312">  const MutableCFOptions mutable_cf_options = *cfd-&gt;GetLatestMutableCFOptions();</a>
<a name="ln5313">  mutex_.Unlock();</a>
<a name="ln5314">  Status s;</a>
<a name="ln5315">  {</a>
<a name="ln5316">    if (creating_new_log) {</a>
<a name="ln5317">      EnvOptions opt_env_opt =</a>
<a name="ln5318">          env_-&gt;OptimizeForLogWrite(env_options_, db_options_);</a>
<a name="ln5319">      if (recycle_log_number) {</a>
<a name="ln5320">        RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln5321">            &quot;reusing log %&quot; PRIu64 &quot; from recycle list\n&quot;, recycle_log_number);</a>
<a name="ln5322">        s = env_-&gt;ReuseWritableFile(</a>
<a name="ln5323">            LogFileName(db_options_.wal_dir, new_log_number),</a>
<a name="ln5324">            LogFileName(db_options_.wal_dir, recycle_log_number), &amp;lfile,</a>
<a name="ln5325">            opt_env_opt);</a>
<a name="ln5326">      } else {</a>
<a name="ln5327">        s = NewWritableFile(env_,</a>
<a name="ln5328">                            LogFileName(db_options_.wal_dir, new_log_number),</a>
<a name="ln5329">                            &amp;lfile, opt_env_opt);</a>
<a name="ln5330">      }</a>
<a name="ln5331">      if (s.ok()) {</a>
<a name="ln5332">        // Our final size should be less than write_buffer_size</a>
<a name="ln5333">        // (compression, etc) but err on the side of caution.</a>
<a name="ln5334">        lfile-&gt;SetPreallocationBlockSize(</a>
<a name="ln5335">            mutable_cf_options.write_buffer_size / 10 +</a>
<a name="ln5336">            mutable_cf_options.write_buffer_size);</a>
<a name="ln5337">        unique_ptr&lt;WritableFileWriter&gt; file_writer(</a>
<a name="ln5338">            new WritableFileWriter(std::move(lfile), opt_env_opt));</a>
<a name="ln5339">        new_log = new log::Writer(std::move(file_writer), new_log_number,</a>
<a name="ln5340">                                  db_options_.recycle_log_file_num &gt; 0);</a>
<a name="ln5341">      }</a>
<a name="ln5342">    }</a>
<a name="ln5343"> </a>
<a name="ln5344">    if (s.ok()) {</a>
<a name="ln5345">      SequenceNumber seq = versions_-&gt;LastSequence();</a>
<a name="ln5346">      new_mem = cfd-&gt;ConstructNewMemtable(mutable_cf_options, seq);</a>
<a name="ln5347">      new_superversion = new SuperVersion();</a>
<a name="ln5348">    }</a>
<a name="ln5349">  }</a>
<a name="ln5350">  RLOG(InfoLogLevel::DEBUG_LEVEL, db_options_.info_log,</a>
<a name="ln5351">      &quot;[%s] New memtable created with log file: #%&quot; PRIu64 &quot;\n&quot;,</a>
<a name="ln5352">      cfd-&gt;GetName().c_str(), new_log_number);</a>
<a name="ln5353">  mutex_.Lock();</a>
<a name="ln5354">  if (!s.ok()) {</a>
<a name="ln5355">    // how do we fail if we're not creating new log?</a>
<a name="ln5356">    assert(creating_new_log);</a>
<a name="ln5357">    assert(!new_mem);</a>
<a name="ln5358">    assert(!new_log);</a>
<a name="ln5359">    return s;</a>
<a name="ln5360">  }</a>
<a name="ln5361">  if (creating_new_log) {</a>
<a name="ln5362">    logfile_number_ = new_log_number;</a>
<a name="ln5363">    assert(new_log != nullptr);</a>
<a name="ln5364">    log_empty_ = true;</a>
<a name="ln5365">    log_dir_synced_ = false;</a>
<a name="ln5366">    logs_.emplace_back(logfile_number_, new_log);</a>
<a name="ln5367">    alive_log_files_.push_back(LogFileNumberSize(logfile_number_));</a>
<a name="ln5368">    for (auto loop_cfd : *versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln5369">      // all this is just optimization to delete logs that</a>
<a name="ln5370">      // are no longer needed -- if CF is empty, that means it</a>
<a name="ln5371">      // doesn't need that particular log to stay alive, so we just</a>
<a name="ln5372">      // advance the log number. no need to persist this in the manifest</a>
<a name="ln5373">      if (loop_cfd-&gt;mem()-&gt;GetFirstSequenceNumber() == 0 &amp;&amp;</a>
<a name="ln5374">          loop_cfd-&gt;imm()-&gt;NumNotFlushed() == 0) {</a>
<a name="ln5375">        loop_cfd-&gt;SetLogNumber(logfile_number_);</a>
<a name="ln5376">      }</a>
<a name="ln5377">    }</a>
<a name="ln5378">  }</a>
<a name="ln5379">  cfd-&gt;mem()-&gt;SetFlushStartTime(std::chrono::steady_clock::now());</a>
<a name="ln5380">  cfd-&gt;mem()-&gt;SetNextLogNumber(logfile_number_);</a>
<a name="ln5381">  cfd-&gt;imm()-&gt;Add(cfd-&gt;mem(), &amp;context-&gt;memtables_to_free_);</a>
<a name="ln5382">  new_mem-&gt;Ref();</a>
<a name="ln5383">  cfd-&gt;SetMemtable(new_mem);</a>
<a name="ln5384">  context-&gt;superversions_to_free_.push_back(InstallSuperVersionAndScheduleWork(</a>
<a name="ln5385">      cfd, new_superversion, mutable_cf_options));</a>
<a name="ln5386"> </a>
<a name="ln5387">  return s;</a>
<a name="ln5388">}</a>
<a name="ln5389"> </a>
<a name="ln5390">#ifndef ROCKSDB_LITE</a>
<a name="ln5391">Status DBImpl::GetPropertiesOfAllTables(ColumnFamilyHandle* column_family,</a>
<a name="ln5392">                                        TablePropertiesCollection* props) {</a>
<a name="ln5393">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln5394">  auto cfd = cfh-&gt;cfd();</a>
<a name="ln5395"> </a>
<a name="ln5396">  // Increment the ref count</a>
<a name="ln5397">  mutex_.Lock();</a>
<a name="ln5398">  auto version = cfd-&gt;current();</a>
<a name="ln5399">  version-&gt;Ref();</a>
<a name="ln5400">  mutex_.Unlock();</a>
<a name="ln5401"> </a>
<a name="ln5402">  auto s = version-&gt;GetPropertiesOfAllTables(props);</a>
<a name="ln5403"> </a>
<a name="ln5404">  // Decrement the ref count</a>
<a name="ln5405">  mutex_.Lock();</a>
<a name="ln5406">  version-&gt;Unref();</a>
<a name="ln5407">  mutex_.Unlock();</a>
<a name="ln5408"> </a>
<a name="ln5409">  return s;</a>
<a name="ln5410">}</a>
<a name="ln5411"> </a>
<a name="ln5412">Status DBImpl::GetPropertiesOfTablesInRange(ColumnFamilyHandle* column_family,</a>
<a name="ln5413">                                            const Range* range, std::size_t n,</a>
<a name="ln5414">                                            TablePropertiesCollection* props) {</a>
<a name="ln5415">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln5416">  auto cfd = cfh-&gt;cfd();</a>
<a name="ln5417"> </a>
<a name="ln5418">  // Increment the ref count</a>
<a name="ln5419">  mutex_.Lock();</a>
<a name="ln5420">  auto version = cfd-&gt;current();</a>
<a name="ln5421">  version-&gt;Ref();</a>
<a name="ln5422">  mutex_.Unlock();</a>
<a name="ln5423"> </a>
<a name="ln5424">  auto s = version-&gt;GetPropertiesOfTablesInRange(range, n, props);</a>
<a name="ln5425"> </a>
<a name="ln5426">  // Decrement the ref count</a>
<a name="ln5427">  mutex_.Lock();</a>
<a name="ln5428">  version-&gt;Unref();</a>
<a name="ln5429">  mutex_.Unlock();</a>
<a name="ln5430"> </a>
<a name="ln5431">  return s;</a>
<a name="ln5432">}</a>
<a name="ln5433"> </a>
<a name="ln5434">#endif  // ROCKSDB_LITE</a>
<a name="ln5435"> </a>
<a name="ln5436">const std::string&amp; DBImpl::GetName() const {</a>
<a name="ln5437">  return dbname_;</a>
<a name="ln5438">}</a>
<a name="ln5439"> </a>
<a name="ln5440">Env* DBImpl::GetEnv() const {</a>
<a name="ln5441">  return env_;</a>
<a name="ln5442">}</a>
<a name="ln5443"> </a>
<a name="ln5444">Env* DBImpl::GetCheckpointEnv() const {</a>
<a name="ln5445">  return checkpoint_env_;</a>
<a name="ln5446">}</a>
<a name="ln5447"> </a>
<a name="ln5448">const Options&amp; DBImpl::GetOptions(ColumnFamilyHandle* column_family) const {</a>
<a name="ln5449">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln5450">  return *cfh-&gt;cfd()-&gt;options();</a>
<a name="ln5451">}</a>
<a name="ln5452"> </a>
<a name="ln5453">const DBOptions&amp; DBImpl::GetDBOptions() const { return db_options_; }</a>
<a name="ln5454"> </a>
<a name="ln5455">bool DBImpl::GetProperty(ColumnFamilyHandle* column_family,</a>
<a name="ln5456">                         const Slice&amp; property, std::string* value) {</a>
<a name="ln5457">  const DBPropertyInfo* property_info = GetPropertyInfo(property);</a>
<a name="ln5458">  value-&gt;clear();</a>
<a name="ln5459">  auto cfd = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family)-&gt;cfd();</a>
<a name="ln5460">  if (property_info == nullptr) {</a>
<a name="ln5461">    return false;</a>
<a name="ln5462">  } else if (property_info-&gt;handle_int) {</a>
<a name="ln5463">    uint64_t int_value;</a>
<a name="ln5464">    bool ret_value =</a>
<a name="ln5465">        GetIntPropertyInternal(cfd, *property_info, false, &amp;int_value);</a>
<a name="ln5466">    if (ret_value) {</a>
<a name="ln5467">      *value = ToString(int_value);</a>
<a name="ln5468">    }</a>
<a name="ln5469">    return ret_value;</a>
<a name="ln5470">  } else if (property_info-&gt;handle_string) {</a>
<a name="ln5471">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln5472">    return cfd-&gt;internal_stats()-&gt;GetStringProperty(*property_info, property,</a>
<a name="ln5473">                                                    value);</a>
<a name="ln5474">  }</a>
<a name="ln5475">  // Shouldn't reach here since exactly one of handle_string and handle_int</a>
<a name="ln5476">  // should be non-nullptr.</a>
<a name="ln5477">  assert(false);</a>
<a name="ln5478">  return false;</a>
<a name="ln5479">}</a>
<a name="ln5480"> </a>
<a name="ln5481">bool DBImpl::GetIntProperty(ColumnFamilyHandle* column_family,</a>
<a name="ln5482">                            const Slice&amp; property, uint64_t* value) {</a>
<a name="ln5483">  const DBPropertyInfo* property_info = GetPropertyInfo(property);</a>
<a name="ln5484">  if (property_info == nullptr || property_info-&gt;handle_int == nullptr) {</a>
<a name="ln5485">    return false;</a>
<a name="ln5486">  }</a>
<a name="ln5487">  auto cfd = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family)-&gt;cfd();</a>
<a name="ln5488">  return GetIntPropertyInternal(cfd, *property_info, false, value);</a>
<a name="ln5489">}</a>
<a name="ln5490"> </a>
<a name="ln5491">bool DBImpl::GetIntPropertyInternal(ColumnFamilyData* cfd,</a>
<a name="ln5492">                                    const DBPropertyInfo&amp; property_info,</a>
<a name="ln5493">                                    bool is_locked, uint64_t* value) {</a>
<a name="ln5494">  assert(property_info.handle_int != nullptr);</a>
<a name="ln5495">  if (!property_info.need_out_of_mutex) {</a>
<a name="ln5496">    if (is_locked) {</a>
<a name="ln5497">      mutex_.AssertHeld();</a>
<a name="ln5498">      return cfd-&gt;internal_stats()-&gt;GetIntProperty(property_info, value, this);</a>
<a name="ln5499">    } else {</a>
<a name="ln5500">      InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln5501">      return cfd-&gt;internal_stats()-&gt;GetIntProperty(property_info, value, this);</a>
<a name="ln5502">    }</a>
<a name="ln5503">  } else {</a>
<a name="ln5504">    SuperVersion* sv = nullptr;</a>
<a name="ln5505">    if (!is_locked) {</a>
<a name="ln5506">      sv = GetAndRefSuperVersion(cfd);</a>
<a name="ln5507">    } else {</a>
<a name="ln5508">      sv = cfd-&gt;GetSuperVersion();</a>
<a name="ln5509">    }</a>
<a name="ln5510"> </a>
<a name="ln5511">    bool ret = cfd-&gt;internal_stats()-&gt;GetIntPropertyOutOfMutex(</a>
<a name="ln5512">        property_info, sv-&gt;current, value);</a>
<a name="ln5513"> </a>
<a name="ln5514">    if (!is_locked) {</a>
<a name="ln5515">      ReturnAndCleanupSuperVersion(cfd, sv);</a>
<a name="ln5516">    }</a>
<a name="ln5517"> </a>
<a name="ln5518">    return ret;</a>
<a name="ln5519">  }</a>
<a name="ln5520">}</a>
<a name="ln5521"> </a>
<a name="ln5522">bool DBImpl::GetAggregatedIntProperty(const Slice&amp; property,</a>
<a name="ln5523">                                      uint64_t* aggregated_value) {</a>
<a name="ln5524">  const DBPropertyInfo* property_info = GetPropertyInfo(property);</a>
<a name="ln5525">  if (property_info == nullptr || property_info-&gt;handle_int == nullptr) {</a>
<a name="ln5526">    return false;</a>
<a name="ln5527">  }</a>
<a name="ln5528"> </a>
<a name="ln5529">  uint64_t sum = 0;</a>
<a name="ln5530">  {</a>
<a name="ln5531">    // Needs mutex to protect the list of column families.</a>
<a name="ln5532">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln5533">    uint64_t value;</a>
<a name="ln5534">    for (auto* cfd : *versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln5535">      if (GetIntPropertyInternal(cfd, *property_info, true, &amp;value)) {</a>
<a name="ln5536">        sum += value;</a>
<a name="ln5537">      } else {</a>
<a name="ln5538">        return false;</a>
<a name="ln5539">      }</a>
<a name="ln5540">    }</a>
<a name="ln5541">  }</a>
<a name="ln5542">  *aggregated_value = sum;</a>
<a name="ln5543">  return true;</a>
<a name="ln5544">}</a>
<a name="ln5545"> </a>
<a name="ln5546">SuperVersion* DBImpl::GetAndRefSuperVersion(ColumnFamilyData* cfd) {</a>
<a name="ln5547">  // TODO(ljin): consider using GetReferencedSuperVersion() directly</a>
<a name="ln5548">  return cfd-&gt;GetThreadLocalSuperVersion(&amp;mutex_);</a>
<a name="ln5549">}</a>
<a name="ln5550"> </a>
<a name="ln5551">// REQUIRED: this function should only be called on the write thread or if the</a>
<a name="ln5552">// mutex is held.</a>
<a name="ln5553">SuperVersion* DBImpl::GetAndRefSuperVersion(uint32_t column_family_id) {</a>
<a name="ln5554">  auto column_family_set = versions_-&gt;GetColumnFamilySet();</a>
<a name="ln5555">  auto cfd = column_family_set-&gt;GetColumnFamily(column_family_id);</a>
<a name="ln5556">  if (!cfd) {</a>
<a name="ln5557">    return nullptr;</a>
<a name="ln5558">  }</a>
<a name="ln5559"> </a>
<a name="ln5560">  return GetAndRefSuperVersion(cfd);</a>
<a name="ln5561">}</a>
<a name="ln5562"> </a>
<a name="ln5563">// REQUIRED:  mutex is NOT held</a>
<a name="ln5564">SuperVersion* DBImpl::GetAndRefSuperVersionUnlocked(uint32_t column_family_id) {</a>
<a name="ln5565">  ColumnFamilyData* cfd;</a>
<a name="ln5566">  {</a>
<a name="ln5567">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln5568">    auto column_family_set = versions_-&gt;GetColumnFamilySet();</a>
<a name="ln5569">    cfd = column_family_set-&gt;GetColumnFamily(column_family_id);</a>
<a name="ln5570">  }</a>
<a name="ln5571"> </a>
<a name="ln5572">  if (!cfd) {</a>
<a name="ln5573">    return nullptr;</a>
<a name="ln5574">  }</a>
<a name="ln5575"> </a>
<a name="ln5576">  return GetAndRefSuperVersion(cfd);</a>
<a name="ln5577">}</a>
<a name="ln5578"> </a>
<a name="ln5579">void DBImpl::ReturnAndCleanupSuperVersion(ColumnFamilyData* cfd,</a>
<a name="ln5580">                                          SuperVersion* sv) {</a>
<a name="ln5581">  bool unref_sv = !cfd-&gt;ReturnThreadLocalSuperVersion(sv);</a>
<a name="ln5582"> </a>
<a name="ln5583">  if (unref_sv) {</a>
<a name="ln5584">    // Release SuperVersion</a>
<a name="ln5585">    if (sv-&gt;Unref()) {</a>
<a name="ln5586">      {</a>
<a name="ln5587">        InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln5588">        sv-&gt;Cleanup();</a>
<a name="ln5589">      }</a>
<a name="ln5590">      delete sv;</a>
<a name="ln5591">      RecordTick(stats_, NUMBER_SUPERVERSION_CLEANUPS);</a>
<a name="ln5592">    }</a>
<a name="ln5593">    RecordTick(stats_, NUMBER_SUPERVERSION_RELEASES);</a>
<a name="ln5594">  }</a>
<a name="ln5595">}</a>
<a name="ln5596"> </a>
<a name="ln5597">// REQUIRED: this function should only be called on the write thread.</a>
<a name="ln5598">void DBImpl::ReturnAndCleanupSuperVersion(uint32_t column_family_id,</a>
<a name="ln5599">                                          SuperVersion* sv) {</a>
<a name="ln5600">  auto column_family_set = versions_-&gt;GetColumnFamilySet();</a>
<a name="ln5601">  auto cfd = column_family_set-&gt;GetColumnFamily(column_family_id);</a>
<a name="ln5602"> </a>
<a name="ln5603">  // If SuperVersion is held, and we successfully fetched a cfd using</a>
<a name="ln5604">  // GetAndRefSuperVersion(), it must still exist.</a>
<a name="ln5605">  assert(cfd != nullptr);</a>
<a name="ln5606">  ReturnAndCleanupSuperVersion(cfd, sv);</a>
<a name="ln5607">}</a>
<a name="ln5608"> </a>
<a name="ln5609">// REQUIRED: Mutex should NOT be held.</a>
<a name="ln5610">void DBImpl::ReturnAndCleanupSuperVersionUnlocked(uint32_t column_family_id,</a>
<a name="ln5611">                                                  SuperVersion* sv) {</a>
<a name="ln5612">  ColumnFamilyData* cfd;</a>
<a name="ln5613">  {</a>
<a name="ln5614">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln5615">    auto column_family_set = versions_-&gt;GetColumnFamilySet();</a>
<a name="ln5616">    cfd = column_family_set-&gt;GetColumnFamily(column_family_id);</a>
<a name="ln5617">  }</a>
<a name="ln5618"> </a>
<a name="ln5619">  // If SuperVersion is held, and we successfully fetched a cfd using</a>
<a name="ln5620">  // GetAndRefSuperVersion(), it must still exist.</a>
<a name="ln5621">  assert(cfd != nullptr);</a>
<a name="ln5622">  ReturnAndCleanupSuperVersion(cfd, sv);</a>
<a name="ln5623">}</a>
<a name="ln5624"> </a>
<a name="ln5625">// REQUIRED: this function should only be called on the write thread or if the</a>
<a name="ln5626">// mutex is held.</a>
<a name="ln5627">ColumnFamilyHandle* DBImpl::GetColumnFamilyHandle(uint32_t column_family_id) {</a>
<a name="ln5628">  ColumnFamilyMemTables* cf_memtables = column_family_memtables_.get();</a>
<a name="ln5629"> </a>
<a name="ln5630">  if (!cf_memtables-&gt;Seek(column_family_id)) {</a>
<a name="ln5631">    return nullptr;</a>
<a name="ln5632">  }</a>
<a name="ln5633"> </a>
<a name="ln5634">  return cf_memtables-&gt;GetColumnFamilyHandle();</a>
<a name="ln5635">}</a>
<a name="ln5636"> </a>
<a name="ln5637">// REQUIRED: mutex is NOT held.</a>
<a name="ln5638">ColumnFamilyHandle* DBImpl::GetColumnFamilyHandleUnlocked(</a>
<a name="ln5639">    uint32_t column_family_id) {</a>
<a name="ln5640">  ColumnFamilyMemTables* cf_memtables = column_family_memtables_.get();</a>
<a name="ln5641"> </a>
<a name="ln5642">  InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln5643"> </a>
<a name="ln5644">  if (!cf_memtables-&gt;Seek(column_family_id)) {</a>
<a name="ln5645">    return nullptr;</a>
<a name="ln5646">  }</a>
<a name="ln5647"> </a>
<a name="ln5648">  return cf_memtables-&gt;GetColumnFamilyHandle();</a>
<a name="ln5649">}</a>
<a name="ln5650"> </a>
<a name="ln5651">Status DBImpl::Import(const std::string&amp; source_dir) {</a>
<a name="ln5652">  const auto seqno = versions_-&gt;LastSequence();</a>
<a name="ln5653">  FlushOptions options;</a>
<a name="ln5654">  RETURN_NOT_OK(Flush(options));</a>
<a name="ln5655">  VersionEdit edit;</a>
<a name="ln5656">  auto status = versions_-&gt;Import(source_dir, seqno, &amp;edit);</a>
<a name="ln5657">  if (!status.ok()) {</a>
<a name="ln5658">    return status;</a>
<a name="ln5659">  }</a>
<a name="ln5660">  return ApplyVersionEdit(&amp;edit);</a>
<a name="ln5661">}</a>
<a name="ln5662"> </a>
<a name="ln5663">bool DBImpl::AreWritesStopped() {</a>
<a name="ln5664">  return write_controller_.IsStopped();</a>
<a name="ln5665">}</a>
<a name="ln5666"> </a>
<a name="ln5667">bool DBImpl::NeedsDelay() {</a>
<a name="ln5668">  return write_controller_.NeedsDelay();</a>
<a name="ln5669">}</a>
<a name="ln5670"> </a>
<a name="ln5671">Result&lt;std::string&gt; DBImpl::GetMiddleKey() {</a>
<a name="ln5672">  InstrumentedMutexLock lock(&amp;mutex_);</a>
<a name="ln5673">  return default_cf_handle_-&gt;cfd()-&gt;current()-&gt;GetMiddleKey();</a>
<a name="ln5674">}</a>
<a name="ln5675"> </a>
<a name="ln5676">void DBImpl::TEST_SwitchMemtable() {</a>
<a name="ln5677">  std::lock_guard&lt;InstrumentedMutex&gt; lock(mutex_);</a>
<a name="ln5678">  WriteContext context;</a>
<a name="ln5679">  CHECK_OK(SwitchMemtable(default_cf_handle_-&gt;cfd(), &amp;context));</a>
<a name="ln5680">}</a>
<a name="ln5681"> </a>
<a name="ln5682">void DBImpl::GetApproximateSizes(ColumnFamilyHandle* column_family,</a>
<a name="ln5683">                                 const Range* range, int n, uint64_t* sizes,</a>
<a name="ln5684">                                 bool include_memtable) {</a>
<a name="ln5685">  Version* v;</a>
<a name="ln5686">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln5687">  auto cfd = cfh-&gt;cfd();</a>
<a name="ln5688">  SuperVersion* sv = GetAndRefSuperVersion(cfd);</a>
<a name="ln5689">  v = sv-&gt;current;</a>
<a name="ln5690"> </a>
<a name="ln5691">  for (int i = 0; i &lt; n; i++) {</a>
<a name="ln5692">    // Convert user_key into a corresponding internal key.</a>
<a name="ln5693">    InternalKey k1(range[i].start, kMaxSequenceNumber, kValueTypeForSeek);</a>
<a name="ln5694">    InternalKey k2(range[i].limit, kMaxSequenceNumber, kValueTypeForSeek);</a>
<a name="ln5695">    sizes[i] = versions_-&gt;ApproximateSize(v, k1.Encode(), k2.Encode());</a>
<a name="ln5696">    if (include_memtable) {</a>
<a name="ln5697">      sizes[i] += sv-&gt;mem-&gt;ApproximateSize(k1.Encode(), k2.Encode());</a>
<a name="ln5698">      sizes[i] += sv-&gt;imm-&gt;ApproximateSize(k1.Encode(), k2.Encode());</a>
<a name="ln5699">    }</a>
<a name="ln5700">  }</a>
<a name="ln5701"> </a>
<a name="ln5702">  ReturnAndCleanupSuperVersion(cfd, sv);</a>
<a name="ln5703">}</a>
<a name="ln5704"> </a>
<a name="ln5705">#ifndef ROCKSDB_LITE</a>
<a name="ln5706">Status DBImpl::GetUpdatesSince(</a>
<a name="ln5707">    SequenceNumber seq, unique_ptr&lt;TransactionLogIterator&gt;* iter,</a>
<a name="ln5708">    const TransactionLogIterator::ReadOptions&amp; read_options) {</a>
<a name="ln5709"> </a>
<a name="ln5710">  RecordTick(stats_, GET_UPDATES_SINCE_CALLS);</a>
<a name="ln5711">  if (seq &gt; versions_-&gt;LastSequence()) {</a>
<a name="ln5712">    return STATUS(NotFound, &quot;Requested sequence not yet written in the db&quot;);</a>
<a name="ln5713">  }</a>
<a name="ln5714">  return wal_manager_.GetUpdatesSince(seq, iter, read_options, versions_.get());</a>
<a name="ln5715">}</a>
<a name="ln5716"> </a>
<a name="ln5717">Status DBImpl::DeleteFile(std::string name) {</a>
<a name="ln5718">  uint64_t number;</a>
<a name="ln5719">  FileType type;</a>
<a name="ln5720">  WalFileType log_type;</a>
<a name="ln5721">  if (!ParseFileName(name, &amp;number, &amp;type, &amp;log_type) ||</a>
<a name="ln5722">      (type != kTableFile &amp;&amp; type != kLogFile)) {</a>
<a name="ln5723">    RLOG(InfoLogLevel::ERROR_LEVEL, db_options_.info_log,</a>
<a name="ln5724">        &quot;DeleteFile %s failed.\n&quot;, name.c_str());</a>
<a name="ln5725">    return STATUS(InvalidArgument, &quot;Invalid file name&quot;);</a>
<a name="ln5726">  }</a>
<a name="ln5727"> </a>
<a name="ln5728">  Status status;</a>
<a name="ln5729">  if (type == kLogFile) {</a>
<a name="ln5730">    // Only allow deleting archived log files</a>
<a name="ln5731">    if (log_type != kArchivedLogFile) {</a>
<a name="ln5732">      RLOG(InfoLogLevel::ERROR_LEVEL, db_options_.info_log,</a>
<a name="ln5733">          &quot;DeleteFile %s failed - not archived log.\n&quot;,</a>
<a name="ln5734">          name.c_str());</a>
<a name="ln5735">      return STATUS(NotSupported, &quot;Delete only supported for archived logs&quot;);</a>
<a name="ln5736">    }</a>
<a name="ln5737">    status = env_-&gt;DeleteFile(db_options_.wal_dir + &quot;/&quot; + name.c_str());</a>
<a name="ln5738">    if (!status.ok()) {</a>
<a name="ln5739">      RLOG(InfoLogLevel::ERROR_LEVEL, db_options_.info_log,</a>
<a name="ln5740">          &quot;DeleteFile %s failed -- %s.\n&quot;,</a>
<a name="ln5741">          name.c_str(), status.ToString().c_str());</a>
<a name="ln5742">    }</a>
<a name="ln5743">    return status;</a>
<a name="ln5744">  }</a>
<a name="ln5745"> </a>
<a name="ln5746">  int level;</a>
<a name="ln5747">  FileMetaData* metadata;</a>
<a name="ln5748">  ColumnFamilyData* cfd;</a>
<a name="ln5749">  VersionEdit edit;</a>
<a name="ln5750">  JobContext job_context(next_job_id_.fetch_add(1), true);</a>
<a name="ln5751">  {</a>
<a name="ln5752">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln5753">    // Delete file is infrequent operation, so could just busy wait here.</a>
<a name="ln5754">    while (versions_-&gt;has_manifest_writers()) {</a>
<a name="ln5755">      mutex_.unlock();</a>
<a name="ln5756">      std::this_thread::sleep_for(10ms);</a>
<a name="ln5757">      mutex_.lock();</a>
<a name="ln5758">    }</a>
<a name="ln5759"> </a>
<a name="ln5760">    status = versions_-&gt;GetMetadataForFile(number, &amp;level, &amp;metadata, &amp;cfd);</a>
<a name="ln5761">    if (!status.ok()) {</a>
<a name="ln5762">      RLOG(InfoLogLevel::WARN_LEVEL, db_options_.info_log,</a>
<a name="ln5763">          &quot;DeleteFile %s failed. File not found\n&quot;, name.c_str());</a>
<a name="ln5764">      job_context.Clean();</a>
<a name="ln5765">      return STATUS(InvalidArgument, &quot;File not found&quot;);</a>
<a name="ln5766">    }</a>
<a name="ln5767">    assert(level &lt; cfd-&gt;NumberLevels());</a>
<a name="ln5768"> </a>
<a name="ln5769">    // If the file is being compacted no need to delete.</a>
<a name="ln5770">    if (metadata-&gt;being_compacted) {</a>
<a name="ln5771">      RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,</a>
<a name="ln5772">          &quot;DeleteFile %s Skipped. File about to be compacted\n&quot;, name.c_str());</a>
<a name="ln5773">      job_context.Clean();</a>
<a name="ln5774">      return Status::OK();</a>
<a name="ln5775">    }</a>
<a name="ln5776"> </a>
<a name="ln5777">    // Only the files in the last level can be deleted externally.</a>
<a name="ln5778">    // This is to make sure that any deletion tombstones are not</a>
<a name="ln5779">    // lost. Check that the level passed is the last level.</a>
<a name="ln5780">    auto* vstoreage = cfd-&gt;current()-&gt;storage_info();</a>
<a name="ln5781">    for (int i = level + 1; i &lt; cfd-&gt;NumberLevels(); i++) {</a>
<a name="ln5782">      if (vstoreage-&gt;NumLevelFiles(i) != 0) {</a>
<a name="ln5783">        RLOG(InfoLogLevel::WARN_LEVEL, db_options_.info_log,</a>
<a name="ln5784">            &quot;DeleteFile %s FAILED. File not in last level\n&quot;, name.c_str());</a>
<a name="ln5785">        job_context.Clean();</a>
<a name="ln5786">        return STATUS(InvalidArgument, &quot;File not in last level&quot;);</a>
<a name="ln5787">      }</a>
<a name="ln5788">    }</a>
<a name="ln5789">    // if level == 0, it has to be the oldest file</a>
<a name="ln5790">    if (level == 0 &amp;&amp;</a>
<a name="ln5791">        vstoreage-&gt;LevelFiles(0).back()-&gt;fd.GetNumber() != number) {</a>
<a name="ln5792">      RLOG(InfoLogLevel::WARN_LEVEL, db_options_.info_log,</a>
<a name="ln5793">          &quot;DeleteFile %s failed ---&quot;</a>
<a name="ln5794">          &quot; target file in level 0 must be the oldest. Expected: %&quot; PRIu64, name.c_str(), number);</a>
<a name="ln5795">      job_context.Clean();</a>
<a name="ln5796">      return STATUS(InvalidArgument, &quot;File in level 0, but not oldest&quot;);</a>
<a name="ln5797">    }</a>
<a name="ln5798">    edit.SetColumnFamily(cfd-&gt;GetID());</a>
<a name="ln5799">    edit.DeleteFile(level, number);</a>
<a name="ln5800">    status = versions_-&gt;LogAndApply(cfd, *cfd-&gt;GetLatestMutableCFOptions(),</a>
<a name="ln5801">                                    &amp;edit, &amp;mutex_, directories_.GetDbDir());</a>
<a name="ln5802">    if (status.ok()) {</a>
<a name="ln5803">      InstallSuperVersionAndScheduleWorkWrapper(</a>
<a name="ln5804">          cfd, &amp;job_context, *cfd-&gt;GetLatestMutableCFOptions());</a>
<a name="ln5805">    }</a>
<a name="ln5806">    FindObsoleteFiles(&amp;job_context, false);</a>
<a name="ln5807">  }  // lock released here</a>
<a name="ln5808"> </a>
<a name="ln5809">  LogFlush(db_options_.info_log);</a>
<a name="ln5810">  // remove files outside the db-lock</a>
<a name="ln5811">  if (job_context.HaveSomethingToDelete()) {</a>
<a name="ln5812">    // Call PurgeObsoleteFiles() without holding mutex.</a>
<a name="ln5813">    PurgeObsoleteFiles(job_context);</a>
<a name="ln5814">  }</a>
<a name="ln5815">  job_context.Clean();</a>
<a name="ln5816"> </a>
<a name="ln5817">  FilesChanged();</a>
<a name="ln5818"> </a>
<a name="ln5819">  return status;</a>
<a name="ln5820">}</a>
<a name="ln5821"> </a>
<a name="ln5822">Status DBImpl::DeleteFilesInRange(ColumnFamilyHandle* column_family,</a>
<a name="ln5823">                                  const Slice* begin, const Slice* end) {</a>
<a name="ln5824">  Status status;</a>
<a name="ln5825">  auto cfh = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family);</a>
<a name="ln5826">  ColumnFamilyData* cfd = cfh-&gt;cfd();</a>
<a name="ln5827">  VersionEdit edit;</a>
<a name="ln5828">  std::vector&lt;FileMetaData*&gt; deleted_files;</a>
<a name="ln5829">  JobContext job_context(next_job_id_.fetch_add(1), true);</a>
<a name="ln5830">  {</a>
<a name="ln5831">    InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln5832">    Version* input_version = cfd-&gt;current();</a>
<a name="ln5833"> </a>
<a name="ln5834">    auto* vstorage = input_version-&gt;storage_info();</a>
<a name="ln5835">    for (int i = 1; i &lt; cfd-&gt;NumberLevels(); i++) {</a>
<a name="ln5836">      if (vstorage-&gt;LevelFiles(i).empty() ||</a>
<a name="ln5837">          !vstorage-&gt;OverlapInLevel(i, begin, end)) {</a>
<a name="ln5838">        continue;</a>
<a name="ln5839">      }</a>
<a name="ln5840">      std::vector&lt;FileMetaData*&gt; level_files;</a>
<a name="ln5841">      InternalKey begin_storage, end_storage, *begin_key, *end_key;</a>
<a name="ln5842">      if (begin == nullptr) {</a>
<a name="ln5843">        begin_key = nullptr;</a>
<a name="ln5844">      } else {</a>
<a name="ln5845">        begin_storage = InternalKey::MaxPossibleForUserKey(*begin);</a>
<a name="ln5846">        begin_key = &amp;begin_storage;</a>
<a name="ln5847">      }</a>
<a name="ln5848">      if (end == nullptr) {</a>
<a name="ln5849">        end_key = nullptr;</a>
<a name="ln5850">      } else {</a>
<a name="ln5851">        end_storage = InternalKey::MinPossibleForUserKey(*end);</a>
<a name="ln5852">        end_key = &amp;end_storage;</a>
<a name="ln5853">      }</a>
<a name="ln5854"> </a>
<a name="ln5855">      vstorage-&gt;GetOverlappingInputs(i, begin_key, end_key, &amp;level_files, -1,</a>
<a name="ln5856">                                     nullptr, false);</a>
<a name="ln5857">      FileMetaData* level_file;</a>
<a name="ln5858">      for (uint32_t j = 0; j &lt; level_files.size(); j++) {</a>
<a name="ln5859">        level_file = level_files[j];</a>
<a name="ln5860">        if (((begin == nullptr) ||</a>
<a name="ln5861">             (cfd-&gt;internal_comparator()-&gt;user_comparator()-&gt;Compare(</a>
<a name="ln5862">                  level_file-&gt;smallest.key.user_key(), *begin) &gt;= 0)) &amp;&amp;</a>
<a name="ln5863">            ((end == nullptr) ||</a>
<a name="ln5864">             (cfd-&gt;internal_comparator()-&gt;user_comparator()-&gt;Compare(</a>
<a name="ln5865">                  level_file-&gt;largest.key.user_key(), *end) &lt;= 0))) {</a>
<a name="ln5866">          if (level_file-&gt;being_compacted) {</a>
<a name="ln5867">            continue;</a>
<a name="ln5868">          }</a>
<a name="ln5869">          edit.SetColumnFamily(cfd-&gt;GetID());</a>
<a name="ln5870">          edit.DeleteFile(i, level_file-&gt;fd.GetNumber());</a>
<a name="ln5871">          deleted_files.push_back(level_file);</a>
<a name="ln5872">          level_file-&gt;being_compacted = true;</a>
<a name="ln5873">        }</a>
<a name="ln5874">      }</a>
<a name="ln5875">    }</a>
<a name="ln5876">    if (edit.GetDeletedFiles().empty()) {</a>
<a name="ln5877">      job_context.Clean();</a>
<a name="ln5878">      return Status::OK();</a>
<a name="ln5879">    }</a>
<a name="ln5880">    input_version-&gt;Ref();</a>
<a name="ln5881">    status = versions_-&gt;LogAndApply(cfd, *cfd-&gt;GetLatestMutableCFOptions(),</a>
<a name="ln5882">                                    &amp;edit, &amp;mutex_, directories_.GetDbDir());</a>
<a name="ln5883">    if (status.ok()) {</a>
<a name="ln5884">      InstallSuperVersionAndScheduleWorkWrapper(</a>
<a name="ln5885">          cfd, &amp;job_context, *cfd-&gt;GetLatestMutableCFOptions());</a>
<a name="ln5886">    }</a>
<a name="ln5887">    for (auto* deleted_file : deleted_files) {</a>
<a name="ln5888">      deleted_file-&gt;being_compacted = false;</a>
<a name="ln5889">    }</a>
<a name="ln5890">    input_version-&gt;Unref();</a>
<a name="ln5891">    FindObsoleteFiles(&amp;job_context, false);</a>
<a name="ln5892">  }  // lock released here</a>
<a name="ln5893"> </a>
<a name="ln5894">  LogFlush(db_options_.info_log);</a>
<a name="ln5895">  // remove files outside the db-lock</a>
<a name="ln5896">  if (job_context.HaveSomethingToDelete()) {</a>
<a name="ln5897">    // Call PurgeObsoleteFiles() without holding mutex.</a>
<a name="ln5898">    PurgeObsoleteFiles(job_context);</a>
<a name="ln5899">  }</a>
<a name="ln5900">  job_context.Clean();</a>
<a name="ln5901">  return status;</a>
<a name="ln5902">}</a>
<a name="ln5903"> </a>
<a name="ln5904">void DBImpl::GetLiveFilesMetaData(std::vector&lt;LiveFileMetaData&gt;* metadata) {</a>
<a name="ln5905">  InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln5906">  versions_-&gt;GetLiveFilesMetaData(metadata);</a>
<a name="ln5907">}</a>
<a name="ln5908"> </a>
<a name="ln5909">UserFrontierPtr DBImpl::GetFlushedFrontier() {</a>
<a name="ln5910">  InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln5911">  auto result = versions_-&gt;FlushedFrontier();</a>
<a name="ln5912">  if (result) {</a>
<a name="ln5913">    return result-&gt;Clone();</a>
<a name="ln5914">  }</a>
<a name="ln5915">  std::vector&lt;LiveFileMetaData&gt; files;</a>
<a name="ln5916">  versions_-&gt;GetLiveFilesMetaData(&amp;files);</a>
<a name="ln5917">  UserFrontierPtr accumulated;</a>
<a name="ln5918">  for (const auto&amp; file : files) {</a>
<a name="ln5919">    if (!file.imported) {</a>
<a name="ln5920">      UserFrontier::Update(</a>
<a name="ln5921">          file.largest.user_frontier.get(), UpdateUserValueType::kLargest, &amp;accumulated);</a>
<a name="ln5922">    }</a>
<a name="ln5923">  }</a>
<a name="ln5924">  return accumulated;</a>
<a name="ln5925">}</a>
<a name="ln5926"> </a>
<a name="ln5927">UserFrontierPtr DBImpl::GetMutableMemTableFrontier(UpdateUserValueType type) {</a>
<a name="ln5928">  InstrumentedMutexLock l(&amp;mutex_);</a>
<a name="ln5929">  UserFrontierPtr accumulated;</a>
<a name="ln5930">  for (auto cfd : *versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln5931">    if (cfd) {</a>
<a name="ln5932">      const auto* mem = cfd-&gt;mem();</a>
<a name="ln5933">      if (mem) {</a>
<a name="ln5934">        if (!cfd-&gt;IsDropped() &amp;&amp; cfd-&gt;imm()-&gt;NumNotFlushed() == 0 &amp;&amp; !mem-&gt;IsEmpty()) {</a>
<a name="ln5935">          auto frontier = mem-&gt;GetFrontier(type);</a>
<a name="ln5936">          if (frontier) {</a>
<a name="ln5937">            UserFrontier::Update(frontier.get(), type, &amp;accumulated);</a>
<a name="ln5938">          } else {</a>
<a name="ln5939">            YB_LOG_EVERY_N_SECS(DFATAL, 5)</a>
<a name="ln5940">                &lt;&lt; db_options_.log_prefix &lt;&lt; &quot;[&quot; &lt;&lt; cfd-&gt;GetName()</a>
<a name="ln5941">                &lt;&lt; &quot;] &quot; &lt;&lt; ToString(type) &lt;&lt; &quot; frontier is not initialized for non-empty MemTable&quot;;</a>
<a name="ln5942">          }</a>
<a name="ln5943">        }</a>
<a name="ln5944">      } else {</a>
<a name="ln5945">        YB_LOG_EVERY_N_SECS(WARNING, 5) &lt;&lt; db_options_.log_prefix</a>
<a name="ln5946">                                        &lt;&lt; &quot;[&quot; &lt;&lt; cfd-&gt;GetName()</a>
<a name="ln5947">                                        &lt;&lt; &quot;] mem is expected to be non-nullptr here&quot;;</a>
<a name="ln5948">      }</a>
<a name="ln5949">    } else {</a>
<a name="ln5950">      YB_LOG_EVERY_N_SECS(WARNING, 5) &lt;&lt; db_options_.log_prefix</a>
<a name="ln5951">                                      &lt;&lt; &quot;cfd is expected to be non-nullptr here&quot;;</a>
<a name="ln5952">    }</a>
<a name="ln5953">  }</a>
<a name="ln5954">  return accumulated;</a>
<a name="ln5955">}</a>
<a name="ln5956"> </a>
<a name="ln5957">Status DBImpl::ApplyVersionEdit(VersionEdit* edit) {</a>
<a name="ln5958">  auto cfd = versions_-&gt;GetColumnFamilySet()-&gt;GetDefault();</a>
<a name="ln5959">  InstrumentedMutexLock lock(&amp;mutex_);</a>
<a name="ln5960">  auto status = versions_-&gt;LogAndApply(cfd, *cfd-&gt;GetCurrentMutableCFOptions(), edit, &amp;mutex_);</a>
<a name="ln5961">  if (!status.ok()) {</a>
<a name="ln5962">    return status;</a>
<a name="ln5963">  }</a>
<a name="ln5964">  cfd-&gt;InstallSuperVersion(new SuperVersion(), &amp;mutex_);</a>
<a name="ln5965"> </a>
<a name="ln5966">  return Status::OK();</a>
<a name="ln5967">}</a>
<a name="ln5968"> </a>
<a name="ln5969">Status DBImpl::ModifyFlushedFrontier(UserFrontierPtr frontier, FrontierModificationMode mode) {</a>
<a name="ln5970">  VersionEdit edit;</a>
<a name="ln5971">  edit.ModifyFlushedFrontier(std::move(frontier), mode);</a>
<a name="ln5972">  return ApplyVersionEdit(&amp;edit);</a>
<a name="ln5973">}</a>
<a name="ln5974"> </a>
<a name="ln5975">void DBImpl::GetColumnFamilyMetaData(</a>
<a name="ln5976">    ColumnFamilyHandle* column_family,</a>
<a name="ln5977">    ColumnFamilyMetaData* cf_meta) {</a>
<a name="ln5978">  assert(column_family);</a>
<a name="ln5979">  auto* cfd = down_cast&lt;ColumnFamilyHandleImpl*&gt;(column_family)-&gt;cfd();</a>
<a name="ln5980">  auto* sv = GetAndRefSuperVersion(cfd);</a>
<a name="ln5981">  sv-&gt;current-&gt;GetColumnFamilyMetaData(cf_meta);</a>
<a name="ln5982">  ReturnAndCleanupSuperVersion(cfd, sv);</a>
<a name="ln5983">}</a>
<a name="ln5984"> </a>
<a name="ln5985">#endif  // ROCKSDB_LITE</a>
<a name="ln5986"> </a>
<a name="ln5987">Status DBImpl::CheckConsistency() {</a>
<a name="ln5988">  mutex_.AssertHeld();</a>
<a name="ln5989">  std::vector&lt;LiveFileMetaData&gt; metadata;</a>
<a name="ln5990">  versions_-&gt;GetLiveFilesMetaData(&amp;metadata);</a>
<a name="ln5991"> </a>
<a name="ln5992">  std::string corruption_messages;</a>
<a name="ln5993">  for (const auto&amp; md : metadata) {</a>
<a name="ln5994">    // md.name has a leading &quot;/&quot;.</a>
<a name="ln5995">    std::string base_file_path = md.db_path + md.name;</a>
<a name="ln5996">    uint64_t base_fsize = 0;</a>
<a name="ln5997">    Status s = env_-&gt;GetFileSize(base_file_path, &amp;base_fsize);</a>
<a name="ln5998">    if (!s.ok() &amp;&amp;</a>
<a name="ln5999">        env_-&gt;GetFileSize(Rocks2LevelTableFileName(base_file_path), &amp;base_fsize).ok()) {</a>
<a name="ln6000">      s = Status::OK();</a>
<a name="ln6001">    }</a>
<a name="ln6002">    if (!s.ok()) {</a>
<a name="ln6003">      corruption_messages +=</a>
<a name="ln6004">          &quot;Can't access &quot; + md.name + &quot;: &quot; + s.ToString() + &quot;\n&quot;;</a>
<a name="ln6005">    } else if (base_fsize != md.base_size) {</a>
<a name="ln6006">      corruption_messages += &quot;Sst base file size mismatch: &quot; + base_file_path +</a>
<a name="ln6007">                             &quot;. Size recorded in manifest &quot; +</a>
<a name="ln6008">                             ToString(md.base_size) + &quot;, actual size &quot; +</a>
<a name="ln6009">                             ToString(base_fsize) + &quot;\n&quot;;</a>
<a name="ln6010">    }</a>
<a name="ln6011">    if (md.total_size &gt; md.base_size) {</a>
<a name="ln6012">      const std::string data_file_path = TableBaseToDataFileName(base_file_path);</a>
<a name="ln6013">      uint64_t data_fsize = 0;</a>
<a name="ln6014">      s = env_-&gt;GetFileSize(data_file_path, &amp;data_fsize);</a>
<a name="ln6015">      const uint64_t md_data_size = md.total_size - md.base_size;</a>
<a name="ln6016">      if (!s.ok()) {</a>
<a name="ln6017">        corruption_messages +=</a>
<a name="ln6018">            &quot;Can't access &quot; + TableBaseToDataFileName(md.name) + &quot;: &quot; + s.ToString() + &quot;\n&quot;;</a>
<a name="ln6019">      } else if (data_fsize != md_data_size) {</a>
<a name="ln6020">        corruption_messages += &quot;Sst data file size mismatch: &quot; + data_file_path +</a>
<a name="ln6021">            &quot;. Data size based on total and base size recorded in manifest &quot; +</a>
<a name="ln6022">            ToString(md_data_size) + &quot;, actual data size &quot; +</a>
<a name="ln6023">            ToString(data_fsize) + &quot;\n&quot;;</a>
<a name="ln6024">      }</a>
<a name="ln6025">    }</a>
<a name="ln6026">  }</a>
<a name="ln6027">  if (corruption_messages.size() == 0) {</a>
<a name="ln6028">    return Status::OK();</a>
<a name="ln6029">  } else {</a>
<a name="ln6030">    return STATUS(Corruption, corruption_messages);</a>
<a name="ln6031">  }</a>
<a name="ln6032">}</a>
<a name="ln6033"> </a>
<a name="ln6034">Status DBImpl::GetDbIdentity(std::string* identity) const {</a>
<a name="ln6035">  std::string idfilename = IdentityFileName(dbname_);</a>
<a name="ln6036">  const EnvOptions soptions;</a>
<a name="ln6037">  unique_ptr&lt;SequentialFileReader&gt; id_file_reader;</a>
<a name="ln6038">  Status s;</a>
<a name="ln6039">  {</a>
<a name="ln6040">    unique_ptr&lt;SequentialFile&gt; idfile;</a>
<a name="ln6041">    s = env_-&gt;NewSequentialFile(idfilename, &amp;idfile, soptions);</a>
<a name="ln6042">    if (!s.ok()) {</a>
<a name="ln6043">      return s;</a>
<a name="ln6044">    }</a>
<a name="ln6045">    id_file_reader.reset(new SequentialFileReader(std::move(idfile)));</a>
<a name="ln6046">  }</a>
<a name="ln6047"> </a>
<a name="ln6048">  uint64_t file_size;</a>
<a name="ln6049">  s = env_-&gt;GetFileSize(idfilename, &amp;file_size);</a>
<a name="ln6050">  if (!s.ok()) {</a>
<a name="ln6051">    return s;</a>
<a name="ln6052">  }</a>
<a name="ln6053">  uint8_t* buffer = reinterpret_cast&lt;uint8_t*&gt;(alloca(file_size));</a>
<a name="ln6054">  Slice id;</a>
<a name="ln6055">  s = id_file_reader-&gt;Read(static_cast&lt;size_t&gt;(file_size), &amp;id, buffer);</a>
<a name="ln6056">  if (!s.ok()) {</a>
<a name="ln6057">    return s;</a>
<a name="ln6058">  }</a>
<a name="ln6059">  identity-&gt;assign(id.cdata(), id.size());</a>
<a name="ln6060">  // If last character is '\n' remove it from identity</a>
<a name="ln6061">  if (!identity-&gt;empty() &amp;&amp; identity-&gt;back() == '\n') {</a>
<a name="ln6062">    identity-&gt;pop_back();</a>
<a name="ln6063">  }</a>
<a name="ln6064">  return s;</a>
<a name="ln6065">}</a>
<a name="ln6066"> </a>
<a name="ln6067">// Default implementations of convenience methods that subclasses of DB</a>
<a name="ln6068">// can call if they wish</a>
<a name="ln6069">Status DB::Put(const WriteOptions&amp; opt, ColumnFamilyHandle* column_family,</a>
<a name="ln6070">               const Slice&amp; key, const Slice&amp; value) {</a>
<a name="ln6071">  // Pre-allocate size of write batch conservatively.</a>
<a name="ln6072">  // 8 bytes are taken by header, 4 bytes for count, 1 byte for type,</a>
<a name="ln6073">  // and we allocate 11 extra bytes for key length, as well as value length.</a>
<a name="ln6074">  WriteBatch batch(key.size() + value.size() + 24);</a>
<a name="ln6075">  batch.Put(column_family, key, value);</a>
<a name="ln6076">  return Write(opt, &amp;batch);</a>
<a name="ln6077">}</a>
<a name="ln6078"> </a>
<a name="ln6079">Status DB::Delete(const WriteOptions&amp; opt, ColumnFamilyHandle* column_family,</a>
<a name="ln6080">                  const Slice&amp; key) {</a>
<a name="ln6081">  WriteBatch batch;</a>
<a name="ln6082">  batch.Delete(column_family, key);</a>
<a name="ln6083">  return Write(opt, &amp;batch);</a>
<a name="ln6084">}</a>
<a name="ln6085"> </a>
<a name="ln6086">Status DB::SingleDelete(const WriteOptions&amp; opt,</a>
<a name="ln6087">                        ColumnFamilyHandle* column_family, const Slice&amp; key) {</a>
<a name="ln6088">  WriteBatch batch;</a>
<a name="ln6089">  batch.SingleDelete(column_family, key);</a>
<a name="ln6090">  return Write(opt, &amp;batch);</a>
<a name="ln6091">}</a>
<a name="ln6092"> </a>
<a name="ln6093">Status DB::Merge(const WriteOptions&amp; opt, ColumnFamilyHandle* column_family,</a>
<a name="ln6094">                 const Slice&amp; key, const Slice&amp; value) {</a>
<a name="ln6095">  WriteBatch batch;</a>
<a name="ln6096">  batch.Merge(column_family, key, value);</a>
<a name="ln6097">  return Write(opt, &amp;batch);</a>
<a name="ln6098">}</a>
<a name="ln6099"> </a>
<a name="ln6100">// Default implementation -- returns not supported status</a>
<a name="ln6101">Status DB::CreateColumnFamily(const ColumnFamilyOptions&amp; cf_options,</a>
<a name="ln6102">                              const std::string&amp; column_family_name,</a>
<a name="ln6103">                              ColumnFamilyHandle** handle) {</a>
<a name="ln6104">  return STATUS(NotSupported, &quot;&quot;);</a>
<a name="ln6105">}</a>
<a name="ln6106">Status DB::DropColumnFamily(ColumnFamilyHandle* column_family) {</a>
<a name="ln6107">  return STATUS(NotSupported, &quot;&quot;);</a>
<a name="ln6108">}</a>
<a name="ln6109"> </a>
<a name="ln6110">DB::~DB() { }</a>
<a name="ln6111"> </a>
<a name="ln6112">Status DB::Open(const Options&amp; options, const std::string&amp; dbname, DB** dbptr) {</a>
<a name="ln6113">  DBOptions db_options(options);</a>
<a name="ln6114">  ColumnFamilyOptions cf_options(options);</a>
<a name="ln6115">  std::vector&lt;ColumnFamilyDescriptor&gt; column_families;</a>
<a name="ln6116">  column_families.push_back(</a>
<a name="ln6117">      ColumnFamilyDescriptor(kDefaultColumnFamilyName, cf_options));</a>
<a name="ln6118">  std::vector&lt;ColumnFamilyHandle*&gt; handles;</a>
<a name="ln6119">  Status s = DB::Open(db_options, dbname, column_families, &amp;handles, dbptr);</a>
<a name="ln6120">  if (s.ok()) {</a>
<a name="ln6121">    assert(handles.size() == 1);</a>
<a name="ln6122">    // i can delete the handle since DBImpl is always holding a reference to</a>
<a name="ln6123">    // default column family</a>
<a name="ln6124">    delete handles[0];</a>
<a name="ln6125">  }</a>
<a name="ln6126">  return s;</a>
<a name="ln6127">}</a>
<a name="ln6128"> </a>
<a name="ln6129">Status DB::Open(const DBOptions&amp; db_options, const std::string&amp; dbname,</a>
<a name="ln6130">                const std::vector&lt;ColumnFamilyDescriptor&gt;&amp; column_families,</a>
<a name="ln6131">                std::vector&lt;ColumnFamilyHandle*&gt;* handles, DB** dbptr) {</a>
<a name="ln6132">  Status s = SanitizeOptionsByTable(db_options, column_families);</a>
<a name="ln6133">  if (!s.ok()) {</a>
<a name="ln6134">    return s;</a>
<a name="ln6135">  }</a>
<a name="ln6136"> </a>
<a name="ln6137">  for (auto&amp; cfd : column_families) {</a>
<a name="ln6138">    s = CheckCompressionSupported(cfd.options);</a>
<a name="ln6139">    if (s.ok() &amp;&amp; db_options.allow_concurrent_memtable_write) {</a>
<a name="ln6140">      s = CheckConcurrentWritesSupported(cfd.options);</a>
<a name="ln6141">    }</a>
<a name="ln6142">    if (!s.ok()) {</a>
<a name="ln6143">      return s;</a>
<a name="ln6144">    }</a>
<a name="ln6145">    if (db_options.db_paths.size() &gt; 1) {</a>
<a name="ln6146">      if ((cfd.options.compaction_style != kCompactionStyleUniversal) &amp;&amp;</a>
<a name="ln6147">          (cfd.options.compaction_style != kCompactionStyleLevel)) {</a>
<a name="ln6148">        return STATUS(NotSupported,</a>
<a name="ln6149">            &quot;More than one DB paths are only supported in &quot;</a>
<a name="ln6150">            &quot;universal and level compaction styles. &quot;);</a>
<a name="ln6151">      }</a>
<a name="ln6152">    }</a>
<a name="ln6153">  }</a>
<a name="ln6154"> </a>
<a name="ln6155">  if (db_options.db_paths.size() &gt; 4) {</a>
<a name="ln6156">    return STATUS(NotSupported,</a>
<a name="ln6157">        &quot;More than four DB paths are not supported yet. &quot;);</a>
<a name="ln6158">  }</a>
<a name="ln6159"> </a>
<a name="ln6160">  *dbptr = nullptr;</a>
<a name="ln6161">  handles-&gt;clear();</a>
<a name="ln6162"> </a>
<a name="ln6163">  size_t max_write_buffer_size = 0;</a>
<a name="ln6164">  for (auto cf : column_families) {</a>
<a name="ln6165">    max_write_buffer_size =</a>
<a name="ln6166">        std::max(max_write_buffer_size, cf.options.write_buffer_size);</a>
<a name="ln6167">  }</a>
<a name="ln6168"> </a>
<a name="ln6169">  DBImpl* impl = new DBImpl(db_options, dbname);</a>
<a name="ln6170">  for (auto db_path : impl-&gt;db_options_.db_paths) {</a>
<a name="ln6171">    s = impl-&gt;env_-&gt;CreateDirIfMissing(db_path.path);</a>
<a name="ln6172">    if (!s.ok()) {</a>
<a name="ln6173">      break;</a>
<a name="ln6174">    }</a>
<a name="ln6175">  }</a>
<a name="ln6176">  // WAL dir could be inside other paths, so we create it after.</a>
<a name="ln6177">  if (s.ok()) {</a>
<a name="ln6178">    s = impl-&gt;env_-&gt;CreateDirIfMissing(impl-&gt;db_options_.wal_dir);</a>
<a name="ln6179">  }</a>
<a name="ln6180"> </a>
<a name="ln6181">  if (!s.ok()) {</a>
<a name="ln6182">    delete impl;</a>
<a name="ln6183">    return s;</a>
<a name="ln6184">  }</a>
<a name="ln6185"> </a>
<a name="ln6186">  s = impl-&gt;CreateArchivalDirectory();</a>
<a name="ln6187">  if (!s.ok()) {</a>
<a name="ln6188">    delete impl;</a>
<a name="ln6189">    return s;</a>
<a name="ln6190">  }</a>
<a name="ln6191">  impl-&gt;mutex_.Lock();</a>
<a name="ln6192">  // Handles create_if_missing, error_if_exists</a>
<a name="ln6193">  s = impl-&gt;Recover(column_families);</a>
<a name="ln6194">  if (s.ok()) {</a>
<a name="ln6195">    uint64_t new_log_number = impl-&gt;versions_-&gt;NewFileNumber();</a>
<a name="ln6196">    unique_ptr&lt;WritableFile&gt; lfile;</a>
<a name="ln6197">    EnvOptions soptions(db_options);</a>
<a name="ln6198">    EnvOptions opt_env_options =</a>
<a name="ln6199">        impl-&gt;db_options_.env-&gt;OptimizeForLogWrite(soptions, impl-&gt;db_options_);</a>
<a name="ln6200">    s = NewWritableFile(impl-&gt;db_options_.env,</a>
<a name="ln6201">                        LogFileName(impl-&gt;db_options_.wal_dir, new_log_number),</a>
<a name="ln6202">                        &amp;lfile, opt_env_options);</a>
<a name="ln6203">    if (s.ok()) {</a>
<a name="ln6204">      lfile-&gt;SetPreallocationBlockSize((max_write_buffer_size / 10) + max_write_buffer_size);</a>
<a name="ln6205">      impl-&gt;logfile_number_ = new_log_number;</a>
<a name="ln6206">      unique_ptr&lt;WritableFileWriter&gt; file_writer(</a>
<a name="ln6207">          new WritableFileWriter(std::move(lfile), opt_env_options));</a>
<a name="ln6208">      impl-&gt;logs_.emplace_back(</a>
<a name="ln6209">          new_log_number,</a>
<a name="ln6210">          new log::Writer(std::move(file_writer), new_log_number,</a>
<a name="ln6211">                          impl-&gt;db_options_.recycle_log_file_num &gt; 0));</a>
<a name="ln6212"> </a>
<a name="ln6213">      // set column family handles</a>
<a name="ln6214">      for (auto cf : column_families) {</a>
<a name="ln6215">        auto cfd =</a>
<a name="ln6216">            impl-&gt;versions_-&gt;GetColumnFamilySet()-&gt;GetColumnFamily(cf.name);</a>
<a name="ln6217">        if (cfd != nullptr) {</a>
<a name="ln6218">          handles-&gt;push_back(</a>
<a name="ln6219">              new ColumnFamilyHandleImpl(cfd, impl, &amp;impl-&gt;mutex_));</a>
<a name="ln6220">          impl-&gt;NewThreadStatusCfInfo(cfd);</a>
<a name="ln6221">        } else {</a>
<a name="ln6222">          if (db_options.create_missing_column_families) {</a>
<a name="ln6223">            // missing column family, create it</a>
<a name="ln6224">            ColumnFamilyHandle* handle;</a>
<a name="ln6225">            impl-&gt;mutex_.Unlock();</a>
<a name="ln6226">            s = impl-&gt;CreateColumnFamily(cf.options, cf.name, &amp;handle);</a>
<a name="ln6227">            impl-&gt;mutex_.Lock();</a>
<a name="ln6228">            if (s.ok()) {</a>
<a name="ln6229">              handles-&gt;push_back(handle);</a>
<a name="ln6230">            } else {</a>
<a name="ln6231">              break;</a>
<a name="ln6232">            }</a>
<a name="ln6233">          } else {</a>
<a name="ln6234">            s = STATUS(InvalidArgument, &quot;Column family not found: &quot;, cf.name);</a>
<a name="ln6235">            break;</a>
<a name="ln6236">          }</a>
<a name="ln6237">        }</a>
<a name="ln6238">      }</a>
<a name="ln6239">    }</a>
<a name="ln6240">    if (s.ok()) {</a>
<a name="ln6241">      for (auto cfd : *impl-&gt;versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln6242">        impl-&gt;InstallSuperVersionAndScheduleWork(cfd, nullptr, *cfd-&gt;GetLatestMutableCFOptions());</a>
<a name="ln6243">      }</a>
<a name="ln6244">      impl-&gt;alive_log_files_.push_back(</a>
<a name="ln6245">          DBImpl::LogFileNumberSize(impl-&gt;logfile_number_));</a>
<a name="ln6246">      impl-&gt;DeleteObsoleteFiles();</a>
<a name="ln6247">      s = impl-&gt;directories_.GetDbDir()-&gt;Fsync();</a>
<a name="ln6248">    }</a>
<a name="ln6249">  }</a>
<a name="ln6250"> </a>
<a name="ln6251">  if (s.ok()) {</a>
<a name="ln6252">    for (auto cfd : *impl-&gt;versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln6253">      if (cfd-&gt;ioptions()-&gt;compaction_style == kCompactionStyleFIFO) {</a>
<a name="ln6254">        auto* vstorage = cfd-&gt;current()-&gt;storage_info();</a>
<a name="ln6255">        for (int i = 1; i &lt; vstorage-&gt;num_levels(); ++i) {</a>
<a name="ln6256">          int num_files = vstorage-&gt;NumLevelFiles(i);</a>
<a name="ln6257">          if (num_files &gt; 0) {</a>
<a name="ln6258">            s = STATUS(InvalidArgument,</a>
<a name="ln6259">                &quot;Not all files are at level 0. Cannot &quot;</a>
<a name="ln6260">                &quot;open with FIFO compaction style.&quot;);</a>
<a name="ln6261">            break;</a>
<a name="ln6262">          }</a>
<a name="ln6263">        }</a>
<a name="ln6264">      }</a>
<a name="ln6265">      if (!cfd-&gt;mem()-&gt;IsSnapshotSupported()) {</a>
<a name="ln6266">        impl-&gt;is_snapshot_supported_ = false;</a>
<a name="ln6267">      }</a>
<a name="ln6268">      if (cfd-&gt;ioptions()-&gt;merge_operator != nullptr &amp;&amp;</a>
<a name="ln6269">          !cfd-&gt;mem()-&gt;IsMergeOperatorSupported()) {</a>
<a name="ln6270">        s = STATUS(InvalidArgument,</a>
<a name="ln6271">            &quot;The memtable of column family %s does not support merge operator &quot;</a>
<a name="ln6272">            &quot;its options.merge_operator is non-null&quot;, cfd-&gt;GetName().c_str());</a>
<a name="ln6273">      }</a>
<a name="ln6274">      if (!s.ok()) {</a>
<a name="ln6275">        break;</a>
<a name="ln6276">      }</a>
<a name="ln6277">    }</a>
<a name="ln6278">  }</a>
<a name="ln6279">  TEST_SYNC_POINT(&quot;DBImpl::Open:Opened&quot;);</a>
<a name="ln6280">  Status persist_options_status;</a>
<a name="ln6281">  if (s.ok()) {</a>
<a name="ln6282">    // Persist RocksDB Options before scheduling the compaction.</a>
<a name="ln6283">    // The WriteOptionsFile() will release and lock the mutex internally.</a>
<a name="ln6284">    persist_options_status = impl-&gt;WriteOptionsFile();</a>
<a name="ln6285"> </a>
<a name="ln6286">    *dbptr = impl;</a>
<a name="ln6287">    impl-&gt;opened_successfully_ = true;</a>
<a name="ln6288">    impl-&gt;MaybeScheduleFlushOrCompaction();</a>
<a name="ln6289">  }</a>
<a name="ln6290">  impl-&gt;mutex_.Unlock();</a>
<a name="ln6291"> </a>
<a name="ln6292">  auto sfm = static_cast&lt;SstFileManagerImpl*&gt;(</a>
<a name="ln6293">      impl-&gt;db_options_.sst_file_manager.get());</a>
<a name="ln6294">  if (s.ok() &amp;&amp; sfm) {</a>
<a name="ln6295">    // Notify SstFileManager about all sst files that already exist in</a>
<a name="ln6296">    // db_paths[0] when the DB is opened.</a>
<a name="ln6297">    auto&amp; db_path = impl-&gt;db_options_.db_paths[0];</a>
<a name="ln6298">    std::vector&lt;std::string&gt; existing_files;</a>
<a name="ln6299">    RETURN_NOT_OK(impl-&gt;db_options_.env-&gt;GetChildren(db_path.path, &amp;existing_files));</a>
<a name="ln6300">    for (auto&amp; file_name : existing_files) {</a>
<a name="ln6301">      uint64_t file_number;</a>
<a name="ln6302">      FileType file_type;</a>
<a name="ln6303">      std::string file_path = db_path.path + &quot;/&quot; + file_name;</a>
<a name="ln6304">      if (ParseFileName(file_name, &amp;file_number, &amp;file_type) &amp;&amp;</a>
<a name="ln6305">          (file_type == kTableFile || file_type == kTableSBlockFile)) {</a>
<a name="ln6306">        RETURN_NOT_OK(sfm-&gt;OnAddFile(file_path));</a>
<a name="ln6307">      }</a>
<a name="ln6308">    }</a>
<a name="ln6309">  }</a>
<a name="ln6310"> </a>
<a name="ln6311">  if (s.ok()) {</a>
<a name="ln6312">    LogFlush(impl-&gt;db_options_.info_log);</a>
<a name="ln6313">    if (!persist_options_status.ok()) {</a>
<a name="ln6314">      if (db_options.fail_if_options_file_error) {</a>
<a name="ln6315">        s = STATUS(IOError,</a>
<a name="ln6316">            &quot;DB::Open() failed --- Unable to persist Options file&quot;,</a>
<a name="ln6317">            persist_options_status.ToString());</a>
<a name="ln6318">      }</a>
<a name="ln6319">      RWARN(impl-&gt;db_options_.info_log,</a>
<a name="ln6320">          &quot;Unable to persist options in DB::Open() -- %s&quot;,</a>
<a name="ln6321">          persist_options_status.ToString().c_str());</a>
<a name="ln6322">    }</a>
<a name="ln6323">  }</a>
<a name="ln6324">  if (!s.ok()) {</a>
<a name="ln6325">    for (auto* h : *handles) {</a>
<a name="ln6326">      delete h;</a>
<a name="ln6327">    }</a>
<a name="ln6328">    handles-&gt;clear();</a>
<a name="ln6329">    delete impl;</a>
<a name="ln6330">    *dbptr = nullptr;</a>
<a name="ln6331">  } else if (impl) {</a>
<a name="ln6332">    impl-&gt;SetSSTFileTickers();</a>
<a name="ln6333">  }</a>
<a name="ln6334"> </a>
<a name="ln6335">  return s;</a>
<a name="ln6336">}</a>
<a name="ln6337"> </a>
<a name="ln6338">yb::Result&lt;std::unique_ptr&lt;DB&gt;&gt; DB::Open(const Options&amp; options, const std::string&amp; name) {</a>
<a name="ln6339">  DB* db = nullptr;</a>
<a name="ln6340">  Status status = Open(options, name, &amp;db);</a>
<a name="ln6341">  if (!status.ok()) {</a>
<a name="ln6342">    delete db;</a>
<a name="ln6343">    return status;</a>
<a name="ln6344">  }</a>
<a name="ln6345">  return std::unique_ptr&lt;DB&gt;(db);</a>
<a name="ln6346">}</a>
<a name="ln6347"> </a>
<a name="ln6348">Status DB::ListColumnFamilies(const DBOptions&amp; db_options,</a>
<a name="ln6349">                              const std::string&amp; name,</a>
<a name="ln6350">                              std::vector&lt;std::string&gt;* column_families) {</a>
<a name="ln6351">  return VersionSet::ListColumnFamilies(column_families,</a>
<a name="ln6352">                                        name,</a>
<a name="ln6353">                                        db_options.boundary_extractor.get(),</a>
<a name="ln6354">                                        db_options.env);</a>
<a name="ln6355">}</a>
<a name="ln6356"> </a>
<a name="ln6357">Snapshot::~Snapshot() {</a>
<a name="ln6358">}</a>
<a name="ln6359"> </a>
<a name="ln6360">Status DestroyDB(const std::string&amp; dbname, const Options&amp; options) {</a>
<a name="ln6361">  const InternalKeyComparator comparator(options.comparator);</a>
<a name="ln6362">  const Options&amp; soptions(SanitizeOptions(dbname, &amp;comparator, options));</a>
<a name="ln6363">  Env* env = soptions.env;</a>
<a name="ln6364">  std::vector&lt;std::string&gt; filenames;</a>
<a name="ln6365"> </a>
<a name="ln6366">  // Ignore error in case directory does not exist</a>
<a name="ln6367">  env-&gt;GetChildrenWarnNotOk(dbname, &amp;filenames);</a>
<a name="ln6368"> </a>
<a name="ln6369">  FileLock* lock;</a>
<a name="ln6370">  const std::string lockname = LockFileName(dbname);</a>
<a name="ln6371">  Status result = env-&gt;LockFile(lockname, &amp;lock);</a>
<a name="ln6372">  if (result.ok()) {</a>
<a name="ln6373">    uint64_t number;</a>
<a name="ln6374">    FileType type;</a>
<a name="ln6375">    InfoLogPrefix info_log_prefix(!options.db_log_dir.empty(), dbname);</a>
<a name="ln6376">    for (size_t i = 0; i &lt; filenames.size(); i++) {</a>
<a name="ln6377">      if (ParseFileName(filenames[i], &amp;number, info_log_prefix.prefix, &amp;type) &amp;&amp;</a>
<a name="ln6378">          type != kDBLockFile) {  // Lock file will be deleted at end</a>
<a name="ln6379">        Status del;</a>
<a name="ln6380">        std::string path_to_delete = dbname + &quot;/&quot; + filenames[i];</a>
<a name="ln6381">        if (type == kMetaDatabase) {</a>
<a name="ln6382">          del = DestroyDB(path_to_delete, options);</a>
<a name="ln6383">        } else if (type == kTableFile || type == kTableSBlockFile) {</a>
<a name="ln6384">          del = DeleteSSTFile(&amp;options, path_to_delete, 0);</a>
<a name="ln6385">        } else {</a>
<a name="ln6386">          del = env-&gt;DeleteFile(path_to_delete);</a>
<a name="ln6387">        }</a>
<a name="ln6388">        if (result.ok() &amp;&amp; !del.ok()) {</a>
<a name="ln6389">          result = del;</a>
<a name="ln6390">        }</a>
<a name="ln6391">      }</a>
<a name="ln6392">    }</a>
<a name="ln6393"> </a>
<a name="ln6394">    for (size_t path_id = 0; path_id &lt; options.db_paths.size(); path_id++) {</a>
<a name="ln6395">      const auto&amp; db_path = options.db_paths[path_id];</a>
<a name="ln6396">      env-&gt;GetChildrenWarnNotOk(db_path.path, &amp;filenames);</a>
<a name="ln6397">      for (size_t i = 0; i &lt; filenames.size(); i++) {</a>
<a name="ln6398">        if (ParseFileName(filenames[i], &amp;number, &amp;type) &amp;&amp;</a>
<a name="ln6399">            // Lock file will be deleted at end</a>
<a name="ln6400">            (type == kTableFile || type == kTableSBlockFile)) {</a>
<a name="ln6401">          std::string table_path = db_path.path + &quot;/&quot; + filenames[i];</a>
<a name="ln6402">          Status del = DeleteSSTFile(&amp;options, table_path,</a>
<a name="ln6403">                                     static_cast&lt;uint32_t&gt;(path_id));</a>
<a name="ln6404">          if (result.ok() &amp;&amp; !del.ok()) {</a>
<a name="ln6405">            result = del;</a>
<a name="ln6406">          }</a>
<a name="ln6407">        }</a>
<a name="ln6408">      }</a>
<a name="ln6409">    }</a>
<a name="ln6410"> </a>
<a name="ln6411">    std::vector&lt;std::string&gt; walDirFiles;</a>
<a name="ln6412">    std::string archivedir = ArchivalDirectory(dbname);</a>
<a name="ln6413">    if (dbname != soptions.wal_dir) {</a>
<a name="ln6414">      env-&gt;GetChildrenWarnNotOk(soptions.wal_dir, &amp;walDirFiles);</a>
<a name="ln6415">      archivedir = ArchivalDirectory(soptions.wal_dir);</a>
<a name="ln6416">    }</a>
<a name="ln6417"> </a>
<a name="ln6418">    // Delete log files in the WAL dir</a>
<a name="ln6419">    for (const auto&amp; file : walDirFiles) {</a>
<a name="ln6420">      if (ParseFileName(file, &amp;number, &amp;type) &amp;&amp; type == kLogFile) {</a>
<a name="ln6421">        Status del = env-&gt;DeleteFile(soptions.wal_dir + &quot;/&quot; + file);</a>
<a name="ln6422">        if (result.ok() &amp;&amp; !del.ok()) {</a>
<a name="ln6423">          result = del;</a>
<a name="ln6424">        }</a>
<a name="ln6425">      }</a>
<a name="ln6426">    }</a>
<a name="ln6427"> </a>
<a name="ln6428">    std::vector&lt;std::string&gt; archiveFiles;</a>
<a name="ln6429">    env-&gt;GetChildrenWarnNotOk(archivedir, &amp;archiveFiles);</a>
<a name="ln6430">    // Delete archival files.</a>
<a name="ln6431">    for (size_t i = 0; i &lt; archiveFiles.size(); ++i) {</a>
<a name="ln6432">      if (ParseFileName(archiveFiles[i], &amp;number, &amp;type) &amp;&amp;</a>
<a name="ln6433">        type == kLogFile) {</a>
<a name="ln6434">        Status del = env-&gt;DeleteFile(archivedir + &quot;/&quot; + archiveFiles[i]);</a>
<a name="ln6435">        if (result.ok() &amp;&amp; !del.ok()) {</a>
<a name="ln6436">          result = del;</a>
<a name="ln6437">        }</a>
<a name="ln6438">      }</a>
<a name="ln6439">    }</a>
<a name="ln6440"> </a>
<a name="ln6441">    // ignore case where no archival directory is present.</a>
<a name="ln6442">    WARN_NOT_OK(env-&gt;DeleteDir(archivedir), &quot;Failed to cleanup dir &quot; + archivedir);</a>
<a name="ln6443"> </a>
<a name="ln6444">    WARN_NOT_OK(env-&gt;UnlockFile(lock), &quot;Unlock file failed&quot;);</a>
<a name="ln6445">    env-&gt;CleanupFile(lockname);</a>
<a name="ln6446">    WARN_NOT_OK(env-&gt;DeleteDir(dbname), &quot;Failed to cleanup dir &quot; + dbname);</a>
<a name="ln6447">    WARN_NOT_OK(env-&gt;DeleteDir(soptions.wal_dir), &quot;Failed to cleanup wal dir &quot; + soptions.wal_dir);</a>
<a name="ln6448">  }</a>
<a name="ln6449">  return result;</a>
<a name="ln6450">}</a>
<a name="ln6451"> </a>
<a name="ln6452">Status DBImpl::WriteOptionsFile() {</a>
<a name="ln6453">#ifndef ROCKSDB_LITE</a>
<a name="ln6454">  mutex_.AssertHeld();</a>
<a name="ln6455"> </a>
<a name="ln6456">  std::vector&lt;std::string&gt; cf_names;</a>
<a name="ln6457">  std::vector&lt;ColumnFamilyOptions&gt; cf_opts;</a>
<a name="ln6458"> </a>
<a name="ln6459">  // This part requires mutex to protect the column family options</a>
<a name="ln6460">  for (auto cfd : *versions_-&gt;GetColumnFamilySet()) {</a>
<a name="ln6461">    if (cfd-&gt;IsDropped()) {</a>
<a name="ln6462">      continue;</a>
<a name="ln6463">    }</a>
<a name="ln6464">    cf_names.push_back(cfd-&gt;GetName());</a>
<a name="ln6465">    cf_opts.push_back(BuildColumnFamilyOptions(</a>
<a name="ln6466">        *cfd-&gt;options(), *cfd-&gt;GetLatestMutableCFOptions()));</a>
<a name="ln6467">  }</a>
<a name="ln6468"> </a>
<a name="ln6469">  // Unlock during expensive operations.  New writes cannot get here</a>
<a name="ln6470">  // because the single write thread ensures all new writes get queued.</a>
<a name="ln6471">  mutex_.Unlock();</a>
<a name="ln6472"> </a>
<a name="ln6473">  std::string file_name =</a>
<a name="ln6474">      TempOptionsFileName(GetName(), versions_-&gt;NewFileNumber());</a>
<a name="ln6475">  Status s = PersistRocksDBOptions(GetDBOptions(), cf_names, cf_opts, file_name,</a>
<a name="ln6476">                                   GetEnv());</a>
<a name="ln6477"> </a>
<a name="ln6478">  if (s.ok()) {</a>
<a name="ln6479">    s = RenameTempFileToOptionsFile(file_name);</a>
<a name="ln6480">  }</a>
<a name="ln6481">  mutex_.Lock();</a>
<a name="ln6482">  return s;</a>
<a name="ln6483">#else</a>
<a name="ln6484">  return Status::OK();</a>
<a name="ln6485">#endif  // !ROCKSDB_LITE</a>
<a name="ln6486">}</a>
<a name="ln6487"> </a>
<a name="ln6488">#ifndef ROCKSDB_LITE</a>
<a name="ln6489">namespace {</a>
<a name="ln6490">void DeleteOptionsFilesHelper(const std::map&lt;uint64_t, std::string&gt;&amp; filenames,</a>
<a name="ln6491">                              const size_t num_files_to_keep,</a>
<a name="ln6492">                              const std::shared_ptr&lt;Logger&gt;&amp; info_log,</a>
<a name="ln6493">                              Env* env) {</a>
<a name="ln6494">  if (filenames.size() &lt;= num_files_to_keep) {</a>
<a name="ln6495">    return;</a>
<a name="ln6496">  }</a>
<a name="ln6497">  for (auto iter = std::next(filenames.begin(), num_files_to_keep);</a>
<a name="ln6498">       iter != filenames.end(); ++iter) {</a>
<a name="ln6499">    if (!env-&gt;DeleteFile(iter-&gt;second).ok()) {</a>
<a name="ln6500">      RWARN(info_log, &quot;Unable to delete options file %s&quot;, iter-&gt;second.c_str());</a>
<a name="ln6501">    }</a>
<a name="ln6502">  }</a>
<a name="ln6503">}</a>
<a name="ln6504">}  // namespace</a>
<a name="ln6505">#endif  // !ROCKSDB_LITE</a>
<a name="ln6506"> </a>
<a name="ln6507">Status DBImpl::DeleteObsoleteOptionsFiles() {</a>
<a name="ln6508">#ifndef ROCKSDB_LITE</a>
<a name="ln6509">  std::vector&lt;std::string&gt; filenames;</a>
<a name="ln6510">  // use ordered map to store keep the filenames sorted from the newest</a>
<a name="ln6511">  // to the oldest.</a>
<a name="ln6512">  std::map&lt;uint64_t, std::string&gt; options_filenames;</a>
<a name="ln6513">  Status s;</a>
<a name="ln6514">  s = GetEnv()-&gt;GetChildren(GetName(), &amp;filenames);</a>
<a name="ln6515">  if (!s.ok()) {</a>
<a name="ln6516">    return s;</a>
<a name="ln6517">  }</a>
<a name="ln6518">  for (auto&amp; filename : filenames) {</a>
<a name="ln6519">    uint64_t file_number;</a>
<a name="ln6520">    FileType type;</a>
<a name="ln6521">    if (ParseFileName(filename, &amp;file_number, &amp;type) &amp;&amp; type == kOptionsFile) {</a>
<a name="ln6522">      options_filenames.insert(</a>
<a name="ln6523">          {std::numeric_limits&lt;uint64_t&gt;::max() - file_number,</a>
<a name="ln6524">           GetName() + &quot;/&quot; + filename});</a>
<a name="ln6525">    }</a>
<a name="ln6526">  }</a>
<a name="ln6527"> </a>
<a name="ln6528">  // Keeps the latest 2 Options file</a>
<a name="ln6529">  const size_t kNumOptionsFilesKept = 2;</a>
<a name="ln6530">  DeleteOptionsFilesHelper(options_filenames, kNumOptionsFilesKept,</a>
<a name="ln6531">                           db_options_.info_log, GetEnv());</a>
<a name="ln6532">  return Status::OK();</a>
<a name="ln6533">#else</a>
<a name="ln6534">  return Status::OK();</a>
<a name="ln6535">#endif  // !ROCKSDB_LITE</a>
<a name="ln6536">}</a>
<a name="ln6537"> </a>
<a name="ln6538">Status DBImpl::RenameTempFileToOptionsFile(const std::string&amp; file_name) {</a>
<a name="ln6539">#ifndef ROCKSDB_LITE</a>
<a name="ln6540">  Status s;</a>
<a name="ln6541">  std::string options_file_name =</a>
<a name="ln6542">      OptionsFileName(GetName(), versions_-&gt;NewFileNumber());</a>
<a name="ln6543">  // Retry if the file name happen to conflict with an existing one.</a>
<a name="ln6544">  s = GetEnv()-&gt;RenameFile(file_name, options_file_name);</a>
<a name="ln6545"> </a>
<a name="ln6546">  WARN_NOT_OK(DeleteObsoleteOptionsFiles(), &quot;Failed to cleanup obsolete options file&quot;);</a>
<a name="ln6547">  return s;</a>
<a name="ln6548">#else</a>
<a name="ln6549">  return Status::OK();</a>
<a name="ln6550">#endif  // !ROCKSDB_LITE</a>
<a name="ln6551">}</a>
<a name="ln6552"> </a>
<a name="ln6553">#if ROCKSDB_USING_THREAD_STATUS</a>
<a name="ln6554"> </a>
<a name="ln6555">void DBImpl::NewThreadStatusCfInfo(</a>
<a name="ln6556">    ColumnFamilyData* cfd) const {</a>
<a name="ln6557">  if (db_options_.enable_thread_tracking) {</a>
<a name="ln6558">    ThreadStatusUtil::NewColumnFamilyInfo(this, cfd, cfd-&gt;GetName(),</a>
<a name="ln6559">                                          cfd-&gt;ioptions()-&gt;env);</a>
<a name="ln6560">  }</a>
<a name="ln6561">}</a>
<a name="ln6562"> </a>
<a name="ln6563">void DBImpl::EraseThreadStatusCfInfo(</a>
<a name="ln6564">    ColumnFamilyData* cfd) const {</a>
<a name="ln6565">  if (db_options_.enable_thread_tracking) {</a>
<a name="ln6566">    ThreadStatusUtil::EraseColumnFamilyInfo(cfd);</a>
<a name="ln6567">  }</a>
<a name="ln6568">}</a>
<a name="ln6569"> </a>
<a name="ln6570">void DBImpl::EraseThreadStatusDbInfo() const {</a>
<a name="ln6571">  if (db_options_.enable_thread_tracking) {</a>
<a name="ln6572">    ThreadStatusUtil::EraseDatabaseInfo(this);</a>
<a name="ln6573">  }</a>
<a name="ln6574">}</a>
<a name="ln6575"> </a>
<a name="ln6576">#else</a>
<a name="ln6577">void DBImpl::NewThreadStatusCfInfo(</a>
<a name="ln6578">    ColumnFamilyData* cfd) const {</a>
<a name="ln6579">}</a>
<a name="ln6580"> </a>
<a name="ln6581">void DBImpl::EraseThreadStatusCfInfo(</a>
<a name="ln6582">    ColumnFamilyData* cfd) const {</a>
<a name="ln6583">}</a>
<a name="ln6584"> </a>
<a name="ln6585">void DBImpl::EraseThreadStatusDbInfo() const {</a>
<a name="ln6586">}</a>
<a name="ln6587">#endif  // ROCKSDB_USING_THREAD_STATUS</a>
<a name="ln6588"> </a>
<a name="ln6589">#ifndef ROCKSDB_LITE</a>
<a name="ln6590">SequenceNumber DBImpl::GetEarliestMemTableSequenceNumber(SuperVersion* sv,</a>
<a name="ln6591">                                                         bool include_history) {</a>
<a name="ln6592">  // Find the earliest sequence number that we know we can rely on reading</a>
<a name="ln6593">  // from the memtable without needing to check sst files.</a>
<a name="ln6594">  SequenceNumber earliest_seq =</a>
<a name="ln6595">      sv-&gt;imm-&gt;GetEarliestSequenceNumber(include_history);</a>
<a name="ln6596">  if (earliest_seq == kMaxSequenceNumber) {</a>
<a name="ln6597">    earliest_seq = sv-&gt;mem-&gt;GetEarliestSequenceNumber();</a>
<a name="ln6598">  }</a>
<a name="ln6599">  assert(sv-&gt;mem-&gt;GetEarliestSequenceNumber() &gt;= earliest_seq);</a>
<a name="ln6600"> </a>
<a name="ln6601">  return earliest_seq;</a>
<a name="ln6602">}</a>
<a name="ln6603">#endif  // ROCKSDB_LITE</a>
<a name="ln6604"> </a>
<a name="ln6605">#ifndef ROCKSDB_LITE</a>
<a name="ln6606">Status DBImpl::GetLatestSequenceForKey(SuperVersion* sv, const Slice&amp; key,</a>
<a name="ln6607">                                       bool cache_only, SequenceNumber* seq,</a>
<a name="ln6608">                                       bool* found_record_for_key) {</a>
<a name="ln6609">  Status s;</a>
<a name="ln6610">  MergeContext merge_context;</a>
<a name="ln6611"> </a>
<a name="ln6612">  SequenceNumber current_seq = versions_-&gt;LastSequence();</a>
<a name="ln6613">  LookupKey lkey(key, current_seq);</a>
<a name="ln6614"> </a>
<a name="ln6615">  *seq = kMaxSequenceNumber;</a>
<a name="ln6616">  *found_record_for_key = false;</a>
<a name="ln6617"> </a>
<a name="ln6618">  // Check if there is a record for this key in the latest memtable</a>
<a name="ln6619">  sv-&gt;mem-&gt;Get(lkey, nullptr, &amp;s, &amp;merge_context, seq);</a>
<a name="ln6620"> </a>
<a name="ln6621">  if (!(s.ok() || s.IsNotFound() || s.IsMergeInProgress())) {</a>
<a name="ln6622">    // unexpected error reading memtable.</a>
<a name="ln6623">    RLOG(InfoLogLevel::ERROR_LEVEL, db_options_.info_log,</a>
<a name="ln6624">        &quot;Unexpected status returned from MemTable::Get: %s\n&quot;,</a>
<a name="ln6625">        s.ToString().c_str());</a>
<a name="ln6626"> </a>
<a name="ln6627">    return s;</a>
<a name="ln6628">  }</a>
<a name="ln6629"> </a>
<a name="ln6630">  if (*seq != kMaxSequenceNumber) {</a>
<a name="ln6631">    // Found a sequence number, no need to check immutable memtables</a>
<a name="ln6632">    *found_record_for_key = true;</a>
<a name="ln6633">    return Status::OK();</a>
<a name="ln6634">  }</a>
<a name="ln6635"> </a>
<a name="ln6636">  // Check if there is a record for this key in the immutable memtables</a>
<a name="ln6637">  sv-&gt;imm-&gt;Get(lkey, nullptr, &amp;s, &amp;merge_context, seq);</a>
<a name="ln6638"> </a>
<a name="ln6639">  if (!(s.ok() || s.IsNotFound() || s.IsMergeInProgress())) {</a>
<a name="ln6640">    // unexpected error reading memtable.</a>
<a name="ln6641">    RLOG(InfoLogLevel::ERROR_LEVEL, db_options_.info_log,</a>
<a name="ln6642">        &quot;Unexpected status returned from MemTableList::Get: %s\n&quot;,</a>
<a name="ln6643">        s.ToString().c_str());</a>
<a name="ln6644"> </a>
<a name="ln6645">    return s;</a>
<a name="ln6646">  }</a>
<a name="ln6647"> </a>
<a name="ln6648">  if (*seq != kMaxSequenceNumber) {</a>
<a name="ln6649">    // Found a sequence number, no need to check memtable history</a>
<a name="ln6650">    *found_record_for_key = true;</a>
<a name="ln6651">    return Status::OK();</a>
<a name="ln6652">  }</a>
<a name="ln6653"> </a>
<a name="ln6654">  // Check if there is a record for this key in the immutable memtables</a>
<a name="ln6655">  sv-&gt;imm-&gt;GetFromHistory(lkey, nullptr, &amp;s, &amp;merge_context, seq);</a>
<a name="ln6656"> </a>
<a name="ln6657">  if (!(s.ok() || s.IsNotFound() || s.IsMergeInProgress())) {</a>
<a name="ln6658">    // unexpected error reading memtable.</a>
<a name="ln6659">    RLOG(InfoLogLevel::ERROR_LEVEL, db_options_.info_log,</a>
<a name="ln6660">        &quot;Unexpected status returned from MemTableList::GetFromHistory: %s\n&quot;,</a>
<a name="ln6661">        s.ToString().c_str());</a>
<a name="ln6662"> </a>
<a name="ln6663">    return s;</a>
<a name="ln6664">  }</a>
<a name="ln6665"> </a>
<a name="ln6666">  if (*seq != kMaxSequenceNumber) {</a>
<a name="ln6667">    // Found a sequence number, no need to check SST files</a>
<a name="ln6668">    *found_record_for_key = true;</a>
<a name="ln6669">    return Status::OK();</a>
<a name="ln6670">  }</a>
<a name="ln6671"> </a>
<a name="ln6672">  // TODO(agiardullo): possible optimization: consider checking cached</a>
<a name="ln6673">  // SST files if cache_only=true?</a>
<a name="ln6674">  if (!cache_only) {</a>
<a name="ln6675">    // Check tables</a>
<a name="ln6676">    ReadOptions read_options;</a>
<a name="ln6677"> </a>
<a name="ln6678">    sv-&gt;current-&gt;Get(read_options, lkey, nullptr, &amp;s, &amp;merge_context,</a>
<a name="ln6679">                     nullptr /* value_found */, found_record_for_key, seq);</a>
<a name="ln6680"> </a>
<a name="ln6681">    if (!(s.ok() || s.IsNotFound() || s.IsMergeInProgress())) {</a>
<a name="ln6682">      // unexpected error reading SST files</a>
<a name="ln6683">      RLOG(InfoLogLevel::ERROR_LEVEL, db_options_.info_log,</a>
<a name="ln6684">          &quot;Unexpected status returned from Version::Get: %s\n&quot;,</a>
<a name="ln6685">          s.ToString().c_str());</a>
<a name="ln6686"> </a>
<a name="ln6687">      return s;</a>
<a name="ln6688">    }</a>
<a name="ln6689">  }</a>
<a name="ln6690"> </a>
<a name="ln6691">  return Status::OK();</a>
<a name="ln6692">}</a>
<a name="ln6693">#endif  // ROCKSDB_LITE</a>
<a name="ln6694"> </a>
<a name="ln6695">const std::string&amp; DBImpl::LogPrefix() const {</a>
<a name="ln6696">  static const std::string kEmptyString;</a>
<a name="ln6697">  return db_options_.info_log ? db_options_.info_log-&gt;Prefix() : kEmptyString;</a>
<a name="ln6698">}</a>
<a name="ln6699"> </a>
<a name="ln6700">}  // namespace rocksdb</a>

</code></pre>
<div class="balloon" rel="171"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="175"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="275"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="599"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="665"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="754"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1090"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v1037/" target="_blank">V1037</a> Two or more case-branches perform the same actions. Check lines: 1090, 1116</p></div>
<div class="balloon" rel="1452"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v1002/" target="_blank">V1002</a> The 'EventLoggerStream' class, containing pointers, constructor and destructor, is copied by the automatically generated copy constructor.</p></div>
<div class="balloon" rel="1847"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2117"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2248"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v595/" target="_blank">V595</a> The 'cfd->compaction_picker()' pointer was utilized before it was verified against nullptr. Check lines: 2248, 2258.</p></div>
<div class="balloon" rel="2463"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v581/" target="_blank">V581</a> The conditional expressions of the 'if' statements situated alongside each other are identical. Check lines: 2460, 2463.</p></div>
<div class="balloon" rel="2820"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v560/" target="_blank">V560</a> A part of conditional expression is always true.</p></div>
<div class="balloon" rel="2855"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v506/" target="_blank">V506</a> Pointer to local variable 'manual_compaction' is stored outside the scope of this variable. Such a pointer will become invalid.</p></div>
<div class="balloon" rel="3191"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="3314"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="3317"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="3340"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="3379"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="3451"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="4821"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v547/" target="_blank">V547</a> Expression 'xfunc_attempted_write' is always false.</p></div>
<div class="balloon" rel="5359"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v773/" target="_blank">V773</a> The function was exited without releasing the 'new_log' pointer. A memory leak is possible.</p></div>
<div class="balloon" rel="5359"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v773/" target="_blank">V773</a> The function was exited without releasing the 'new_superversion' pointer. A memory leak is possible.</p></div>
<div class="balloon" rel="5679"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6331"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v668/" target="_blank">V668</a> There is no sense in testing the 'impl' pointer against null, as the memory was allocated using the 'new' operator. The exception will be generated in the case of memory allocation error.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
