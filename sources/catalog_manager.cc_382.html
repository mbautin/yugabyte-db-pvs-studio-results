
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
  <title>catalog_manager.cc</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">// Licensed to the Apache Software Foundation (ASF) under one</a>
<a name="ln2">// or more contributor license agreements.  See the NOTICE file</a>
<a name="ln3">// distributed with this work for additional information</a>
<a name="ln4">// regarding copyright ownership.  The ASF licenses this file</a>
<a name="ln5">// to you under the Apache License, Version 2.0 (the</a>
<a name="ln6">// &quot;License&quot;); you may not use this file except in compliance</a>
<a name="ln7">// with the License.  You may obtain a copy of the License at</a>
<a name="ln8">//</a>
<a name="ln9">//   http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="ln10">//</a>
<a name="ln11">// Unless required by applicable law or agreed to in writing,</a>
<a name="ln12">// software distributed under the License is distributed on an</a>
<a name="ln13">// &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</a>
<a name="ln14">// KIND, either express or implied.  See the License for the</a>
<a name="ln15">// specific language governing permissions and limitations</a>
<a name="ln16">// under the License.</a>
<a name="ln17">//</a>
<a name="ln18">// The following only applies to changes made to this file as part of YugaByte development.</a>
<a name="ln19">//</a>
<a name="ln20">// Portions Copyright (c) YugaByte, Inc.</a>
<a name="ln21">//</a>
<a name="ln22">// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except</a>
<a name="ln23">// in compliance with the License.  You may obtain a copy of the License at</a>
<a name="ln24">//</a>
<a name="ln25">// http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="ln26">//</a>
<a name="ln27">// Unless required by applicable law or agreed to in writing, software distributed under the License</a>
<a name="ln28">// is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express</a>
<a name="ln29">// or implied.  See the License for the specific language governing permissions and limitations</a>
<a name="ln30">// under the License.</a>
<a name="ln31">//</a>
<a name="ln32">// ================================================================================================</a>
<a name="ln33">//</a>
<a name="ln34">// The catalog manager handles the current list of tables</a>
<a name="ln35">// and tablets in the cluster, as well as their current locations.</a>
<a name="ln36">// Since most operations in the master go through these data</a>
<a name="ln37">// structures, locking is carefully managed here to prevent unnecessary</a>
<a name="ln38">// contention and deadlocks:</a>
<a name="ln39">//</a>
<a name="ln40">// - each structure has an internal spinlock used for operations that</a>
<a name="ln41">//   are purely in-memory (eg the current status of replicas)</a>
<a name="ln42">// - data that is persisted on disk is stored in separate PersistentTable(t)Info</a>
<a name="ln43">//   structs. These are managed using copy-on-write so that writers may block</a>
<a name="ln44">//   writing them back to disk while not impacting concurrent readers.</a>
<a name="ln45">//</a>
<a name="ln46">// Usage rules:</a>
<a name="ln47">// - You may obtain READ locks in any order. READ locks should never block,</a>
<a name="ln48">//   since they only conflict with COMMIT which is a purely in-memory operation.</a>
<a name="ln49">//   Thus they are deadlock-free.</a>
<a name="ln50">// - If you need a WRITE lock on both a table and one or more of its tablets,</a>
<a name="ln51">//   acquire the lock on the table first. This strict ordering prevents deadlocks.</a>
<a name="ln52">//</a>
<a name="ln53">// ================================================================================================</a>
<a name="ln54"> </a>
<a name="ln55">#include &quot;yb/master/catalog_manager.h&quot;</a>
<a name="ln56">#include &quot;yb/master/catalog_manager-internal.h&quot;</a>
<a name="ln57"> </a>
<a name="ln58">#include &lt;stdlib.h&gt;</a>
<a name="ln59"> </a>
<a name="ln60">#include &lt;algorithm&gt;</a>
<a name="ln61">#include &lt;bitset&gt;</a>
<a name="ln62">#include &lt;functional&gt;</a>
<a name="ln63">#include &lt;mutex&gt;</a>
<a name="ln64">#include &lt;set&gt;</a>
<a name="ln65">#include &lt;unordered_map&gt;</a>
<a name="ln66">#include &lt;vector&gt;</a>
<a name="ln67"> </a>
<a name="ln68">#include &lt;boost/optional.hpp&gt;</a>
<a name="ln69">#include &lt;boost/thread/shared_mutex.hpp&gt;</a>
<a name="ln70">#include &lt;glog/logging.h&gt;</a>
<a name="ln71">#include &lt;google/protobuf/text_format.h&gt;</a>
<a name="ln72">#include &quot;yb/common/common_flags.h&quot;</a>
<a name="ln73">#include &quot;yb/common/partial_row.h&quot;</a>
<a name="ln74">#include &quot;yb/common/partition.h&quot;</a>
<a name="ln75">#include &quot;yb/common/roles_permissions.h&quot;</a>
<a name="ln76">#include &quot;yb/common/wire_protocol.h&quot;</a>
<a name="ln77">#include &quot;yb/consensus/consensus.h&quot;</a>
<a name="ln78">#include &quot;yb/consensus/consensus.proxy.h&quot;</a>
<a name="ln79">#include &quot;yb/consensus/consensus_peers.h&quot;</a>
<a name="ln80">#include &quot;yb/consensus/quorum_util.h&quot;</a>
<a name="ln81">#include &quot;yb/gutil/atomicops.h&quot;</a>
<a name="ln82">#include &quot;yb/gutil/map-util.h&quot;</a>
<a name="ln83">#include &quot;yb/gutil/mathlimits.h&quot;</a>
<a name="ln84">#include &quot;yb/gutil/stl_util.h&quot;</a>
<a name="ln85">#include &quot;yb/gutil/strings/escaping.h&quot;</a>
<a name="ln86">#include &quot;yb/gutil/strings/join.h&quot;</a>
<a name="ln87">#include &quot;yb/gutil/strings/substitute.h&quot;</a>
<a name="ln88">#include &quot;yb/gutil/sysinfo.h&quot;</a>
<a name="ln89">#include &quot;yb/gutil/walltime.h&quot;</a>
<a name="ln90">#include &quot;yb/master/async_rpc_tasks.h&quot;</a>
<a name="ln91">#include &quot;yb/master/backfill_index.h&quot;</a>
<a name="ln92">#include &quot;yb/master/catalog_loaders.h&quot;</a>
<a name="ln93">#include &quot;yb/master/catalog_manager_bg_tasks.h&quot;</a>
<a name="ln94">#include &quot;yb/master/catalog_manager_util.h&quot;</a>
<a name="ln95">#include &quot;yb/master/cluster_balance.h&quot;</a>
<a name="ln96">#include &quot;yb/master/encryption_manager.h&quot;</a>
<a name="ln97">#include &quot;yb/master/master.h&quot;</a>
<a name="ln98">#include &quot;yb/master/master.pb.h&quot;</a>
<a name="ln99">#include &quot;yb/master/master.proxy.h&quot;</a>
<a name="ln100">#include &quot;yb/master/master_error.h&quot;</a>
<a name="ln101">#include &quot;yb/master/master_util.h&quot;</a>
<a name="ln102">#include &quot;yb/master/sys_catalog_constants.h&quot;</a>
<a name="ln103">#include &quot;yb/master/sys_catalog_initialization.h&quot;</a>
<a name="ln104">#include &quot;yb/master/sys_catalog.h&quot;</a>
<a name="ln105">#include &quot;yb/master/system_tablet.h&quot;</a>
<a name="ln106">#include &quot;yb/master/tasks_tracker.h&quot;</a>
<a name="ln107">#include &quot;yb/master/ts_descriptor.h&quot;</a>
<a name="ln108">#include &quot;yb/master/ts_manager.h&quot;</a>
<a name="ln109">#include &quot;yb/master/yql_aggregates_vtable.h&quot;</a>
<a name="ln110">#include &quot;yb/master/yql_auth_resource_role_permissions_index.h&quot;</a>
<a name="ln111">#include &quot;yb/master/yql_auth_role_permissions_vtable.h&quot;</a>
<a name="ln112">#include &quot;yb/master/yql_auth_roles_vtable.h&quot;</a>
<a name="ln113">#include &quot;yb/master/yql_columns_vtable.h&quot;</a>
<a name="ln114">#include &quot;yb/master/yql_empty_vtable.h&quot;</a>
<a name="ln115">#include &quot;yb/master/yql_functions_vtable.h&quot;</a>
<a name="ln116">#include &quot;yb/master/yql_indexes_vtable.h&quot;</a>
<a name="ln117">#include &quot;yb/master/yql_keyspaces_vtable.h&quot;</a>
<a name="ln118">#include &quot;yb/master/yql_local_vtable.h&quot;</a>
<a name="ln119">#include &quot;yb/master/yql_partitions_vtable.h&quot;</a>
<a name="ln120">#include &quot;yb/master/yql_peers_vtable.h&quot;</a>
<a name="ln121">#include &quot;yb/master/yql_size_estimates_vtable.h&quot;</a>
<a name="ln122">#include &quot;yb/master/yql_tables_vtable.h&quot;</a>
<a name="ln123">#include &quot;yb/master/yql_triggers_vtable.h&quot;</a>
<a name="ln124">#include &quot;yb/master/yql_types_vtable.h&quot;</a>
<a name="ln125">#include &quot;yb/master/yql_views_vtable.h&quot;</a>
<a name="ln126"> </a>
<a name="ln127">#include &quot;yb/tserver/ts_tablet_manager.h&quot;</a>
<a name="ln128">#include &quot;yb/rpc/messenger.h&quot;</a>
<a name="ln129"> </a>
<a name="ln130">#include &quot;yb/tablet/operations/change_metadata_operation.h&quot;</a>
<a name="ln131">#include &quot;yb/tablet/tablet.h&quot;</a>
<a name="ln132">#include &quot;yb/tablet/tablet_metadata.h&quot;</a>
<a name="ln133"> </a>
<a name="ln134">#include &quot;yb/tserver/tserver_admin.proxy.h&quot;</a>
<a name="ln135"> </a>
<a name="ln136">#include &quot;yb/util/crypt.h&quot;</a>
<a name="ln137">#include &quot;yb/util/debug-util.h&quot;</a>
<a name="ln138">#include &quot;yb/util/debug/trace_event.h&quot;</a>
<a name="ln139">#include &quot;yb/util/flag_tags.h&quot;</a>
<a name="ln140">#include &quot;yb/util/logging.h&quot;</a>
<a name="ln141">#include &quot;yb/util/math_util.h&quot;</a>
<a name="ln142">#include &quot;yb/util/monotime.h&quot;</a>
<a name="ln143">#include &quot;yb/util/random_util.h&quot;</a>
<a name="ln144">#include &quot;yb/util/rw_mutex.h&quot;</a>
<a name="ln145">#include &quot;yb/util/status.h&quot;</a>
<a name="ln146">#include &quot;yb/util/stopwatch.h&quot;</a>
<a name="ln147">#include &quot;yb/util/thread.h&quot;</a>
<a name="ln148">#include &quot;yb/util/thread_restrictions.h&quot;</a>
<a name="ln149">#include &quot;yb/util/threadpool.h&quot;</a>
<a name="ln150">#include &quot;yb/util/trace.h&quot;</a>
<a name="ln151">#include &quot;yb/util/tsan_util.h&quot;</a>
<a name="ln152">#include &quot;yb/util/uuid.h&quot;</a>
<a name="ln153"> </a>
<a name="ln154">#include &quot;yb/client/client.h&quot;</a>
<a name="ln155">#include &quot;yb/client/client-internal.h&quot;</a>
<a name="ln156">#include &quot;yb/client/meta_cache.h&quot;</a>
<a name="ln157">#include &quot;yb/client/table_creator.h&quot;</a>
<a name="ln158">#include &quot;yb/client/table_handle.h&quot;</a>
<a name="ln159">#include &quot;yb/client/yb_table_name.h&quot;</a>
<a name="ln160"> </a>
<a name="ln161">#include &quot;yb/tserver/remote_bootstrap_client.h&quot;</a>
<a name="ln162">#include &quot;yb/tserver/remote_bootstrap_snapshots.h&quot;</a>
<a name="ln163"> </a>
<a name="ln164">#include &quot;yb/yql/redis/redisserver/redis_constants.h&quot;</a>
<a name="ln165">#include &quot;yb/yql/pgwrapper/pg_wrapper.h&quot;</a>
<a name="ln166">#include &quot;yb/util/shared_lock.h&quot;</a>
<a name="ln167"> </a>
<a name="ln168">using namespace std::literals;</a>
<a name="ln169"> </a>
<a name="ln170">DEFINE_int32(master_ts_rpc_timeout_ms, 30 * 1000,  // 30 sec</a>
<a name="ln171">             &quot;Timeout used for the Master-&gt;TS async rpc calls.&quot;);</a>
<a name="ln172">TAG_FLAG(master_ts_rpc_timeout_ms, advanced);</a>
<a name="ln173"> </a>
<a name="ln174">DEFINE_int32(tablet_creation_timeout_ms, 30 * 1000,  // 30 sec</a>
<a name="ln175">             &quot;Timeout used by the master when attempting to create tablet &quot;</a>
<a name="ln176">             &quot;replicas during table creation.&quot;);</a>
<a name="ln177">TAG_FLAG(tablet_creation_timeout_ms, advanced);</a>
<a name="ln178"> </a>
<a name="ln179">DEFINE_bool(catalog_manager_wait_for_new_tablets_to_elect_leader, true,</a>
<a name="ln180">            &quot;Whether the catalog manager should wait for a newly created tablet to &quot;</a>
<a name="ln181">            &quot;elect a leader before considering it successfully created. &quot;</a>
<a name="ln182">            &quot;This is disabled in some tests where we explicitly manage leader &quot;</a>
<a name="ln183">            &quot;election.&quot;);</a>
<a name="ln184">TAG_FLAG(catalog_manager_wait_for_new_tablets_to_elect_leader, hidden);</a>
<a name="ln185"> </a>
<a name="ln186">DEFINE_int32(catalog_manager_inject_latency_in_delete_table_ms, 0,</a>
<a name="ln187">             &quot;Number of milliseconds that the master will sleep in DeleteTable.&quot;);</a>
<a name="ln188">TAG_FLAG(catalog_manager_inject_latency_in_delete_table_ms, hidden);</a>
<a name="ln189"> </a>
<a name="ln190">DECLARE_int32(catalog_manager_bg_task_wait_ms);</a>
<a name="ln191"> </a>
<a name="ln192">DEFINE_int32(replication_factor, 3,</a>
<a name="ln193">             &quot;Default number of replicas for tables that do not have the num_replicas set.&quot;);</a>
<a name="ln194">TAG_FLAG(replication_factor, advanced);</a>
<a name="ln195"> </a>
<a name="ln196">DEFINE_int32(max_create_tablets_per_ts, 50,</a>
<a name="ln197">             &quot;The number of tablets per TS that can be requested for a new table.&quot;);</a>
<a name="ln198">TAG_FLAG(max_create_tablets_per_ts, advanced);</a>
<a name="ln199"> </a>
<a name="ln200">DEFINE_int32(catalog_manager_report_batch_size, 1,</a>
<a name="ln201">            &quot;The max number of tablets evaluated in the heartbeat as a single SysCatalog update.&quot;);</a>
<a name="ln202">TAG_FLAG(catalog_manager_report_batch_size, advanced);</a>
<a name="ln203"> </a>
<a name="ln204">DEFINE_int32(master_failover_catchup_timeout_ms, 30 * 1000 * yb::kTimeMultiplier,  // 30 sec</a>
<a name="ln205">             &quot;Amount of time to give a newly-elected leader master to load&quot;</a>
<a name="ln206">             &quot; the previous master's metadata and become active. If this time&quot;</a>
<a name="ln207">             &quot; is exceeded, the node crashes.&quot;);</a>
<a name="ln208">TAG_FLAG(master_failover_catchup_timeout_ms, advanced);</a>
<a name="ln209">TAG_FLAG(master_failover_catchup_timeout_ms, experimental);</a>
<a name="ln210"> </a>
<a name="ln211">DEFINE_bool(master_tombstone_evicted_tablet_replicas, true,</a>
<a name="ln212">            &quot;Whether the Master should tombstone (delete) tablet replicas that &quot;</a>
<a name="ln213">            &quot;are no longer part of the latest reported raft config.&quot;);</a>
<a name="ln214">TAG_FLAG(master_tombstone_evicted_tablet_replicas, hidden);</a>
<a name="ln215"> </a>
<a name="ln216">// Temporary.  Can be removed after long-run testing.</a>
<a name="ln217">DEFINE_bool(master_ignore_stale_cstate, true,</a>
<a name="ln218">            &quot;Whether Master processes the raft config when the version is lower.&quot;);</a>
<a name="ln219">TAG_FLAG(master_ignore_stale_cstate, hidden);</a>
<a name="ln220"> </a>
<a name="ln221">DEFINE_bool(catalog_manager_check_ts_count_for_create_table, true,</a>
<a name="ln222">            &quot;Whether the master should ensure that there are enough live tablet &quot;</a>
<a name="ln223">            &quot;servers to satisfy the provided replication count before allowing &quot;</a>
<a name="ln224">            &quot;a table to be created.&quot;);</a>
<a name="ln225">TAG_FLAG(catalog_manager_check_ts_count_for_create_table, hidden);</a>
<a name="ln226"> </a>
<a name="ln227">METRIC_DEFINE_gauge_uint32(cluster, num_tablet_servers_live,</a>
<a name="ln228">                           &quot;Number of live tservers in the cluster&quot;, yb::MetricUnit::kUnits,</a>
<a name="ln229">                           &quot;The number of tablet servers that have responded or done a heartbeat &quot;</a>
<a name="ln230">                           &quot;in the time interval defined by the gflag &quot;</a>
<a name="ln231">                           &quot;FLAGS_tserver_unresponsive_timeout_ms.&quot;);</a>
<a name="ln232"> </a>
<a name="ln233">METRIC_DEFINE_gauge_uint32(cluster, num_tablet_servers_dead,</a>
<a name="ln234">                           &quot;Number of dead tservers in the cluster&quot;, yb::MetricUnit::kUnits,</a>
<a name="ln235">                           &quot;The number of tablet servers that have not responded or done a &quot;</a>
<a name="ln236">                           &quot;heartbeat in the time interval defined by the gflag &quot;</a>
<a name="ln237">                           &quot;FLAGS_tserver_unresponsive_timeout_ms.&quot;);</a>
<a name="ln238"> </a>
<a name="ln239">DEFINE_test_flag(uint64, inject_latency_during_remote_bootstrap_secs, 0,</a>
<a name="ln240">                 &quot;Number of seconds to sleep during a remote bootstrap.&quot;);</a>
<a name="ln241"> </a>
<a name="ln242">DEFINE_test_flag(bool, catalog_manager_simulate_system_table_create_failure, false,</a>
<a name="ln243">                 &quot;This is only used in tests to simulate a failure where the table information is &quot;</a>
<a name="ln244">                 &quot;persisted in syscatalog, but the tablet information is not yet persisted and &quot;</a>
<a name="ln245">                 &quot;there is a failure.&quot;);</a>
<a name="ln246"> </a>
<a name="ln247">DEFINE_string(cluster_uuid, &quot;&quot;, &quot;Cluster UUID to be used by this cluster&quot;);</a>
<a name="ln248">TAG_FLAG(cluster_uuid, hidden);</a>
<a name="ln249"> </a>
<a name="ln250">DECLARE_int32(yb_num_shards_per_tserver);</a>
<a name="ln251"> </a>
<a name="ln252">DEFINE_uint64(transaction_table_num_tablets, 0,</a>
<a name="ln253">    &quot;Number of tablets to use when creating the transaction status table.&quot;</a>
<a name="ln254">    &quot;0 to use the same default num tablets as for regular tables.&quot;);</a>
<a name="ln255"> </a>
<a name="ln256">DEFINE_bool(master_enable_metrics_snapshotter, false, &quot;Should metrics snapshotter be enabled&quot;);</a>
<a name="ln257"> </a>
<a name="ln258">DEFINE_uint64(metrics_snapshots_table_num_tablets, 0,</a>
<a name="ln259">    &quot;Number of tablets to use when creating the metrics snapshots table.&quot;</a>
<a name="ln260">    &quot;0 to use the same default num tablets as for regular tables.&quot;);</a>
<a name="ln261"> </a>
<a name="ln262">DEFINE_bool(disable_index_backfill, false,</a>
<a name="ln263">    &quot;A kill switch to disable multi-stage backfill for YCQL indexes.&quot;);</a>
<a name="ln264">TAG_FLAG(disable_index_backfill, runtime);</a>
<a name="ln265">TAG_FLAG(disable_index_backfill, hidden);</a>
<a name="ln266"> </a>
<a name="ln267">DEFINE_bool(disable_index_backfill_for_non_txn_tables, true,</a>
<a name="ln268">    &quot;A kill switch to disable multi-stage backfill for user encorced YCQL indexes. &quot;</a>
<a name="ln269">    &quot;Note that setting this to true may cause the create index flow to be slow. &quot;</a>
<a name="ln270">    &quot;This is needed to ensure the safety of the index backfill process. See also &quot;</a>
<a name="ln271">    &quot;index_backfill_upperbound_for_user_enforced_txn_duration_ms&quot;);</a>
<a name="ln272">TAG_FLAG(disable_index_backfill_for_non_txn_tables, runtime);</a>
<a name="ln273">TAG_FLAG(disable_index_backfill_for_non_txn_tables, hidden);</a>
<a name="ln274"> </a>
<a name="ln275">DEFINE_bool(</a>
<a name="ln276">    hide_pg_catalog_table_creation_logs, false,</a>
<a name="ln277">    &quot;Whether to hide detailed log messages for PostgreSQL catalog table creation. &quot;</a>
<a name="ln278">    &quot;This cuts down test logs significantly.&quot;);</a>
<a name="ln279">TAG_FLAG(hide_pg_catalog_table_creation_logs, hidden);</a>
<a name="ln280"> </a>
<a name="ln281">DEFINE_test_flag(int32, simulate_slow_table_create_secs, 0,</a>
<a name="ln282">    &quot;Simulates a slow table creation by sleeping after the table has been added to memory.&quot;);</a>
<a name="ln283"> </a>
<a name="ln284">DEFINE_test_flag(int32, simulate_slow_system_tablet_bootstrap_secs, 0,</a>
<a name="ln285">    &quot;Simulates a slow tablet bootstrap by adding a sleep before system tablet init.&quot;);</a>
<a name="ln286"> </a>
<a name="ln287">DEFINE_test_flag(bool, return_error_if_namespace_not_found, false,</a>
<a name="ln288">    &quot;Return an error from ListTables if a namespace id is not found in the map&quot;);</a>
<a name="ln289"> </a>
<a name="ln290">DEFINE_test_flag(bool, hang_on_namespace_transition, false,</a>
<a name="ln291">    &quot;Used in tests to simulate a lapse between issuing a namespace op and final processing.&quot;);</a>
<a name="ln292"> </a>
<a name="ln293">DEFINE_test_flag(bool, simulate_crash_after_table_marked_deleting, false,</a>
<a name="ln294">    &quot;Crash yb-master after table's state is set to DELETING. This skips tablets deletion.&quot;);</a>
<a name="ln295"> </a>
<a name="ln296">DECLARE_int32(yb_client_admin_operation_timeout_sec);</a>
<a name="ln297"> </a>
<a name="ln298">DEFINE_test_flag(bool, tablegroup_master_only, false,</a>
<a name="ln299">                 &quot;This is only for MasterTest to be able to test tablegroups without the&quot;</a>
<a name="ln300">                 &quot; transaction status table being created.&quot;);</a>
<a name="ln301"> </a>
<a name="ln302">DEFINE_bool(enable_register_ts_from_raft, false, &quot;Whether to register a tserver from the consensus &quot;</a>
<a name="ln303">                                                 &quot;information of a reported tablet.&quot;);</a>
<a name="ln304"> </a>
<a name="ln305">DECLARE_int32(tserver_unresponsive_timeout_ms);</a>
<a name="ln306"> </a>
<a name="ln307">namespace yb {</a>
<a name="ln308">namespace master {</a>
<a name="ln309"> </a>
<a name="ln310">using std::atomic;</a>
<a name="ln311">using std::shared_ptr;</a>
<a name="ln312">using std::string;</a>
<a name="ln313">using std::unique_ptr;</a>
<a name="ln314">using std::vector;</a>
<a name="ln315"> </a>
<a name="ln316">using namespace std::placeholders;</a>
<a name="ln317"> </a>
<a name="ln318">using base::subtle::NoBarrier_Load;</a>
<a name="ln319">using base::subtle::NoBarrier_CompareAndSwap;</a>
<a name="ln320">using consensus::kMinimumTerm;</a>
<a name="ln321">using consensus::CONSENSUS_CONFIG_COMMITTED;</a>
<a name="ln322">using consensus::CONSENSUS_CONFIG_ACTIVE;</a>
<a name="ln323">using consensus::COMMITTED_OPID;</a>
<a name="ln324">using consensus::Consensus;</a>
<a name="ln325">using consensus::ConsensusMetadata;</a>
<a name="ln326">using consensus::ConsensusServiceProxy;</a>
<a name="ln327">using consensus::ConsensusStatePB;</a>
<a name="ln328">using consensus::GetConsensusRole;</a>
<a name="ln329">using consensus::RaftPeerPB;</a>
<a name="ln330">using consensus::StartRemoteBootstrapRequestPB;</a>
<a name="ln331">using rpc::RpcContext;</a>
<a name="ln332">using strings::Substitute;</a>
<a name="ln333">using tablet::TABLET_DATA_COPYING;</a>
<a name="ln334">using tablet::TABLET_DATA_DELETED;</a>
<a name="ln335">using tablet::TABLET_DATA_READY;</a>
<a name="ln336">using tablet::TABLET_DATA_TOMBSTONED;</a>
<a name="ln337">using tablet::TabletDataState;</a>
<a name="ln338">using tablet::RaftGroupMetadata;</a>
<a name="ln339">using tablet::RaftGroupMetadataPtr;</a>
<a name="ln340">using tablet::TabletPeer;</a>
<a name="ln341">using tablet::RaftGroupStatePB;</a>
<a name="ln342">using tablet::TabletStatusListener;</a>
<a name="ln343">using tablet::TabletStatusPB;</a>
<a name="ln344">using tserver::HandleReplacingStaleTablet;</a>
<a name="ln345">using tserver::TabletServerErrorPB;</a>
<a name="ln346">using master::MasterServiceProxy;</a>
<a name="ln347">using yb::pgwrapper::PgWrapper;</a>
<a name="ln348">using yb::server::MasterAddressesToString;</a>
<a name="ln349"> </a>
<a name="ln350">using yb::client::YBClient;</a>
<a name="ln351">using yb::client::YBClientBuilder;</a>
<a name="ln352">using yb::client::YBColumnSchema;</a>
<a name="ln353">using yb::client::YBSchema;</a>
<a name="ln354">using yb::client::YBSchemaBuilder;</a>
<a name="ln355">using yb::client::YBTable;</a>
<a name="ln356">using yb::client::YBTableCreator;</a>
<a name="ln357">using yb::client::YBTableName;</a>
<a name="ln358"> </a>
<a name="ln359">namespace {</a>
<a name="ln360"> </a>
<a name="ln361">// Macros to access index information in CATALOG.</a>
<a name="ln362">//</a>
<a name="ln363">// NOTES from file master.proto for SysTablesEntryPB.</a>
<a name="ln364">// - For index table: [to be deprecated and replaced by &quot;index_info&quot;]</a>
<a name="ln365">//     optional bytes indexed_table_id = 13; // Indexed table id of this index.</a>
<a name="ln366">//     optional bool is_local_index = 14 [ default = false ];  // Whether this is a local index.</a>
<a name="ln367">//     optional bool is_unique_index = 15 [ default = false ]; // Whether this is a unique index.</a>
<a name="ln368">// - During transition period, we have to consider both fields and the following macros help</a>
<a name="ln369">//   avoiding duplicate protobuf version check thru out our code.</a>
<a name="ln370"> </a>
<a name="ln371">#define PROTO_GET_INDEXED_TABLE_ID(tabpb) \</a>
<a name="ln372">  (tabpb.has_index_info() ? tabpb.index_info().indexed_table_id() \</a>
<a name="ln373">                          : tabpb.indexed_table_id())</a>
<a name="ln374"> </a>
<a name="ln375">#define PROTO_GET_IS_LOCAL(tabpb) \</a>
<a name="ln376">  (tabpb.has_index_info() ? tabpb.index_info().is_local() \</a>
<a name="ln377">                          : tabpb.is_local_index())</a>
<a name="ln378"> </a>
<a name="ln379">#define PROTO_GET_IS_UNIQUE(tabpb) \</a>
<a name="ln380">  (tabpb.has_index_info() ? tabpb.index_info().is_unique() \</a>
<a name="ln381">                          : tabpb.is_unique_index())</a>
<a name="ln382"> </a>
<a name="ln383">#define PROTO_IS_INDEX(tabpb) \</a>
<a name="ln384">  (tabpb.has_index_info() || !tabpb.indexed_table_id().empty())</a>
<a name="ln385"> </a>
<a name="ln386">#define PROTO_IS_TABLE(tabpb) \</a>
<a name="ln387">  (!tabpb.has_index_info() &amp;&amp; tabpb.indexed_table_id().empty())</a>
<a name="ln388"> </a>
<a name="ln389">#define PROTO_PTR_IS_INDEX(tabpb) \</a>
<a name="ln390">  (tabpb-&gt;has_index_info() || !tabpb-&gt;indexed_table_id().empty())</a>
<a name="ln391"> </a>
<a name="ln392">#define PROTO_PTR_IS_TABLE(tabpb) \</a>
<a name="ln393">  (!tabpb-&gt;has_index_info() &amp;&amp; tabpb-&gt;indexed_table_id().empty())</a>
<a name="ln394"> </a>
<a name="ln395">#if (0)</a>
<a name="ln396">// Once the deprecated fields are obsolete, the above macros should be defined as the following.</a>
<a name="ln397">#define PROTO_GET_INDEXED_TABLE_ID(tabpb) (tabpb.index_info().indexed_table_id())</a>
<a name="ln398">#define PROTO_GET_IS_LOCAL(tabpb) (tabpb.index_info().is_local())</a>
<a name="ln399">#define PROTO_GET_IS_UNIQUE(tabpb) (tabpb.index_info().is_unique())</a>
<a name="ln400">#define PROTO_IS_INDEX(tabpb) (tabpb.has_index_info())</a>
<a name="ln401">#define PROTO_IS_TABLE(tabpb) (!tabpb.has_index_info())</a>
<a name="ln402">#define PROTO_PTR_IS_INDEX(tabpb) (tabpb-&gt;has_index_info())</a>
<a name="ln403">#define PROTO_PTR_IS_TABLE(tabpb) (!tabpb-&gt;has_index_info())</a>
<a name="ln404"> </a>
<a name="ln405">#endif</a>
<a name="ln406"> </a>
<a name="ln407">class IndexInfoBuilder {</a>
<a name="ln408"> public:</a>
<a name="ln409">  explicit IndexInfoBuilder(IndexInfoPB* index_info) : index_info_(*index_info) {</a>
<a name="ln410">    DVLOG(3) &lt;&lt; &quot; After &quot; &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; &quot; index_info_ is &quot; &lt;&lt; yb::ToString(index_info_);</a>
<a name="ln411">  }</a>
<a name="ln412"> </a>
<a name="ln413">  void ApplyProperties(const TableId&amp; indexed_table_id, bool is_local, bool is_unique) {</a>
<a name="ln414">    index_info_.set_indexed_table_id(indexed_table_id);</a>
<a name="ln415">    index_info_.set_version(0);</a>
<a name="ln416">    index_info_.set_is_local(is_local);</a>
<a name="ln417">    index_info_.set_is_unique(is_unique);</a>
<a name="ln418">    DVLOG(3) &lt;&lt; &quot; After &quot; &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; &quot; index_info_ is &quot; &lt;&lt; yb::ToString(index_info_);</a>
<a name="ln419">  }</a>
<a name="ln420"> </a>
<a name="ln421">  CHECKED_STATUS ApplyColumnMapping(const Schema&amp; indexed_schema, const Schema&amp; index_schema) {</a>
<a name="ln422">    for (size_t i = 0; i &lt; index_schema.num_columns(); i++) {</a>
<a name="ln423">      const auto&amp; col_name = index_schema.column(i).name();</a>
<a name="ln424">      const auto indexed_col_idx = indexed_schema.find_column(col_name);</a>
<a name="ln425">      if (PREDICT_FALSE(indexed_col_idx == Schema::kColumnNotFound)) {</a>
<a name="ln426">        return STATUS(NotFound, &quot;The indexed table column does not exist&quot;, col_name);</a>
<a name="ln427">      }</a>
<a name="ln428">      auto* col = index_info_.add_columns();</a>
<a name="ln429">      col-&gt;set_column_id(index_schema.column_id(i));</a>
<a name="ln430">      col-&gt;set_indexed_column_id(indexed_schema.column_id(indexed_col_idx));</a>
<a name="ln431">    }</a>
<a name="ln432">    index_info_.set_hash_column_count(index_schema.num_hash_key_columns());</a>
<a name="ln433">    index_info_.set_range_column_count(index_schema.num_range_key_columns());</a>
<a name="ln434"> </a>
<a name="ln435">    for (size_t i = 0; i &lt; indexed_schema.num_hash_key_columns(); i++) {</a>
<a name="ln436">      index_info_.add_indexed_hash_column_ids(indexed_schema.column_id(i));</a>
<a name="ln437">    }</a>
<a name="ln438">    for (size_t i = indexed_schema.num_hash_key_columns(); i &lt; indexed_schema.num_key_columns();</a>
<a name="ln439">        i++) {</a>
<a name="ln440">      index_info_.add_indexed_range_column_ids(indexed_schema.column_id(i));</a>
<a name="ln441">    }</a>
<a name="ln442">    DVLOG(3) &lt;&lt; &quot; After &quot; &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; &quot; index_info_ is &quot; &lt;&lt; yb::ToString(index_info_);</a>
<a name="ln443">    return Status::OK();</a>
<a name="ln444">  }</a>
<a name="ln445"> </a>
<a name="ln446"> private:</a>
<a name="ln447">  IndexInfoPB&amp; index_info_;</a>
<a name="ln448">};</a>
<a name="ln449"> </a>
<a name="ln450">template&lt;class RespClass&gt;</a>
<a name="ln451">Status CheckIfTableDeletedOrNotRunning(TableInfo::lock_type* lock, RespClass* resp) {</a>
<a name="ln452">  // This covers both in progress and fully deleted objects.</a>
<a name="ln453">  if (lock-&gt;data().started_deleting()) {</a>
<a name="ln454">    Status s = STATUS_SUBSTITUTE(NotFound,</a>
<a name="ln455">        &quot;The object '$0.$1' does not exist&quot;, lock-&gt;data().namespace_id(), lock-&gt;data().name());</a>
<a name="ln456">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln457">  }</a>
<a name="ln458">  if (!lock-&gt;data().is_running()) {</a>
<a name="ln459">    Status s = STATUS_SUBSTITUTE(ServiceUnavailable,</a>
<a name="ln460">        &quot;The object '$0.$1' is not running&quot;, lock-&gt;data().namespace_id(), lock-&gt;data().name());</a>
<a name="ln461">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln462">  }</a>
<a name="ln463">  return Status::OK();</a>
<a name="ln464">}</a>
<a name="ln465"> </a>
<a name="ln466">#define RETURN_NAMESPACE_NOT_FOUND(s, resp)                                       \</a>
<a name="ln467">  do {                                                                            \</a>
<a name="ln468">    if (PREDICT_FALSE(!s.ok())) {                                                 \</a>
<a name="ln469">      if (s.IsNotFound()) {                                                       \</a>
<a name="ln470">        return SetupError(                                                        \</a>
<a name="ln471">            resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_NOT_FOUND, s);        \</a>
<a name="ln472">      }                                                                           \</a>
<a name="ln473">      return s;                                                                   \</a>
<a name="ln474">    }                                                                             \</a>
<a name="ln475">  } while (false)</a>
<a name="ln476"> </a>
<a name="ln477">MasterErrorPB_Code NamespaceMasterError(SysNamespaceEntryPB_State state) {</a>
<a name="ln478">  switch (state) {</a>
<a name="ln479">    case SysNamespaceEntryPB::PREPARING: FALLTHROUGH_INTENDED;</a>
<a name="ln480">    case SysNamespaceEntryPB::DELETING:</a>
<a name="ln481">      return MasterErrorPB::IN_TRANSITION_CAN_RETRY;</a>
<a name="ln482">    case SysNamespaceEntryPB::DELETED: FALLTHROUGH_INTENDED;</a>
<a name="ln483">    case SysNamespaceEntryPB::FAILED: FALLTHROUGH_INTENDED;</a>
<a name="ln484">    case SysNamespaceEntryPB::RUNNING:</a>
<a name="ln485">      return MasterErrorPB::INTERNAL_ERROR;</a>
<a name="ln486">    default:</a>
<a name="ln487">      FATAL_INVALID_ENUM_VALUE(SysNamespaceEntryPB_State, state);</a>
<a name="ln488">  }</a>
<a name="ln489">}</a>
<a name="ln490"> </a>
<a name="ln491">size_t GetNameMapperIndex(YQLDatabase db_type) {</a>
<a name="ln492">  switch (db_type) {</a>
<a name="ln493">    case YQL_DATABASE_UNKNOWN: break;</a>
<a name="ln494">    case YQL_DATABASE_CQL: return 1;</a>
<a name="ln495">    case YQL_DATABASE_PGSQL: return 2;</a>
<a name="ln496">    case YQL_DATABASE_REDIS: return 3;</a>
<a name="ln497">  }</a>
<a name="ln498">  CHECK(false) &lt;&lt; &quot;Unexpected db type &quot; &lt;&lt; db_type;</a>
<a name="ln499">  return 0;</a>
<a name="ln500">}</a>
<a name="ln501"> </a>
<a name="ln502">bool IsIndexBackfillEnabled(TableType table_type, bool is_transactional) {</a>
<a name="ln503">  // Fetch the runtime flag to prevent any issues from the updates to flag while processing.</a>
<a name="ln504">  const bool disabled =</a>
<a name="ln505">      (table_type == PGSQL_TABLE_TYPE</a>
<a name="ln506">          ? GetAtomicFlag(&amp;FLAGS_ysql_disable_index_backfill)</a>
<a name="ln507">          : GetAtomicFlag(&amp;FLAGS_disable_index_backfill) ||</a>
<a name="ln508">      (!is_transactional &amp;&amp; GetAtomicFlag(&amp;FLAGS_disable_index_backfill_for_non_txn_tables)));</a>
<a name="ln509">  return !disabled;</a>
<a name="ln510">}</a>
<a name="ln511"> </a>
<a name="ln512">}  // anonymous namespace</a>
<a name="ln513"> </a>
<a name="ln514">////////////////////////////////////////////////////////////</a>
<a name="ln515">// CatalogManager</a>
<a name="ln516">////////////////////////////////////////////////////////////</a>
<a name="ln517"> </a>
<a name="ln518">CatalogManager::NamespaceInfoMap&amp; CatalogManager::NamespaceNameMapper::operator[](</a>
<a name="ln519">    YQLDatabase db_type) {</a>
<a name="ln520">  return typed_maps_[GetNameMapperIndex(db_type)];</a>
<a name="ln521">}</a>
<a name="ln522"> </a>
<a name="ln523">const CatalogManager::NamespaceInfoMap&amp; CatalogManager::NamespaceNameMapper::operator[](</a>
<a name="ln524">    YQLDatabase db_type) const {</a>
<a name="ln525">  return typed_maps_[GetNameMapperIndex(db_type)];</a>
<a name="ln526">}</a>
<a name="ln527"> </a>
<a name="ln528">void CatalogManager::NamespaceNameMapper::clear() {</a>
<a name="ln529">  for (auto&amp; m : typed_maps_) {</a>
<a name="ln530">    m.clear();</a>
<a name="ln531">  }</a>
<a name="ln532">}</a>
<a name="ln533"> </a>
<a name="ln534">CatalogManager::CatalogManager(Master* master)</a>
<a name="ln535">    : master_(master),</a>
<a name="ln536">      rng_(GetRandomSeed32()),</a>
<a name="ln537">      tablet_exists_(false),</a>
<a name="ln538">      state_(kConstructed),</a>
<a name="ln539">      leader_ready_term_(-1),</a>
<a name="ln540">      leader_lock_(RWMutex::Priority::PREFER_WRITING),</a>
<a name="ln541">      load_balance_policy_(new enterprise::ClusterLoadBalancer(this)),</a>
<a name="ln542">      permissions_manager_(std::make_unique&lt;PermissionsManager&gt;(this)),</a>
<a name="ln543">      tasks_tracker_(new TasksTracker(IsUserInitiated::kFalse)),</a>
<a name="ln544">      jobs_tracker_(new TasksTracker(IsUserInitiated::kTrue)),</a>
<a name="ln545">      encryption_manager_(new EncryptionManager()) {</a>
<a name="ln546">  yb::InitCommonFlags();</a>
<a name="ln547">  CHECK_OK(ThreadPoolBuilder(&quot;leader-initialization&quot;)</a>
<a name="ln548">           .set_max_threads(1)</a>
<a name="ln549">           .Build(&amp;worker_pool_));</a>
<a name="ln550">  CHECK_OK(ThreadPoolBuilder(&quot;CatalogManagerBGTasks&quot;).Build(&amp;background_tasks_thread_pool_));</a>
<a name="ln551"> </a>
<a name="ln552">  if (master_) {</a>
<a name="ln553">    sys_catalog_.reset(new SysCatalogTable(</a>
<a name="ln554">        master_, master_-&gt;metric_registry(),</a>
<a name="ln555">        Bind(&amp;CatalogManager::ElectedAsLeaderCb, Unretained(this))));</a>
<a name="ln556">  }</a>
<a name="ln557">}</a>
<a name="ln558"> </a>
<a name="ln559">CatalogManager::~CatalogManager() {</a>
<a name="ln560">  Shutdown();</a>
<a name="ln561">}</a>
<a name="ln562"> </a>
<a name="ln563">Status CatalogManager::Init(bool is_first_run) {</a>
<a name="ln564">  {</a>
<a name="ln565">    std::lock_guard&lt;simple_spinlock&gt; l(state_lock_);</a>
<a name="ln566">    CHECK_EQ(kConstructed, state_);</a>
<a name="ln567">    state_ = kStarting;</a>
<a name="ln568">  }</a>
<a name="ln569"> </a>
<a name="ln570">  // Initialize the metrics emitted by the catalog manager.</a>
<a name="ln571">  metric_num_tablet_servers_live_ =</a>
<a name="ln572">    METRIC_num_tablet_servers_live.Instantiate(master_-&gt;metric_entity_cluster(), 0);</a>
<a name="ln573"> </a>
<a name="ln574">  metric_num_tablet_servers_dead_ =</a>
<a name="ln575">    METRIC_num_tablet_servers_dead.Instantiate(master_-&gt;metric_entity_cluster(), 0);</a>
<a name="ln576"> </a>
<a name="ln577">  RETURN_NOT_OK_PREPEND(InitSysCatalogAsync(is_first_run),</a>
<a name="ln578">                        &quot;Failed to initialize sys tables async&quot;);</a>
<a name="ln579"> </a>
<a name="ln580">  if (PREDICT_FALSE(FLAGS_TEST_simulate_slow_system_tablet_bootstrap_secs &gt; 0)) {</a>
<a name="ln581">    LOG(INFO) &lt;&lt; &quot;Simulating slow system tablet bootstrap&quot;;</a>
<a name="ln582">    SleepFor(MonoDelta::FromSeconds(FLAGS_TEST_simulate_slow_system_tablet_bootstrap_secs));</a>
<a name="ln583">  }</a>
<a name="ln584"> </a>
<a name="ln585">  // WaitUntilRunning() must run outside of the lock as to prevent</a>
<a name="ln586">  // deadlock. This is safe as WaitUntilRunning waits for another</a>
<a name="ln587">  // thread to finish its work and doesn't itself depend on any state</a>
<a name="ln588">  // within CatalogManager. Need not start sys catalog or background tasks</a>
<a name="ln589">  // when we are started in shell mode.</a>
<a name="ln590">  if (!master_-&gt;opts().IsShellMode()) {</a>
<a name="ln591">    RETURN_NOT_OK_PREPEND(sys_catalog_-&gt;WaitUntilRunning(),</a>
<a name="ln592">                          &quot;Failed waiting for the catalog tablet to run&quot;);</a>
<a name="ln593">    std::vector&lt;consensus::RaftPeerPB&gt; masters_raft;</a>
<a name="ln594">    RETURN_NOT_OK(master_-&gt;ListRaftConfigMasters(&amp;masters_raft));</a>
<a name="ln595">    HostPortSet hps;</a>
<a name="ln596">    for (const auto&amp; peer : masters_raft) {</a>
<a name="ln597">      if (master_-&gt;instance_pb().permanent_uuid() == peer.permanent_uuid()) {</a>
<a name="ln598">        continue;</a>
<a name="ln599">      }</a>
<a name="ln600">      HostPort hp = HostPortFromPB(DesiredHostPort(peer, master_-&gt;MakeCloudInfoPB()));</a>
<a name="ln601">      hps.insert(hp);</a>
<a name="ln602">    }</a>
<a name="ln603">    RETURN_NOT_OK(encryption_manager_-&gt;AddPeersToGetUniverseKeyFrom(hps));</a>
<a name="ln604">    RETURN_NOT_OK(EnableBgTasks());</a>
<a name="ln605">  }</a>
<a name="ln606"> </a>
<a name="ln607">  {</a>
<a name="ln608">    std::lock_guard&lt;simple_spinlock&gt; l(state_lock_);</a>
<a name="ln609">    CHECK_EQ(kStarting, state_);</a>
<a name="ln610">    state_ = kRunning;</a>
<a name="ln611">  }</a>
<a name="ln612"> </a>
<a name="ln613">  Started();</a>
<a name="ln614"> </a>
<a name="ln615">  return Status::OK();</a>
<a name="ln616">}</a>
<a name="ln617"> </a>
<a name="ln618">Status CatalogManager::ChangeEncryptionInfo(const ChangeEncryptionInfoRequestPB* req,</a>
<a name="ln619">                                            ChangeEncryptionInfoResponsePB* resp) {</a>
<a name="ln620">  return STATUS(InvalidCommand, &quot;Command only supported in enterprise build.&quot;);</a>
<a name="ln621">}</a>
<a name="ln622"> </a>
<a name="ln623">Status CatalogManager::ElectedAsLeaderCb() {</a>
<a name="ln624">  time_elected_leader_ = MonoTime::Now();</a>
<a name="ln625">  return worker_pool_-&gt;SubmitClosure(</a>
<a name="ln626">      Bind(&amp;CatalogManager::LoadSysCatalogDataTask, Unretained(this)));</a>
<a name="ln627">}</a>
<a name="ln628"> </a>
<a name="ln629">Status CatalogManager::WaitUntilCaughtUpAsLeader(const MonoDelta&amp; timeout) {</a>
<a name="ln630">  string uuid = master_-&gt;fs_manager()-&gt;uuid();</a>
<a name="ln631">  Consensus* consensus = tablet_peer()-&gt;consensus();</a>
<a name="ln632">  ConsensusStatePB cstate = consensus-&gt;ConsensusState(CONSENSUS_CONFIG_ACTIVE);</a>
<a name="ln633">  if (!cstate.has_leader_uuid() || cstate.leader_uuid() != uuid) {</a>
<a name="ln634">    return STATUS_SUBSTITUTE(IllegalState,</a>
<a name="ln635">        &quot;Node $0 not leader. Consensus state: $1&quot;, uuid, cstate.ShortDebugString());</a>
<a name="ln636">  }</a>
<a name="ln637"> </a>
<a name="ln638">  // Wait for all transactions to be committed.</a>
<a name="ln639">  const CoarseTimePoint deadline = CoarseMonoClock::now() + timeout;</a>
<a name="ln640">  RETURN_NOT_OK(tablet_peer()-&gt;operation_tracker()-&gt;WaitForAllToFinish(timeout));</a>
<a name="ln641"> </a>
<a name="ln642">  RETURN_NOT_OK(tablet_peer()-&gt;consensus()-&gt;WaitForLeaderLeaseImprecise(deadline));</a>
<a name="ln643">  return Status::OK();</a>
<a name="ln644">}</a>
<a name="ln645"> </a>
<a name="ln646">void CatalogManager::LoadSysCatalogDataTask() {</a>
<a name="ln647">  auto consensus = tablet_peer()-&gt;shared_consensus();</a>
<a name="ln648">  const int64_t term = consensus-&gt;ConsensusState(CONSENSUS_CONFIG_ACTIVE).current_term();</a>
<a name="ln649">  Status s = WaitUntilCaughtUpAsLeader(</a>
<a name="ln650">      MonoDelta::FromMilliseconds(FLAGS_master_failover_catchup_timeout_ms));</a>
<a name="ln651"> </a>
<a name="ln652">  int64_t term_after_wait = consensus-&gt;ConsensusState(CONSENSUS_CONFIG_ACTIVE).current_term();</a>
<a name="ln653">  if (term_after_wait != term) {</a>
<a name="ln654">    // If we got elected leader again while waiting to catch up then we will get another callback to</a>
<a name="ln655">    // update state from sys_catalog, so bail now.</a>
<a name="ln656">    //</a>
<a name="ln657">    // If we failed when waiting, i.e. could not acquire a leader lease, this could be due to us</a>
<a name="ln658">    // becoming a follower. If we're not partitioned away, we'll know about a new term soon.</a>
<a name="ln659">    LOG(INFO) &lt;&lt; &quot;Term change from &quot; &lt;&lt; term &lt;&lt; &quot; to &quot; &lt;&lt; term_after_wait</a>
<a name="ln660">              &lt;&lt; &quot; while waiting for master leader catchup. Not loading sys catalog metadata. &quot;</a>
<a name="ln661">              &lt;&lt; &quot;Status of waiting: &quot; &lt;&lt; s;</a>
<a name="ln662">    return;</a>
<a name="ln663">  }</a>
<a name="ln664"> </a>
<a name="ln665">  if (!s.ok()) {</a>
<a name="ln666">    // This could happen e.g. if we are a partitioned-away leader that failed to acquire a leader</a>
<a name="ln667">    // lease.</a>
<a name="ln668">    //</a>
<a name="ln669">    // TODO: handle this cleanly by transitioning to a follower without crashing.</a>
<a name="ln670">    WARN_NOT_OK(s, &quot;Failed waiting for node to catch up after master election&quot;);</a>
<a name="ln671"> </a>
<a name="ln672">    if (s.IsTimedOut()) {</a>
<a name="ln673">      LOG(FATAL) &lt;&lt; &quot;Shutting down due to unavailability of other masters after&quot;</a>
<a name="ln674">                 &lt;&lt; &quot; election. TODO: Abdicate instead.&quot;;</a>
<a name="ln675">    }</a>
<a name="ln676">    return;</a>
<a name="ln677">  }</a>
<a name="ln678"> </a>
<a name="ln679">  LOG(INFO) &lt;&lt; &quot;Loading table and tablet metadata into memory for term &quot; &lt;&lt; term;</a>
<a name="ln680">  LOG_SLOW_EXECUTION(WARNING, 1000, LogPrefix() + &quot;Loading metadata into memory&quot;) {</a>
<a name="ln681">    Status status = VisitSysCatalog(term);</a>
<a name="ln682">    if (!status.ok()) {</a>
<a name="ln683">      if (status.IsShutdownInProgress()) {</a>
<a name="ln684">        LOG(INFO) &lt;&lt; &quot;Error loading sys catalog; because shutdown is in progress. term &quot; &lt;&lt; term</a>
<a name="ln685">                  &lt;&lt; &quot; status : &quot; &lt;&lt; status;</a>
<a name="ln686">        return;</a>
<a name="ln687">      }</a>
<a name="ln688">      auto new_term = consensus-&gt;ConsensusState(CONSENSUS_CONFIG_ACTIVE).current_term();</a>
<a name="ln689">      if (new_term != term) {</a>
<a name="ln690">        LOG(INFO) &lt;&lt; &quot;Error loading sys catalog; but that's OK as term was changed from &quot; &lt;&lt; term</a>
<a name="ln691">                  &lt;&lt; &quot; to &quot; &lt;&lt; new_term &lt;&lt; &quot;: &quot; &lt;&lt; status;</a>
<a name="ln692">        return;</a>
<a name="ln693">      }</a>
<a name="ln694">      LOG(FATAL) &lt;&lt; &quot;Failed to load sys catalog: &quot; &lt;&lt; status;</a>
<a name="ln695">    }</a>
<a name="ln696">  }</a>
<a name="ln697"> </a>
<a name="ln698">  std::lock_guard&lt;simple_spinlock&gt; l(state_lock_);</a>
<a name="ln699">  leader_ready_term_ = term;</a>
<a name="ln700">  LOG(INFO) &lt;&lt; &quot;Completed load of sys catalog in term &quot; &lt;&lt; term;</a>
<a name="ln701">}</a>
<a name="ln702"> </a>
<a name="ln703">CHECKED_STATUS CatalogManager::WaitForWorkerPoolTests(const MonoDelta&amp; timeout) const {</a>
<a name="ln704">  if (!worker_pool_-&gt;WaitFor(timeout)) {</a>
<a name="ln705">    return STATUS(TimedOut, &quot;Worker Pool hasn't finished processing tasks&quot;);</a>
<a name="ln706">  }</a>
<a name="ln707">  return Status::OK();</a>
<a name="ln708">}</a>
<a name="ln709"> </a>
<a name="ln710">Status CatalogManager::VisitSysCatalog(int64_t term) {</a>
<a name="ln711">  // Block new catalog operations, and wait for existing operations to finish.</a>
<a name="ln712">  LOG(INFO) &lt;&lt; __func__ &lt;&lt; &quot;: Wait on leader_lock_ for any existing operations to finish.&quot;;</a>
<a name="ln713">  auto start = std::chrono::steady_clock::now();</a>
<a name="ln714">  std::lock_guard&lt;RWMutex&gt; leader_lock_guard(leader_lock_);</a>
<a name="ln715">  auto finish = std::chrono::steady_clock::now();</a>
<a name="ln716"> </a>
<a name="ln717">  static const auto kLongLockAcquisitionLimit = RegularBuildVsSanitizers(100ms, 750ms);</a>
<a name="ln718">  if (finish &gt; start + kLongLockAcquisitionLimit) {</a>
<a name="ln719">    LOG(WARNING) &lt;&lt; &quot;Long wait on leader_lock_: &quot; &lt;&lt; yb::ToString(finish - start);</a>
<a name="ln720">  }</a>
<a name="ln721"> </a>
<a name="ln722">  LOG(INFO) &lt;&lt; __func__ &lt;&lt; &quot;: Acquire catalog manager lock_ before loading sys catalog..&quot;;</a>
<a name="ln723">  std::lock_guard&lt;LockType&gt; lock(lock_);</a>
<a name="ln724">  VLOG(3) &lt;&lt; __func__ &lt;&lt; &quot;: Acquired the catalog manager lock_&quot;;</a>
<a name="ln725"> </a>
<a name="ln726">  // Abort any outstanding tasks. All TableInfos are orphaned below, so</a>
<a name="ln727">  // it's important to end their tasks now; otherwise Shutdown() will</a>
<a name="ln728">  // destroy master state used by these tasks.</a>
<a name="ln729">  std::vector&lt;scoped_refptr&lt;TableInfo&gt;&gt; tables;</a>
<a name="ln730">  AppendValuesFromMap(*table_ids_map_, &amp;tables);</a>
<a name="ln731">  AbortAndWaitForAllTasks(tables);</a>
<a name="ln732"> </a>
<a name="ln733">  // Clear internal maps and run data loaders.</a>
<a name="ln734">  RETURN_NOT_OK(RunLoaders(term));</a>
<a name="ln735"> </a>
<a name="ln736">  // Prepare various default system configurations.</a>
<a name="ln737">  RETURN_NOT_OK(PrepareDefaultSysConfig(term));</a>
<a name="ln738"> </a>
<a name="ln739">  if ((FLAGS_use_initial_sys_catalog_snapshot || FLAGS_enable_ysql) &amp;&amp;</a>
<a name="ln740">      !FLAGS_initial_sys_catalog_snapshot_path.empty() &amp;&amp;</a>
<a name="ln741">      !FLAGS_create_initial_sys_catalog_snapshot) {</a>
<a name="ln742">    if (!namespace_ids_map_.empty() || !system_tablets_.empty()) {</a>
<a name="ln743">      LOG(INFO) &lt;&lt; &quot;This is an existing cluster, not initializing from a sys catalog snapshot.&quot;;</a>
<a name="ln744">    } else {</a>
<a name="ln745">      Result&lt;bool&gt; dir_exists =</a>
<a name="ln746">          Env::Default()-&gt;DoesDirectoryExist(FLAGS_initial_sys_catalog_snapshot_path);</a>
<a name="ln747">      if (dir_exists.ok() &amp;&amp; *dir_exists) {</a>
<a name="ln748">        bool initdb_was_already_done = false;</a>
<a name="ln749">        {</a>
<a name="ln750">          auto l = ysql_catalog_config_-&gt;LockForRead();</a>
<a name="ln751">          initdb_was_already_done = l-&gt;data().pb.ysql_catalog_config().initdb_done();</a>
<a name="ln752">        }</a>
<a name="ln753">        if (initdb_was_already_done) {</a>
<a name="ln754">          LOG(INFO) &lt;&lt; &quot;initdb has been run before, no need to restore sys catalog from &quot;</a>
<a name="ln755">                    &lt;&lt; &quot;the initial snapshot&quot;;</a>
<a name="ln756">        } else {</a>
<a name="ln757">          LOG(INFO) &lt;&lt; &quot;Restoring snapshot in sys catalog&quot;;</a>
<a name="ln758">          Status restore_status = RestoreInitialSysCatalogSnapshot(</a>
<a name="ln759">              FLAGS_initial_sys_catalog_snapshot_path,</a>
<a name="ln760">              sys_catalog_-&gt;tablet_peer().get(),</a>
<a name="ln761">              term);</a>
<a name="ln762">          if (!restore_status.ok()) {</a>
<a name="ln763">            LOG(ERROR) &lt;&lt; &quot;Failed restoring snapshot in sys catalog&quot;;</a>
<a name="ln764">            return restore_status;</a>
<a name="ln765">          }</a>
<a name="ln766"> </a>
<a name="ln767">          LOG(INFO) &lt;&lt; &quot;Re-initializing cluster config&quot;;</a>
<a name="ln768">          cluster_config_.reset();</a>
<a name="ln769">          RETURN_NOT_OK(PrepareDefaultClusterConfig(term));</a>
<a name="ln770"> </a>
<a name="ln771">          LOG(INFO) &lt;&lt; &quot;Restoring snapshot completed, considering initdb finished&quot;;</a>
<a name="ln772">          RETURN_NOT_OK(InitDbFinished(Status::OK(), term));</a>
<a name="ln773">          RETURN_NOT_OK(RunLoaders(term));</a>
<a name="ln774">        }</a>
<a name="ln775">      } else {</a>
<a name="ln776">        LOG(WARNING) &lt;&lt; &quot;Initial sys catalog snapshot directory does not exist: &quot;</a>
<a name="ln777">                     &lt;&lt; FLAGS_initial_sys_catalog_snapshot_path</a>
<a name="ln778">                     &lt;&lt; (dir_exists.ok() ? &quot;&quot; : &quot;, status: &quot; + dir_exists.status().ToString());</a>
<a name="ln779">      }</a>
<a name="ln780">    }</a>
<a name="ln781">  }</a>
<a name="ln782"> </a>
<a name="ln783">  // Create the system namespaces (created only if they don't already exist).</a>
<a name="ln784">  RETURN_NOT_OK(PrepareDefaultNamespaces(term));</a>
<a name="ln785"> </a>
<a name="ln786">  // Create the system tables (created only if they don't already exist).</a>
<a name="ln787">  RETURN_NOT_OK(PrepareSystemTables(term));</a>
<a name="ln788"> </a>
<a name="ln789">  // Create the default cassandra (created only if they don't already exist).</a>
<a name="ln790">  RETURN_NOT_OK(permissions_manager_-&gt;PrepareDefaultRoles(term));</a>
<a name="ln791"> </a>
<a name="ln792">  // If this is the first time we start up, we have no config information as default. We write an</a>
<a name="ln793">  // empty version 0.</a>
<a name="ln794">  RETURN_NOT_OK(PrepareDefaultClusterConfig(term));</a>
<a name="ln795"> </a>
<a name="ln796">  permissions_manager_-&gt;BuildRecursiveRolesUnlocked();</a>
<a name="ln797"> </a>
<a name="ln798">  if (FLAGS_enable_ysql) {</a>
<a name="ln799">    LOG(INFO) &lt;&lt; &quot;YSQL is enabled, will create the transaction status table when &quot;</a>
<a name="ln800">              &lt;&lt; FLAGS_replication_factor &lt;&lt; &quot; tablet servers are online&quot;;</a>
<a name="ln801">    master_-&gt;ts_manager()-&gt;SetTSCountCallback(FLAGS_replication_factor, [this]{</a>
<a name="ln802">      LOG(INFO) &lt;&lt; FLAGS_replication_factor</a>
<a name="ln803">                &lt;&lt; &quot; tablet servers registered, creating the transaction status table&quot;;</a>
<a name="ln804">      // Retry table creation until it succeedes. It might fail initially because placement UUID</a>
<a name="ln805">      // of live replicas is set through an RPC from YugaWare, and we won't be able to calculate</a>
<a name="ln806">      // the number of primary (non-read-replica) tablet servers until that happens.</a>
<a name="ln807">      while (true) {</a>
<a name="ln808">        const auto s = CreateTransactionsStatusTableIfNeeded(/* rpc */ nullptr);</a>
<a name="ln809">        if (s.ok()) {</a>
<a name="ln810">          break;</a>
<a name="ln811">        }</a>
<a name="ln812">        LOG(WARNING) &lt;&lt; &quot;Failed creating transaction status table, waiting: &quot; &lt;&lt; s;</a>
<a name="ln813">        SleepFor(MonoDelta::FromSeconds(1));</a>
<a name="ln814">      }</a>
<a name="ln815">      LOG(INFO) &lt;&lt; &quot;Finished creating transaction status table asynchronously&quot;;</a>
<a name="ln816">    });</a>
<a name="ln817">  }</a>
<a name="ln818"> </a>
<a name="ln819">  if (!StartRunningInitDbIfNeeded(term)) {</a>
<a name="ln820">    // If we are not running initdb, this is an existing cluster, and we need to check whether we</a>
<a name="ln821">    // need to do a one-time migration to make YSQL system catalog tables transactional.</a>
<a name="ln822">    RETURN_NOT_OK(MakeYsqlSysCatalogTablesTransactional(</a>
<a name="ln823">        table_ids_map_.CheckOut().get_ptr(), sys_catalog_.get(), ysql_catalog_config_.get(), term));</a>
<a name="ln824">  }</a>
<a name="ln825"> </a>
<a name="ln826">  return Status::OK();</a>
<a name="ln827">}</a>
<a name="ln828"> </a>
<a name="ln829">template &lt;class Loader&gt;</a>
<a name="ln830">Status CatalogManager::Load(const std::string&amp; title, const int64_t term) {</a>
<a name="ln831">  LOG(INFO) &lt;&lt; __func__ &lt;&lt; &quot;: Loading &quot; &lt;&lt; title &lt;&lt; &quot; into memory.&quot;;</a>
<a name="ln832">  std::unique_ptr&lt;Loader&gt; loader = std::make_unique&lt;Loader&gt;(this, term);</a>
<a name="ln833">  RETURN_NOT_OK_PREPEND(</a>
<a name="ln834">      sys_catalog_-&gt;Visit(loader.get()),</a>
<a name="ln835">      &quot;Failed while visiting &quot; + title + &quot; in sys catalog&quot;);</a>
<a name="ln836">  return Status::OK();</a>
<a name="ln837">}</a>
<a name="ln838"> </a>
<a name="ln839">Status CatalogManager::RunLoaders(int64_t term) {</a>
<a name="ln840">  // Clear the table and tablet state.</a>
<a name="ln841">  table_names_map_.clear();</a>
<a name="ln842">  auto table_ids_map_checkout = table_ids_map_.CheckOut();</a>
<a name="ln843">  table_ids_map_checkout-&gt;clear();</a>
<a name="ln844"> </a>
<a name="ln845">  auto tablet_map_checkout = tablet_map_.CheckOut();</a>
<a name="ln846">  tablet_map_checkout-&gt;clear();</a>
<a name="ln847"> </a>
<a name="ln848">  // Clear the namespace mappings.</a>
<a name="ln849">  namespace_ids_map_.clear();</a>
<a name="ln850">  namespace_names_mapper_.clear();</a>
<a name="ln851"> </a>
<a name="ln852">  // Clear the type mappings.</a>
<a name="ln853">  udtype_ids_map_.clear();</a>
<a name="ln854">  udtype_names_map_.clear();</a>
<a name="ln855"> </a>
<a name="ln856">  // Clear the current cluster config.</a>
<a name="ln857">  cluster_config_.reset();</a>
<a name="ln858"> </a>
<a name="ln859">  // Clear the roles mapping.</a>
<a name="ln860">  permissions_manager()-&gt;ClearRolesUnlocked();</a>
<a name="ln861"> </a>
<a name="ln862">  // Clear redis config mapping.</a>
<a name="ln863">  redis_config_map_.clear();</a>
<a name="ln864"> </a>
<a name="ln865">  // Clear ysql catalog config.</a>
<a name="ln866">  ysql_catalog_config_.reset();</a>
<a name="ln867"> </a>
<a name="ln868">  // Clear recent tasks.</a>
<a name="ln869">  tasks_tracker_-&gt;Reset();</a>
<a name="ln870"> </a>
<a name="ln871">  // Clear recent jobs.</a>
<a name="ln872">  jobs_tracker_-&gt;Reset();</a>
<a name="ln873"> </a>
<a name="ln874">  std::vector&lt;std::shared_ptr&lt;TSDescriptor&gt;&gt; descs;</a>
<a name="ln875">  master_-&gt;ts_manager()-&gt;GetAllDescriptors(&amp;descs);</a>
<a name="ln876">  for (const auto&amp; ts_desc : descs) {</a>
<a name="ln877">    ts_desc-&gt;set_has_tablet_report(false);</a>
<a name="ln878">  }</a>
<a name="ln879"> </a>
<a name="ln880">  RETURN_NOT_OK(Load&lt;TableLoader&gt;(&quot;tables&quot;, term));</a>
<a name="ln881">  RETURN_NOT_OK(Load&lt;TabletLoader&gt;(&quot;tablets&quot;, term));</a>
<a name="ln882">  RETURN_NOT_OK(Load&lt;NamespaceLoader&gt;(&quot;namespaces&quot;, term));</a>
<a name="ln883">  RETURN_NOT_OK(Load&lt;UDTypeLoader&gt;(&quot;user-defined types&quot;, term));</a>
<a name="ln884">  RETURN_NOT_OK(Load&lt;ClusterConfigLoader&gt;(&quot;cluster configuration&quot;, term));</a>
<a name="ln885">  RETURN_NOT_OK(Load&lt;RoleLoader&gt;(&quot;roles&quot;, term));</a>
<a name="ln886">  RETURN_NOT_OK(Load&lt;RedisConfigLoader&gt;(&quot;Redis config&quot;, term));</a>
<a name="ln887">  RETURN_NOT_OK(Load&lt;SysConfigLoader&gt;(&quot;sys config&quot;, term));</a>
<a name="ln888"> </a>
<a name="ln889">  return Status::OK();</a>
<a name="ln890">}</a>
<a name="ln891"> </a>
<a name="ln892">Status CatalogManager::PrepareDefaultClusterConfig(int64_t term) {</a>
<a name="ln893">  if (cluster_config_) {</a>
<a name="ln894">    LOG(INFO) &lt;&lt; &quot;Cluster configuration has already been set up, skipping re-initialization.&quot;;</a>
<a name="ln895">    return Status::OK();</a>
<a name="ln896">  }</a>
<a name="ln897"> </a>
<a name="ln898">  // Create default.</a>
<a name="ln899">  SysClusterConfigEntryPB config;</a>
<a name="ln900">  config.set_version(0);</a>
<a name="ln901"> </a>
<a name="ln902">  std::string cluster_uuid_source;</a>
<a name="ln903">  if (!FLAGS_cluster_uuid.empty()) {</a>
<a name="ln904">    Uuid uuid;</a>
<a name="ln905">    RETURN_NOT_OK(uuid.FromString(FLAGS_cluster_uuid));</a>
<a name="ln906">    config.set_cluster_uuid(FLAGS_cluster_uuid);</a>
<a name="ln907">    cluster_uuid_source = &quot;from the --cluster_uuid flag&quot;;</a>
<a name="ln908">  } else {</a>
<a name="ln909">    auto uuid = Uuid::Generate();</a>
<a name="ln910">    config.set_cluster_uuid(to_string(uuid));</a>
<a name="ln911">    cluster_uuid_source = &quot;(randomly generated)&quot;;</a>
<a name="ln912">  }</a>
<a name="ln913">  LOG(INFO) &lt;&lt; &quot;Setting cluster UUID to &quot; &lt;&lt; config.cluster_uuid() &lt;&lt; &quot; &quot; &lt;&lt; cluster_uuid_source;</a>
<a name="ln914"> </a>
<a name="ln915">  // Create in memory object.</a>
<a name="ln916">  cluster_config_ = new ClusterConfigInfo();</a>
<a name="ln917"> </a>
<a name="ln918">  // Prepare write.</a>
<a name="ln919">  auto l = cluster_config_-&gt;LockForWrite();</a>
<a name="ln920">  l-&gt;mutable_data()-&gt;pb = std::move(config);</a>
<a name="ln921"> </a>
<a name="ln922">  // Write to sys_catalog and in memory.</a>
<a name="ln923">  RETURN_NOT_OK(sys_catalog_-&gt;AddItem(cluster_config_.get(), term));</a>
<a name="ln924">  l-&gt;Commit();</a>
<a name="ln925"> </a>
<a name="ln926">  return Status::OK();</a>
<a name="ln927">}</a>
<a name="ln928"> </a>
<a name="ln929">Status CatalogManager::PrepareDefaultSysConfig(int64_t term) {</a>
<a name="ln930">  RETURN_NOT_OK(permissions_manager()-&gt;PrepareDefaultSecurityConfigUnlocked(term));</a>
<a name="ln931"> </a>
<a name="ln932">  if (!ysql_catalog_config_) {</a>
<a name="ln933">    SysYSQLCatalogConfigEntryPB ysql_catalog_config;</a>
<a name="ln934">    ysql_catalog_config.set_version(0);</a>
<a name="ln935"> </a>
<a name="ln936">    // Create in memory objects.</a>
<a name="ln937">    ysql_catalog_config_ = new SysConfigInfo(kYsqlCatalogConfigType);</a>
<a name="ln938"> </a>
<a name="ln939">    // Prepare write.</a>
<a name="ln940">    auto l = ysql_catalog_config_-&gt;LockForWrite();</a>
<a name="ln941">    *l-&gt;mutable_data()-&gt;pb.mutable_ysql_catalog_config() = std::move(ysql_catalog_config);</a>
<a name="ln942"> </a>
<a name="ln943">    // Write to sys_catalog and in memory.</a>
<a name="ln944">    RETURN_NOT_OK(sys_catalog_-&gt;AddItem(ysql_catalog_config_.get(), term));</a>
<a name="ln945">    l-&gt;Commit();</a>
<a name="ln946">  }</a>
<a name="ln947"> </a>
<a name="ln948">  return Status::OK();</a>
<a name="ln949">}</a>
<a name="ln950"> </a>
<a name="ln951">bool CatalogManager::StartRunningInitDbIfNeeded(int64_t term) {</a>
<a name="ln952">  if (!ShouldAutoRunInitDb(ysql_catalog_config_.get(), pg_proc_exists_)) {</a>
<a name="ln953">    return false;</a>
<a name="ln954">  }</a>
<a name="ln955"> </a>
<a name="ln956">  string master_addresses_str = MasterAddressesToString(</a>
<a name="ln957">      *master_-&gt;opts().GetMasterAddresses());</a>
<a name="ln958"> </a>
<a name="ln959">  initdb_future_ = std::async(std::launch::async, [this, master_addresses_str, term] {</a>
<a name="ln960">    if (FLAGS_create_initial_sys_catalog_snapshot) {</a>
<a name="ln961">      initial_snapshot_writer_.emplace();</a>
<a name="ln962">    }</a>
<a name="ln963"> </a>
<a name="ln964">    Status status = PgWrapper::InitDbForYSQL(master_addresses_str, &quot;/tmp&quot;);</a>
<a name="ln965"> </a>
<a name="ln966">    if (FLAGS_create_initial_sys_catalog_snapshot &amp;&amp; status.ok()) {</a>
<a name="ln967">      Status write_snapshot_status = initial_snapshot_writer_-&gt;WriteSnapshot(</a>
<a name="ln968">          sys_catalog_-&gt;tablet_peer()-&gt;tablet(),</a>
<a name="ln969">          FLAGS_initial_sys_catalog_snapshot_path);</a>
<a name="ln970">      if (!write_snapshot_status.ok()) {</a>
<a name="ln971">        status = write_snapshot_status;</a>
<a name="ln972">      }</a>
<a name="ln973">    }</a>
<a name="ln974">    Status finish_status = InitDbFinished(status, term);</a>
<a name="ln975">    if (!finish_status.ok()) {</a>
<a name="ln976">      if (status.ok()) {</a>
<a name="ln977">        status = finish_status;</a>
<a name="ln978">      }</a>
<a name="ln979">      LOG(WARNING) &lt;&lt; &quot;Failed to set initdb as finished in sys catalog: &quot; &lt;&lt; finish_status;</a>
<a name="ln980">    }</a>
<a name="ln981">    return status;</a>
<a name="ln982">  });</a>
<a name="ln983">  return true;</a>
<a name="ln984">}</a>
<a name="ln985"> </a>
<a name="ln986">Status CatalogManager::PrepareDefaultNamespaces(int64_t term) {</a>
<a name="ln987">  RETURN_NOT_OK(PrepareNamespace(</a>
<a name="ln988">      YQL_DATABASE_CQL, kSystemNamespaceName, kSystemNamespaceId, term));</a>
<a name="ln989">  RETURN_NOT_OK(PrepareNamespace(</a>
<a name="ln990">      YQL_DATABASE_CQL, kSystemSchemaNamespaceName, kSystemSchemaNamespaceId, term));</a>
<a name="ln991">  RETURN_NOT_OK(PrepareNamespace(</a>
<a name="ln992">      YQL_DATABASE_CQL, kSystemAuthNamespaceName, kSystemAuthNamespaceId, term));</a>
<a name="ln993">  return Status::OK();</a>
<a name="ln994">}</a>
<a name="ln995"> </a>
<a name="ln996">Status CatalogManager::PrepareSystemTables(int64_t term) {</a>
<a name="ln997">  // Prepare sys catalog table.</a>
<a name="ln998">  RETURN_NOT_OK(PrepareSysCatalogTable(term));</a>
<a name="ln999"> </a>
<a name="ln1000">  // Create the required system tables here.</a>
<a name="ln1001">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;PeersVTable&gt;(</a>
<a name="ln1002">      kSystemPeersTableName, kSystemNamespaceName, kSystemNamespaceId, term)));</a>
<a name="ln1003">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;LocalVTable&gt;(</a>
<a name="ln1004">      kSystemLocalTableName, kSystemNamespaceName, kSystemNamespaceId, term)));</a>
<a name="ln1005">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;YQLKeyspacesVTable&gt;(</a>
<a name="ln1006">      kSystemSchemaKeyspacesTableName, kSystemSchemaNamespaceName, kSystemSchemaNamespaceId,</a>
<a name="ln1007">      term)));</a>
<a name="ln1008">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;YQLTablesVTable&gt;(</a>
<a name="ln1009">      kSystemSchemaTablesTableName, kSystemSchemaNamespaceName, kSystemSchemaNamespaceId, term)));</a>
<a name="ln1010">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;YQLColumnsVTable&gt;(</a>
<a name="ln1011">      kSystemSchemaColumnsTableName, kSystemSchemaNamespaceName, kSystemSchemaNamespaceId, term)));</a>
<a name="ln1012">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;YQLSizeEstimatesVTable&gt;(</a>
<a name="ln1013">      kSystemSizeEstimatesTableName, kSystemNamespaceName, kSystemNamespaceId, term)));</a>
<a name="ln1014"> </a>
<a name="ln1015">  // Empty tables.</a>
<a name="ln1016">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;YQLAggregatesVTable&gt;(</a>
<a name="ln1017">      kSystemSchemaAggregatesTableName, kSystemSchemaNamespaceName, kSystemSchemaNamespaceId,</a>
<a name="ln1018">      term)));</a>
<a name="ln1019">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;YQLFunctionsVTable&gt;(</a>
<a name="ln1020">      kSystemSchemaFunctionsTableName, kSystemSchemaNamespaceName, kSystemSchemaNamespaceId,</a>
<a name="ln1021">      term)));</a>
<a name="ln1022">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;YQLIndexesVTable&gt;(</a>
<a name="ln1023">      kSystemSchemaIndexesTableName, kSystemSchemaNamespaceName, kSystemSchemaNamespaceId, term)));</a>
<a name="ln1024">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;YQLTriggersVTable&gt;(</a>
<a name="ln1025">      kSystemSchemaTriggersTableName, kSystemSchemaNamespaceName, kSystemSchemaNamespaceId, term)));</a>
<a name="ln1026">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;YQLViewsVTable&gt;(</a>
<a name="ln1027">      kSystemSchemaViewsTableName, kSystemSchemaNamespaceName, kSystemSchemaNamespaceId, term)));</a>
<a name="ln1028">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;QLTypesVTable&gt;(</a>
<a name="ln1029">      kSystemSchemaTypesTableName, kSystemSchemaNamespaceName, kSystemSchemaNamespaceId, term)));</a>
<a name="ln1030">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;YQLPartitionsVTable&gt;(</a>
<a name="ln1031">      kSystemPartitionsTableName, kSystemNamespaceName, kSystemNamespaceId, term)));</a>
<a name="ln1032"> </a>
<a name="ln1033">  // System auth tables.</a>
<a name="ln1034">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;YQLAuthRolesVTable&gt;(</a>
<a name="ln1035">      kSystemAuthRolesTableName, kSystemAuthNamespaceName, kSystemAuthNamespaceId, term)));</a>
<a name="ln1036">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;YQLAuthRolePermissionsVTable&gt;(</a>
<a name="ln1037">      kSystemAuthRolePermissionsTableName, kSystemAuthNamespaceName, kSystemAuthNamespaceId,</a>
<a name="ln1038">      term)));</a>
<a name="ln1039">  RETURN_NOT_OK((PrepareSystemTableTemplate&lt;YQLAuthResourceRolePermissionsIndexVTable&gt;(</a>
<a name="ln1040">      kSystemAuthResourceRolePermissionsIndexTableName, kSystemAuthNamespaceName,</a>
<a name="ln1041">      kSystemAuthNamespaceId, term)));</a>
<a name="ln1042"> </a>
<a name="ln1043">  // Ensure kNumSystemTables is in-sync with the system tables created.</a>
<a name="ln1044">  LOG_IF(DFATAL, system_tablets_.size() != kNumSystemTables)</a>
<a name="ln1045">      &lt;&lt; &quot;kNumSystemTables is &quot; &lt;&lt; kNumSystemTables &lt;&lt; &quot; but &quot; &lt;&lt; system_tablets_.size()</a>
<a name="ln1046">      &lt;&lt; &quot; tables were created&quot;;</a>
<a name="ln1047"> </a>
<a name="ln1048">  return Status::OK();</a>
<a name="ln1049">}</a>
<a name="ln1050"> </a>
<a name="ln1051">Status CatalogManager::PrepareSysCatalogTable(int64_t term) {</a>
<a name="ln1052">  // Prepare sys catalog table info.</a>
<a name="ln1053">  auto sys_catalog_table_iter = table_ids_map_-&gt;find(kSysCatalogTableId);</a>
<a name="ln1054">  if (sys_catalog_table_iter == table_ids_map_-&gt;end()) {</a>
<a name="ln1055">    scoped_refptr&lt;TableInfo&gt; table = NewTableInfo(kSysCatalogTableId);</a>
<a name="ln1056">    table-&gt;mutable_metadata()-&gt;StartMutation();</a>
<a name="ln1057">    SysTablesEntryPB&amp; metadata = table-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb;</a>
<a name="ln1058">    metadata.set_state(SysTablesEntryPB::RUNNING);</a>
<a name="ln1059">    metadata.set_namespace_id(kSystemSchemaNamespaceId);</a>
<a name="ln1060">    metadata.set_name(kSysCatalogTableName);</a>
<a name="ln1061">    metadata.set_table_type(TableType::YQL_TABLE_TYPE);</a>
<a name="ln1062">    SchemaToPB(sys_catalog_-&gt;schema_, metadata.mutable_schema());</a>
<a name="ln1063">    metadata.set_version(0);</a>
<a name="ln1064"> </a>
<a name="ln1065">    auto table_ids_map_checkout = table_ids_map_.CheckOut();</a>
<a name="ln1066">    sys_catalog_table_iter = table_ids_map_checkout-&gt;emplace(table-&gt;id(), table).first;</a>
<a name="ln1067">    table_names_map_[{kSystemSchemaNamespaceId, kSysCatalogTableName}] = table;</a>
<a name="ln1068"> </a>
<a name="ln1069">    RETURN_NOT_OK(sys_catalog_-&gt;AddItem(table.get(), term));</a>
<a name="ln1070">    table-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln1071">  }</a>
<a name="ln1072"> </a>
<a name="ln1073">  // Prepare sys catalog tablet info.</a>
<a name="ln1074">  if (tablet_map_-&gt;count(kSysCatalogTabletId) == 0) {</a>
<a name="ln1075">    scoped_refptr&lt;TableInfo&gt; table = sys_catalog_table_iter-&gt;second;</a>
<a name="ln1076">    scoped_refptr&lt;TabletInfo&gt; tablet(new TabletInfo(table, kSysCatalogTabletId));</a>
<a name="ln1077">    tablet-&gt;mutable_metadata()-&gt;StartMutation();</a>
<a name="ln1078">    SysTabletsEntryPB&amp; metadata = tablet-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb;</a>
<a name="ln1079">    metadata.set_state(SysTabletsEntryPB::RUNNING);</a>
<a name="ln1080"> </a>
<a name="ln1081">    auto l = table-&gt;LockForRead();</a>
<a name="ln1082">    PartitionSchema partition_schema;</a>
<a name="ln1083">    RETURN_NOT_OK(PartitionSchema::FromPB(l-&gt;data().pb.partition_schema(),</a>
<a name="ln1084">                                          sys_catalog_-&gt;schema_,</a>
<a name="ln1085">                                          &amp;partition_schema));</a>
<a name="ln1086">    vector&lt;Partition&gt; partitions;</a>
<a name="ln1087">    RETURN_NOT_OK(partition_schema.CreatePartitions(1, &amp;partitions));</a>
<a name="ln1088">    partitions[0].ToPB(metadata.mutable_partition());</a>
<a name="ln1089">    metadata.set_table_id(table-&gt;id());</a>
<a name="ln1090">    metadata.add_table_ids(table-&gt;id());</a>
<a name="ln1091"> </a>
<a name="ln1092">    table-&gt;AddTablet(tablet.get());</a>
<a name="ln1093"> </a>
<a name="ln1094">    auto tablet_map_checkout = tablet_map_.CheckOut();</a>
<a name="ln1095">    (*tablet_map_checkout)[tablet-&gt;tablet_id()] = tablet;</a>
<a name="ln1096"> </a>
<a name="ln1097">    RETURN_NOT_OK(sys_catalog_-&gt;AddItem(tablet.get(), term));</a>
<a name="ln1098">    tablet-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln1099">  }</a>
<a name="ln1100"> </a>
<a name="ln1101">  system_tablets_[kSysCatalogTabletId] = sys_catalog_-&gt;tablet_peer_-&gt;shared_tablet();</a>
<a name="ln1102"> </a>
<a name="ln1103">  return Status::OK();</a>
<a name="ln1104">}</a>
<a name="ln1105"> </a>
<a name="ln1106">template &lt;class T&gt;</a>
<a name="ln1107">Status CatalogManager::PrepareSystemTableTemplate(const TableName&amp; table_name,</a>
<a name="ln1108">                                                  const NamespaceName&amp; namespace_name,</a>
<a name="ln1109">                                                  const NamespaceId&amp; namespace_id,</a>
<a name="ln1110">                                                  int64_t term) {</a>
<a name="ln1111">  YQLVirtualTable* vtable = new T(master_);</a>
<a name="ln1112">  return PrepareSystemTable(</a>
<a name="ln1113">      table_name, namespace_name, namespace_id, vtable-&gt;schema(), term, vtable);</a>
<a name="ln1114">}</a>
<a name="ln1115"> </a>
<a name="ln1116">Status CatalogManager::PrepareSystemTable(const TableName&amp; table_name,</a>
<a name="ln1117">                                          const NamespaceName&amp; namespace_name,</a>
<a name="ln1118">                                          const NamespaceId&amp; namespace_id,</a>
<a name="ln1119">                                          const Schema&amp; schema,</a>
<a name="ln1120">                                          int64_t term,</a>
<a name="ln1121">                                          YQLVirtualTable* vtable) {</a>
<a name="ln1122">  std::unique_ptr&lt;YQLVirtualTable&gt; yql_storage(vtable);</a>
<a name="ln1123"> </a>
<a name="ln1124">  scoped_refptr&lt;TableInfo&gt; table = FindPtrOrNull(table_names_map_,</a>
<a name="ln1125">                                                 std::make_pair(namespace_id, table_name));</a>
<a name="ln1126">  bool create_table = true;</a>
<a name="ln1127">  if (table != nullptr) {</a>
<a name="ln1128">    LOG(INFO) &lt;&lt; &quot;Table &quot; &lt;&lt; namespace_name &lt;&lt; &quot;.&quot; &lt;&lt; table_name &lt;&lt; &quot; already created&quot;;</a>
<a name="ln1129"> </a>
<a name="ln1130">    Schema persisted_schema;</a>
<a name="ln1131">    RETURN_NOT_OK(table-&gt;GetSchema(&amp;persisted_schema));</a>
<a name="ln1132">    if (!persisted_schema.Equals(schema)) {</a>
<a name="ln1133">      LOG(INFO) &lt;&lt; &quot;Updating schema of &quot; &lt;&lt; namespace_name &lt;&lt; &quot;.&quot; &lt;&lt; table_name &lt;&lt; &quot; ...&quot;;</a>
<a name="ln1134">      auto l = table-&gt;LockForWrite();</a>
<a name="ln1135">      SchemaToPB(schema, l-&gt;mutable_data()-&gt;pb.mutable_schema());</a>
<a name="ln1136">      l-&gt;mutable_data()-&gt;pb.set_version(l-&gt;data().pb.version() + 1);</a>
<a name="ln1137"> </a>
<a name="ln1138">      // Update sys-catalog with the new table schema.</a>
<a name="ln1139">      RETURN_NOT_OK(sys_catalog_-&gt;UpdateItem(table.get(), term));</a>
<a name="ln1140">      l-&gt;Commit();</a>
<a name="ln1141">    }</a>
<a name="ln1142"> </a>
<a name="ln1143">    // There might have been a failure after writing the table but before writing the tablets. As</a>
<a name="ln1144">    // a result, if we don't find any tablets, we try to create the tablets only again.</a>
<a name="ln1145">    vector&lt;scoped_refptr&lt;TabletInfo&gt;&gt; tablets;</a>
<a name="ln1146">    table-&gt;GetAllTablets(&amp;tablets);</a>
<a name="ln1147">    if (!tablets.empty()) {</a>
<a name="ln1148">      // Initialize the appropriate system tablet.</a>
<a name="ln1149">      DCHECK_EQ(1, tablets.size());</a>
<a name="ln1150">      system_tablets_[tablets[0]-&gt;tablet_id()] =</a>
<a name="ln1151">          std::make_shared&lt;SystemTablet&gt;(schema, std::move(yql_storage), tablets[0]-&gt;tablet_id());</a>
<a name="ln1152">      return Status::OK();</a>
<a name="ln1153">    } else {</a>
<a name="ln1154">      // Table is already created, only need to create tablets now.</a>
<a name="ln1155">      LOG(INFO) &lt;&lt; &quot;Creating tablets for &quot; &lt;&lt; namespace_name &lt;&lt; &quot;.&quot; &lt;&lt; table_name &lt;&lt; &quot; ...&quot;;</a>
<a name="ln1156">      create_table = false;</a>
<a name="ln1157">    }</a>
<a name="ln1158">  }</a>
<a name="ln1159"> </a>
<a name="ln1160">  vector&lt;TabletInfo*&gt; tablets;</a>
<a name="ln1161"> </a>
<a name="ln1162">  // Create partitions.</a>
<a name="ln1163">  vector&lt;Partition&gt; partitions;</a>
<a name="ln1164">  PartitionSchemaPB partition_schema_pb;</a>
<a name="ln1165">  partition_schema_pb.set_hash_schema(PartitionSchemaPB::MULTI_COLUMN_HASH_SCHEMA);</a>
<a name="ln1166">  PartitionSchema partition_schema;</a>
<a name="ln1167">  RETURN_NOT_OK(PartitionSchema::FromPB(partition_schema_pb, schema, &amp;partition_schema));</a>
<a name="ln1168">  RETURN_NOT_OK(partition_schema.CreatePartitions(1, &amp;partitions));</a>
<a name="ln1169"> </a>
<a name="ln1170">  if (create_table) {</a>
<a name="ln1171">    // Fill in details for the system table.</a>
<a name="ln1172">    CreateTableRequestPB req;</a>
<a name="ln1173">    req.set_name(table_name);</a>
<a name="ln1174">    req.set_table_type(TableType::YQL_TABLE_TYPE);</a>
<a name="ln1175"> </a>
<a name="ln1176">    RETURN_NOT_OK(CreateTableInMemory(</a>
<a name="ln1177">        req, schema, partition_schema, true /* create_tablets */, namespace_id, namespace_name,</a>
<a name="ln1178">        partitions, nullptr, &amp;tablets, nullptr, &amp;table));</a>
<a name="ln1179">    LOG(INFO) &lt;&lt; &quot;Inserted new &quot; &lt;&lt; namespace_name &lt;&lt; &quot;.&quot; &lt;&lt; table_name</a>
<a name="ln1180">              &lt;&lt; &quot; table info into CatalogManager maps&quot;;</a>
<a name="ln1181">    // Update the on-disk table state to &quot;running&quot;.</a>
<a name="ln1182">    table-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb.set_state(SysTablesEntryPB::RUNNING);</a>
<a name="ln1183">    RETURN_NOT_OK(sys_catalog_-&gt;AddItem(table.get(), term));</a>
<a name="ln1184">    LOG(INFO) &lt;&lt; &quot;Wrote table to system catalog: &quot; &lt;&lt; ToString(table) &lt;&lt; &quot;, tablets: &quot;</a>
<a name="ln1185">              &lt;&lt; ToString(tablets);</a>
<a name="ln1186">  } else {</a>
<a name="ln1187">    // Still need to create the tablets.</a>
<a name="ln1188">    RETURN_NOT_OK(CreateTabletsFromTable(partitions, table, &amp;tablets));</a>
<a name="ln1189">  }</a>
<a name="ln1190"> </a>
<a name="ln1191">  DCHECK_EQ(1, tablets.size());</a>
<a name="ln1192">  // We use LOG_ASSERT here since this is expected to crash in some unit tests.</a>
<a name="ln1193">  LOG_ASSERT(!FLAGS_TEST_catalog_manager_simulate_system_table_create_failure);</a>
<a name="ln1194"> </a>
<a name="ln1195">  // Write Tablets to sys-tablets (in &quot;running&quot; state since we don't want the loadbalancer to</a>
<a name="ln1196">  // assign these tablets since this table is virtual).</a>
<a name="ln1197">  for (TabletInfo *tablet : tablets) {</a>
<a name="ln1198">    tablet-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb.set_state(SysTabletsEntryPB::RUNNING);</a>
<a name="ln1199">  }</a>
<a name="ln1200">  RETURN_NOT_OK(sys_catalog_-&gt;AddItems(tablets, term));</a>
<a name="ln1201">  LOG(INFO) &lt;&lt; &quot;Wrote tablets to system catalog: &quot; &lt;&lt; ToString(tablets);</a>
<a name="ln1202"> </a>
<a name="ln1203">  // Commit the in-memory state.</a>
<a name="ln1204">  if (create_table) {</a>
<a name="ln1205">    table-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln1206">  }</a>
<a name="ln1207"> </a>
<a name="ln1208">  for (TabletInfo *tablet : tablets) {</a>
<a name="ln1209">    tablet-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln1210">  }</a>
<a name="ln1211"> </a>
<a name="ln1212">  // Finally create the appropriate tablet object.</a>
<a name="ln1213">  system_tablets_[tablets[0]-&gt;tablet_id()] =</a>
<a name="ln1214">      std::make_shared&lt;SystemTablet&gt;(schema, std::move(yql_storage), tablets[0]-&gt;tablet_id());</a>
<a name="ln1215">  return Status::OK();</a>
<a name="ln1216">}</a>
<a name="ln1217"> </a>
<a name="ln1218">bool CatalogManager::IsYcqlNamespace(const NamespaceInfo&amp; ns) {</a>
<a name="ln1219">  return ns.database_type() == YQLDatabase::YQL_DATABASE_CQL;</a>
<a name="ln1220">}</a>
<a name="ln1221"> </a>
<a name="ln1222">bool CatalogManager::IsYcqlTable(const TableInfo&amp; table) {</a>
<a name="ln1223">  return table.GetTableType() == TableType::YQL_TABLE_TYPE &amp;&amp; table.id() != kSysCatalogTableId;</a>
<a name="ln1224">}</a>
<a name="ln1225"> </a>
<a name="ln1226">Status CatalogManager::PrepareNamespace(</a>
<a name="ln1227">    YQLDatabase db_type, const NamespaceName&amp; name, const NamespaceId&amp; id, int64_t term) {</a>
<a name="ln1228"> </a>
<a name="ln1229">  scoped_refptr&lt;NamespaceInfo&gt; ns = FindPtrOrNull(namespace_ids_map_, id);</a>
<a name="ln1230">  if (ns != nullptr) {</a>
<a name="ln1231">    LOG(INFO) &lt;&lt; &quot;Keyspace &quot; &lt;&lt; ns-&gt;ToString() &lt;&lt; &quot; already created, skipping initialization&quot;;</a>
<a name="ln1232">    return Status::OK();</a>
<a name="ln1233">  }</a>
<a name="ln1234"> </a>
<a name="ln1235">  // Create entry.</a>
<a name="ln1236">  SysNamespaceEntryPB ns_entry;</a>
<a name="ln1237">  ns_entry.set_name(name);</a>
<a name="ln1238">  ns_entry.set_database_type(db_type);</a>
<a name="ln1239">  ns_entry.set_state(SysNamespaceEntryPB::RUNNING);</a>
<a name="ln1240"> </a>
<a name="ln1241">  // Create in memory object.</a>
<a name="ln1242">  ns = new NamespaceInfo(id);</a>
<a name="ln1243"> </a>
<a name="ln1244">  // Prepare write.</a>
<a name="ln1245">  auto l = ns-&gt;LockForWrite();</a>
<a name="ln1246">  l-&gt;mutable_data()-&gt;pb = std::move(ns_entry);</a>
<a name="ln1247"> </a>
<a name="ln1248">  namespace_ids_map_[id] = ns;</a>
<a name="ln1249">  namespace_names_mapper_[db_type][l-&gt;mutable_data()-&gt;pb.name()] = ns;</a>
<a name="ln1250"> </a>
<a name="ln1251">  // Write to sys_catalog and in memory.</a>
<a name="ln1252">  RETURN_NOT_OK(sys_catalog_-&gt;AddItem(ns.get(), term));</a>
<a name="ln1253">  l-&gt;Commit();</a>
<a name="ln1254"> </a>
<a name="ln1255">  LOG(INFO) &lt;&lt; &quot;Created default keyspace: &quot; &lt;&lt; ns-&gt;ToString();</a>
<a name="ln1256">  return Status::OK();</a>
<a name="ln1257">}</a>
<a name="ln1258"> </a>
<a name="ln1259">Status CatalogManager::CheckLocalHostInMasterAddresses() {</a>
<a name="ln1260">  auto local_hostport = master_-&gt;first_rpc_address();</a>
<a name="ln1261">  std::vector&lt;IpAddress&gt; local_addrs;</a>
<a name="ln1262"> </a>
<a name="ln1263">  if (local_hostport.address().is_unspecified()) {</a>
<a name="ln1264">    auto status = GetLocalAddresses(&amp;local_addrs, AddressFilter::ANY);</a>
<a name="ln1265">    if (!status.ok() || local_addrs.empty()) {</a>
<a name="ln1266">      LOG(WARNING) &lt;&lt; &quot;Could not enumerate network interfaces due to &quot; &lt;&lt; status &lt;&lt; &quot;, found &quot;</a>
<a name="ln1267">                   &lt;&lt; local_addrs.size() &lt;&lt; &quot; local addresses.&quot;;</a>
<a name="ln1268">      return Status::OK();</a>
<a name="ln1269">    }</a>
<a name="ln1270">  } else {</a>
<a name="ln1271">    local_addrs.push_back(local_hostport.address());</a>
<a name="ln1272">  }</a>
<a name="ln1273"> </a>
<a name="ln1274">  std::vector&lt;Endpoint&gt; resolved_addresses;</a>
<a name="ln1275">  Status s = server::ResolveMasterAddresses(master_-&gt;opts().GetMasterAddresses(),</a>
<a name="ln1276">                                            &amp;resolved_addresses);</a>
<a name="ln1277">  RETURN_NOT_OK(s);</a>
<a name="ln1278"> </a>
<a name="ln1279">  for (auto const &amp;addr : resolved_addresses) {</a>
<a name="ln1280">    if (addr.address().is_unspecified() ||</a>
<a name="ln1281">        std::find(local_addrs.begin(), local_addrs.end(), addr.address()) !=</a>
<a name="ln1282">            local_addrs.end()) {</a>
<a name="ln1283">      return Status::OK();</a>
<a name="ln1284">    }</a>
<a name="ln1285">  }</a>
<a name="ln1286">  return STATUS_SUBSTITUTE(IllegalState,</a>
<a name="ln1287">      &quot;None of the local addresses are present in master_addresses $0.&quot;,</a>
<a name="ln1288">      master_-&gt;opts().master_addresses_flag);</a>
<a name="ln1289">}</a>
<a name="ln1290"> </a>
<a name="ln1291">Status CatalogManager::InitSysCatalogAsync(bool is_first_run) {</a>
<a name="ln1292">  std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln1293">  if (is_first_run) {</a>
<a name="ln1294">    if (!master_-&gt;opts().AreMasterAddressesProvided()) {</a>
<a name="ln1295">      master_-&gt;SetShellMode(true);</a>
<a name="ln1296">      LOG(INFO) &lt;&lt; &quot;Starting master in shell mode.&quot;;</a>
<a name="ln1297">      return Status::OK();</a>
<a name="ln1298">    }</a>
<a name="ln1299"> </a>
<a name="ln1300">    RETURN_NOT_OK(CheckLocalHostInMasterAddresses());</a>
<a name="ln1301">    RETURN_NOT_OK(sys_catalog_-&gt;CreateNew(master_-&gt;fs_manager()));</a>
<a name="ln1302">  } else {</a>
<a name="ln1303">    RETURN_NOT_OK(sys_catalog_-&gt;Load(master_-&gt;fs_manager()));</a>
<a name="ln1304">  }</a>
<a name="ln1305">  return Status::OK();</a>
<a name="ln1306">}</a>
<a name="ln1307"> </a>
<a name="ln1308">bool CatalogManager::IsInitialized() const {</a>
<a name="ln1309">  std::lock_guard&lt;simple_spinlock&gt; l(state_lock_);</a>
<a name="ln1310">  return state_ == kRunning;</a>
<a name="ln1311">}</a>
<a name="ln1312"> </a>
<a name="ln1313">// TODO - delete this API after HandleReportedTablet() usage is removed.</a>
<a name="ln1314">Status CatalogManager::CheckIsLeaderAndReady() const {</a>
<a name="ln1315">  std::lock_guard&lt;simple_spinlock&gt; l(state_lock_);</a>
<a name="ln1316">  if (PREDICT_FALSE(state_ != kRunning)) {</a>
<a name="ln1317">    return STATUS_SUBSTITUTE(ServiceUnavailable,</a>
<a name="ln1318">        &quot;Catalog manager is shutting down. State: $0&quot;, state_);</a>
<a name="ln1319">  }</a>
<a name="ln1320">  string uuid = master_-&gt;fs_manager()-&gt;uuid();</a>
<a name="ln1321">  if (master_-&gt;opts().IsShellMode()) {</a>
<a name="ln1322">    // Consensus and other internal fields should not be checked when is shell mode.</a>
<a name="ln1323">    return STATUS_SUBSTITUTE(IllegalState,</a>
<a name="ln1324">        &quot;Catalog manager of $0 is in shell mode, not the leader&quot;, uuid);</a>
<a name="ln1325">  }</a>
<a name="ln1326">  Consensus* consensus = tablet_peer()-&gt;consensus();</a>
<a name="ln1327">  if (consensus == nullptr) {</a>
<a name="ln1328">    return STATUS(IllegalState, &quot;Consensus has not been initialized yet&quot;);</a>
<a name="ln1329">  }</a>
<a name="ln1330">  ConsensusStatePB cstate = consensus-&gt;ConsensusState(CONSENSUS_CONFIG_COMMITTED);</a>
<a name="ln1331">  if (PREDICT_FALSE(!cstate.has_leader_uuid() || cstate.leader_uuid() != uuid)) {</a>
<a name="ln1332">    return STATUS_SUBSTITUTE(IllegalState,</a>
<a name="ln1333">        &quot;Not the leader. Local UUID: $0, Consensus state: $1&quot;, uuid, cstate.ShortDebugString());</a>
<a name="ln1334">  }</a>
<a name="ln1335">  if (PREDICT_FALSE(leader_ready_term_ != cstate.current_term())) {</a>
<a name="ln1336">    return STATUS_SUBSTITUTE(ServiceUnavailable,</a>
<a name="ln1337">        &quot;Leader not yet ready to serve requests: ready term $0 vs cstate term $1&quot;,</a>
<a name="ln1338">        leader_ready_term_, cstate.current_term());</a>
<a name="ln1339">  }</a>
<a name="ln1340">  return Status::OK();</a>
<a name="ln1341">}</a>
<a name="ln1342"> </a>
<a name="ln1343">const std::shared_ptr&lt;tablet::TabletPeer&gt; CatalogManager::tablet_peer() const {</a>
<a name="ln1344">  return sys_catalog_-&gt;tablet_peer();</a>
<a name="ln1345">}</a>
<a name="ln1346"> </a>
<a name="ln1347">RaftPeerPB::Role CatalogManager::Role() const {</a>
<a name="ln1348">  CHECK(IsInitialized());</a>
<a name="ln1349">  if (master_-&gt;opts().IsShellMode()) {</a>
<a name="ln1350">    return RaftPeerPB::NON_PARTICIPANT;</a>
<a name="ln1351">  }</a>
<a name="ln1352"> </a>
<a name="ln1353">  return tablet_peer()-&gt;consensus()-&gt;role();</a>
<a name="ln1354">}</a>
<a name="ln1355"> </a>
<a name="ln1356">void CatalogManager::Shutdown() {</a>
<a name="ln1357">  {</a>
<a name="ln1358">    std::lock_guard&lt;simple_spinlock&gt; l(state_lock_);</a>
<a name="ln1359">    if (state_ == kClosing) {</a>
<a name="ln1360">      VLOG(2) &lt;&lt; &quot;CatalogManager already shut down&quot;;</a>
<a name="ln1361">      return;</a>
<a name="ln1362">    }</a>
<a name="ln1363">    state_ = kClosing;</a>
<a name="ln1364">  }</a>
<a name="ln1365"> </a>
<a name="ln1366">  // Shutdown the Catalog Manager background thread (load balancing).</a>
<a name="ln1367">  if (background_tasks_) {</a>
<a name="ln1368">    background_tasks_-&gt;Shutdown();</a>
<a name="ln1369">  }</a>
<a name="ln1370">  // Shutdown the Catalog Manager background tasks (CM only) thread pool.</a>
<a name="ln1371">  if (background_tasks_thread_pool_) {</a>
<a name="ln1372">    background_tasks_thread_pool_-&gt;Shutdown();</a>
<a name="ln1373">  }</a>
<a name="ln1374">  // Shutdown the Catalog Manager worker (CM&lt;-&gt;TS) pool.</a>
<a name="ln1375">  if (worker_pool_) {</a>
<a name="ln1376">    worker_pool_-&gt;Shutdown();</a>
<a name="ln1377">  }</a>
<a name="ln1378"> </a>
<a name="ln1379">  // Mark all outstanding table tasks as aborted and wait for them to fail.</a>
<a name="ln1380">  //</a>
<a name="ln1381">  // There may be an outstanding table visitor thread modifying the table map,</a>
<a name="ln1382">  // so we must make a copy of it before we iterate. It's OK if the visitor</a>
<a name="ln1383">  // adds more entries to the map even after we finish; it won't start any new</a>
<a name="ln1384">  // tasks for those entries.</a>
<a name="ln1385">  vector&lt;scoped_refptr&lt;TableInfo&gt;&gt; copy;</a>
<a name="ln1386">  {</a>
<a name="ln1387">    SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln1388">    AppendValuesFromMap(*table_ids_map_, &amp;copy);</a>
<a name="ln1389">  }</a>
<a name="ln1390">  AbortAndWaitForAllTasks(copy);</a>
<a name="ln1391"> </a>
<a name="ln1392">  // Shut down the underlying storage for tables and tablets.</a>
<a name="ln1393">  if (sys_catalog_) {</a>
<a name="ln1394">    sys_catalog_-&gt;Shutdown();</a>
<a name="ln1395">  }</a>
<a name="ln1396"> </a>
<a name="ln1397">  // Reset the jobs/tasks tracker.</a>
<a name="ln1398">  tasks_tracker_-&gt;Reset();</a>
<a name="ln1399">  jobs_tracker_-&gt;Reset();</a>
<a name="ln1400"> </a>
<a name="ln1401">  if (initdb_future_ &amp;&amp; initdb_future_-&gt;wait_for(0s) != std::future_status::ready) {</a>
<a name="ln1402">    LOG(WARNING) &lt;&lt; &quot;initdb is still running, waiting for it to complete.&quot;;</a>
<a name="ln1403">    initdb_future_-&gt;wait();</a>
<a name="ln1404">    LOG(INFO) &lt;&lt; &quot;Finished running initdb, proceeding with catalog manager shutdown.&quot;;</a>
<a name="ln1405">  }</a>
<a name="ln1406">}</a>
<a name="ln1407"> </a>
<a name="ln1408">Status CatalogManager::CheckOnline() const {</a>
<a name="ln1409">  if (PREDICT_FALSE(!IsInitialized())) {</a>
<a name="ln1410">    return STATUS(ServiceUnavailable, &quot;CatalogManager is not running&quot;);</a>
<a name="ln1411">  }</a>
<a name="ln1412">  return Status::OK();</a>
<a name="ln1413">}</a>
<a name="ln1414"> </a>
<a name="ln1415">Status CatalogManager::AbortTableCreation(TableInfo* table,</a>
<a name="ln1416">                                          const vector&lt;TabletInfo*&gt;&amp; tablets,</a>
<a name="ln1417">                                          const Status&amp; s,</a>
<a name="ln1418">                                          CreateTableResponsePB* resp) {</a>
<a name="ln1419">  LOG(WARNING) &lt;&lt; s;</a>
<a name="ln1420"> </a>
<a name="ln1421">  const TableId table_id = table-&gt;id();</a>
<a name="ln1422">  const TableName table_name = table-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb.name();</a>
<a name="ln1423">  const NamespaceId table_namespace_id =</a>
<a name="ln1424">      table-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb.namespace_id();</a>
<a name="ln1425">  vector&lt;string&gt; tablet_ids_to_erase;</a>
<a name="ln1426">  for (TabletInfo* tablet : tablets) {</a>
<a name="ln1427">    tablet_ids_to_erase.push_back(tablet-&gt;tablet_id());</a>
<a name="ln1428">  }</a>
<a name="ln1429"> </a>
<a name="ln1430">  LOG(INFO) &lt;&lt; &quot;Aborting creation of table '&quot; &lt;&lt; table_name &lt;&lt; &quot;', erasing table and tablets (&quot; &lt;&lt;</a>
<a name="ln1431">      JoinStrings(tablet_ids_to_erase, &quot;,&quot;) &lt;&lt; &quot;) from in-memory state.&quot;;</a>
<a name="ln1432"> </a>
<a name="ln1433">  // Since this is a failed creation attempt, it's safe to just abort</a>
<a name="ln1434">  // all tasks, as (by definition) no tasks may be pending against a</a>
<a name="ln1435">  // table that has failed to successfully create.</a>
<a name="ln1436">  table-&gt;AbortTasksAndClose();</a>
<a name="ln1437">  table-&gt;WaitTasksCompletion();</a>
<a name="ln1438"> </a>
<a name="ln1439">  std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln1440"> </a>
<a name="ln1441">  // Call AbortMutation() manually, as otherwise the lock won't be released.</a>
<a name="ln1442">  for (TabletInfo* tablet : tablets) {</a>
<a name="ln1443">    tablet-&gt;mutable_metadata()-&gt;AbortMutation();</a>
<a name="ln1444">  }</a>
<a name="ln1445">  table-&gt;mutable_metadata()-&gt;AbortMutation();</a>
<a name="ln1446">  auto tablet_map_checkout = tablet_map_.CheckOut();</a>
<a name="ln1447">  for (const TabletId&amp; tablet_id_to_erase : tablet_ids_to_erase) {</a>
<a name="ln1448">    CHECK_EQ(tablet_map_checkout-&gt;erase(tablet_id_to_erase), 1)</a>
<a name="ln1449">        &lt;&lt; &quot;Unable to erase tablet &quot; &lt;&lt; tablet_id_to_erase &lt;&lt; &quot; from tablet map.&quot;;</a>
<a name="ln1450">  }</a>
<a name="ln1451"> </a>
<a name="ln1452">  auto table_ids_map_checkout = table_ids_map_.CheckOut();</a>
<a name="ln1453">  table_names_map_.erase({table_namespace_id, table_name}); // Not present if PGSQL table.</a>
<a name="ln1454">  CHECK_EQ(table_ids_map_checkout-&gt;erase(table_id), 1)</a>
<a name="ln1455">      &lt;&lt; &quot;Unable to erase table with id &quot; &lt;&lt; table_id &lt;&lt; &quot; from table ids map.&quot;;</a>
<a name="ln1456"> </a>
<a name="ln1457">  return CheckIfNoLongerLeaderAndSetupError(s, resp);</a>
<a name="ln1458">}</a>
<a name="ln1459"> </a>
<a name="ln1460">Status CatalogManager::ValidateTableReplicationInfo(const ReplicationInfoPB&amp; replication_info) {</a>
<a name="ln1461">  // TODO(bogdan): add the actual subset rules, instead of just erroring out as not supported.</a>
<a name="ln1462">  const auto&amp; live_placement_info = replication_info.live_replicas();</a>
<a name="ln1463">  if (!(live_placement_info.placement_blocks().empty() &amp;&amp;</a>
<a name="ln1464">        live_placement_info.num_replicas() &lt;= 0 &amp;&amp;</a>
<a name="ln1465">        live_placement_info.placement_uuid().empty()) ||</a>
<a name="ln1466">      !replication_info.read_replicas().empty() ||</a>
<a name="ln1467">      !replication_info.affinitized_leaders().empty()) {</a>
<a name="ln1468">    return STATUS(</a>
<a name="ln1469">        InvalidArgument,</a>
<a name="ln1470">        &quot;Unsupported: cannot set table level replication info yet.&quot;);</a>
<a name="ln1471">  }</a>
<a name="ln1472">  return Status::OK();</a>
<a name="ln1473">}</a>
<a name="ln1474"> </a>
<a name="ln1475">Status CatalogManager::AddIndexInfoToTable(const scoped_refptr&lt;TableInfo&gt;&amp; indexed_table,</a>
<a name="ln1476">                                           const IndexInfoPB&amp; index_info,</a>
<a name="ln1477">                                           CreateTableResponsePB* resp) {</a>
<a name="ln1478">  LOG(INFO) &lt;&lt; &quot;AddIndexInfoToTable to &quot; &lt;&lt; indexed_table-&gt;ToString() &lt;&lt; &quot;  IndexInfo &quot;</a>
<a name="ln1479">            &lt;&lt; yb::ToString(index_info);</a>
<a name="ln1480">  TRACE(&quot;Locking indexed table&quot;);</a>
<a name="ln1481">  auto l = DCHECK_NOTNULL(indexed_table)-&gt;LockForWrite();</a>
<a name="ln1482">  RETURN_NOT_OK(CheckIfTableDeletedOrNotRunning(l.get(), resp));</a>
<a name="ln1483"> </a>
<a name="ln1484">  // Add index info to indexed table and increment schema version.</a>
<a name="ln1485">  l-&gt;mutable_data()-&gt;pb.add_indexes()-&gt;CopyFrom(index_info);</a>
<a name="ln1486">  l-&gt;mutable_data()-&gt;pb.set_version(l-&gt;mutable_data()-&gt;pb.version() + 1);</a>
<a name="ln1487">  l-&gt;mutable_data()-&gt;set_state(SysTablesEntryPB::ALTERING,</a>
<a name="ln1488">                               Substitute(&quot;Alter table version=$0 ts=$1&quot;,</a>
<a name="ln1489">                                          l-&gt;mutable_data()-&gt;pb.version(),</a>
<a name="ln1490">                                          LocalTimeAsString()));</a>
<a name="ln1491"> </a>
<a name="ln1492">  // Update sys-catalog with the new indexed table info.</a>
<a name="ln1493">  TRACE(&quot;Updating indexed table metadata on disk&quot;);</a>
<a name="ln1494">  RETURN_NOT_OK(sys_catalog_-&gt;UpdateItem(indexed_table.get(), leader_ready_term()));</a>
<a name="ln1495"> </a>
<a name="ln1496">  // Update the in-memory state.</a>
<a name="ln1497">  TRACE(&quot;Committing in-memory state&quot;);</a>
<a name="ln1498">  l-&gt;Commit();</a>
<a name="ln1499"> </a>
<a name="ln1500">  SendAlterTableRequest(indexed_table);</a>
<a name="ln1501"> </a>
<a name="ln1502">  return Status::OK();</a>
<a name="ln1503">}</a>
<a name="ln1504"> </a>
<a name="ln1505">Status CatalogManager::CreateCopartitionedTable(const CreateTableRequestPB&amp; req,</a>
<a name="ln1506">                                                CreateTableResponsePB* resp,</a>
<a name="ln1507">                                                rpc::RpcContext* rpc,</a>
<a name="ln1508">                                                Schema schema,</a>
<a name="ln1509">                                                scoped_refptr&lt;NamespaceInfo&gt; ns) {</a>
<a name="ln1510">  scoped_refptr&lt;TableInfo&gt; parent_table_info;</a>
<a name="ln1511">  Status s;</a>
<a name="ln1512">  PartitionSchema partition_schema;</a>
<a name="ln1513">  std::vector&lt;Partition&gt; partitions;</a>
<a name="ln1514"> </a>
<a name="ln1515">  const NamespaceId&amp; namespace_id = ns-&gt;id();</a>
<a name="ln1516">  const NamespaceName&amp; namespace_name = ns-&gt;name();</a>
<a name="ln1517"> </a>
<a name="ln1518">  std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln1519">  TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln1520">  parent_table_info = FindPtrOrNull(*table_ids_map_,</a>
<a name="ln1521">                                    schema.table_properties().CopartitionTableId());</a>
<a name="ln1522">  if (parent_table_info == nullptr) {</a>
<a name="ln1523">    s = STATUS(NotFound, &quot;The object does not exist: copartitioned table with id&quot;,</a>
<a name="ln1524">               schema.table_properties().CopartitionTableId());</a>
<a name="ln1525">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln1526">  }</a>
<a name="ln1527"> </a>
<a name="ln1528">  scoped_refptr&lt;TableInfo&gt; this_table_info;</a>
<a name="ln1529">  std::vector&lt;TabletInfo *&gt; tablets;</a>
<a name="ln1530">  TabletInfos scoped_ref_tablets;</a>
<a name="ln1531">  // Verify that the table does not exist.</a>
<a name="ln1532">  this_table_info = FindPtrOrNull(table_names_map_, {namespace_id, req.name()});</a>
<a name="ln1533"> </a>
<a name="ln1534">  if (this_table_info != nullptr) {</a>
<a name="ln1535">    s = STATUS_SUBSTITUTE(AlreadyPresent,</a>
<a name="ln1536">        &quot;Object '$0.$1' already exists&quot;,</a>
<a name="ln1537">        GetNamespaceNameUnlocked(this_table_info), this_table_info-&gt;name());</a>
<a name="ln1538">    LOG(WARNING) &lt;&lt; &quot;Found table: &quot; &lt;&lt; this_table_info-&gt;ToStringWithState()</a>
<a name="ln1539">                 &lt;&lt; &quot;. Failed creating copartitioned table with error: &quot;</a>
<a name="ln1540">                 &lt;&lt; s.ToString() &lt;&lt; &quot; Request:\n&quot; &lt;&lt; req.DebugString();</a>
<a name="ln1541">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_ALREADY_PRESENT, s);</a>
<a name="ln1542">  }</a>
<a name="ln1543">  // Don't add copartitioned tables to Namespaces that aren't running.</a>
<a name="ln1544">  if (ns-&gt;state() != SysNamespaceEntryPB::RUNNING) {</a>
<a name="ln1545">    Status s = STATUS_SUBSTITUTE(TryAgain,</a>
<a name="ln1546">        &quot;Namespace not running (State=$0).  Cannot create $1.$2&quot;,</a>
<a name="ln1547">        ns-&gt;state(), ns-&gt;name(), req.name() );</a>
<a name="ln1548">    return SetupError(resp-&gt;mutable_error(), NamespaceMasterError(ns-&gt;state()), s);</a>
<a name="ln1549">  }</a>
<a name="ln1550"> </a>
<a name="ln1551">  // TODO: pass index_info for copartitioned index.</a>
<a name="ln1552">  RETURN_NOT_OK(CreateTableInMemory(</a>
<a name="ln1553">      req, schema, partition_schema, false /* create_tablets */, namespace_id, namespace_name,</a>
<a name="ln1554">      partitions, nullptr, nullptr, resp, &amp;this_table_info));</a>
<a name="ln1555"> </a>
<a name="ln1556">  TRACE(&quot;Inserted new table info into CatalogManager maps&quot;);</a>
<a name="ln1557"> </a>
<a name="ln1558">  // NOTE: the table is already locked for write at this point,</a>
<a name="ln1559">  // since the CreateTableInfo function leave it in that state.</a>
<a name="ln1560">  // It will get committed at the end of this function.</a>
<a name="ln1561">  // Sanity check: the table should be in &quot;preparing&quot; state.</a>
<a name="ln1562">  CHECK_EQ(SysTablesEntryPB::PREPARING, this_table_info-&gt;metadata().dirty().pb.state());</a>
<a name="ln1563">  parent_table_info-&gt;GetAllTablets(&amp;scoped_ref_tablets);</a>
<a name="ln1564">  for (auto tablet : scoped_ref_tablets) {</a>
<a name="ln1565">    tablets.push_back(tablet.get());</a>
<a name="ln1566">    tablet-&gt;mutable_metadata()-&gt;StartMutation();</a>
<a name="ln1567">    tablet-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb.add_table_ids(this_table_info-&gt;id());</a>
<a name="ln1568">  }</a>
<a name="ln1569"> </a>
<a name="ln1570">  // Update Tablets about new table id to sys-tablets.</a>
<a name="ln1571">  s = sys_catalog_-&gt;UpdateItems(tablets, leader_ready_term());</a>
<a name="ln1572">  if (PREDICT_FALSE(!s.ok())) {</a>
<a name="ln1573">    return AbortTableCreation(this_table_info.get(), tablets, s.CloneAndPrepend(</a>
<a name="ln1574">        Substitute(&quot;An error occurred while inserting to sys-tablets: $0&quot;, s.ToString())), resp);</a>
<a name="ln1575">  }</a>
<a name="ln1576">  TRACE(&quot;Wrote tablets to system table&quot;);</a>
<a name="ln1577"> </a>
<a name="ln1578">  // Update the on-disk table state to &quot;running&quot;.</a>
<a name="ln1579">  this_table_info-&gt;AddTablets(tablets);</a>
<a name="ln1580">  this_table_info-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb.set_state(SysTablesEntryPB::RUNNING);</a>
<a name="ln1581">  s = sys_catalog_-&gt;AddItem(this_table_info.get(), leader_ready_term());</a>
<a name="ln1582">  if (PREDICT_FALSE(!s.ok())) {</a>
<a name="ln1583">    return AbortTableCreation(this_table_info.get(), tablets, s.CloneAndPrepend(</a>
<a name="ln1584">        Substitute(&quot;An error occurred while inserting to sys-tablets: $0&quot;,</a>
<a name="ln1585">                   s.ToString())), resp);</a>
<a name="ln1586">  }</a>
<a name="ln1587">  TRACE(&quot;Wrote table to system table&quot;);</a>
<a name="ln1588"> </a>
<a name="ln1589">  // Commit the in-memory state.</a>
<a name="ln1590">  this_table_info-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln1591"> </a>
<a name="ln1592">  for (TabletInfo *tablet : tablets) {</a>
<a name="ln1593">    tablet-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln1594">  }</a>
<a name="ln1595"> </a>
<a name="ln1596">  for (const auto&amp; tablet : scoped_ref_tablets) {</a>
<a name="ln1597">    SendCopartitionTabletRequest(tablet, this_table_info);</a>
<a name="ln1598">  }</a>
<a name="ln1599"> </a>
<a name="ln1600">  LOG(INFO) &lt;&lt; &quot;Successfully created table &quot; &lt;&lt; this_table_info-&gt;ToString()</a>
<a name="ln1601">            &lt;&lt; &quot; per request from &quot; &lt;&lt; RequestorString(rpc);</a>
<a name="ln1602">  return Status::OK();</a>
<a name="ln1603">}</a>
<a name="ln1604"> </a>
<a name="ln1605">namespace {</a>
<a name="ln1606"> </a>
<a name="ln1607">std::array&lt;PartitionPB, 2&gt; CreateNewTabletsPartition(</a>
<a name="ln1608">    const TabletInfo&amp; tablet_info, const std::string&amp; split_partition_key) {</a>
<a name="ln1609">  const auto&amp; source_partition = tablet_info.LockForRead()-&gt;data().pb.partition();</a>
<a name="ln1610"> </a>
<a name="ln1611">  std::array&lt;PartitionPB, 2&gt; new_tablets_partition;</a>
<a name="ln1612"> </a>
<a name="ln1613">  new_tablets_partition.fill(source_partition);</a>
<a name="ln1614"> </a>
<a name="ln1615">  new_tablets_partition[0].set_partition_key_end(split_partition_key);</a>
<a name="ln1616">  new_tablets_partition[1].set_partition_key_start(split_partition_key);</a>
<a name="ln1617"> </a>
<a name="ln1618">  return new_tablets_partition;</a>
<a name="ln1619">}</a>
<a name="ln1620"> </a>
<a name="ln1621">}  // namespace</a>
<a name="ln1622"> </a>
<a name="ln1623">Status CatalogManager::TEST_SplitTablet(</a>
<a name="ln1624">    const scoped_refptr&lt;TabletInfo&gt;&amp; source_tablet_info, docdb::DocKeyHash split_hash_code) {</a>
<a name="ln1625">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln1626">  return DoSplitTablet(source_tablet_info, split_hash_code);</a>
<a name="ln1627">}</a>
<a name="ln1628"> </a>
<a name="ln1629">Status CatalogManager::DoSplitTablet(</a>
<a name="ln1630">    const scoped_refptr&lt;TabletInfo&gt;&amp; source_tablet_info, const std::string&amp; split_encoded_key,</a>
<a name="ln1631">    const std::string&amp; split_partition_key) {</a>
<a name="ln1632">  if (source_tablet_info-&gt;colocated()) {</a>
<a name="ln1633">    return STATUS_FORMAT(</a>
<a name="ln1634">        IllegalState, &quot;Tablet splitting is not supported for colocated tables, tablet_id: $0&quot;,</a>
<a name="ln1635">        source_tablet_info-&gt;tablet_id());</a>
<a name="ln1636">  }</a>
<a name="ln1637"> </a>
<a name="ln1638">  constexpr auto kNumSplitParts = 2;</a>
<a name="ln1639"> </a>
<a name="ln1640">  std::array&lt;PartitionPB, kNumSplitParts&gt; new_tablets_partition = CreateNewTabletsPartition(</a>
<a name="ln1641">      *source_tablet_info, split_partition_key);</a>
<a name="ln1642"> </a>
<a name="ln1643">  std::array&lt;TabletId, kNumSplitParts&gt; new_tablet_ids;</a>
<a name="ln1644">  for (int i = 0; i &lt; kNumSplitParts; ++i) {</a>
<a name="ln1645">    auto* new_tablet_info = VERIFY_RESULT(</a>
<a name="ln1646">        RegisterNewTabletForSplit(*source_tablet_info, new_tablets_partition[i]));</a>
<a name="ln1647">    new_tablet_ids[i] = new_tablet_info-&gt;id();</a>
<a name="ln1648">  }</a>
<a name="ln1649"> </a>
<a name="ln1650">  // TODO(tsplit): what if source tablet will be deleted before or during TS leader is processing</a>
<a name="ln1651">  // split? Add unit-test.</a>
<a name="ln1652">  SendSplitTabletRequest(</a>
<a name="ln1653">      source_tablet_info, new_tablet_ids, split_encoded_key, split_partition_key);</a>
<a name="ln1654"> </a>
<a name="ln1655">  return Status::OK();</a>
<a name="ln1656">}</a>
<a name="ln1657"> </a>
<a name="ln1658">Status CatalogManager::DoSplitTablet(</a>
<a name="ln1659">    const scoped_refptr&lt;TabletInfo&gt;&amp; source_tablet_info, docdb::DocKeyHash split_hash_code) {</a>
<a name="ln1660">  docdb::KeyBytes split_encoded_key;</a>
<a name="ln1661">  docdb::DocKeyEncoderAfterTableIdStep(&amp;split_encoded_key)</a>
<a name="ln1662">      .Hash(split_hash_code, std::vector&lt;docdb::PrimitiveValue&gt;());</a>
<a name="ln1663"> </a>
<a name="ln1664">  const auto split_partition_key = PartitionSchema::EncodeMultiColumnHashValue(split_hash_code);</a>
<a name="ln1665"> </a>
<a name="ln1666">  return DoSplitTablet(source_tablet_info, split_encoded_key.ToStringBuffer(), split_partition_key);</a>
<a name="ln1667">}</a>
<a name="ln1668"> </a>
<a name="ln1669">Result&lt;scoped_refptr&lt;TabletInfo&gt;&gt; CatalogManager::GetTabletInfo(const TabletId&amp; tablet_id) {</a>
<a name="ln1670">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln1671"> </a>
<a name="ln1672">  std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln1673">  TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln1674"> </a>
<a name="ln1675">  const auto tablet_info = FindPtrOrNull(*tablet_map_, tablet_id);</a>
<a name="ln1676">  SCHECK(tablet_info != nullptr, NotFound, Format(&quot;Tablet $0 not found&quot;, tablet_id));</a>
<a name="ln1677"> </a>
<a name="ln1678">  return tablet_info;</a>
<a name="ln1679">}</a>
<a name="ln1680"> </a>
<a name="ln1681">Status CatalogManager::SplitTablet(</a>
<a name="ln1682">    const TabletId&amp; tablet_id, const std::string&amp; split_encoded_key,</a>
<a name="ln1683">    const std::string&amp; split_partition_key) {</a>
<a name="ln1684">  const auto source_tablet_info = VERIFY_RESULT(GetTabletInfo(tablet_id));</a>
<a name="ln1685"> </a>
<a name="ln1686">  return DoSplitTablet(source_tablet_info, split_encoded_key, split_partition_key);</a>
<a name="ln1687">}</a>
<a name="ln1688"> </a>
<a name="ln1689">Status CatalogManager::SplitTablet(</a>
<a name="ln1690">    const SplitTabletRequestPB* req, SplitTabletResponsePB* resp, rpc::RpcContext* rpc) {</a>
<a name="ln1691">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln1692"> </a>
<a name="ln1693">  const auto source_tablet_id = req-&gt;tablet_id();</a>
<a name="ln1694">  const auto source_tablet_info = VERIFY_RESULT(GetTabletInfo(source_tablet_id));</a>
<a name="ln1695">  const auto source_partition = source_tablet_info-&gt;LockForRead()-&gt;data().pb.partition();</a>
<a name="ln1696"> </a>
<a name="ln1697">  const auto start_hash_code = source_partition.partition_key_start().empty()</a>
<a name="ln1698">      ? 0</a>
<a name="ln1699">      : PartitionSchema::DecodeMultiColumnHashValue(source_partition.partition_key_start());</a>
<a name="ln1700"> </a>
<a name="ln1701">  const auto end_hash_code = source_partition.partition_key_end().empty()</a>
<a name="ln1702">      ? std::numeric_limits&lt;docdb::DocKeyHash&gt;::max()</a>
<a name="ln1703">      : PartitionSchema::DecodeMultiColumnHashValue(source_partition.partition_key_end());</a>
<a name="ln1704"> </a>
<a name="ln1705">  const auto split_hash_code = (start_hash_code + end_hash_code) / 2;</a>
<a name="ln1706"> </a>
<a name="ln1707">  return DoSplitTablet(source_tablet_info, split_hash_code);</a>
<a name="ln1708">}</a>
<a name="ln1709"> </a>
<a name="ln1710">namespace {</a>
<a name="ln1711"> </a>
<a name="ln1712">CHECKED_STATUS ValidateCreateTableSchema(const Schema&amp; schema, CreateTableResponsePB* resp) {</a>
<a name="ln1713">  if (schema.has_column_ids()) {</a>
<a name="ln1714">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA,</a>
<a name="ln1715">                      STATUS(InvalidArgument, &quot;User requests should not have Column IDs&quot;));</a>
<a name="ln1716">  }</a>
<a name="ln1717">  if (schema.num_key_columns() &lt;= 0) {</a>
<a name="ln1718">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA,</a>
<a name="ln1719">                      STATUS(InvalidArgument, &quot;Must specify at least one key column&quot;));</a>
<a name="ln1720">  }</a>
<a name="ln1721">  for (int i = 0; i &lt; schema.num_key_columns(); i++) {</a>
<a name="ln1722">    if (!IsTypeAllowableInKey(schema.column(i).type_info())) {</a>
<a name="ln1723">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA,</a>
<a name="ln1724">                        STATUS(InvalidArgument, &quot;Invalid datatype for primary key column&quot;));</a>
<a name="ln1725">    }</a>
<a name="ln1726">  }</a>
<a name="ln1727">  return Status::OK();</a>
<a name="ln1728">}</a>
<a name="ln1729"> </a>
<a name="ln1730">}  // namespace</a>
<a name="ln1731"> </a>
<a name="ln1732">Status CatalogManager::CreatePgsqlSysTable(const CreateTableRequestPB* req,</a>
<a name="ln1733">                                           CreateTableResponsePB* resp) {</a>
<a name="ln1734">  LOG(INFO) &lt;&lt; &quot;CreatePgsqlSysTable: &quot; &lt;&lt; req-&gt;name();</a>
<a name="ln1735">  // Lookup the namespace and verify if it exists.</a>
<a name="ln1736">  TRACE(&quot;Looking up namespace&quot;);</a>
<a name="ln1737">  scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln1738">  RETURN_NAMESPACE_NOT_FOUND(FindNamespace(req-&gt;namespace_(), &amp;ns), resp);</a>
<a name="ln1739">  const NamespaceId&amp; namespace_id = ns-&gt;id();</a>
<a name="ln1740">  const NamespaceName&amp; namespace_name = ns-&gt;name();</a>
<a name="ln1741"> </a>
<a name="ln1742">  Schema schema;</a>
<a name="ln1743">  Schema client_schema;</a>
<a name="ln1744">  RETURN_NOT_OK(SchemaFromPB(req-&gt;schema(), &amp;client_schema));</a>
<a name="ln1745">  // If the schema contains column ids, we are copying a Postgres table from one namespace to</a>
<a name="ln1746">  // another. In that case, just use the schema as-is. Otherwise, validate the schema.</a>
<a name="ln1747">  if (client_schema.has_column_ids()) {</a>
<a name="ln1748">    schema = std::move(client_schema);</a>
<a name="ln1749">  } else {</a>
<a name="ln1750">    RETURN_NOT_OK(ValidateCreateTableSchema(client_schema, resp));</a>
<a name="ln1751">    schema = client_schema.CopyWithColumnIds();</a>
<a name="ln1752">  }</a>
<a name="ln1753">  schema.mutable_table_properties()-&gt;set_is_ysql_catalog_table(true);</a>
<a name="ln1754"> </a>
<a name="ln1755">  // Verify no hash partition schema is specified.</a>
<a name="ln1756">  if (req-&gt;partition_schema().has_hash_schema()) {</a>
<a name="ln1757">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA,</a>
<a name="ln1758">                      STATUS(InvalidArgument,</a>
<a name="ln1759">                             &quot;PostgreSQL system catalog tables are non-partitioned&quot;));</a>
<a name="ln1760">  }</a>
<a name="ln1761"> </a>
<a name="ln1762">  if (req-&gt;table_type() != TableType::PGSQL_TABLE_TYPE) {</a>
<a name="ln1763">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA,</a>
<a name="ln1764">                      STATUS_FORMAT(</a>
<a name="ln1765">                          InvalidArgument,</a>
<a name="ln1766">                          &quot;Expected table type to be PGSQL_TABLE_TYPE ($0), got $1 ($2)&quot;,</a>
<a name="ln1767">                          PGSQL_TABLE_TYPE,</a>
<a name="ln1768">                          TableType_Name(req-&gt;table_type())));</a>
<a name="ln1769"> </a>
<a name="ln1770">  }</a>
<a name="ln1771"> </a>
<a name="ln1772">  // Create partition schema and one partition.</a>
<a name="ln1773">  PartitionSchema partition_schema;</a>
<a name="ln1774">  vector&lt;Partition&gt; partitions;</a>
<a name="ln1775">  RETURN_NOT_OK(partition_schema.CreatePartitions(1, &amp;partitions));</a>
<a name="ln1776"> </a>
<a name="ln1777">  // Create table info in memory.</a>
<a name="ln1778">  scoped_refptr&lt;TableInfo&gt; table;</a>
<a name="ln1779">  vector&lt;TabletInfo*&gt; tablets;</a>
<a name="ln1780">  {</a>
<a name="ln1781">    std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln1782">    TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln1783"> </a>
<a name="ln1784">    // Verify that the table does not exist.</a>
<a name="ln1785">    table = FindPtrOrNull(table_names_map_, {namespace_id, req-&gt;name()});</a>
<a name="ln1786">    if (table != nullptr) {</a>
<a name="ln1787">      Status s = STATUS_SUBSTITUTE(AlreadyPresent,</a>
<a name="ln1788">          &quot;Object '$0.$1' already exists&quot;, ns-&gt;name(), table-&gt;name());</a>
<a name="ln1789">      LOG(WARNING) &lt;&lt; &quot;Found table: &quot; &lt;&lt; table-&gt;ToStringWithState()</a>
<a name="ln1790">                   &lt;&lt; &quot;. Failed creating PostgreSQL system table with error: &quot;</a>
<a name="ln1791">                   &lt;&lt; s.ToString() &lt;&lt; &quot; Request:\n&quot; &lt;&lt; req-&gt;DebugString();</a>
<a name="ln1792">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_ALREADY_PRESENT, s);</a>
<a name="ln1793">    }</a>
<a name="ln1794"> </a>
<a name="ln1795">    RETURN_NOT_OK(CreateTableInMemory(</a>
<a name="ln1796">        *req, schema, partition_schema, false /* create_tablets */, namespace_id, namespace_name,</a>
<a name="ln1797">        partitions, nullptr /* index_info */, nullptr /* tablets */, resp, &amp;table));</a>
<a name="ln1798"> </a>
<a name="ln1799">    scoped_refptr&lt;TabletInfo&gt; tablet = tablet_map_-&gt;find(kSysCatalogTabletId)-&gt;second;</a>
<a name="ln1800">    auto tablet_lock = tablet-&gt;LockForWrite();</a>
<a name="ln1801">    tablet_lock-&gt;mutable_data()-&gt;pb.add_table_ids(table-&gt;id());</a>
<a name="ln1802">    table-&gt;AddTablet(tablet.get());</a>
<a name="ln1803"> </a>
<a name="ln1804">    RETURN_NOT_OK(sys_catalog_-&gt;UpdateItem(tablet.get(), leader_ready_term()));</a>
<a name="ln1805">    tablet_lock-&gt;Commit();</a>
<a name="ln1806">  }</a>
<a name="ln1807">  TRACE(&quot;Inserted new table info into CatalogManager maps&quot;);</a>
<a name="ln1808"> </a>
<a name="ln1809">  // Update the on-disk table state to &quot;running&quot;.</a>
<a name="ln1810">  table-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb.set_state(SysTablesEntryPB::RUNNING);</a>
<a name="ln1811">  Status s = sys_catalog_-&gt;AddItem(table.get(), leader_ready_term());</a>
<a name="ln1812">  if (PREDICT_FALSE(!s.ok())) {</a>
<a name="ln1813">    // TODO(NIC): tablets is empty here.  Probably want 'tablet' in the previous scope?</a>
<a name="ln1814">    return AbortTableCreation(table.get(), tablets,</a>
<a name="ln1815">                              s.CloneAndPrepend(</a>
<a name="ln1816">                                  Substitute(&quot;An error occurred while inserting to sys-tablets: $0&quot;,</a>
<a name="ln1817">                                             s.ToString())),</a>
<a name="ln1818">                              resp);</a>
<a name="ln1819">  }</a>
<a name="ln1820">  TRACE(&quot;Wrote table to system table&quot;);</a>
<a name="ln1821"> </a>
<a name="ln1822">  // Commit the in-memory state.</a>
<a name="ln1823">  table-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln1824"> </a>
<a name="ln1825">  tserver::ChangeMetadataRequestPB change_req;</a>
<a name="ln1826">  change_req.set_tablet_id(kSysCatalogTabletId);</a>
<a name="ln1827">  auto&amp; add_table = *change_req.mutable_add_table();</a>
<a name="ln1828"> </a>
<a name="ln1829">  add_table.set_table_id(req-&gt;table_id());</a>
<a name="ln1830">  add_table.set_table_type(TableType::PGSQL_TABLE_TYPE);</a>
<a name="ln1831">  add_table.set_table_name(req-&gt;name());</a>
<a name="ln1832">  SchemaToPB(schema, add_table.mutable_schema());</a>
<a name="ln1833">  add_table.set_schema_version(0);</a>
<a name="ln1834"> </a>
<a name="ln1835">  partition_schema.ToPB(add_table.mutable_partition_schema());</a>
<a name="ln1836"> </a>
<a name="ln1837">  RETURN_NOT_OK(tablet::SyncReplicateChangeMetadataOperation(</a>
<a name="ln1838">      &amp;change_req, sys_catalog_-&gt;tablet_peer().get(), leader_ready_term()));</a>
<a name="ln1839"> </a>
<a name="ln1840">  if (initial_snapshot_writer_) {</a>
<a name="ln1841">    initial_snapshot_writer_-&gt;AddMetadataChange(change_req);</a>
<a name="ln1842">  }</a>
<a name="ln1843">  return Status::OK();</a>
<a name="ln1844">}</a>
<a name="ln1845"> </a>
<a name="ln1846">Status CatalogManager::ReservePgsqlOids(const ReservePgsqlOidsRequestPB* req,</a>
<a name="ln1847">                                        ReservePgsqlOidsResponsePB* resp,</a>
<a name="ln1848">                                        rpc::RpcContext* rpc) {</a>
<a name="ln1849">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln1850"> </a>
<a name="ln1851">  VLOG(1) &lt;&lt; &quot;ReservePgsqlOids request: &quot; &lt;&lt; req-&gt;ShortDebugString();</a>
<a name="ln1852"> </a>
<a name="ln1853">  // Lookup namespace</a>
<a name="ln1854">  scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln1855">  {</a>
<a name="ln1856">    SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln1857">    ns = FindPtrOrNull(namespace_ids_map_, req-&gt;namespace_id());</a>
<a name="ln1858">  }</a>
<a name="ln1859">  if (!ns) {</a>
<a name="ln1860">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_NOT_FOUND,</a>
<a name="ln1861">                      STATUS(NotFound, &quot;Namespace not found&quot;, req-&gt;namespace_id()));</a>
<a name="ln1862">  }</a>
<a name="ln1863"> </a>
<a name="ln1864">  // Reserve oids.</a>
<a name="ln1865">  auto l = ns-&gt;LockForWrite();</a>
<a name="ln1866"> </a>
<a name="ln1867">  uint32_t begin_oid = l-&gt;data().pb.next_pg_oid();</a>
<a name="ln1868">  if (begin_oid &lt; req-&gt;next_oid()) {</a>
<a name="ln1869">    begin_oid = req-&gt;next_oid();</a>
<a name="ln1870">  }</a>
<a name="ln1871">  if (begin_oid == std::numeric_limits&lt;uint32_t&gt;::max()) {</a>
<a name="ln1872">    LOG(WARNING) &lt;&lt; Format(&quot;No more object identifier is available for Postgres database $0 ($1)&quot;,</a>
<a name="ln1873">                           l-&gt;data().pb.name(), req-&gt;namespace_id());</a>
<a name="ln1874">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::UNKNOWN_ERROR,</a>
<a name="ln1875">                      STATUS(InvalidArgument, &quot;No more object identifier is available&quot;));</a>
<a name="ln1876">  }</a>
<a name="ln1877"> </a>
<a name="ln1878">  uint32_t end_oid = begin_oid + req-&gt;count();</a>
<a name="ln1879">  if (end_oid &lt; begin_oid) {</a>
<a name="ln1880">    end_oid = std::numeric_limits&lt;uint32_t&gt;::max(); // Handle wraparound.</a>
<a name="ln1881">  }</a>
<a name="ln1882"> </a>
<a name="ln1883">  resp-&gt;set_begin_oid(begin_oid);</a>
<a name="ln1884">  resp-&gt;set_end_oid(end_oid);</a>
<a name="ln1885">  l-&gt;mutable_data()-&gt;pb.set_next_pg_oid(end_oid);</a>
<a name="ln1886"> </a>
<a name="ln1887">  // Update the on-disk state.</a>
<a name="ln1888">  const Status s = sys_catalog_-&gt;UpdateItem(ns.get(), leader_ready_term());</a>
<a name="ln1889">  if (!s.ok()) {</a>
<a name="ln1890">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::UNKNOWN_ERROR, s);</a>
<a name="ln1891">  }</a>
<a name="ln1892"> </a>
<a name="ln1893">  // Commit the in-memory state.</a>
<a name="ln1894">  l-&gt;Commit();</a>
<a name="ln1895"> </a>
<a name="ln1896">  VLOG(1) &lt;&lt; &quot;ReservePgsqlOids response: &quot; &lt;&lt; resp-&gt;ShortDebugString();</a>
<a name="ln1897"> </a>
<a name="ln1898">  return Status::OK();</a>
<a name="ln1899">}</a>
<a name="ln1900"> </a>
<a name="ln1901">Status CatalogManager::GetYsqlCatalogConfig(const GetYsqlCatalogConfigRequestPB* req,</a>
<a name="ln1902">                                            GetYsqlCatalogConfigResponsePB* resp,</a>
<a name="ln1903">                                            rpc::RpcContext* rpc) {</a>
<a name="ln1904">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln1905">  VLOG(1) &lt;&lt; &quot;GetYsqlCatalogConfig request: &quot; &lt;&lt; req-&gt;ShortDebugString();</a>
<a name="ln1906">  auto l = CHECK_NOTNULL(ysql_catalog_config_.get())-&gt;LockForRead();</a>
<a name="ln1907">  resp-&gt;set_version(l-&gt;data().pb.ysql_catalog_config().version());</a>
<a name="ln1908"> </a>
<a name="ln1909">  return Status::OK();</a>
<a name="ln1910">}</a>
<a name="ln1911"> </a>
<a name="ln1912">Status CatalogManager::CopyPgsqlSysTables(const NamespaceId&amp; namespace_id,</a>
<a name="ln1913">                                          const std::vector&lt;scoped_refptr&lt;TableInfo&gt;&gt;&amp; tables) {</a>
<a name="ln1914">  const uint32_t database_oid = CHECK_RESULT(GetPgsqlDatabaseOid(namespace_id));</a>
<a name="ln1915">  vector&lt;TableId&gt; source_table_ids;</a>
<a name="ln1916">  vector&lt;TableId&gt; target_table_ids;</a>
<a name="ln1917">  for (const auto&amp; table : tables) {</a>
<a name="ln1918">    CreateTableRequestPB table_req;</a>
<a name="ln1919">    CreateTableResponsePB table_resp;</a>
<a name="ln1920"> </a>
<a name="ln1921">    const uint32_t table_oid = VERIFY_RESULT(GetPgsqlTableOid(table-&gt;id()));</a>
<a name="ln1922">    const TableId table_id = GetPgsqlTableId(database_oid, table_oid);</a>
<a name="ln1923"> </a>
<a name="ln1924">    // Hold read lock until rows from the table are copied also.</a>
<a name="ln1925">    auto l = table-&gt;LockForRead();</a>
<a name="ln1926"> </a>
<a name="ln1927">    // Skip shared table.</a>
<a name="ln1928">    if (l-&gt;data().pb.is_pg_shared_table()) {</a>
<a name="ln1929">      continue;</a>
<a name="ln1930">    }</a>
<a name="ln1931"> </a>
<a name="ln1932">    table_req.set_name(l-&gt;data().pb.name());</a>
<a name="ln1933">    table_req.mutable_namespace_()-&gt;set_id(namespace_id);</a>
<a name="ln1934">    table_req.set_table_type(PGSQL_TABLE_TYPE);</a>
<a name="ln1935">    table_req.mutable_schema()-&gt;CopyFrom(l-&gt;data().schema());</a>
<a name="ln1936">    table_req.set_is_pg_catalog_table(true);</a>
<a name="ln1937">    table_req.set_table_id(table_id);</a>
<a name="ln1938"> </a>
<a name="ln1939">    if (PROTO_IS_INDEX(l-&gt;data().pb)) {</a>
<a name="ln1940">      const uint32_t indexed_table_oid =</a>
<a name="ln1941">        VERIFY_RESULT(GetPgsqlTableOid(PROTO_GET_INDEXED_TABLE_ID(l-&gt;data().pb)));</a>
<a name="ln1942">      const TableId indexed_table_id = GetPgsqlTableId(database_oid, indexed_table_oid);</a>
<a name="ln1943"> </a>
<a name="ln1944">      // Set index_info.</a>
<a name="ln1945">      // Previously created INDEX wouldn't have the attribute index_info.</a>
<a name="ln1946">      if (l-&gt;data().pb.has_index_info()) {</a>
<a name="ln1947">        table_req.mutable_index_info()-&gt;CopyFrom(l-&gt;data().pb.index_info());</a>
<a name="ln1948">        table_req.mutable_index_info()-&gt;set_indexed_table_id(indexed_table_id);</a>
<a name="ln1949">      }</a>
<a name="ln1950"> </a>
<a name="ln1951">      // Set deprecated field for index_info.</a>
<a name="ln1952">      table_req.set_indexed_table_id(indexed_table_id);</a>
<a name="ln1953">      table_req.set_is_local_index(PROTO_GET_IS_LOCAL(l-&gt;data().pb));</a>
<a name="ln1954">      table_req.set_is_unique_index(PROTO_GET_IS_UNIQUE(l-&gt;data().pb));</a>
<a name="ln1955">    }</a>
<a name="ln1956"> </a>
<a name="ln1957">    auto s = CreatePgsqlSysTable(&amp;table_req, &amp;table_resp);</a>
<a name="ln1958">    if (!s.ok()) {</a>
<a name="ln1959">      return s.CloneAndPrepend(Substitute(</a>
<a name="ln1960">          &quot;Failure when creating PGSQL System Tables: $0&quot;, table_resp.error().ShortDebugString()));</a>
<a name="ln1961">    }</a>
<a name="ln1962"> </a>
<a name="ln1963">    source_table_ids.push_back(table-&gt;id());</a>
<a name="ln1964">    target_table_ids.push_back(table_id);</a>
<a name="ln1965">  }</a>
<a name="ln1966">  RETURN_NOT_OK(</a>
<a name="ln1967">      sys_catalog_-&gt;CopyPgsqlTables(source_table_ids, target_table_ids, leader_ready_term()));</a>
<a name="ln1968">  return Status::OK();</a>
<a name="ln1969">}</a>
<a name="ln1970"> </a>
<a name="ln1971">// Create a new table.</a>
<a name="ln1972">// See README file in this directory for a description of the design.</a>
<a name="ln1973">Status CatalogManager::CreateTable(const CreateTableRequestPB* orig_req,</a>
<a name="ln1974">                                   CreateTableResponsePB* resp,</a>
<a name="ln1975">                                   rpc::RpcContext* rpc) {</a>
<a name="ln1976">  DVLOG(3) &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; &quot; Begin. &quot; &lt;&lt; orig_req-&gt;DebugString();</a>
<a name="ln1977">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln1978"> </a>
<a name="ln1979">  const bool is_pg_table = orig_req-&gt;table_type() == PGSQL_TABLE_TYPE;</a>
<a name="ln1980">  const bool is_pg_catalog_table = is_pg_table &amp;&amp; orig_req-&gt;is_pg_catalog_table();</a>
<a name="ln1981">  if (!is_pg_catalog_table || !FLAGS_hide_pg_catalog_table_creation_logs) {</a>
<a name="ln1982">    LOG(INFO) &lt;&lt; &quot;CreateTable from &quot; &lt;&lt; RequestorString(rpc)</a>
<a name="ln1983">                &lt;&lt; &quot;:\n&quot; &lt;&lt; orig_req-&gt;DebugString();</a>
<a name="ln1984">  } else {</a>
<a name="ln1985">    LOG(INFO) &lt;&lt; &quot;CreateTable from &quot; &lt;&lt; RequestorString(rpc) &lt;&lt; &quot;: &quot; &lt;&lt; orig_req-&gt;name();</a>
<a name="ln1986">  }</a>
<a name="ln1987"> </a>
<a name="ln1988">  const bool is_transactional = orig_req-&gt;schema().table_properties().is_transactional();</a>
<a name="ln1989">  // If this is a transactional table, we need to create the transaction status table (if it does</a>
<a name="ln1990">  // not exist already).</a>
<a name="ln1991">  if (is_transactional &amp;&amp; (!is_pg_catalog_table || !FLAGS_create_initial_sys_catalog_snapshot)) {</a>
<a name="ln1992">    Status s = CreateTransactionsStatusTableIfNeeded(rpc);</a>
<a name="ln1993">    if (!s.ok()) {</a>
<a name="ln1994">      return s.CloneAndPrepend(&quot;Error while creating transaction status table&quot;);</a>
<a name="ln1995">    }</a>
<a name="ln1996">  } else {</a>
<a name="ln1997">    VLOG(1)</a>
<a name="ln1998">        &lt;&lt; &quot;Not attempting to create a transaction status table:\n&quot;</a>
<a name="ln1999">        &lt;&lt; &quot;  &quot; &lt;&lt; EXPR_VALUE_FOR_LOG(is_transactional) &lt;&lt; &quot;\n &quot;</a>
<a name="ln2000">        &lt;&lt; &quot;  &quot; &lt;&lt; EXPR_VALUE_FOR_LOG(is_pg_catalog_table) &lt;&lt; &quot;\n &quot;</a>
<a name="ln2001">        &lt;&lt; &quot;  &quot; &lt;&lt; EXPR_VALUE_FOR_LOG(FLAGS_create_initial_sys_catalog_snapshot);</a>
<a name="ln2002">  }</a>
<a name="ln2003"> </a>
<a name="ln2004">  if (is_pg_catalog_table) {</a>
<a name="ln2005">    return CreatePgsqlSysTable(orig_req, resp);</a>
<a name="ln2006">  }</a>
<a name="ln2007"> </a>
<a name="ln2008">  Status s;</a>
<a name="ln2009">  const char* const object_type = PROTO_PTR_IS_TABLE(orig_req) ? &quot;table&quot; : &quot;index&quot;;</a>
<a name="ln2010"> </a>
<a name="ln2011">  // Copy the request, so we can fill in some defaults.</a>
<a name="ln2012">  CreateTableRequestPB req = *orig_req;</a>
<a name="ln2013"> </a>
<a name="ln2014">  // Lookup the namespace and verify if it exists.</a>
<a name="ln2015">  TRACE(&quot;Looking up namespace&quot;);</a>
<a name="ln2016">  scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln2017">  RETURN_NAMESPACE_NOT_FOUND(FindNamespace(req.namespace_(), &amp;ns), resp);</a>
<a name="ln2018">  auto ns_lock = ns-&gt;LockForRead();</a>
<a name="ln2019">  if (ns-&gt;database_type() != GetDatabaseTypeForTable(req.table_type())) {</a>
<a name="ln2020">    Status s = STATUS(NotFound, &quot;Namespace not found&quot;);</a>
<a name="ln2021">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_NOT_FOUND, s);</a>
<a name="ln2022">  }</a>
<a name="ln2023">  const NamespaceId&amp; namespace_id = ns-&gt;id();</a>
<a name="ln2024">  const NamespaceName&amp; namespace_name = ns-&gt;name();</a>
<a name="ln2025"> </a>
<a name="ln2026">  // For index table, find the table info</a>
<a name="ln2027">  scoped_refptr&lt;TableInfo&gt; indexed_table;</a>
<a name="ln2028">  if (PROTO_IS_INDEX(req)) {</a>
<a name="ln2029">    TRACE(&quot;Looking up indexed table&quot;);</a>
<a name="ln2030">    indexed_table = GetTableInfo(req.indexed_table_id());</a>
<a name="ln2031">    if (indexed_table == nullptr) {</a>
<a name="ln2032">      return STATUS_SUBSTITUTE(</a>
<a name="ln2033">            NotFound, &quot;The indexed table $0 does not exist&quot;, req.indexed_table_id());</a>
<a name="ln2034">    }</a>
<a name="ln2035"> </a>
<a name="ln2036">    TRACE(&quot;Locking indexed table&quot;);</a>
<a name="ln2037">    auto l_indexed_tbl = indexed_table-&gt;LockForRead();</a>
<a name="ln2038">    RETURN_NOT_OK(CheckIfTableDeletedOrNotRunning(l_indexed_tbl.get(), resp));</a>
<a name="ln2039">  }</a>
<a name="ln2040"> </a>
<a name="ln2041">  // Determine if this table should be colocated. If not specified, the table should be colocated if</a>
<a name="ln2042">  // and only if the namespace is colocated.</a>
<a name="ln2043">  bool colocated = ns-&gt;colocated();</a>
<a name="ln2044">  if (!req.colocated()) {</a>
<a name="ln2045">    // Opt out of colocation if the request says so.</a>
<a name="ln2046">    colocated = false;</a>
<a name="ln2047">  } else if (indexed_table &amp;&amp; !indexed_table-&gt;colocated()) {</a>
<a name="ln2048">    // Opt out of colocation if the indexed table opted out of colocation.</a>
<a name="ln2049">    colocated = false;</a>
<a name="ln2050">  }</a>
<a name="ln2051"> </a>
<a name="ln2052">  // Validate schema.</a>
<a name="ln2053">  Schema client_schema;</a>
<a name="ln2054"> </a>
<a name="ln2055">  // TODO: If this is a colocated index table in a colocated database, convert any hash partition</a>
<a name="ln2056">  // columns into range partition columns. This is because postgres does not know that this index</a>
<a name="ln2057">  // table is in a colocated database. When we get to the &quot;tablespaces&quot; step where we store this</a>
<a name="ln2058">  // into PG metadata, then PG will know if db/table is colocated and do the work there.</a>
<a name="ln2059">  if ((colocated || req.has_tablegroup_id()) &amp;&amp; PROTO_IS_INDEX(req)) {</a>
<a name="ln2060">    for (auto&amp; col_pb : *req.mutable_schema()-&gt;mutable_columns()) {</a>
<a name="ln2061">      col_pb.set_is_hash_key(false);</a>
<a name="ln2062">    }</a>
<a name="ln2063">  }</a>
<a name="ln2064"> </a>
<a name="ln2065">  RETURN_NOT_OK(SchemaFromPB(req.schema(), &amp;client_schema));</a>
<a name="ln2066">  RETURN_NOT_OK(ValidateCreateTableSchema(client_schema, resp));</a>
<a name="ln2067"> </a>
<a name="ln2068">  // checking that referenced user-defined types (if any) exist.</a>
<a name="ln2069">  {</a>
<a name="ln2070">    SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln2071">    for (int i = 0; i &lt; client_schema.num_columns(); i++) {</a>
<a name="ln2072">      for (const auto &amp;udt_id : client_schema.column(i).type()-&gt;GetUserDefinedTypeIds()) {</a>
<a name="ln2073">        if (FindPtrOrNull(udtype_ids_map_, udt_id) == nullptr) {</a>
<a name="ln2074">          Status s = STATUS(InvalidArgument, &quot;Referenced user-defined type not found&quot;);</a>
<a name="ln2075">          return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA, s);</a>
<a name="ln2076">        }</a>
<a name="ln2077">      }</a>
<a name="ln2078">    }</a>
<a name="ln2079">  }</a>
<a name="ln2080">  // TODO (ENG-1860) The referenced namespace and types retrieved/checked above could be deleted</a>
<a name="ln2081">  // some time between this point and table creation below.</a>
<a name="ln2082">  Schema schema = client_schema.CopyWithColumnIds();</a>
<a name="ln2083">  if (schema.table_properties().HasCopartitionTableId()) {</a>
<a name="ln2084">    return CreateCopartitionedTable(req, resp, rpc, schema, ns);</a>
<a name="ln2085">  }</a>
<a name="ln2086"> </a>
<a name="ln2087">  if (colocated || req.has_tablegroup_id()) {</a>
<a name="ln2088">    // If the table is colocated, then there should be no hash partition columns.</a>
<a name="ln2089">    // Do the same for tables that are being placed in tablegroups.</a>
<a name="ln2090">    if (schema.num_hash_key_columns() &gt; 0) {</a>
<a name="ln2091">      Status s = STATUS(InvalidArgument, &quot;Cannot colocate hash partitioned table&quot;);</a>
<a name="ln2092">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA, s);</a>
<a name="ln2093">    }</a>
<a name="ln2094">  } else if (</a>
<a name="ln2095">      !req.partition_schema().has_hash_schema() &amp;&amp; !req.partition_schema().has_range_schema()) {</a>
<a name="ln2096">    // If neither hash nor range schema have been specified by the protobuf request, we assume the</a>
<a name="ln2097">    // table uses a hash schema, and we use the table_type and hash_key to determine the hashing</a>
<a name="ln2098">    // scheme (redis or multi-column) that should be used.</a>
<a name="ln2099">    if (req.table_type() == REDIS_TABLE_TYPE) {</a>
<a name="ln2100">      req.mutable_partition_schema()-&gt;set_hash_schema(PartitionSchemaPB::REDIS_HASH_SCHEMA);</a>
<a name="ln2101">    } else if (schema.num_hash_key_columns() &gt; 0) {</a>
<a name="ln2102">      req.mutable_partition_schema()-&gt;set_hash_schema(PartitionSchemaPB::MULTI_COLUMN_HASH_SCHEMA);</a>
<a name="ln2103">    } else {</a>
<a name="ln2104">      Status s = STATUS(InvalidArgument, &quot;Unknown table type or partitioning method&quot;);</a>
<a name="ln2105">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA, s);</a>
<a name="ln2106">    }</a>
<a name="ln2107">  }</a>
<a name="ln2108"> </a>
<a name="ln2109">  // Get cluster level placement info.</a>
<a name="ln2110">  ReplicationInfoPB replication_info;</a>
<a name="ln2111">  {</a>
<a name="ln2112">    auto l = cluster_config_-&gt;LockForRead();</a>
<a name="ln2113">    replication_info = l-&gt;data().pb.replication_info();</a>
<a name="ln2114">  }</a>
<a name="ln2115">  // Calculate number of tablets to be used.</a>
<a name="ln2116">  int num_tablets = req.schema().table_properties().num_tablets();</a>
<a name="ln2117">  if (num_tablets &lt;= 0) {</a>
<a name="ln2118">    num_tablets = req.num_tablets();</a>
<a name="ln2119">  }</a>
<a name="ln2120"> </a>
<a name="ln2121">  if (num_tablets &lt;= 0) {</a>
<a name="ln2122">    SharedLock&lt;LockType&gt; l(blacklist_lock_);</a>
<a name="ln2123">    // Use default as client could have gotten the value before any tserver had heartbeated</a>
<a name="ln2124">    // to (a new) master leader.</a>
<a name="ln2125">    TSDescriptorVector ts_descs;</a>
<a name="ln2126">    master_-&gt;ts_manager()-&gt;GetAllLiveDescriptorsInCluster(</a>
<a name="ln2127">        &amp;ts_descs, replication_info.live_replicas().placement_uuid(), blacklistState.tservers_);</a>
<a name="ln2128">    num_tablets = ts_descs.size() * (is_pg_table ? FLAGS_ysql_num_shards_per_tserver</a>
<a name="ln2129">                                                 : FLAGS_yb_num_shards_per_tserver);</a>
<a name="ln2130">    LOG(INFO) &lt;&lt; &quot;Setting default tablets to &quot; &lt;&lt; num_tablets &lt;&lt; &quot; with &quot;</a>
<a name="ln2131">              &lt;&lt; ts_descs.size() &lt;&lt; &quot; primary servers&quot;;</a>
<a name="ln2132">  }</a>
<a name="ln2133">  schema.mutable_table_properties()-&gt;SetNumTablets(num_tablets);</a>
<a name="ln2134"> </a>
<a name="ln2135">  // Create partitions.</a>
<a name="ln2136">  PartitionSchema partition_schema;</a>
<a name="ln2137">  vector&lt;Partition&gt; partitions;</a>
<a name="ln2138">  if (colocated || req.has_tablegroup_id()) {</a>
<a name="ln2139">    RETURN_NOT_OK(partition_schema.CreatePartitions(1, &amp;partitions));</a>
<a name="ln2140">    req.clear_partition_schema();</a>
<a name="ln2141">    req.set_num_tablets(1);</a>
<a name="ln2142">  } else {</a>
<a name="ln2143">    s = PartitionSchema::FromPB(req.partition_schema(), schema, &amp;partition_schema);</a>
<a name="ln2144">    if (req.partition_schema().has_hash_schema()) {</a>
<a name="ln2145">      switch (partition_schema.hash_schema()) {</a>
<a name="ln2146">        case YBHashSchema::kPgsqlHash:</a>
<a name="ln2147">          // TODO(neil) After a discussion, PGSQL hash should be done appropriately.</a>
<a name="ln2148">          // For now, let's not doing anything. Just borrow the multi column hash.</a>
<a name="ln2149">          FALLTHROUGH_INTENDED;</a>
<a name="ln2150">        case YBHashSchema::kMultiColumnHash: {</a>
<a name="ln2151">          // Use the given number of tablets to create partitions and ignore the other schema</a>
<a name="ln2152">          // options in the request.</a>
<a name="ln2153">          RETURN_NOT_OK(partition_schema.CreatePartitions(num_tablets, &amp;partitions));</a>
<a name="ln2154">          break;</a>
<a name="ln2155">        }</a>
<a name="ln2156">        case YBHashSchema::kRedisHash: {</a>
<a name="ln2157">          RETURN_NOT_OK(</a>
<a name="ln2158">              partition_schema.CreatePartitions(num_tablets, &amp;partitions, kRedisClusterSlots));</a>
<a name="ln2159">          break;</a>
<a name="ln2160">        }</a>
<a name="ln2161">      }</a>
<a name="ln2162">    } else if (req.partition_schema().has_range_schema()) {</a>
<a name="ln2163">      vector&lt;std::string&gt; split_rows;</a>
<a name="ln2164">      for (const auto&amp; row : req.partition_schema().range_schema().split_rows()) {</a>
<a name="ln2165">        split_rows.push_back(row);</a>
<a name="ln2166">      }</a>
<a name="ln2167"> </a>
<a name="ln2168">      RETURN_NOT_OK(partition_schema.CreatePartitions(split_rows, schema, &amp;partitions));</a>
<a name="ln2169">      DCHECK_EQ(split_rows.size() + 1, partitions.size());</a>
<a name="ln2170">    } else {</a>
<a name="ln2171">      DFATAL_OR_RETURN_NOT_OK(STATUS(InvalidArgument, &quot;Invalid partition method&quot;));</a>
<a name="ln2172">    }</a>
<a name="ln2173">  }</a>
<a name="ln2174"> </a>
<a name="ln2175">  // Validate the table placement rules are a subset of the cluster ones.</a>
<a name="ln2176">  s = ValidateTableReplicationInfo(req.replication_info());</a>
<a name="ln2177">  if (PREDICT_FALSE(!s.ok())) {</a>
<a name="ln2178">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA, s);</a>
<a name="ln2179">  }</a>
<a name="ln2180"> </a>
<a name="ln2181">  // For index table, populate the index info.</a>
<a name="ln2182">  IndexInfoPB index_info;</a>
<a name="ln2183"> </a>
<a name="ln2184">  const bool index_backfill_enabled =</a>
<a name="ln2185">      IsIndexBackfillEnabled(orig_req-&gt;table_type(), is_transactional);</a>
<a name="ln2186">  if (req.has_index_info()) {</a>
<a name="ln2187">    // Current message format.</a>
<a name="ln2188">    index_info.CopyFrom(req.index_info());</a>
<a name="ln2189"> </a>
<a name="ln2190">    // Assign column-ids that have just been computed and assigned to &quot;index_info&quot;.</a>
<a name="ln2191">    if (!is_pg_table) {</a>
<a name="ln2192">      DCHECK_EQ(index_info.columns().size(), schema.num_columns())</a>
<a name="ln2193">        &lt;&lt; &quot;Number of columns are not the same between index_info and index_schema&quot;;</a>
<a name="ln2194">      // int colidx = 0;</a>
<a name="ln2195">      for (int colidx = 0; colidx &lt; schema.num_columns(); colidx++) {</a>
<a name="ln2196">        index_info.mutable_columns(colidx)-&gt;set_column_id(schema.column_id(colidx));</a>
<a name="ln2197">      }</a>
<a name="ln2198">    }</a>
<a name="ln2199">  } else if (req.has_indexed_table_id()) {</a>
<a name="ln2200">    // Old client message format when rolling upgrade (Not having &quot;index_info&quot;).</a>
<a name="ln2201">    IndexInfoBuilder index_info_builder(&amp;index_info);</a>
<a name="ln2202">    index_info_builder.ApplyProperties(req.indexed_table_id(),</a>
<a name="ln2203">        req.is_local_index(), req.is_unique_index());</a>
<a name="ln2204">    if (orig_req-&gt;table_type() != PGSQL_TABLE_TYPE) {</a>
<a name="ln2205">      Schema indexed_schema;</a>
<a name="ln2206">      RETURN_NOT_OK(indexed_table-&gt;GetSchema(&amp;indexed_schema));</a>
<a name="ln2207">      RETURN_NOT_OK(index_info_builder.ApplyColumnMapping(indexed_schema, schema));</a>
<a name="ln2208">    }</a>
<a name="ln2209">  }</a>
<a name="ln2210"> </a>
<a name="ln2211">  if ((req.has_index_info() || req.has_indexed_table_id()) &amp;&amp;</a>
<a name="ln2212">      index_backfill_enabled &amp;&amp;</a>
<a name="ln2213">      !req.skip_index_backfill()) {</a>
<a name="ln2214">    // Start off the index table with major compactions disabled. We need this to preserve</a>
<a name="ln2215">    // the delete markers until the backfill process is completed.</a>
<a name="ln2216">    // No need to set index_permissions in the index table.</a>
<a name="ln2217">    schema.SetIsBackfilling(true);</a>
<a name="ln2218">  }</a>
<a name="ln2219"> </a>
<a name="ln2220">  LOG(INFO) &lt;&lt; &quot;CreateTable with IndexInfo &quot; &lt;&lt; yb::ToString(index_info);</a>
<a name="ln2221">  TSDescriptorVector all_ts_descs;</a>
<a name="ln2222">  master_-&gt;ts_manager()-&gt;GetAllLiveDescriptors(&amp;all_ts_descs);</a>
<a name="ln2223">  s = CheckValidReplicationInfo(replication_info, all_ts_descs, partitions, resp);</a>
<a name="ln2224">  if (!s.ok()) {</a>
<a name="ln2225">    return s;</a>
<a name="ln2226">  }</a>
<a name="ln2227"> </a>
<a name="ln2228">  scoped_refptr&lt;TableInfo&gt; table;</a>
<a name="ln2229">  vector&lt;TabletInfo*&gt; tablets;</a>
<a name="ln2230">  bool tablets_exist;</a>
<a name="ln2231">  bool tablegroup_tablets_exist = false;</a>
<a name="ln2232"> </a>
<a name="ln2233">  {</a>
<a name="ln2234">    std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln2235">    auto ns_lock = ns-&gt;LockForRead();</a>
<a name="ln2236">    TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln2237"> </a>
<a name="ln2238">    tablets_exist =</a>
<a name="ln2239">        colocated &amp;&amp; colocated_tablet_ids_map_.find(ns-&gt;id()) != colocated_tablet_ids_map_.end();</a>
<a name="ln2240">    // Verify that the table does not exist.</a>
<a name="ln2241">    table = FindPtrOrNull(table_names_map_, {namespace_id, req.name()});</a>
<a name="ln2242"> </a>
<a name="ln2243">    if (table != nullptr) {</a>
<a name="ln2244">      s = STATUS_SUBSTITUTE(AlreadyPresent,</a>
<a name="ln2245">              &quot;Object '$0.$1' already exists&quot;, ns-&gt;name(), table-&gt;name());</a>
<a name="ln2246">      LOG(WARNING) &lt;&lt; &quot;Found table: &quot; &lt;&lt; table-&gt;ToStringWithState()</a>
<a name="ln2247">                   &lt;&lt; &quot;. Failed creating table with error: &quot;</a>
<a name="ln2248">                   &lt;&lt; s.ToString() &lt;&lt; &quot; Request:\n&quot; &lt;&lt; orig_req-&gt;DebugString();</a>
<a name="ln2249">      // If the table already exists, we set the response table_id field to the id of the table that</a>
<a name="ln2250">      // already exists. This is necessary because before we return the error to the client (or</a>
<a name="ln2251">      // success in case of a &quot;CREATE TABLE IF NOT EXISTS&quot; request) we want to wait for the existing</a>
<a name="ln2252">      // table to be available to receive requests. And we need the table id for that.</a>
<a name="ln2253">      resp-&gt;set_table_id(table-&gt;id());</a>
<a name="ln2254">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_ALREADY_PRESENT, s);</a>
<a name="ln2255">    }</a>
<a name="ln2256"> </a>
<a name="ln2257">    // Namespace state validity check:</a>
<a name="ln2258">    // 1. Allow Namespaces that are RUNNING</a>
<a name="ln2259">    // 2. Allow Namespaces that are PREPARING under 2 situations</a>
<a name="ln2260">    //    2a. System Namespaces.</a>
<a name="ln2261">    //    2b. The parent table from a Colocated Namespace.</a>
<a name="ln2262">    const auto parent_table_name = ns-&gt;id() + kColocatedParentTableNameSuffix;</a>
<a name="ln2263">    bool valid_ns_state = (ns-&gt;state() == SysNamespaceEntryPB::RUNNING) ||</a>
<a name="ln2264">      (ns-&gt;state() == SysNamespaceEntryPB::PREPARING &amp;&amp;</a>
<a name="ln2265">        (ns-&gt;name() == kSystemNamespaceName || req.name() == parent_table_name));</a>
<a name="ln2266">    if (!valid_ns_state) {</a>
<a name="ln2267">      Status s = STATUS_SUBSTITUTE(TryAgain, &quot;Invalid Namespace State ($0).  Cannot create $1.$2&quot;,</a>
<a name="ln2268">          SysNamespaceEntryPB::State_Name(ns-&gt;state()), ns-&gt;name(), req.name() );</a>
<a name="ln2269">      return SetupError(resp-&gt;mutable_error(), NamespaceMasterError(ns-&gt;state()), s);</a>
<a name="ln2270">    }</a>
<a name="ln2271"> </a>
<a name="ln2272">    // Check whether this CREATE TABLE request which has a tablegroup_id is for a normal user table</a>
<a name="ln2273">    // or the request to create the parent table for the tablegroup. This is done by checking the</a>
<a name="ln2274">    // catalog manager maps.</a>
<a name="ln2275">    if (req.has_tablegroup_id() &amp;&amp;</a>
<a name="ln2276">        tablegroup_tablet_ids_map_.find(ns-&gt;id()) != tablegroup_tablet_ids_map_.end() &amp;&amp;</a>
<a name="ln2277">        tablegroup_tablet_ids_map_[ns-&gt;id()].find(req.tablegroup_id()) !=</a>
<a name="ln2278">        tablegroup_tablet_ids_map_[ns-&gt;id()].end()) {</a>
<a name="ln2279">      tablegroup_tablets_exist = true;</a>
<a name="ln2280">    }</a>
<a name="ln2281"> </a>
<a name="ln2282">    RETURN_NOT_OK(CreateTableInMemory(</a>
<a name="ln2283">        req, schema, partition_schema,</a>
<a name="ln2284">        !tablets_exist &amp;&amp; !tablegroup_tablets_exist /* create_tablets */, namespace_id,</a>
<a name="ln2285">        namespace_name, partitions, &amp;index_info, &amp;tablets, resp, &amp;table));</a>
<a name="ln2286"> </a>
<a name="ln2287">    // Section is executed when a table is either the parent table or a user table in a tablegroup.</a>
<a name="ln2288">    // It additionally sets the table metadata (and tablet metadata if this is the parent table)</a>
<a name="ln2289">    // to have the colocated property so we can take advantage of code reuse.</a>
<a name="ln2290">    if (req.has_tablegroup_id()) {</a>
<a name="ln2291">      table-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb.set_colocated(true);</a>
<a name="ln2292">      if (tablegroup_tablets_exist) {</a>
<a name="ln2293">        // If the table is not a tablegroup parent table, it performs a lookup for the proper tablet</a>
<a name="ln2294">        // to place the table on as a child table.</a>
<a name="ln2295">        scoped_refptr&lt;TabletInfo&gt; tablet =</a>
<a name="ln2296">            tablegroup_tablet_ids_map_[ns-&gt;id()][req.tablegroup_id()];</a>
<a name="ln2297">        DSCHECK(</a>
<a name="ln2298">            tablet-&gt;colocated(), InternalError,</a>
<a name="ln2299">            &quot;The tablet for tablegroup should be colocated.&quot;);</a>
<a name="ln2300">        tablets.push_back(tablet.get());</a>
<a name="ln2301">        auto tablet_lock = tablet-&gt;LockForWrite();</a>
<a name="ln2302">        tablet_lock-&gt;mutable_data()-&gt;pb.add_table_ids(table-&gt;id());</a>
<a name="ln2303">        RETURN_NOT_OK(sys_catalog_-&gt;UpdateItem(tablet.get(), leader_ready_term()));</a>
<a name="ln2304">        tablet_lock-&gt;Commit();</a>
<a name="ln2305"> </a>
<a name="ln2306">        tablet-&gt;mutable_metadata()-&gt;StartMutation();</a>
<a name="ln2307">        table-&gt;AddTablets(tablets);</a>
<a name="ln2308">        tablegroup_ids_map_[req.tablegroup_id()]-&gt;AddChildTable(table-&gt;id());</a>
<a name="ln2309">      } else {</a>
<a name="ln2310">        // If the table is a tablegroup parent table, it creates a dummy tablet for the tablegroup</a>
<a name="ln2311">        // along with updating the catalog manager maps.</a>
<a name="ln2312">        DSCHECK_EQ(</a>
<a name="ln2313">            tablets.size(), 1, InternalError,</a>
<a name="ln2314">            &quot;Only one tablet should be created for each tablegroup&quot;);</a>
<a name="ln2315">        tablets[0]-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb.set_colocated(true);</a>
<a name="ln2316">        // Update catalog manager maps for tablegroups</a>
<a name="ln2317">        tablegroup_tablet_ids_map_[ns-&gt;id()][req.tablegroup_id()] =</a>
<a name="ln2318">            tablet_map_-&gt;find(tablets[0]-&gt;id())-&gt;second;</a>
<a name="ln2319">      }</a>
<a name="ln2320">    } else if (colocated) {</a>
<a name="ln2321">      table-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb.set_colocated(true);</a>
<a name="ln2322">      // if the tablet already exists, add the tablet to tablets</a>
<a name="ln2323">      if (tablets_exist) {</a>
<a name="ln2324">        scoped_refptr&lt;TabletInfo&gt; tablet = colocated_tablet_ids_map_[ns-&gt;id()];</a>
<a name="ln2325">        DSCHECK(</a>
<a name="ln2326">            tablet-&gt;colocated(), InternalError,</a>
<a name="ln2327">            &quot;The tablet for colocated database should be colocated.&quot;);</a>
<a name="ln2328">        tablets.push_back(tablet.get());</a>
<a name="ln2329">        auto tablet_lock = tablet-&gt;LockForWrite();</a>
<a name="ln2330">        tablet_lock-&gt;mutable_data()-&gt;pb.add_table_ids(table-&gt;id());</a>
<a name="ln2331">        RETURN_NOT_OK(sys_catalog_-&gt;UpdateItem(tablet.get(), leader_ready_term()));</a>
<a name="ln2332">        tablet_lock-&gt;Commit();</a>
<a name="ln2333"> </a>
<a name="ln2334">        tablet-&gt;mutable_metadata()-&gt;StartMutation();</a>
<a name="ln2335">        table-&gt;AddTablets(tablets);</a>
<a name="ln2336">      } else {  // Record the tablet</a>
<a name="ln2337">        DSCHECK_EQ(</a>
<a name="ln2338">            tablets.size(), 1, InternalError,</a>
<a name="ln2339">            &quot;Only one tablet should be created for each colocated database&quot;);</a>
<a name="ln2340">        tablets[0]-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb.set_colocated(true);</a>
<a name="ln2341">        colocated_tablet_ids_map_[ns-&gt;id()] = tablet_map_-&gt;find(tablets[0]-&gt;id())-&gt;second;</a>
<a name="ln2342">      }</a>
<a name="ln2343">    }</a>
<a name="ln2344">  }</a>
<a name="ln2345"> </a>
<a name="ln2346">  if (PREDICT_FALSE(FLAGS_TEST_simulate_slow_table_create_secs &gt; 0)) {</a>
<a name="ln2347">    LOG(INFO) &lt;&lt; &quot;Simulating slow table creation&quot;;</a>
<a name="ln2348">    SleepFor(MonoDelta::FromSeconds(FLAGS_TEST_simulate_slow_table_create_secs));</a>
<a name="ln2349">  }</a>
<a name="ln2350"> </a>
<a name="ln2351">  // NOTE: the table and tablets are already locked for write at this point,</a>
<a name="ln2352">  // since the CreateTableInfo/CreateTabletInfo functions leave them in that state.</a>
<a name="ln2353">  // They will get committed at the end of this function.</a>
<a name="ln2354">  // Sanity check: the tables and tablets should all be in &quot;preparing&quot; state.</a>
<a name="ln2355">  CHECK_EQ(SysTablesEntryPB::PREPARING, table-&gt;metadata().dirty().pb.state());</a>
<a name="ln2356">  if (tablets_exist || tablegroup_tablets_exist) {</a>
<a name="ln2357">    TRACE(&quot;Inserted new table and updating tablet info into CatalogManager maps&quot;);</a>
<a name="ln2358">    VLOG(1) &lt;&lt; &quot;Inserted new table and updating tablet info into &quot;</a>
<a name="ln2359">               &quot;CatalogManager maps&quot;;</a>
<a name="ln2360">    s = sys_catalog_-&gt;UpdateItems(tablets, leader_ready_term());</a>
<a name="ln2361">  } else {</a>
<a name="ln2362">    TRACE(&quot;Inserted new table and tablet info into CatalogManager maps&quot;);</a>
<a name="ln2363">    VLOG(1) &lt;&lt; &quot;Inserted new table and tablet info into CatalogManager maps&quot;;</a>
<a name="ln2364">    for (const TabletInfo *tablet : tablets) {</a>
<a name="ln2365">      CHECK_EQ(SysTabletsEntryPB::PREPARING, tablet-&gt;metadata().dirty().pb.state());</a>
<a name="ln2366">    }</a>
<a name="ln2367">    // Write Tablets to sys-tablets (in &quot;preparing&quot; state).</a>
<a name="ln2368">    s = sys_catalog_-&gt;AddItems(tablets, leader_ready_term());</a>
<a name="ln2369">  }</a>
<a name="ln2370"> </a>
<a name="ln2371">  if (PREDICT_FALSE(!s.ok())) {</a>
<a name="ln2372">    return AbortTableCreation(table.get(), tablets,</a>
<a name="ln2373">                              s.CloneAndPrepend(</a>
<a name="ln2374">                                  Substitute(&quot;An error occurred while inserting to sys-tablets: $0&quot;,</a>
<a name="ln2375">                                             s.ToString())),</a>
<a name="ln2376">                              resp);</a>
<a name="ln2377">  }</a>
<a name="ln2378">  TRACE(&quot;Wrote tablets to system table&quot;);</a>
<a name="ln2379"> </a>
<a name="ln2380">  // Update the on-disk table state to &quot;running&quot;.</a>
<a name="ln2381">  table-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb.set_state(SysTablesEntryPB::RUNNING);</a>
<a name="ln2382">  s = sys_catalog_-&gt;AddItem(table.get(), leader_ready_term());</a>
<a name="ln2383">  if (PREDICT_FALSE(!s.ok())) {</a>
<a name="ln2384">    return AbortTableCreation(table.get(), tablets,</a>
<a name="ln2385">                              s.CloneAndPrepend(</a>
<a name="ln2386">                                  Substitute(&quot;An error occurred while inserting to sys-tablets: $0&quot;,</a>
<a name="ln2387">                                             s.ToString())),</a>
<a name="ln2388">                              resp);</a>
<a name="ln2389">  }</a>
<a name="ln2390">  TRACE(&quot;Wrote table to system table&quot;);</a>
<a name="ln2391"> </a>
<a name="ln2392">  // For index table, insert index info in the indexed table.  However, for backwards compatibility,</a>
<a name="ln2393">  // don't insert index info for YSQL tables.</a>
<a name="ln2394">  if ((req.has_index_info() || req.has_indexed_table_id()) &amp;&amp;</a>
<a name="ln2395">      (index_backfill_enabled || !is_pg_table)) {</a>
<a name="ln2396">    if (index_backfill_enabled &amp;&amp; !req.skip_index_backfill()) {</a>
<a name="ln2397">      index_info.set_index_permissions(INDEX_PERM_DELETE_ONLY);</a>
<a name="ln2398">    }</a>
<a name="ln2399">    s = AddIndexInfoToTable(indexed_table, index_info, resp);</a>
<a name="ln2400">    if (PREDICT_FALSE(!s.ok())) {</a>
<a name="ln2401">      return AbortTableCreation(table.get(), tablets,</a>
<a name="ln2402">                                s.CloneAndPrepend(</a>
<a name="ln2403">                                    Substitute(&quot;An error occurred while inserting index info: $0&quot;,</a>
<a name="ln2404">                                               s.ToString())),</a>
<a name="ln2405">                                resp);</a>
<a name="ln2406">    }</a>
<a name="ln2407">  }</a>
<a name="ln2408"> </a>
<a name="ln2409">  // Commit the in-memory state.</a>
<a name="ln2410">  table-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln2411"> </a>
<a name="ln2412">  for (TabletInfo *tablet : tablets) {</a>
<a name="ln2413">    tablet-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln2414">  }</a>
<a name="ln2415"> </a>
<a name="ln2416">  if ((colocated &amp;&amp; tablets_exist) || (req.has_tablegroup_id() &amp;&amp; tablegroup_tablets_exist)) {</a>
<a name="ln2417">    auto call =</a>
<a name="ln2418">        std::make_shared&lt;AsyncAddTableToTablet&gt;(master_, AsyncTaskPool(), tablets[0], table);</a>
<a name="ln2419">    table-&gt;AddTask(call);</a>
<a name="ln2420">    WARN_NOT_OK(ScheduleTask(call), &quot;Failed to send AddTableToTablet request&quot;);</a>
<a name="ln2421">  }</a>
<a name="ln2422"> </a>
<a name="ln2423">  if (req.has_creator_role_name()) {</a>
<a name="ln2424">    const NamespaceName&amp; keyspace_name = req.namespace_().name();</a>
<a name="ln2425">    const TableName&amp; table_name = req.name();</a>
<a name="ln2426">    RETURN_NOT_OK(permissions_manager_-&gt;GrantPermissions(</a>
<a name="ln2427">        req.creator_role_name(),</a>
<a name="ln2428">        get_canonical_table(keyspace_name, table_name),</a>
<a name="ln2429">        table_name,</a>
<a name="ln2430">        keyspace_name,</a>
<a name="ln2431">        all_permissions_for_resource(ResourceType::TABLE),</a>
<a name="ln2432">        ResourceType::TABLE,</a>
<a name="ln2433">        resp));</a>
<a name="ln2434">  }</a>
<a name="ln2435"> </a>
<a name="ln2436">  LOG(INFO) &lt;&lt; &quot;Successfully created &quot; &lt;&lt; object_type &lt;&lt; &quot; &quot; &lt;&lt; table-&gt;ToString()</a>
<a name="ln2437">            &lt;&lt; &quot; per request from &quot; &lt;&lt; RequestorString(rpc);</a>
<a name="ln2438">  background_tasks_-&gt;Wake();</a>
<a name="ln2439"> </a>
<a name="ln2440">  if (FLAGS_master_enable_metrics_snapshotter &amp;&amp;</a>
<a name="ln2441">      !(req.table_type() == TableType::YQL_TABLE_TYPE &amp;&amp;</a>
<a name="ln2442">        namespace_id == kSystemNamespaceId &amp;&amp;</a>
<a name="ln2443">        req.name() == kMetricsSnapshotsTableName)) {</a>
<a name="ln2444">    Status s = CreateMetricsSnapshotsTableIfNeeded(rpc);</a>
<a name="ln2445">    if (!s.ok()) {</a>
<a name="ln2446">      return s.CloneAndPrepend(&quot;Error while creating metrics snapshots table&quot;);</a>
<a name="ln2447">    }</a>
<a name="ln2448">  }</a>
<a name="ln2449"> </a>
<a name="ln2450">  DVLOG(3) &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; &quot; Done.&quot;;</a>
<a name="ln2451">  return Status::OK();</a>
<a name="ln2452">}</a>
<a name="ln2453"> </a>
<a name="ln2454">Status CatalogManager::CreateTabletsFromTable(const vector&lt;Partition&gt;&amp; partitions,</a>
<a name="ln2455">                                              const scoped_refptr&lt;TableInfo&gt;&amp; table,</a>
<a name="ln2456">                                              std::vector&lt;TabletInfo*&gt;* tablets) {</a>
<a name="ln2457">  // Create the TabletInfo objects in state PREPARING.</a>
<a name="ln2458">  for (const Partition&amp; partition : partitions) {</a>
<a name="ln2459">    PartitionPB partition_pb;</a>
<a name="ln2460">    partition.ToPB(&amp;partition_pb);</a>
<a name="ln2461">    tablets-&gt;push_back(CreateTabletInfo(table.get(), partition_pb));</a>
<a name="ln2462">  }</a>
<a name="ln2463"> </a>
<a name="ln2464">  // Add the table/tablets to the in-memory map for the assignment.</a>
<a name="ln2465">  table-&gt;AddTablets(*tablets);</a>
<a name="ln2466">  auto tablet_map_checkout = tablet_map_.CheckOut();</a>
<a name="ln2467">  for (TabletInfo* tablet : *tablets) {</a>
<a name="ln2468">    InsertOrDie(tablet_map_checkout.get_ptr(), tablet-&gt;tablet_id(), tablet);</a>
<a name="ln2469">  }</a>
<a name="ln2470"> </a>
<a name="ln2471">  return Status::OK();</a>
<a name="ln2472">}</a>
<a name="ln2473"> </a>
<a name="ln2474">int CatalogManager::GetNumReplicasFromPlacementInfo(const PlacementInfoPB&amp; placement_info) {</a>
<a name="ln2475">  return placement_info.num_replicas() &gt; 0 ?</a>
<a name="ln2476">      placement_info.num_replicas() : FLAGS_replication_factor;</a>
<a name="ln2477">}</a>
<a name="ln2478"> </a>
<a name="ln2479">Status CatalogManager::CheckValidReplicationInfo(const ReplicationInfoPB&amp; replication_info,</a>
<a name="ln2480">                                                 const TSDescriptorVector&amp; all_ts_descs,</a>
<a name="ln2481">                                                 const vector&lt;Partition&gt;&amp; partitions,</a>
<a name="ln2482">                                                 CreateTableResponsePB* resp) {</a>
<a name="ln2483">  return CheckValidPlacementInfo(replication_info.live_replicas(), all_ts_descs, partitions, resp);</a>
<a name="ln2484">}</a>
<a name="ln2485"> </a>
<a name="ln2486">Status CatalogManager::CheckValidPlacementInfo(const PlacementInfoPB&amp; placement_info,</a>
<a name="ln2487">                                               const TSDescriptorVector&amp; ts_descs,</a>
<a name="ln2488">                                               const vector&lt;Partition&gt;&amp; partitions,</a>
<a name="ln2489">                                               CreateTableResponsePB* resp) {</a>
<a name="ln2490">  // Verify that the total number of tablets is reasonable, relative to the number</a>
<a name="ln2491">  // of live tablet servers.</a>
<a name="ln2492">  int num_live_tservers = ts_descs.size();</a>
<a name="ln2493">  int num_replicas = GetNumReplicasFromPlacementInfo(placement_info);</a>
<a name="ln2494">  int max_tablets = FLAGS_max_create_tablets_per_ts * num_live_tservers;</a>
<a name="ln2495">  Status s;</a>
<a name="ln2496">  string msg;</a>
<a name="ln2497">  if (num_replicas &gt; 1 &amp;&amp; max_tablets &gt; 0 &amp;&amp; partitions.size() &gt; max_tablets) {</a>
<a name="ln2498">    msg = Substitute(&quot;The requested number of tablets ($0) is over the permitted maximum ($1)&quot;,</a>
<a name="ln2499">                     partitions.size(), max_tablets);</a>
<a name="ln2500">    s = STATUS(InvalidArgument, msg);</a>
<a name="ln2501">    LOG(WARNING) &lt;&lt; msg;</a>
<a name="ln2502">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::TOO_MANY_TABLETS, s);</a>
<a name="ln2503">  }</a>
<a name="ln2504"> </a>
<a name="ln2505">  // Verify that the number of replicas isn't larger than the number of live tablet</a>
<a name="ln2506">  // servers.</a>
<a name="ln2507">  if (FLAGS_catalog_manager_check_ts_count_for_create_table &amp;&amp;</a>
<a name="ln2508">      num_replicas &gt; num_live_tservers) {</a>
<a name="ln2509">    msg = Substitute(&quot;Not enough live tablet servers to create table with replication factor $0. &quot;</a>
<a name="ln2510">                     &quot;$1 tablet servers are alive.&quot;, num_replicas, num_live_tservers);</a>
<a name="ln2511">    LOG(WARNING) &lt;&lt; msg</a>
<a name="ln2512">                 &lt;&lt; &quot;. Placement info: &quot; &lt;&lt; placement_info.ShortDebugString()</a>
<a name="ln2513">                 &lt;&lt; &quot;, replication factor flag: &quot; &lt;&lt; FLAGS_replication_factor;</a>
<a name="ln2514">    s = STATUS(InvalidArgument, msg);</a>
<a name="ln2515">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::REPLICATION_FACTOR_TOO_HIGH, s);</a>
<a name="ln2516">  }</a>
<a name="ln2517"> </a>
<a name="ln2518">  // Verify that placement requests are reasonable and we can satisfy the minimums.</a>
<a name="ln2519">  if (!placement_info.placement_blocks().empty()) {</a>
<a name="ln2520">    int minimum_sum = 0;</a>
<a name="ln2521">    for (const auto&amp; pb : placement_info.placement_blocks()) {</a>
<a name="ln2522">      minimum_sum += pb.min_num_replicas();</a>
<a name="ln2523">      if (!pb.has_cloud_info()) {</a>
<a name="ln2524">        msg = Substitute(&quot;Got placement info without cloud info set: $0&quot;, pb.ShortDebugString());</a>
<a name="ln2525">        s = STATUS(InvalidArgument, msg);</a>
<a name="ln2526">        LOG(WARNING) &lt;&lt; msg;</a>
<a name="ln2527">        return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA, s);</a>
<a name="ln2528">      }</a>
<a name="ln2529">    }</a>
<a name="ln2530"> </a>
<a name="ln2531">    if (minimum_sum &gt; num_replicas) {</a>
<a name="ln2532">      msg = Substitute(&quot;Sum of minimum replicas per placement ($0) is greater than num_replicas &quot;</a>
<a name="ln2533">                       &quot; ($1)&quot;, minimum_sum, num_replicas);</a>
<a name="ln2534">      s = STATUS(InvalidArgument, msg);</a>
<a name="ln2535">      LOG(WARNING) &lt;&lt; msg;</a>
<a name="ln2536">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA, s);</a>
<a name="ln2537">    }</a>
<a name="ln2538">  }</a>
<a name="ln2539">  return Status::OK();</a>
<a name="ln2540">}</a>
<a name="ln2541"> </a>
<a name="ln2542">Status CatalogManager::CreateTableInMemory(const CreateTableRequestPB&amp; req,</a>
<a name="ln2543">                                           const Schema&amp; schema,</a>
<a name="ln2544">                                           const PartitionSchema&amp; partition_schema,</a>
<a name="ln2545">                                           const bool create_tablets,</a>
<a name="ln2546">                                           const NamespaceId&amp; namespace_id,</a>
<a name="ln2547">                                           const NamespaceName&amp; namespace_name,</a>
<a name="ln2548">                                           const std::vector&lt;Partition&gt;&amp; partitions,</a>
<a name="ln2549">                                           IndexInfoPB* index_info,</a>
<a name="ln2550">                                           std::vector&lt;TabletInfo*&gt;* tablets,</a>
<a name="ln2551">                                           CreateTableResponsePB* resp,</a>
<a name="ln2552">                                           scoped_refptr&lt;TableInfo&gt;* table) {</a>
<a name="ln2553">  // Add the new table in &quot;preparing&quot; state.</a>
<a name="ln2554">  *table = CreateTableInfo(req, schema, partition_schema, namespace_id, namespace_name, index_info);</a>
<a name="ln2555">  const TableId&amp; table_id = (*table)-&gt;id();</a>
<a name="ln2556">  auto table_ids_map_checkout = table_ids_map_.CheckOut();</a>
<a name="ln2557">  (*table_ids_map_checkout)[table_id] = *table;</a>
<a name="ln2558">  // Do not add Postgres tables to the name map as the table name is not unique in a namespace.</a>
<a name="ln2559">  if (req.table_type() != PGSQL_TABLE_TYPE) {</a>
<a name="ln2560">    table_names_map_[{namespace_id, req.name()}] = *table;</a>
<a name="ln2561">  }</a>
<a name="ln2562"> </a>
<a name="ln2563">  if (create_tablets) {</a>
<a name="ln2564">    RETURN_NOT_OK(CreateTabletsFromTable(partitions, *table, tablets));</a>
<a name="ln2565">  }</a>
<a name="ln2566"> </a>
<a name="ln2567">  if (resp != nullptr) {</a>
<a name="ln2568">    resp-&gt;set_table_id(table_id);</a>
<a name="ln2569">  }</a>
<a name="ln2570"> </a>
<a name="ln2571">  HandleNewTableId(table_id);</a>
<a name="ln2572"> </a>
<a name="ln2573">  return Status::OK();</a>
<a name="ln2574">}</a>
<a name="ln2575"> </a>
<a name="ln2576">Status CatalogManager::CreateTransactionsStatusTableIfNeeded(rpc::RpcContext *rpc) {</a>
<a name="ln2577">  TableIdentifierPB table_indentifier;</a>
<a name="ln2578">  table_indentifier.set_table_name(kTransactionsTableName);</a>
<a name="ln2579">  table_indentifier.mutable_namespace_()-&gt;set_name(kSystemNamespaceName);</a>
<a name="ln2580"> </a>
<a name="ln2581">  // Check that the namespace exists.</a>
<a name="ln2582">  scoped_refptr&lt;NamespaceInfo&gt; ns_info;</a>
<a name="ln2583">  RETURN_NOT_OK(FindNamespace(table_indentifier.namespace_(), &amp;ns_info));</a>
<a name="ln2584">  if (!ns_info) {</a>
<a name="ln2585">    return STATUS(NotFound, &quot;Namespace does not exist&quot;, kSystemNamespaceName);</a>
<a name="ln2586">  }</a>
<a name="ln2587"> </a>
<a name="ln2588">  // If status table exists, do nothing, otherwise create it.</a>
<a name="ln2589">  scoped_refptr&lt;TableInfo&gt; table_info;</a>
<a name="ln2590">  RETURN_NOT_OK(FindTable(table_indentifier, &amp;table_info));</a>
<a name="ln2591"> </a>
<a name="ln2592">  if (table_info) {</a>
<a name="ln2593">    VLOG(1) &lt;&lt; &quot;Transaction status table already exists, not creating.&quot;;</a>
<a name="ln2594">    return Status::OK();</a>
<a name="ln2595">  }</a>
<a name="ln2596"> </a>
<a name="ln2597">  LOG(INFO) &lt;&lt; &quot;Creating the transaction status table&quot;;</a>
<a name="ln2598">  // Set up a CreateTable request internally.</a>
<a name="ln2599">  CreateTableRequestPB req;</a>
<a name="ln2600">  CreateTableResponsePB resp;</a>
<a name="ln2601">  req.set_name(kTransactionsTableName);</a>
<a name="ln2602">  req.mutable_namespace_()-&gt;set_name(kSystemNamespaceName);</a>
<a name="ln2603">  req.set_table_type(TableType::TRANSACTION_STATUS_TABLE_TYPE);</a>
<a name="ln2604"> </a>
<a name="ln2605">  // Explicitly set the number tablets if the corresponding flag is set, otherwise CreateTable</a>
<a name="ln2606">  // will use the same defaults as for regular tables.</a>
<a name="ln2607">  if (FLAGS_transaction_table_num_tablets &gt; 0) {</a>
<a name="ln2608">    req.mutable_schema()-&gt;mutable_table_properties()-&gt;set_num_tablets(</a>
<a name="ln2609">        FLAGS_transaction_table_num_tablets);</a>
<a name="ln2610">    req.set_num_tablets(FLAGS_transaction_table_num_tablets);</a>
<a name="ln2611">  }</a>
<a name="ln2612"> </a>
<a name="ln2613">  ColumnSchema hash(kRedisKeyColumnName, BINARY, /* is_nullable */ false, /* is_hash_key */ true);</a>
<a name="ln2614">  ColumnSchemaToPB(hash, req.mutable_schema()-&gt;mutable_columns()-&gt;Add());</a>
<a name="ln2615"> </a>
<a name="ln2616">  Status s = CreateTable(&amp;req, &amp;resp, rpc);</a>
<a name="ln2617">  // We do not lock here so it is technically possible that the table was already created.</a>
<a name="ln2618">  // If so, there is nothing to do so we just ignore the &quot;AlreadyPresent&quot; error.</a>
<a name="ln2619">  if (!s.ok() &amp;&amp; !s.IsAlreadyPresent()) {</a>
<a name="ln2620">    return s;</a>
<a name="ln2621">  }</a>
<a name="ln2622"> </a>
<a name="ln2623">  return Status::OK();</a>
<a name="ln2624">}</a>
<a name="ln2625"> </a>
<a name="ln2626">Status CatalogManager::CreateMetricsSnapshotsTableIfNeeded(rpc::RpcContext *rpc) {</a>
<a name="ln2627">  TableIdentifierPB table_indentifier;</a>
<a name="ln2628">  table_indentifier.set_table_name(kMetricsSnapshotsTableName);</a>
<a name="ln2629">  table_indentifier.mutable_namespace_()-&gt;set_name(kSystemNamespaceName);</a>
<a name="ln2630"> </a>
<a name="ln2631">  // Check that the namespace exists.</a>
<a name="ln2632">  scoped_refptr&lt;NamespaceInfo&gt; ns_info;</a>
<a name="ln2633">  RETURN_NOT_OK(FindNamespace(table_indentifier.namespace_(), &amp;ns_info));</a>
<a name="ln2634">  if (!ns_info) {</a>
<a name="ln2635">    return STATUS(NotFound, &quot;Namespace does not exist&quot;, kSystemNamespaceName);</a>
<a name="ln2636">  }</a>
<a name="ln2637"> </a>
<a name="ln2638">  // If status table exists do nothing, otherwise create it.</a>
<a name="ln2639">  scoped_refptr&lt;TableInfo&gt; table_info;</a>
<a name="ln2640">  RETURN_NOT_OK(FindTable(table_indentifier, &amp;table_info));</a>
<a name="ln2641"> </a>
<a name="ln2642">  if (!table_info) {</a>
<a name="ln2643">    // Set up a CreateTable request internally.</a>
<a name="ln2644">    CreateTableRequestPB req;</a>
<a name="ln2645">    CreateTableResponsePB resp;</a>
<a name="ln2646">    req.set_name(kMetricsSnapshotsTableName);</a>
<a name="ln2647">    req.mutable_namespace_()-&gt;set_name(kSystemNamespaceName);</a>
<a name="ln2648">    req.set_table_type(TableType::YQL_TABLE_TYPE);</a>
<a name="ln2649"> </a>
<a name="ln2650">    // Explicitly set the number tablets if the corresponding flag is set, otherwise CreateTable</a>
<a name="ln2651">    // will use the same defaults as for regular tables.</a>
<a name="ln2652">    if (FLAGS_metrics_snapshots_table_num_tablets &gt; 0) {</a>
<a name="ln2653">      req.mutable_schema()-&gt;mutable_table_properties()-&gt;set_num_tablets(</a>
<a name="ln2654">          FLAGS_metrics_snapshots_table_num_tablets);</a>
<a name="ln2655">      req.set_num_tablets(FLAGS_metrics_snapshots_table_num_tablets);</a>
<a name="ln2656">    }</a>
<a name="ln2657"> </a>
<a name="ln2658">    // Schema description: &quot;node&quot; refers to tserver uuid. &quot;entity_type&quot; can be either</a>
<a name="ln2659">    // &quot;tserver&quot; or &quot;table&quot;. &quot;entity_id&quot; is uuid of corresponding tserver or table.</a>
<a name="ln2660">    // &quot;metric&quot; is the name of the metric and &quot;value&quot; is its val. &quot;ts&quot; is time at</a>
<a name="ln2661">    // which the snapshot was recorded. &quot;details&quot; is a json column for future extensibility.</a>
<a name="ln2662"> </a>
<a name="ln2663">    YBSchemaBuilder schemaBuilder;</a>
<a name="ln2664">    schemaBuilder.AddColumn(&quot;node&quot;)-&gt;Type(STRING)-&gt;HashPrimaryKey()-&gt;NotNull();</a>
<a name="ln2665">    schemaBuilder.AddColumn(&quot;entity_type&quot;)-&gt;Type(STRING)-&gt;PrimaryKey()-&gt;NotNull();</a>
<a name="ln2666">    schemaBuilder.AddColumn(&quot;entity_id&quot;)-&gt;Type(STRING)-&gt;PrimaryKey()-&gt;NotNull();</a>
<a name="ln2667">    schemaBuilder.AddColumn(&quot;metric&quot;)-&gt;Type(STRING)-&gt;PrimaryKey()-&gt;NotNull();</a>
<a name="ln2668">    schemaBuilder.AddColumn(&quot;ts&quot;)-&gt;Type(TIMESTAMP)-&gt;PrimaryKey()-&gt;NotNull()-&gt;</a>
<a name="ln2669">      SetSortingType(ColumnSchema::SortingType::kDescending);</a>
<a name="ln2670">    schemaBuilder.AddColumn(&quot;value&quot;)-&gt;Type(INT64);</a>
<a name="ln2671">    schemaBuilder.AddColumn(&quot;details&quot;)-&gt;Type(JSONB);</a>
<a name="ln2672"> </a>
<a name="ln2673">    YBSchema ybschema;</a>
<a name="ln2674">    CHECK_OK(schemaBuilder.Build(&amp;ybschema));</a>
<a name="ln2675"> </a>
<a name="ln2676">    auto schema = yb::client::internal::GetSchema(ybschema);</a>
<a name="ln2677">    SchemaToPB(schema, req.mutable_schema());</a>
<a name="ln2678"> </a>
<a name="ln2679">    Status s = CreateTable(&amp;req, &amp;resp, rpc);</a>
<a name="ln2680">    // We do not lock here so it is technically possible that the table was already created.</a>
<a name="ln2681">    // If so, there is nothing to do so we just ignore the &quot;AlreadyPresent&quot; error.</a>
<a name="ln2682">    if (!s.ok() &amp;&amp; !s.IsAlreadyPresent()) {</a>
<a name="ln2683">      return s;</a>
<a name="ln2684">    }</a>
<a name="ln2685">  }</a>
<a name="ln2686">  return Status::OK();</a>
<a name="ln2687">}</a>
<a name="ln2688"> </a>
<a name="ln2689">Status CatalogManager::IsCreateTableDone(const IsCreateTableDoneRequestPB* req,</a>
<a name="ln2690">                                         IsCreateTableDoneResponsePB* resp) {</a>
<a name="ln2691">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln2692"> </a>
<a name="ln2693">  scoped_refptr&lt;TableInfo&gt; table;</a>
<a name="ln2694"> </a>
<a name="ln2695">  // 1. Lookup the table and verify if it exists.</a>
<a name="ln2696">  TRACE(&quot;Looking up table&quot;);</a>
<a name="ln2697">  RETURN_NOT_OK(FindTable(req-&gt;table(), &amp;table));</a>
<a name="ln2698">  if (table == nullptr) {</a>
<a name="ln2699">    Status s = STATUS(NotFound, &quot;The object does not exist&quot;, req-&gt;table().ShortDebugString());</a>
<a name="ln2700">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln2701">  }</a>
<a name="ln2702"> </a>
<a name="ln2703">  TRACE(&quot;Locking table&quot;);</a>
<a name="ln2704">  auto l = table-&gt;LockForRead();</a>
<a name="ln2705">  RETURN_NOT_OK(CheckIfTableDeletedOrNotRunning(l.get(), resp));</a>
<a name="ln2706">  const auto&amp; pb = l-&gt;data().pb;</a>
<a name="ln2707"> </a>
<a name="ln2708">  // 2. Verify if the create is in-progress.</a>
<a name="ln2709">  TRACE(&quot;Verify if the table creation is in progress for $0&quot;, table-&gt;ToString());</a>
<a name="ln2710">  resp-&gt;set_done(!table-&gt;IsCreateInProgress());</a>
<a name="ln2711"> </a>
<a name="ln2712">  // 3. Set any current errors, if we are experiencing issues creating the table. This will be</a>
<a name="ln2713">  // bubbled up to the MasterService layer. If it is an error, it gets wrapped around in</a>
<a name="ln2714">  // MasterErrorPB::UNKNOWN_ERROR.</a>
<a name="ln2715">  RETURN_NOT_OK(table-&gt;GetCreateTableErrorStatus());</a>
<a name="ln2716"> </a>
<a name="ln2717">  // 4. For index table:</a>
<a name="ln2718">  //   a. If backfill is enabled, check if an index is present in indexed table's index map.</a>
<a name="ln2719">  //   b. Otherwise check if alter schema is done on the indexed table as well.</a>
<a name="ln2720">  // TODO(alex, amit): While (4.a) sounds like it should be enabled for both YSQL and YCQL,</a>
<a name="ln2721">  //    currently it makes YCQL index backfill unstable - which is indicated by intermittent</a>
<a name="ln2722">  //    failures of various tests under CppCassandraDriverTest - mostly TestCreateIndex.</a>
<a name="ln2723">  if (resp-&gt;done() &amp;&amp; PROTO_IS_INDEX(pb)) {</a>
<a name="ln2724">    // TODO(alex, jason): This is a quick fix to make sure we treat unique index as non-backfilling.</a>
<a name="ln2725">    //    We should remove this once we've implemented #4899.</a>
<a name="ln2726">    bool is_unique_index = pb.has_index_info() &amp;&amp; pb.index_info().is_unique();</a>
<a name="ln2727">    auto&amp; indexed_table_id = PROTO_GET_INDEXED_TABLE_ID(pb);</a>
<a name="ln2728">    if (pb.table_type() == PGSQL_TABLE_TYPE &amp;&amp;</a>
<a name="ln2729">        !is_unique_index &amp;&amp;</a>
<a name="ln2730">        IsUserCreatedTable(*table) &amp;&amp;</a>
<a name="ln2731">        IsIndexBackfillEnabled(pb.table_type(),</a>
<a name="ln2732">                               pb.schema().table_properties().is_transactional())) {</a>
<a name="ln2733">      GetTableSchemaRequestPB get_schema_req;</a>
<a name="ln2734">      GetTableSchemaResponsePB get_schema_resp;</a>
<a name="ln2735">      get_schema_req.mutable_table()-&gt;set_table_id(indexed_table_id);</a>
<a name="ln2736">      const Status s = GetTableSchema(&amp;get_schema_req, &amp;get_schema_resp);</a>
<a name="ln2737">      if (!s.ok()) {</a>
<a name="ln2738">        resp-&gt;mutable_error()-&gt;Swap(get_schema_resp.mutable_error());</a>
<a name="ln2739">        return s;</a>
<a name="ln2740">      }</a>
<a name="ln2741"> </a>
<a name="ln2742">      resp-&gt;set_done(false);</a>
<a name="ln2743">      for (const auto&amp; index : get_schema_resp.indexes()) {</a>
<a name="ln2744">        if (index.has_table_id() &amp;&amp; index.table_id() == table-&gt;id()) {</a>
<a name="ln2745">          resp-&gt;set_done(true);</a>
<a name="ln2746">          break;</a>
<a name="ln2747">        }</a>
<a name="ln2748">      }</a>
<a name="ln2749">    } else {</a>
<a name="ln2750">      // TODO(alex, amit): We probably should be fine doing something like (a) case here, since we</a>
<a name="ln2751">      //                   shouldn't care if other indexes are being created</a>
<a name="ln2752">      IsAlterTableDoneRequestPB alter_table_req;</a>
<a name="ln2753">      IsAlterTableDoneResponsePB alter_table_resp;</a>
<a name="ln2754">      alter_table_req.mutable_table()-&gt;set_table_id(indexed_table_id);</a>
<a name="ln2755">      const Status s = IsAlterTableDone(&amp;alter_table_req, &amp;alter_table_resp);</a>
<a name="ln2756">      if (!s.ok()) {</a>
<a name="ln2757">        resp-&gt;mutable_error()-&gt;Swap(alter_table_resp.mutable_error());</a>
<a name="ln2758">        return s;</a>
<a name="ln2759">      }</a>
<a name="ln2760">      resp-&gt;set_done(alter_table_resp.done());</a>
<a name="ln2761">    }</a>
<a name="ln2762">  }</a>
<a name="ln2763"> </a>
<a name="ln2764">  // If this is a transactional table we are not done until the transaction status table is created.</a>
<a name="ln2765">  // However, if we are currently initializing the system catalog snapshot, we don't create the</a>
<a name="ln2766">  // transactions table.</a>
<a name="ln2767">  if (!FLAGS_create_initial_sys_catalog_snapshot &amp;&amp;</a>
<a name="ln2768">      resp-&gt;done() &amp;&amp; pb.schema().table_properties().is_transactional()) {</a>
<a name="ln2769">    RETURN_NOT_OK(IsTransactionStatusTableCreated(resp));</a>
<a name="ln2770">  }</a>
<a name="ln2771"> </a>
<a name="ln2772">  // We are not done until the metrics snapshots table is created.</a>
<a name="ln2773">  if (FLAGS_master_enable_metrics_snapshotter &amp;&amp; resp-&gt;done() &amp;&amp;</a>
<a name="ln2774">      !(table-&gt;GetTableType() == TableType::YQL_TABLE_TYPE &amp;&amp;</a>
<a name="ln2775">        table-&gt;namespace_id() == kSystemNamespaceId &amp;&amp;</a>
<a name="ln2776">        table-&gt;name() == kMetricsSnapshotsTableName)) {</a>
<a name="ln2777">    RETURN_NOT_OK(IsMetricsSnapshotsTableCreated(resp));</a>
<a name="ln2778">  }</a>
<a name="ln2779"> </a>
<a name="ln2780">  // If this is a colocated table and there is a pending AddTableToTablet task then we are not done.</a>
<a name="ln2781">  if (resp-&gt;done() &amp;&amp; pb.colocated()) {</a>
<a name="ln2782">    resp-&gt;set_done(!table-&gt;HasTasks(MonitoredTask::Type::ASYNC_ADD_TABLE_TO_TABLET));</a>
<a name="ln2783">  }</a>
<a name="ln2784"> </a>
<a name="ln2785">  return Status::OK();</a>
<a name="ln2786">}</a>
<a name="ln2787"> </a>
<a name="ln2788">Status CatalogManager::IsCreateTableInProgress(const TableId&amp; table_id,</a>
<a name="ln2789">                                               CoarseTimePoint deadline,</a>
<a name="ln2790">                                               bool* create_in_progress) {</a>
<a name="ln2791">  DCHECK_ONLY_NOTNULL(create_in_progress);</a>
<a name="ln2792">  DCHECK(!table_id.empty());</a>
<a name="ln2793"> </a>
<a name="ln2794">  IsCreateTableDoneRequestPB req;</a>
<a name="ln2795">  IsCreateTableDoneResponsePB resp;</a>
<a name="ln2796">  req.mutable_table()-&gt;set_table_id(table_id);</a>
<a name="ln2797">  RETURN_NOT_OK(IsCreateTableDone(&amp;req, &amp;resp));</a>
<a name="ln2798"> </a>
<a name="ln2799">  if (resp.has_error()) {</a>
<a name="ln2800">    return StatusFromPB(resp.error().status());</a>
<a name="ln2801">  }</a>
<a name="ln2802"> </a>
<a name="ln2803">  *create_in_progress = !resp.done();</a>
<a name="ln2804">  return Status::OK();</a>
<a name="ln2805">}</a>
<a name="ln2806"> </a>
<a name="ln2807">Status CatalogManager::WaitForCreateTableToFinish(const TableId&amp; table_id) {</a>
<a name="ln2808">  MonoDelta default_admin_operation_timeout(</a>
<a name="ln2809">      MonoDelta::FromSeconds(FLAGS_yb_client_admin_operation_timeout_sec));</a>
<a name="ln2810">  auto deadline = CoarseMonoClock::Now() + default_admin_operation_timeout;</a>
<a name="ln2811"> </a>
<a name="ln2812">  return client::RetryFunc(</a>
<a name="ln2813">      deadline, &quot;Waiting on Create Table to be completed&quot;, &quot;Timed out waiting for Table Creation&quot;,</a>
<a name="ln2814">      std::bind(&amp;CatalogManager::IsCreateTableInProgress, this, table_id, _1, _2));</a>
<a name="ln2815">}</a>
<a name="ln2816"> </a>
<a name="ln2817">Status CatalogManager::IsTransactionStatusTableCreated(IsCreateTableDoneResponsePB* resp) {</a>
<a name="ln2818">  IsCreateTableDoneRequestPB req;</a>
<a name="ln2819"> </a>
<a name="ln2820">  req.mutable_table()-&gt;set_table_name(kTransactionsTableName);</a>
<a name="ln2821">  req.mutable_table()-&gt;mutable_namespace_()-&gt;set_name(kSystemNamespaceName);</a>
<a name="ln2822"> </a>
<a name="ln2823">  return IsCreateTableDone(&amp;req, resp);</a>
<a name="ln2824">}</a>
<a name="ln2825"> </a>
<a name="ln2826">Status CatalogManager::IsMetricsSnapshotsTableCreated(IsCreateTableDoneResponsePB* resp) {</a>
<a name="ln2827">  IsCreateTableDoneRequestPB req;</a>
<a name="ln2828"> </a>
<a name="ln2829">  req.mutable_table()-&gt;set_table_name(kMetricsSnapshotsTableName);</a>
<a name="ln2830">  req.mutable_table()-&gt;mutable_namespace_()-&gt;set_name(kSystemNamespaceName);</a>
<a name="ln2831">  req.mutable_table()-&gt;mutable_namespace_()-&gt;set_database_type(YQLDatabase::YQL_DATABASE_CQL);</a>
<a name="ln2832"> </a>
<a name="ln2833">  return IsCreateTableDone(&amp;req, resp);</a>
<a name="ln2834">}</a>
<a name="ln2835"> </a>
<a name="ln2836">std::string CatalogManager::GenerateId(boost::optional&lt;const SysRowEntry::Type&gt; entity_type) {</a>
<a name="ln2837">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln2838">  return GenerateIdUnlocked(entity_type);</a>
<a name="ln2839">}</a>
<a name="ln2840"> </a>
<a name="ln2841">std::string CatalogManager::GenerateIdUnlocked(</a>
<a name="ln2842">    boost::optional&lt;const SysRowEntry::Type&gt; entity_type) {</a>
<a name="ln2843">  while (true) {</a>
<a name="ln2844">    // Generate id and make sure it is unique within its category.</a>
<a name="ln2845">    std::string id = oid_generator_.Next();</a>
<a name="ln2846">    if (!entity_type) {</a>
<a name="ln2847">      return id;</a>
<a name="ln2848">    }</a>
<a name="ln2849">    switch (*entity_type) {</a>
<a name="ln2850">      case SysRowEntry::NAMESPACE:</a>
<a name="ln2851">        if (FindPtrOrNull(namespace_ids_map_, id) == nullptr) return id;</a>
<a name="ln2852">        break;</a>
<a name="ln2853">      case SysRowEntry::TABLE:</a>
<a name="ln2854">        if (FindPtrOrNull(*table_ids_map_, id) == nullptr) return id;</a>
<a name="ln2855">        break;</a>
<a name="ln2856">      case SysRowEntry::TABLET:</a>
<a name="ln2857">        if (FindPtrOrNull(*tablet_map_, id) == nullptr) return id;</a>
<a name="ln2858">        break;</a>
<a name="ln2859">      case SysRowEntry::UDTYPE:</a>
<a name="ln2860">        if (FindPtrOrNull(udtype_ids_map_, id) == nullptr) return id;</a>
<a name="ln2861">        break;</a>
<a name="ln2862">      case SysRowEntry::SNAPSHOT:</a>
<a name="ln2863">        return id;</a>
<a name="ln2864">      case SysRowEntry::CDC_STREAM:</a>
<a name="ln2865">        if (!CDCStreamExistsUnlocked(id)) return id;</a>
<a name="ln2866">        break;</a>
<a name="ln2867">      case SysRowEntry::UNKNOWN: FALLTHROUGH_INTENDED;</a>
<a name="ln2868">      case SysRowEntry::CLUSTER_CONFIG: FALLTHROUGH_INTENDED;</a>
<a name="ln2869">      case SysRowEntry::ROLE: FALLTHROUGH_INTENDED;</a>
<a name="ln2870">      case SysRowEntry::REDIS_CONFIG: FALLTHROUGH_INTENDED;</a>
<a name="ln2871">      case SysRowEntry::UNIVERSE_REPLICATION: FALLTHROUGH_INTENDED;</a>
<a name="ln2872">      case SysRowEntry::SYS_CONFIG:</a>
<a name="ln2873">        LOG(DFATAL) &lt;&lt; &quot;Invalid id type: &quot; &lt;&lt; *entity_type;</a>
<a name="ln2874">        return id;</a>
<a name="ln2875">    }</a>
<a name="ln2876">  }</a>
<a name="ln2877">}</a>
<a name="ln2878"> </a>
<a name="ln2879">scoped_refptr&lt;TableInfo&gt; CatalogManager::CreateTableInfo(const CreateTableRequestPB&amp; req,</a>
<a name="ln2880">                                                         const Schema&amp; schema,</a>
<a name="ln2881">                                                         const PartitionSchema&amp; partition_schema,</a>
<a name="ln2882">                                                         const NamespaceId&amp; namespace_id,</a>
<a name="ln2883">                                                         const NamespaceName&amp; namespace_name,</a>
<a name="ln2884">                                                         IndexInfoPB* index_info) {</a>
<a name="ln2885">  DCHECK(schema.has_column_ids());</a>
<a name="ln2886">  TableId table_id</a>
<a name="ln2887">      = !req.table_id().empty() ? req.table_id() : GenerateIdUnlocked(SysRowEntry::TABLE);</a>
<a name="ln2888">  scoped_refptr&lt;TableInfo&gt; table = NewTableInfo(table_id);</a>
<a name="ln2889">  table-&gt;mutable_metadata()-&gt;StartMutation();</a>
<a name="ln2890">  SysTablesEntryPB *metadata = &amp;table-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb;</a>
<a name="ln2891">  metadata-&gt;set_state(SysTablesEntryPB::PREPARING);</a>
<a name="ln2892">  metadata-&gt;set_name(req.name());</a>
<a name="ln2893">  metadata-&gt;set_table_type(req.table_type());</a>
<a name="ln2894">  metadata-&gt;set_namespace_id(namespace_id);</a>
<a name="ln2895">  metadata-&gt;set_namespace_name(namespace_name);</a>
<a name="ln2896">  metadata-&gt;set_version(0);</a>
<a name="ln2897">  metadata-&gt;set_next_column_id(ColumnId(schema.max_col_id() + 1));</a>
<a name="ln2898">  // TODO(bogdan): add back in replication_info once we allow overrides!</a>
<a name="ln2899">  // Use the Schema object passed in, since it has the column IDs already assigned,</a>
<a name="ln2900">  // whereas the user request PB does not.</a>
<a name="ln2901">  SchemaToPB(schema, metadata-&gt;mutable_schema());</a>
<a name="ln2902">  partition_schema.ToPB(metadata-&gt;mutable_partition_schema());</a>
<a name="ln2903">  // For index table, set index details (indexed table id and whether the index is local).</a>
<a name="ln2904">  if (req.has_index_info()) {</a>
<a name="ln2905">    metadata-&gt;mutable_index_info()-&gt;CopyFrom(req.index_info());</a>
<a name="ln2906"> </a>
<a name="ln2907">    // Set the deprecated fields also for compatibility reasons.</a>
<a name="ln2908">    metadata-&gt;set_indexed_table_id(req.index_info().indexed_table_id());</a>
<a name="ln2909">    metadata-&gt;set_is_local_index(req.index_info().is_local());</a>
<a name="ln2910">    metadata-&gt;set_is_unique_index(req.index_info().is_unique());</a>
<a name="ln2911"> </a>
<a name="ln2912">    // Setup index info.</a>
<a name="ln2913">    if (index_info != nullptr) {</a>
<a name="ln2914">      index_info-&gt;set_table_id(table-&gt;id());</a>
<a name="ln2915">      metadata-&gt;mutable_index_info()-&gt;CopyFrom(*index_info);</a>
<a name="ln2916">    }</a>
<a name="ln2917">  } else if (req.has_indexed_table_id()) {</a>
<a name="ln2918">    // Read data from the deprecated field and update the new fields.</a>
<a name="ln2919">    metadata-&gt;mutable_index_info()-&gt;set_indexed_table_id(req.indexed_table_id());</a>
<a name="ln2920">    metadata-&gt;mutable_index_info()-&gt;set_is_local(req.is_local_index());</a>
<a name="ln2921">    metadata-&gt;mutable_index_info()-&gt;set_is_unique(req.is_unique_index());</a>
<a name="ln2922"> </a>
<a name="ln2923">    // Set the deprecated fields also for compatibility reasons.</a>
<a name="ln2924">    metadata-&gt;set_indexed_table_id(req.indexed_table_id());</a>
<a name="ln2925">    metadata-&gt;set_is_local_index(req.is_local_index());</a>
<a name="ln2926">    metadata-&gt;set_is_unique_index(req.is_unique_index());</a>
<a name="ln2927"> </a>
<a name="ln2928">    // Setup index info.</a>
<a name="ln2929">    if (index_info != nullptr) {</a>
<a name="ln2930">      index_info-&gt;set_table_id(table-&gt;id());</a>
<a name="ln2931">      metadata-&gt;mutable_index_info()-&gt;CopyFrom(*index_info);</a>
<a name="ln2932">    }</a>
<a name="ln2933">  }</a>
<a name="ln2934"> </a>
<a name="ln2935">  if (req.is_pg_shared_table()) {</a>
<a name="ln2936">    metadata-&gt;set_is_pg_shared_table(true);</a>
<a name="ln2937">  }</a>
<a name="ln2938"> </a>
<a name="ln2939">  return table;</a>
<a name="ln2940">}</a>
<a name="ln2941"> </a>
<a name="ln2942">TabletInfo* CatalogManager::CreateTabletInfo(TableInfo* table,</a>
<a name="ln2943">                                             const PartitionPB&amp; partition) {</a>
<a name="ln2944">  TabletInfo* tablet = new TabletInfo(table, GenerateIdUnlocked(SysRowEntry::TABLET));</a>
<a name="ln2945">  tablet-&gt;mutable_metadata()-&gt;StartMutation();</a>
<a name="ln2946">  SysTabletsEntryPB *metadata = &amp;tablet-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb;</a>
<a name="ln2947">  metadata-&gt;set_state(SysTabletsEntryPB::PREPARING);</a>
<a name="ln2948">  metadata-&gt;mutable_partition()-&gt;CopyFrom(partition);</a>
<a name="ln2949">  metadata-&gt;set_table_id(table-&gt;id());</a>
<a name="ln2950">  // This is important: we are setting the first table id in the table_ids list</a>
<a name="ln2951">  // to be the id of the original table that creates the tablet.</a>
<a name="ln2952">  metadata-&gt;add_table_ids(table-&gt;id());</a>
<a name="ln2953">  return tablet;</a>
<a name="ln2954">}</a>
<a name="ln2955"> </a>
<a name="ln2956">Status CatalogManager::RemoveTableIdsFromTabletInfo(</a>
<a name="ln2957">    TabletInfoPtr tablet_info,</a>
<a name="ln2958">    unordered_set&lt;TableId&gt; tables_to_remove) {</a>
<a name="ln2959">  auto tablet_lock = tablet_info-&gt;LockForWrite();</a>
<a name="ln2960"> </a>
<a name="ln2961">  google::protobuf::RepeatedPtrField&lt;std::string&gt; new_table_ids;</a>
<a name="ln2962">  for (const auto&amp; table_id : tablet_lock-&gt;data().pb.table_ids()) {</a>
<a name="ln2963">    if (tables_to_remove.find(table_id) == tables_to_remove.end()) {</a>
<a name="ln2964">      *new_table_ids.Add() = std::move(table_id);</a>
<a name="ln2965">    }</a>
<a name="ln2966">  }</a>
<a name="ln2967">  tablet_lock-&gt;mutable_data()-&gt;pb.mutable_table_ids()-&gt;Swap(&amp;new_table_ids);</a>
<a name="ln2968"> </a>
<a name="ln2969">  RETURN_NOT_OK(sys_catalog_-&gt;UpdateItem(tablet_info.get(), leader_ready_term()));</a>
<a name="ln2970">  tablet_lock-&gt;Commit();</a>
<a name="ln2971">  return Status::OK();</a>
<a name="ln2972">}</a>
<a name="ln2973"> </a>
<a name="ln2974">Status CatalogManager::FindTable(const TableIdentifierPB&amp; table_identifier,</a>
<a name="ln2975">                                 scoped_refptr&lt;TableInfo&gt; *table_info) {</a>
<a name="ln2976">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln2977"> </a>
<a name="ln2978">  if (table_identifier.has_table_id()) {</a>
<a name="ln2979">    *table_info = FindPtrOrNull(*table_ids_map_, table_identifier.table_id());</a>
<a name="ln2980">  } else if (table_identifier.has_table_name()) {</a>
<a name="ln2981">    NamespaceId namespace_id;</a>
<a name="ln2982"> </a>
<a name="ln2983">    if (table_identifier.has_namespace_()) {</a>
<a name="ln2984">      const auto&amp; namespace_info = table_identifier.namespace_();</a>
<a name="ln2985">      if (namespace_info.has_id()) {</a>
<a name="ln2986">        namespace_id = namespace_info.id();</a>
<a name="ln2987">      } else if (namespace_info.has_name()) {</a>
<a name="ln2988">        // Find namespace by its name.</a>
<a name="ln2989">        scoped_refptr&lt;NamespaceInfo&gt; ns = FindPtrOrNull(</a>
<a name="ln2990">            namespace_names_mapper_[GetDatabaseType(namespace_info)],</a>
<a name="ln2991">            namespace_info.name());</a>
<a name="ln2992"> </a>
<a name="ln2993">        if (ns == nullptr) {</a>
<a name="ln2994">          // The namespace was not found. This is a correct case. Just return NULL.</a>
<a name="ln2995">          *table_info = nullptr;</a>
<a name="ln2996">          return Status::OK();</a>
<a name="ln2997">        }</a>
<a name="ln2998"> </a>
<a name="ln2999">        namespace_id = ns-&gt;id();</a>
<a name="ln3000">      } else {</a>
<a name="ln3001">        return STATUS(InvalidArgument, &quot;Neither keyspace id or keyspace name are specified&quot;);</a>
<a name="ln3002">      }</a>
<a name="ln3003">    }</a>
<a name="ln3004"> </a>
<a name="ln3005">    if (namespace_id.empty()) {</a>
<a name="ln3006">      return STATUS(InvalidArgument, &quot;No namespace used&quot;);</a>
<a name="ln3007">    }</a>
<a name="ln3008"> </a>
<a name="ln3009">    *table_info = FindPtrOrNull(table_names_map_, {namespace_id, table_identifier.table_name()});</a>
<a name="ln3010">  } else {</a>
<a name="ln3011">    return STATUS(InvalidArgument, &quot;Neither table id or table name are specified&quot;);</a>
<a name="ln3012">  }</a>
<a name="ln3013">  return Status::OK();</a>
<a name="ln3014">}</a>
<a name="ln3015"> </a>
<a name="ln3016">Status CatalogManager::FindNamespaceUnlocked(const NamespaceIdentifierPB&amp; ns_identifier,</a>
<a name="ln3017">                                             scoped_refptr&lt;NamespaceInfo&gt;* ns_info) const {</a>
<a name="ln3018">  if (ns_identifier.has_id()) {</a>
<a name="ln3019">    *ns_info = FindPtrOrNull(namespace_ids_map_, ns_identifier.id());</a>
<a name="ln3020">    if (*ns_info == nullptr) {</a>
<a name="ln3021">      return STATUS(NotFound, &quot;Keyspace identifier not found&quot;, ns_identifier.id());</a>
<a name="ln3022">    }</a>
<a name="ln3023">  } else if (ns_identifier.has_name()) {</a>
<a name="ln3024">    auto db = GetDatabaseType(ns_identifier);</a>
<a name="ln3025">    *ns_info = FindPtrOrNull(namespace_names_mapper_[db], ns_identifier.name());</a>
<a name="ln3026">    if (*ns_info == nullptr) {</a>
<a name="ln3027">      return STATUS(NotFound, &quot;Keyspace name not found&quot;, ns_identifier.name());</a>
<a name="ln3028">    }</a>
<a name="ln3029">  } else {</a>
<a name="ln3030">    return STATUS(NotFound, &quot;Neither keyspace id nor keyspace name is specified.&quot;);</a>
<a name="ln3031">  }</a>
<a name="ln3032">  return Status::OK();</a>
<a name="ln3033">}</a>
<a name="ln3034"> </a>
<a name="ln3035">Status CatalogManager::FindNamespace(const NamespaceIdentifierPB&amp; ns_identifier,</a>
<a name="ln3036">                                     scoped_refptr&lt;NamespaceInfo&gt;* ns_info) const {</a>
<a name="ln3037">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln3038">  return FindNamespaceUnlocked(ns_identifier, ns_info);</a>
<a name="ln3039">}</a>
<a name="ln3040"> </a>
<a name="ln3041">Result&lt;TableDescription&gt; CatalogManager::DescribeTable(const TableIdentifierPB&amp; table_identifier) {</a>
<a name="ln3042">  TableDescription result;</a>
<a name="ln3043"> </a>
<a name="ln3044">  // Lookup the table and verify it exists.</a>
<a name="ln3045">  TRACE(&quot;Looking up table&quot;);</a>
<a name="ln3046">  RETURN_NOT_OK(FindTable(table_identifier, &amp;result.table_info));</a>
<a name="ln3047">  if (result.table_info == nullptr) {</a>
<a name="ln3048">    return STATUS(NotFound, &quot;Object does not exist&quot;, table_identifier.ShortDebugString(),</a>
<a name="ln3049">                  MasterError(MasterErrorPB::OBJECT_NOT_FOUND));</a>
<a name="ln3050">  }</a>
<a name="ln3051"> </a>
<a name="ln3052">  NamespaceId namespace_id;</a>
<a name="ln3053">  {</a>
<a name="ln3054">    TRACE(&quot;Locking table&quot;);</a>
<a name="ln3055">    auto l = result.table_info-&gt;LockForRead();</a>
<a name="ln3056"> </a>
<a name="ln3057">    if (result.table_info-&gt;IsCreateInProgress()) {</a>
<a name="ln3058">      return STATUS(IllegalState, &quot;Table creation is in progress&quot;, result.table_info-&gt;ToString(),</a>
<a name="ln3059">                    MasterError(MasterErrorPB::TABLE_CREATION_IS_IN_PROGRESS));</a>
<a name="ln3060">    }</a>
<a name="ln3061"> </a>
<a name="ln3062">    result.table_info-&gt;GetAllTablets(&amp;result.tablet_infos);</a>
<a name="ln3063"> </a>
<a name="ln3064">    namespace_id = result.table_info-&gt;namespace_id();</a>
<a name="ln3065">  }</a>
<a name="ln3066"> </a>
<a name="ln3067">  {</a>
<a name="ln3068">    TRACE(&quot;Looking up namespace&quot;);</a>
<a name="ln3069">    SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln3070"> </a>
<a name="ln3071">    result.namespace_info = FindPtrOrNull(namespace_ids_map_, namespace_id);</a>
<a name="ln3072">    if (result.namespace_info == nullptr) {</a>
<a name="ln3073">      return STATUS(</a>
<a name="ln3074">          InvalidArgument, &quot;Could not find namespace by namespace id&quot;, namespace_id,</a>
<a name="ln3075">          MasterError(MasterErrorPB::NAMESPACE_NOT_FOUND));</a>
<a name="ln3076">    }</a>
<a name="ln3077">  }</a>
<a name="ln3078"> </a>
<a name="ln3079">  return result;</a>
<a name="ln3080">}</a>
<a name="ln3081"> </a>
<a name="ln3082">// Truncate a Table.</a>
<a name="ln3083">Status CatalogManager::TruncateTable(const TruncateTableRequestPB* req,</a>
<a name="ln3084">                                     TruncateTableResponsePB* resp,</a>
<a name="ln3085">                                     rpc::RpcContext* rpc) {</a>
<a name="ln3086">  LOG(INFO) &lt;&lt; &quot;Servicing TruncateTable request from &quot; &lt;&lt; RequestorString(rpc)</a>
<a name="ln3087">            &lt;&lt; &quot;: &quot; &lt;&lt; req-&gt;ShortDebugString();</a>
<a name="ln3088"> </a>
<a name="ln3089">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln3090"> </a>
<a name="ln3091">  for (int i = 0; i &lt; req-&gt;table_ids_size(); i++) {</a>
<a name="ln3092">    RETURN_NOT_OK(TruncateTable(req-&gt;table_ids(i), resp, rpc));</a>
<a name="ln3093">  }</a>
<a name="ln3094"> </a>
<a name="ln3095">  return Status::OK();</a>
<a name="ln3096">}</a>
<a name="ln3097"> </a>
<a name="ln3098">Status CatalogManager::TruncateTable(const TableId&amp; table_id,</a>
<a name="ln3099">                                     TruncateTableResponsePB* resp,</a>
<a name="ln3100">                                     rpc::RpcContext* rpc) {</a>
<a name="ln3101">  // Lookup the table and verify if it exists.</a>
<a name="ln3102">  TRACE(Substitute(&quot;Looking up object by id $0&quot;, table_id));</a>
<a name="ln3103">  scoped_refptr&lt;TableInfo&gt; table;</a>
<a name="ln3104">  {</a>
<a name="ln3105">    SharedLock&lt;LockType&gt; cm_shared_lock(lock_);</a>
<a name="ln3106">    table = FindPtrOrNull(*table_ids_map_, table_id);</a>
<a name="ln3107">    if (table == nullptr) {</a>
<a name="ln3108">      Status s = STATUS_SUBSTITUTE(NotFound, &quot;The object with id $0 does not exist&quot;, table_id);</a>
<a name="ln3109">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln3110">    }</a>
<a name="ln3111">  }</a>
<a name="ln3112"> </a>
<a name="ln3113">  TRACE(Substitute(&quot;Locking object with id $0&quot;, table_id));</a>
<a name="ln3114">  auto l = table-&gt;LockForRead();</a>
<a name="ln3115">  RETURN_NOT_OK(CheckIfTableDeletedOrNotRunning(l.get(), resp));</a>
<a name="ln3116"> </a>
<a name="ln3117">  // Truncate on a colocated table should not hit master because it should be handled by a write</a>
<a name="ln3118">  // DML that creates a table-level tombstone.</a>
<a name="ln3119">  LOG_IF(WARNING, IsColocatedUserTable(*table)) &lt;&lt; &quot;cannot truncate a colocated table on master&quot;;</a>
<a name="ln3120"> </a>
<a name="ln3121">  // Send a Truncate() request to each tablet in the table.</a>
<a name="ln3122">  SendTruncateTableRequest(table);</a>
<a name="ln3123"> </a>
<a name="ln3124">  LOG(INFO) &lt;&lt; &quot;Successfully initiated TRUNCATE for &quot; &lt;&lt; table-&gt;ToString() &lt;&lt; &quot; per request from &quot;</a>
<a name="ln3125">            &lt;&lt; RequestorString(rpc);</a>
<a name="ln3126">  background_tasks_-&gt;Wake();</a>
<a name="ln3127"> </a>
<a name="ln3128">  // Truncate indexes also.</a>
<a name="ln3129">  // Note: PG table does not have references to indexes in the base table, so associated indexes</a>
<a name="ln3130">  //       must be truncated from the PG code separately.</a>
<a name="ln3131">  const bool is_index = PROTO_IS_INDEX(l-&gt;data().pb);</a>
<a name="ln3132">  DCHECK(!is_index || l-&gt;data().pb.indexes().empty()) &lt;&lt; &quot;indexes should be empty for index table&quot;;</a>
<a name="ln3133">  for (const auto&amp; index_info : l-&gt;data().pb.indexes()) {</a>
<a name="ln3134">    RETURN_NOT_OK(TruncateTable(index_info.table_id(), resp, rpc));</a>
<a name="ln3135">  }</a>
<a name="ln3136"> </a>
<a name="ln3137">  return Status::OK();</a>
<a name="ln3138">}</a>
<a name="ln3139"> </a>
<a name="ln3140">void CatalogManager::SendTruncateTableRequest(const scoped_refptr&lt;TableInfo&gt;&amp; table) {</a>
<a name="ln3141">  vector&lt;scoped_refptr&lt;TabletInfo&gt;&gt; tablets;</a>
<a name="ln3142">  table-&gt;GetAllTablets(&amp;tablets);</a>
<a name="ln3143">  for (const scoped_refptr&lt;TabletInfo&gt;&amp; tablet : tablets) {</a>
<a name="ln3144">    SendTruncateTabletRequest(tablet);</a>
<a name="ln3145">  }</a>
<a name="ln3146">}</a>
<a name="ln3147"> </a>
<a name="ln3148">void CatalogManager::SendTruncateTabletRequest(const scoped_refptr&lt;TabletInfo&gt;&amp; tablet) {</a>
<a name="ln3149">  LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Truncating tablet &quot; &lt;&lt; tablet-&gt;id();</a>
<a name="ln3150">  auto call = std::make_shared&lt;AsyncTruncate&gt;(master_, AsyncTaskPool(), tablet);</a>
<a name="ln3151">  tablet-&gt;table()-&gt;AddTask(call);</a>
<a name="ln3152">  auto status = ScheduleTask(call);</a>
<a name="ln3153">  WARN_NOT_OK(status, Substitute(&quot;Failed to send truncate request for tablet $0&quot;, tablet-&gt;id()));</a>
<a name="ln3154">}</a>
<a name="ln3155"> </a>
<a name="ln3156">Status CatalogManager::IsTruncateTableDone(const IsTruncateTableDoneRequestPB* req,</a>
<a name="ln3157">                                           IsTruncateTableDoneResponsePB* resp) {</a>
<a name="ln3158">  LOG(INFO) &lt;&lt; &quot;Servicing IsTruncateTableDone request for table id &quot; &lt;&lt; req-&gt;table_id();</a>
<a name="ln3159">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln3160"> </a>
<a name="ln3161">  // Lookup the truncated table.</a>
<a name="ln3162">  TRACE(&quot;Looking up table $0&quot;, req-&gt;table_id());</a>
<a name="ln3163">  std::lock_guard&lt;LockType&gt; l_map(lock_);</a>
<a name="ln3164">  scoped_refptr&lt;TableInfo&gt; table = FindPtrOrNull(*table_ids_map_, req-&gt;table_id());</a>
<a name="ln3165"> </a>
<a name="ln3166">  if (table == nullptr) {</a>
<a name="ln3167">    Status s = STATUS(NotFound, &quot;The object does not exist: table with id&quot;, req-&gt;table_id());</a>
<a name="ln3168">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln3169">  }</a>
<a name="ln3170"> </a>
<a name="ln3171">  TRACE(&quot;Locking table&quot;);</a>
<a name="ln3172">  auto l = table-&gt;LockForRead();</a>
<a name="ln3173">  RETURN_NOT_OK(CheckIfTableDeletedOrNotRunning(l.get(), resp));</a>
<a name="ln3174"> </a>
<a name="ln3175">  resp-&gt;set_done(!table-&gt;HasTasks(MonitoredTask::Type::ASYNC_TRUNCATE_TABLET));</a>
<a name="ln3176">  return Status::OK();</a>
<a name="ln3177">}</a>
<a name="ln3178"> </a>
<a name="ln3179">Status CatalogManager::MarkIndexInfoFromTableForDeletion(</a>
<a name="ln3180">    const TableId&amp; indexed_table_id, const TableId&amp; index_table_id, bool multi_stage,</a>
<a name="ln3181">    DeleteTableResponsePB* resp) {</a>
<a name="ln3182">  // Lookup the indexed table and verify if it exists.</a>
<a name="ln3183">  scoped_refptr&lt;TableInfo&gt; indexed_table = GetTableInfo(indexed_table_id);</a>
<a name="ln3184">  if (indexed_table == nullptr) {</a>
<a name="ln3185">    LOG(WARNING) &lt;&lt; &quot;Indexed table &quot; &lt;&lt; indexed_table_id &lt;&lt; &quot; for index &quot;</a>
<a name="ln3186">                 &lt;&lt; index_table_id &lt;&lt; &quot; not found&quot;;</a>
<a name="ln3187">    return Status::OK();</a>
<a name="ln3188">  }</a>
<a name="ln3189"> </a>
<a name="ln3190">  if (resp) {</a>
<a name="ln3191">    NamespaceIdentifierPB nsId;</a>
<a name="ln3192">    nsId.set_id(indexed_table-&gt;namespace_id());</a>
<a name="ln3193">    scoped_refptr&lt;NamespaceInfo&gt; nsInfo;</a>
<a name="ln3194">    RETURN_NOT_OK(FindNamespace(nsId, &amp;nsInfo));</a>
<a name="ln3195">    auto* resp_indexed_table = resp-&gt;mutable_indexed_table();</a>
<a name="ln3196">    resp_indexed_table-&gt;mutable_namespace_()-&gt;set_name(nsInfo-&gt;name());</a>
<a name="ln3197">    resp_indexed_table-&gt;set_table_name(indexed_table-&gt;name());</a>
<a name="ln3198">    resp_indexed_table-&gt;set_table_id(indexed_table_id);</a>
<a name="ln3199">  }</a>
<a name="ln3200">  if (multi_stage) {</a>
<a name="ln3201">    RETURN_NOT_OK(MultiStageAlterTable::UpdateIndexPermission(</a>
<a name="ln3202">        this, indexed_table,</a>
<a name="ln3203">        {{index_table_id, IndexPermissions::INDEX_PERM_WRITE_AND_DELETE_WHILE_REMOVING}}));</a>
<a name="ln3204">  } else {</a>
<a name="ln3205">    RETURN_NOT_OK(DeleteIndexInfoFromTable(indexed_table_id, index_table_id));</a>
<a name="ln3206">  }</a>
<a name="ln3207"> </a>
<a name="ln3208">  // Actual Deletion of the index info will happen asynchronously after all the</a>
<a name="ln3209">  // tablets move to the new IndexPermission of DELETE_ONLY_WHILE_REMOVING.</a>
<a name="ln3210">  SendAlterTableRequest(indexed_table);</a>
<a name="ln3211">  return Status::OK();</a>
<a name="ln3212">}</a>
<a name="ln3213"> </a>
<a name="ln3214">Status CatalogManager::DeleteIndexInfoFromTable(</a>
<a name="ln3215">    const TableId&amp; indexed_table_id, const TableId&amp; index_table_id) {</a>
<a name="ln3216">  scoped_refptr&lt;TableInfo&gt; indexed_table = GetTableInfo(indexed_table_id);</a>
<a name="ln3217">  if (indexed_table == nullptr) {</a>
<a name="ln3218">    LOG(WARNING) &lt;&lt; &quot;Indexed table &quot; &lt;&lt; indexed_table_id &lt;&lt; &quot; for index &quot; &lt;&lt; index_table_id</a>
<a name="ln3219">                 &lt;&lt; &quot; not found&quot;;</a>
<a name="ln3220">    return Status::OK();</a>
<a name="ln3221">  }</a>
<a name="ln3222">  TRACE(&quot;Locking indexed table&quot;);</a>
<a name="ln3223">  auto l = indexed_table-&gt;LockForWrite();</a>
<a name="ln3224">  auto &amp;indexed_table_data = *l-&gt;mutable_data();</a>
<a name="ln3225"> </a>
<a name="ln3226">  MultiStageAlterTable::CopySchemaDetailsToFullyApplied(&amp;indexed_table_data.pb);</a>
<a name="ln3227">  auto *indexes = indexed_table_data.pb.mutable_indexes();</a>
<a name="ln3228">  for (int i = 0; i &lt; indexes-&gt;size(); i++) {</a>
<a name="ln3229">    if (indexes-&gt;Get(i).table_id() == index_table_id) {</a>
<a name="ln3230"> </a>
<a name="ln3231">      indexes-&gt;DeleteSubrange(i, 1);</a>
<a name="ln3232"> </a>
<a name="ln3233">      indexed_table_data.pb.set_version(indexed_table_data.pb.version() + 1);</a>
<a name="ln3234">      indexed_table_data.set_state(SysTablesEntryPB::ALTERING,</a>
<a name="ln3235">                                   Substitute(&quot;Alter table version=$0 ts=$1&quot;,</a>
<a name="ln3236">                                              indexed_table_data.pb.version(),</a>
<a name="ln3237">                                              LocalTimeAsString()));</a>
<a name="ln3238"> </a>
<a name="ln3239">      // Update sys-catalog with the deleted indexed table info.</a>
<a name="ln3240">      TRACE(&quot;Updating indexed table metadata on disk&quot;);</a>
<a name="ln3241">      RETURN_NOT_OK(sys_catalog_-&gt;UpdateItem(indexed_table.get(), leader_ready_term()));</a>
<a name="ln3242"> </a>
<a name="ln3243">      // Update the in-memory state.</a>
<a name="ln3244">      TRACE(&quot;Committing in-memory state&quot;);</a>
<a name="ln3245">      l-&gt;Commit();</a>
<a name="ln3246">      return Status::OK();</a>
<a name="ln3247">    }</a>
<a name="ln3248">  }</a>
<a name="ln3249"> </a>
<a name="ln3250">  LOG(WARNING) &lt;&lt; &quot;Index &quot; &lt;&lt; index_table_id &lt;&lt; &quot; not found in indexed table &quot; &lt;&lt; indexed_table_id;</a>
<a name="ln3251">  return Status::OK();</a>
<a name="ln3252">}</a>
<a name="ln3253"> </a>
<a name="ln3254">Status CatalogManager::DeleteTable(</a>
<a name="ln3255">    const DeleteTableRequestPB* req, DeleteTableResponsePB* resp, rpc::RpcContext* rpc) {</a>
<a name="ln3256">  LOG(INFO) &lt;&lt; &quot;Servicing DeleteTable request from &quot; &lt;&lt; RequestorString(rpc) &lt;&lt; &quot;: &quot;</a>
<a name="ln3257">            &lt;&lt; req-&gt;ShortDebugString();</a>
<a name="ln3258"> </a>
<a name="ln3259">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln3260"> </a>
<a name="ln3261">  if (req-&gt;is_index_table()) {</a>
<a name="ln3262">    TRACE(&quot;Looking up index&quot;);</a>
<a name="ln3263">    TableIdentifierPB table_identifier = req-&gt;table();</a>
<a name="ln3264">    scoped_refptr&lt;TableInfo&gt; table;</a>
<a name="ln3265">    RETURN_NOT_OK(FindTable(table_identifier, &amp;table));</a>
<a name="ln3266">    if (table == nullptr) {</a>
<a name="ln3267">      Status s = STATUS(NotFound, &quot;The object does not exist&quot;, table_identifier.ShortDebugString());</a>
<a name="ln3268">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln3269">    }</a>
<a name="ln3270">    TableId table_id = table-&gt;id();</a>
<a name="ln3271">    resp-&gt;set_table_id(table_id);</a>
<a name="ln3272">    TableId indexed_table_id;</a>
<a name="ln3273">    {</a>
<a name="ln3274">      auto l = table-&gt;LockForRead();</a>
<a name="ln3275">      indexed_table_id = PROTO_GET_INDEXED_TABLE_ID(l-&gt;data().pb);</a>
<a name="ln3276">    }</a>
<a name="ln3277">    scoped_refptr&lt;TableInfo&gt; indexed_table = GetTableInfo(indexed_table_id);</a>
<a name="ln3278">    // We don't need to handle user enforced txns separately here because there</a>
<a name="ln3279">    // is no additional wait.</a>
<a name="ln3280">    // TODO(jason): use FLAGS_ysql_disable_index_backfill when closing issue #4936.</a>
<a name="ln3281">    const bool is_pg_table = indexed_table-&gt;GetTableType() == PGSQL_TABLE_TYPE;</a>
<a name="ln3282">    const bool disable_index_backfill =</a>
<a name="ln3283">        (is_pg_table ? true : GetAtomicFlag(&amp;FLAGS_disable_index_backfill));</a>
<a name="ln3284">    if (!disable_index_backfill) {</a>
<a name="ln3285">      return MarkIndexInfoFromTableForDeletion(</a>
<a name="ln3286">          indexed_table_id, table_id, /* multi_stage */ true, resp);</a>
<a name="ln3287">    }</a>
<a name="ln3288">  }</a>
<a name="ln3289"> </a>
<a name="ln3290">  return DeleteTableInternal(req, resp, rpc);</a>
<a name="ln3291">}</a>
<a name="ln3292"> </a>
<a name="ln3293">// Delete a Table</a>
<a name="ln3294">//  - Update the table state to &quot;DELETING&quot;.</a>
<a name="ln3295">//  - Issue DeleteTablet tasks to all said tablets.</a>
<a name="ln3296">//  - Update all the underlying tablet states as &quot;DELETED&quot;.</a>
<a name="ln3297">//</a>
<a name="ln3298">// This order of events can help us guarantee that:</a>
<a name="ln3299">//  - If a table is DELETING/DELETED, we do not add further tasks to it.</a>
<a name="ln3300">//  - A DeleteTable is done when a table is either DELETING or DELETED and has no running tasks.</a>
<a name="ln3301">//  - If a table is DELETING and it has no tasks on it, then it is safe to mark DELETED.</a>
<a name="ln3302">//</a>
<a name="ln3303">// We are lazy about deletions.</a>
<a name="ln3304">//</a>
<a name="ln3305">// IMPORTANT: If modifying, consider updating DeleteYsqlDBTables(), the bulk deletion API.</a>
<a name="ln3306">Status CatalogManager::DeleteTableInternal(</a>
<a name="ln3307">    const DeleteTableRequestPB* req, DeleteTableResponsePB* resp, rpc::RpcContext* rpc) {</a>
<a name="ln3308">  vector&lt;scoped_refptr&lt;TableInfo&gt;&gt; tables;</a>
<a name="ln3309">  vector&lt;unique_ptr&lt;TableInfo::lock_type&gt;&gt; table_locks;</a>
<a name="ln3310"> </a>
<a name="ln3311">  RETURN_NOT_OK(DeleteTableInMemory(req-&gt;table(), req-&gt;is_index_table(),</a>
<a name="ln3312">                                    true /* update_indexed_table */,</a>
<a name="ln3313">                                    &amp;tables, &amp;table_locks, resp, rpc));</a>
<a name="ln3314"> </a>
<a name="ln3315">  // Delete any CDC streams that are set up on this table.</a>
<a name="ln3316">  TRACE(&quot;Deleting CDC streams on table&quot;);</a>
<a name="ln3317">  RETURN_NOT_OK(DeleteCDCStreamsForTable(resp-&gt;table_id()));</a>
<a name="ln3318"> </a>
<a name="ln3319">  // Update the in-memory state.</a>
<a name="ln3320">  TRACE(&quot;Committing in-memory state&quot;);</a>
<a name="ln3321">  for (int i = 0; i &lt; table_locks.size(); i++) {</a>
<a name="ln3322">    table_locks[i]-&gt;Commit();</a>
<a name="ln3323">  }</a>
<a name="ln3324"> </a>
<a name="ln3325">  if (PREDICT_FALSE(FLAGS_catalog_manager_inject_latency_in_delete_table_ms &gt; 0)) {</a>
<a name="ln3326">    LOG(INFO) &lt;&lt; &quot;Sleeping in CatalogManager::DeleteTable for &quot; &lt;&lt;</a>
<a name="ln3327">        FLAGS_catalog_manager_inject_latency_in_delete_table_ms &lt;&lt; &quot; ms&quot;;</a>
<a name="ln3328">    SleepFor(MonoDelta::FromMilliseconds(FLAGS_catalog_manager_inject_latency_in_delete_table_ms));</a>
<a name="ln3329">  }</a>
<a name="ln3330"> </a>
<a name="ln3331">  for (const scoped_refptr&lt;TableInfo&gt; &amp;table : tables) {</a>
<a name="ln3332">    // Send a DeleteTablet() request to each tablet replica in the table.</a>
<a name="ln3333">    DeleteTabletsAndSendRequests(table);</a>
<a name="ln3334">    // Send a RemoveTableFromTablet() request to each colocated parent tablet replica in the table.</a>
<a name="ln3335">    if (IsColocatedUserTable(*table)) {</a>
<a name="ln3336">      auto call = std::make_shared&lt;AsyncRemoveTableFromTablet&gt;(</a>
<a name="ln3337">          master_, AsyncTaskPool(), table-&gt;GetColocatedTablet(), table);</a>
<a name="ln3338">      table-&gt;AddTask(call);</a>
<a name="ln3339">      WARN_NOT_OK(ScheduleTask(call), &quot;Failed to send RemoveTableFromTablet request&quot;);</a>
<a name="ln3340">    }</a>
<a name="ln3341">  }</a>
<a name="ln3342"> </a>
<a name="ln3343">  // If there are any permissions granted on this table find them and delete them. This is necessary</a>
<a name="ln3344">  // because we keep track of the permissions based on the canonical resource name which is a</a>
<a name="ln3345">  // combination of the keyspace and table names, so if another table with the same name is created</a>
<a name="ln3346">  // (in the same keyspace where the previous one existed), and the permissions were not deleted at</a>
<a name="ln3347">  // the time of the previous table deletion, then the permissions that existed for the previous</a>
<a name="ln3348">  // table will automatically be granted to the new table even though this wasn't the intention.</a>
<a name="ln3349">  string canonical_resource = get_canonical_table(req-&gt;table().namespace_().name(),</a>
<a name="ln3350">                                                  req-&gt;table().table_name());</a>
<a name="ln3351">  RETURN_NOT_OK(permissions_manager_-&gt;RemoveAllPermissionsForResource(canonical_resource, resp));</a>
<a name="ln3352"> </a>
<a name="ln3353">  LOG(INFO) &lt;&lt; &quot;Successfully initiated deletion of &quot;</a>
<a name="ln3354">            &lt;&lt; (req-&gt;is_index_table() ? &quot;index&quot; : &quot;table&quot;) &lt;&lt; &quot; with &quot;</a>
<a name="ln3355">            &lt;&lt; req-&gt;table().DebugString() &lt;&lt; &quot; per request from &quot; &lt;&lt; RequestorString(rpc);</a>
<a name="ln3356">  // Asynchronously cleans up the final memory traces of the deleted database.</a>
<a name="ln3357">  background_tasks_-&gt;Wake();</a>
<a name="ln3358">  return Status::OK();</a>
<a name="ln3359">}</a>
<a name="ln3360"> </a>
<a name="ln3361">Status CatalogManager::DeleteTableInMemory(const TableIdentifierPB&amp; table_identifier,</a>
<a name="ln3362">                                           const bool is_index_table,</a>
<a name="ln3363">                                           const bool update_indexed_table,</a>
<a name="ln3364">                                           vector&lt;scoped_refptr&lt;TableInfo&gt;&gt;* tables,</a>
<a name="ln3365">                                           vector&lt;unique_ptr&lt;TableInfo::lock_type&gt;&gt;* table_lcks,</a>
<a name="ln3366">                                           DeleteTableResponsePB* resp,</a>
<a name="ln3367">                                           rpc::RpcContext* rpc) {</a>
<a name="ln3368">  // TODO(NIC): How to handle a DeleteTable request when the namespace is being deleted?</a>
<a name="ln3369">  const char* const object_type = is_index_table ? &quot;index&quot; : &quot;table&quot;;</a>
<a name="ln3370">  const bool cascade_delete_index = is_index_table &amp;&amp; !update_indexed_table;</a>
<a name="ln3371"> </a>
<a name="ln3372">  scoped_refptr&lt;TableInfo&gt; table;</a>
<a name="ln3373"> </a>
<a name="ln3374">  // Lookup the table and verify if it exists.</a>
<a name="ln3375">  TRACE(Substitute(&quot;Looking up $0&quot;, object_type));</a>
<a name="ln3376">  RETURN_NOT_OK(FindTable(table_identifier, &amp;table));</a>
<a name="ln3377">  if (table == nullptr) {</a>
<a name="ln3378">    if (cascade_delete_index) {</a>
<a name="ln3379">      LOG(WARNING) &lt;&lt; &quot;Index &quot; &lt;&lt; table_identifier.DebugString() &lt;&lt; &quot; not found&quot;;</a>
<a name="ln3380">      return Status::OK();</a>
<a name="ln3381">    } else {</a>
<a name="ln3382">      Status s = STATUS(NotFound, &quot;The object does not exist&quot;, table_identifier.ShortDebugString());</a>
<a name="ln3383">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln3384">    }</a>
<a name="ln3385">  }</a>
<a name="ln3386"> </a>
<a name="ln3387">  TRACE(Substitute(&quot;Locking $0&quot;, object_type));</a>
<a name="ln3388">  auto l = table-&gt;LockForWrite();</a>
<a name="ln3389">  resp-&gt;set_table_id(table-&gt;id());</a>
<a name="ln3390"> </a>
<a name="ln3391">  if (is_index_table == PROTO_IS_TABLE(l-&gt;data().pb)) {</a>
<a name="ln3392">    Status s = STATUS(NotFound, &quot;The object does not exist&quot;);</a>
<a name="ln3393">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln3394">  }</a>
<a name="ln3395"> </a>
<a name="ln3396">  if (l-&gt;data().started_deleting()) {</a>
<a name="ln3397">    if (cascade_delete_index) {</a>
<a name="ln3398">      LOG(WARNING) &lt;&lt; &quot;Index &quot; &lt;&lt; table_identifier.DebugString() &lt;&lt; &quot; was deleted&quot;;</a>
<a name="ln3399">      return Status::OK();</a>
<a name="ln3400">    } else {</a>
<a name="ln3401">      Status s = STATUS(NotFound, &quot;The object was deleted&quot;, l-&gt;data().pb.state_msg());</a>
<a name="ln3402">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln3403">    }</a>
<a name="ln3404">  }</a>
<a name="ln3405"> </a>
<a name="ln3406">  TRACE(&quot;Updating metadata on disk&quot;);</a>
<a name="ln3407">  // Update the metadata for the on-disk state.</a>
<a name="ln3408">  l-&gt;mutable_data()-&gt;set_state(SysTablesEntryPB::DELETING,</a>
<a name="ln3409">                               Substitute(&quot;Started deleting at $0&quot;, LocalTimeAsString()));</a>
<a name="ln3410"> </a>
<a name="ln3411">  // Update sys-catalog with the removed table state.</a>
<a name="ln3412">  Status s = sys_catalog_-&gt;UpdateItem(table.get(), leader_ready_term());</a>
<a name="ln3413"> </a>
<a name="ln3414">  if (PREDICT_FALSE(FLAGS_TEST_simulate_crash_after_table_marked_deleting)) {</a>
<a name="ln3415">    return Status::OK();</a>
<a name="ln3416">  }</a>
<a name="ln3417"> </a>
<a name="ln3418">  if (!s.ok()) {</a>
<a name="ln3419">    // The mutation will be aborted when 'l' exits the scope on early return.</a>
<a name="ln3420">    s = s.CloneAndPrepend(Substitute(&quot;An error occurred while updating sys tables: $0&quot;,</a>
<a name="ln3421">                                     s.ToString()));</a>
<a name="ln3422">    LOG(WARNING) &lt;&lt; s.ToString();</a>
<a name="ln3423">    return CheckIfNoLongerLeaderAndSetupError(s, resp);</a>
<a name="ln3424">  }</a>
<a name="ln3425"> </a>
<a name="ln3426">  // Update the internal table maps.</a>
<a name="ln3427">  // Exclude Postgres tables which are not in the name map.</a>
<a name="ln3428">  if (l-&gt;data().table_type() != PGSQL_TABLE_TYPE) {</a>
<a name="ln3429">    TRACE(&quot;Removing from by-name map&quot;);</a>
<a name="ln3430">    std::lock_guard&lt;LockType&gt; l_map(lock_);</a>
<a name="ln3431">    if (table_names_map_.erase({l-&gt;data().namespace_id(), l-&gt;data().name()}) != 1) {</a>
<a name="ln3432">      PANIC_RPC(rpc, &quot;Could not remove table from map, name=&quot; + table-&gt;ToString());</a>
<a name="ln3433">    }</a>
<a name="ln3434">    table_ids_map_.Commit();</a>
<a name="ln3435">  }</a>
<a name="ln3436"> </a>
<a name="ln3437">  // For regular (indexed) table, delete all its index tables if any. Else for index table, delete</a>
<a name="ln3438">  // index info from the indexed table.</a>
<a name="ln3439">  if (!is_index_table) {</a>
<a name="ln3440">    TableIdentifierPB index_identifier;</a>
<a name="ln3441">    for (auto index : l-&gt;data().pb.indexes()) {</a>
<a name="ln3442">      index_identifier.set_table_id(index.table_id());</a>
<a name="ln3443">      RETURN_NOT_OK(DeleteTableInMemory(index_identifier, true /* is_index_table */,</a>
<a name="ln3444">                                        false /* update_index_table */, tables,</a>
<a name="ln3445">                                        table_lcks, resp, rpc));</a>
<a name="ln3446">    }</a>
<a name="ln3447">  } else if (update_indexed_table) {</a>
<a name="ln3448">    s = MarkIndexInfoFromTableForDeletion(</a>
<a name="ln3449">        PROTO_GET_INDEXED_TABLE_ID(l-&gt;data().pb), table-&gt;id(), /* multi_stage */ false, resp);</a>
<a name="ln3450">    if (!s.ok()) {</a>
<a name="ln3451">      s = s.CloneAndPrepend(Substitute(&quot;An error occurred while deleting index info: $0&quot;,</a>
<a name="ln3452">                                       s.ToString()));</a>
<a name="ln3453">      LOG(WARNING) &lt;&lt; s.ToString();</a>
<a name="ln3454">      return CheckIfNoLongerLeaderAndSetupError(s, resp);</a>
<a name="ln3455">    }</a>
<a name="ln3456">  }</a>
<a name="ln3457"> </a>
<a name="ln3458">  table-&gt;AbortTasks();</a>
<a name="ln3459"> </a>
<a name="ln3460">  // For regular (indexed) table, insert table info and lock in the front of the list. Else for</a>
<a name="ln3461">  // index table, append them to the end. We do so so that we will commit and delete the indexed</a>
<a name="ln3462">  // table first before its indexes.</a>
<a name="ln3463">  if (!is_index_table) {</a>
<a name="ln3464">    tables-&gt;insert(tables-&gt;begin(), table);</a>
<a name="ln3465">    table_lcks-&gt;insert(table_lcks-&gt;begin(), std::move(l));</a>
<a name="ln3466">  } else {</a>
<a name="ln3467">    tables-&gt;push_back(table);</a>
<a name="ln3468">    table_lcks-&gt;push_back(std::move(l));</a>
<a name="ln3469">  }</a>
<a name="ln3470"> </a>
<a name="ln3471">  return Status::OK();</a>
<a name="ln3472">}</a>
<a name="ln3473"> </a>
<a name="ln3474">void CatalogManager::CleanUpDeletedTables() {</a>
<a name="ln3475">  // TODO(bogdan): Cache tables being deleted to make this iterate only over those?</a>
<a name="ln3476">  vector&lt;scoped_refptr&lt;TableInfo&gt;&gt; tables_to_delete;</a>
<a name="ln3477">  {</a>
<a name="ln3478">    std::lock_guard&lt;LockType&gt; l_map(lock_);</a>
<a name="ln3479">    // Garbage collecting.</a>
<a name="ln3480">    // Going through all tables under the global lock.</a>
<a name="ln3481">    for (const auto&amp; it : *table_ids_map_) {</a>
<a name="ln3482">      scoped_refptr&lt;TableInfo&gt; table(it.second);</a>
<a name="ln3483"> </a>
<a name="ln3484">      if (!table-&gt;HasTasks()) {</a>
<a name="ln3485">        // Lock the candidate table and check the tablets under the lock.</a>
<a name="ln3486">        auto l = table-&gt;LockForRead();</a>
<a name="ln3487"> </a>
<a name="ln3488">        // For normal runtime operations, this should only contain tables in DELETING state.</a>
<a name="ln3489">        // However, for master failover, the catalog loaders currently have to bring in tables in</a>
<a name="ln3490">        // memory even in DELETED state, for safely loading the respective tablets for them</a>
<a name="ln3491">        //</a>
<a name="ln3492">        // Eventually, for these DELETED tables, we'll want to also remove them from memory.</a>
<a name="ln3493">        if (l-&gt;data().is_deleting()) {</a>
<a name="ln3494">          // The current relevant order of operations during a DeleteTable is:</a>
<a name="ln3495">          // 1) Mark the table as DELETING</a>
<a name="ln3496">          // 2) Abort the current table tasks</a>
<a name="ln3497">          // 3) Per tablet, send DeleteTable requests to all TS, then mark that tablet as DELETED</a>
<a name="ln3498">          //</a>
<a name="ln3499">          // This creates a race, wherein, after 2, HasTasks can be false, but we still have not</a>
<a name="ln3500">          // gotten to point 3, which would add further tasks for the deletes.</a>
<a name="ln3501">          //</a>
<a name="ln3502">          // However, HasTasks is cheaper than AreAllTabletsDeleted...</a>
<a name="ln3503">          if (table-&gt;AreAllTabletsDeleted() ||</a>
<a name="ln3504">              IsSystemTableUnlocked(*table) ||</a>
<a name="ln3505">              IsColocatedUserTable(*table)) {</a>
<a name="ln3506">            tables_to_delete.push_back(table);</a>
<a name="ln3507">            // TODO(bogdan): uncomment this once we also untangle catalog loader logic.</a>
<a name="ln3508">            // Since we have lock_, this table cannot be in the map AND be DELETED.</a>
<a name="ln3509">            // DCHECK(!l-&gt;data().is_deleted());</a>
<a name="ln3510">          }</a>
<a name="ln3511">        }</a>
<a name="ln3512">      }</a>
<a name="ln3513">    }</a>
<a name="ln3514">  }</a>
<a name="ln3515">  // Mark the tables as DELETED and remove them from the in-memory maps.</a>
<a name="ln3516">  vector&lt;TableInfo*&gt; tables_to_update_on_disk;</a>
<a name="ln3517">  for (auto table : tables_to_delete) {</a>
<a name="ln3518">    table-&gt;mutable_metadata()-&gt;StartMutation();</a>
<a name="ln3519">    // TODO: Turn this into a DCHECK again once we fix the catalog loaders to not need to load</a>
<a name="ln3520">    // DELETED tables as well.</a>
<a name="ln3521">    if (table-&gt;metadata().state().pb.state() == SysTablesEntryPB::DELETING) {</a>
<a name="ln3522">      // Update the metadata for the on-disk state.</a>
<a name="ln3523">      LOG(INFO) &lt;&lt; &quot;Marking table as DELETED: &quot; &lt;&lt; table-&gt;ToString();</a>
<a name="ln3524">      table-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;set_state(SysTablesEntryPB::DELETED,</a>
<a name="ln3525">          Substitute(&quot;Deleted with tablets at $0&quot;, LocalTimeAsString()));</a>
<a name="ln3526">      tables_to_update_on_disk.push_back(table.get());</a>
<a name="ln3527">    } else {</a>
<a name="ln3528">      // TODO(bogdan): We need to abort here, until we remove it from the map, otherwise we'd leave</a>
<a name="ln3529">      // this lock locked...</a>
<a name="ln3530">      table-&gt;mutable_metadata()-&gt;AbortMutation();</a>
<a name="ln3531">    }</a>
<a name="ln3532">  }</a>
<a name="ln3533">  if (tables_to_update_on_disk.size() &gt; 0) {</a>
<a name="ln3534">    Status s = sys_catalog_-&gt;UpdateItems(tables_to_update_on_disk, leader_ready_term());</a>
<a name="ln3535">    if (!s.ok()) {</a>
<a name="ln3536">      LOG(WARNING) &lt;&lt; &quot;Error marking tables as DELETED: &quot; &lt;&lt; s.ToString();</a>
<a name="ln3537">      return;</a>
<a name="ln3538">    }</a>
<a name="ln3539">  }</a>
<a name="ln3540">  // Delete from in-memory maps.</a>
<a name="ln3541">  // TODO(bogdan):</a>
<a name="ln3542">  // - why do we not delete these from disk?</a>
<a name="ln3543">  // - do we even need to remove these? seems the loaders read them from disk into maps anyway...</a>
<a name="ln3544">  // - what about the tablets? is it ok to have TabletInfos with missing tables for them?</a>
<a name="ln3545">  // {</a>
<a name="ln3546">  //   std::lock_guard&lt;LockType&gt; l_map(lock_);</a>
<a name="ln3547">  //   for (auto table : tables_to_delete) {</a>
<a name="ln3548">  // TODO(bogdan): Come back to this once we figure out all concurrency issues.</a>
<a name="ln3549">  //     table_ids_map_.erase(table-&gt;id());</a>
<a name="ln3550">  //   }</a>
<a name="ln3551">  // }</a>
<a name="ln3552">  // Update the table in-memory info as DELETED after we've removed them from the maps.</a>
<a name="ln3553">  for (auto table : tables_to_update_on_disk) {</a>
<a name="ln3554">    table-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln3555">  }</a>
<a name="ln3556">  // TODO: Check if we want to delete the totally deleted table from the sys_catalog here.</a>
<a name="ln3557"> </a>
<a name="ln3558">  // TODO: SysCatalog::DeleteItem() if we've DELETED all user tables in a DELETING namespace.</a>
<a name="ln3559">  // TODO: Also properly handle namespace_ids_map_.erase(table-&gt;namespace_id())</a>
<a name="ln3560">}</a>
<a name="ln3561"> </a>
<a name="ln3562">Status CatalogManager::IsDeleteTableDone(const IsDeleteTableDoneRequestPB* req,</a>
<a name="ln3563">                                         IsDeleteTableDoneResponsePB* resp) {</a>
<a name="ln3564">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln3565"> </a>
<a name="ln3566">  // Lookup the deleted table.</a>
<a name="ln3567">  TRACE(&quot;Looking up table $0&quot;, req-&gt;table_id());</a>
<a name="ln3568">  std::lock_guard&lt;LockType&gt; l_map(lock_);</a>
<a name="ln3569">  scoped_refptr&lt;TableInfo&gt; table = FindPtrOrNull(*table_ids_map_, req-&gt;table_id());</a>
<a name="ln3570"> </a>
<a name="ln3571">  if (table == nullptr) {</a>
<a name="ln3572">    LOG(INFO) &lt;&lt; &quot;Servicing IsDeleteTableDone request for table id &quot;</a>
<a name="ln3573">              &lt;&lt; req-&gt;table_id() &lt;&lt; &quot;: deleted (not found)&quot;;</a>
<a name="ln3574">    resp-&gt;set_done(true);</a>
<a name="ln3575">    return Status::OK();</a>
<a name="ln3576">  }</a>
<a name="ln3577"> </a>
<a name="ln3578">  TRACE(&quot;Locking table&quot;);</a>
<a name="ln3579">  auto l = table-&gt;LockForRead();</a>
<a name="ln3580"> </a>
<a name="ln3581">  if (!l-&gt;data().started_deleting()) {</a>
<a name="ln3582">    LOG(WARNING) &lt;&lt; &quot;Servicing IsDeleteTableDone request for table id &quot;</a>
<a name="ln3583">                 &lt;&lt; req-&gt;table_id() &lt;&lt; &quot;: NOT deleted&quot;;</a>
<a name="ln3584">    Status s = STATUS(IllegalState, &quot;The object was NOT deleted&quot;, l-&gt;data().pb.state_msg());</a>
<a name="ln3585">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln3586">  }</a>
<a name="ln3587"> </a>
<a name="ln3588">  // Temporary fix for github issue #5290.</a>
<a name="ln3589">  // TODO: Wait till deletion completed for tablegroup parent table.</a>
<a name="ln3590">  if (IsTablegroupParentTable(*table)) {</a>
<a name="ln3591">    LOG(INFO) &lt;&lt; &quot;Servicing IsDeleteTableDone request for tablegroup parent table id &quot;</a>
<a name="ln3592">              &lt;&lt; req-&gt;table_id() &lt;&lt; &quot;: deleting. Skipping wait for DELETED state.&quot;;</a>
<a name="ln3593">    resp-&gt;set_done(true);</a>
<a name="ln3594">    return Status::OK();</a>
<a name="ln3595">  }</a>
<a name="ln3596"> </a>
<a name="ln3597">  if (l-&gt;data().is_deleted()) {</a>
<a name="ln3598">    LOG(INFO) &lt;&lt; &quot;Servicing IsDeleteTableDone request for table id &quot;</a>
<a name="ln3599">              &lt;&lt; req-&gt;table_id() &lt;&lt; &quot;: totally deleted&quot;;</a>
<a name="ln3600">      resp-&gt;set_done(true);</a>
<a name="ln3601">  } else {</a>
<a name="ln3602">    LOG(INFO) &lt;&lt; &quot;Servicing IsDeleteTableDone request for table id &quot; &lt;&lt; req-&gt;table_id()</a>
<a name="ln3603">              &lt;&lt; ((!IsColocatedUserTable(*table)) ? &quot;: deleting tablets&quot; : &quot;&quot;);</a>
<a name="ln3604"> </a>
<a name="ln3605">    std::vector&lt;std::shared_ptr&lt;TSDescriptor&gt;&gt; descs;</a>
<a name="ln3606">    master_-&gt;ts_manager()-&gt;GetAllDescriptors(&amp;descs);</a>
<a name="ln3607">    for (auto&amp; ts_desc : descs) {</a>
<a name="ln3608">      LOG(INFO) &lt;&lt; &quot;Deleting on &quot; &lt;&lt; ts_desc-&gt;permanent_uuid() &lt;&lt; &quot;: &quot;</a>
<a name="ln3609">                &lt;&lt; ts_desc-&gt;PendingTabletDeleteToString();</a>
<a name="ln3610">    }</a>
<a name="ln3611"> </a>
<a name="ln3612">    resp-&gt;set_done(false);</a>
<a name="ln3613">  }</a>
<a name="ln3614"> </a>
<a name="ln3615">  return Status::OK();</a>
<a name="ln3616">}</a>
<a name="ln3617"> </a>
<a name="ln3618">namespace {</a>
<a name="ln3619"> </a>
<a name="ln3620">CHECKED_STATUS ApplyAlterSteps(const SysTablesEntryPB&amp; current_pb,</a>
<a name="ln3621">                               const AlterTableRequestPB* req,</a>
<a name="ln3622">                               Schema* new_schema,</a>
<a name="ln3623">                               ColumnId* next_col_id) {</a>
<a name="ln3624">  const SchemaPB&amp; current_schema_pb = current_pb.schema();</a>
<a name="ln3625">  Schema cur_schema;</a>
<a name="ln3626">  RETURN_NOT_OK(SchemaFromPB(current_schema_pb, &amp;cur_schema));</a>
<a name="ln3627"> </a>
<a name="ln3628">  SchemaBuilder builder(cur_schema);</a>
<a name="ln3629">  if (current_pb.has_next_column_id()) {</a>
<a name="ln3630">    builder.set_next_column_id(ColumnId(current_pb.next_column_id()));</a>
<a name="ln3631">  }</a>
<a name="ln3632">  if (current_pb.has_colocated() &amp;&amp; current_pb.colocated()) {</a>
<a name="ln3633">    if (current_schema_pb.table_properties().is_ysql_catalog_table()) {</a>
<a name="ln3634">      Uuid cotable_id;</a>
<a name="ln3635">      RETURN_NOT_OK(cotable_id.FromHexString(req-&gt;table().table_id()));</a>
<a name="ln3636">      builder.set_cotable_id(cotable_id);</a>
<a name="ln3637">    } else {</a>
<a name="ln3638">      uint32_t pgtable_id = VERIFY_RESULT(GetPgsqlTableOid(req-&gt;table().table_id()));</a>
<a name="ln3639">      builder.set_pgtable_id(pgtable_id);</a>
<a name="ln3640">    }</a>
<a name="ln3641">  }</a>
<a name="ln3642"> </a>
<a name="ln3643">  for (const AlterTableRequestPB::Step&amp; step : req-&gt;alter_schema_steps()) {</a>
<a name="ln3644">    switch (step.type()) {</a>
<a name="ln3645">      case AlterTableRequestPB::ADD_COLUMN: {</a>
<a name="ln3646">        if (!step.has_add_column()) {</a>
<a name="ln3647">          return STATUS(InvalidArgument, &quot;ADD_COLUMN missing column info&quot;);</a>
<a name="ln3648">        }</a>
<a name="ln3649"> </a>
<a name="ln3650">        // Verify that encoding is appropriate for the new column's type.</a>
<a name="ln3651">        ColumnSchemaPB new_col_pb = step.add_column().schema();</a>
<a name="ln3652">        if (new_col_pb.has_id()) {</a>
<a name="ln3653">          return STATUS_SUBSTITUTE(InvalidArgument,</a>
<a name="ln3654">              &quot;column $0: client should not specify column id&quot;, new_col_pb.ShortDebugString());</a>
<a name="ln3655">        }</a>
<a name="ln3656">        ColumnSchema new_col = ColumnSchemaFromPB(new_col_pb);</a>
<a name="ln3657"> </a>
<a name="ln3658">        RETURN_NOT_OK(builder.AddColumn(new_col, false));</a>
<a name="ln3659">        break;</a>
<a name="ln3660">      }</a>
<a name="ln3661"> </a>
<a name="ln3662">      case AlterTableRequestPB::DROP_COLUMN: {</a>
<a name="ln3663">        if (!step.has_drop_column()) {</a>
<a name="ln3664">          return STATUS(InvalidArgument, &quot;DROP_COLUMN missing column info&quot;);</a>
<a name="ln3665">        }</a>
<a name="ln3666"> </a>
<a name="ln3667">        if (cur_schema.is_key_column(step.drop_column().name())) {</a>
<a name="ln3668">          return STATUS(InvalidArgument, &quot;cannot remove a key column&quot;);</a>
<a name="ln3669">        }</a>
<a name="ln3670"> </a>
<a name="ln3671">        RETURN_NOT_OK(builder.RemoveColumn(step.drop_column().name()));</a>
<a name="ln3672">        break;</a>
<a name="ln3673">      }</a>
<a name="ln3674"> </a>
<a name="ln3675">      case AlterTableRequestPB::RENAME_COLUMN: {</a>
<a name="ln3676">        if (!step.has_rename_column()) {</a>
<a name="ln3677">          return STATUS(InvalidArgument, &quot;RENAME_COLUMN missing column info&quot;);</a>
<a name="ln3678">        }</a>
<a name="ln3679"> </a>
<a name="ln3680">        RETURN_NOT_OK(builder.RenameColumn(</a>
<a name="ln3681">        step.rename_column().old_name(),</a>
<a name="ln3682">        step.rename_column().new_name()));</a>
<a name="ln3683">        break;</a>
<a name="ln3684">      }</a>
<a name="ln3685"> </a>
<a name="ln3686">        // TODO: EDIT_COLUMN.</a>
<a name="ln3687"> </a>
<a name="ln3688">      default: {</a>
<a name="ln3689">        return STATUS_SUBSTITUTE(InvalidArgument, &quot;Invalid alter step type: $0&quot;, step.type());</a>
<a name="ln3690">      }</a>
<a name="ln3691">    }</a>
<a name="ln3692">  }</a>
<a name="ln3693"> </a>
<a name="ln3694">  if (req-&gt;has_alter_properties()) {</a>
<a name="ln3695">    RETURN_NOT_OK(builder.AlterProperties(req-&gt;alter_properties()));</a>
<a name="ln3696">  }</a>
<a name="ln3697"> </a>
<a name="ln3698">  *new_schema = builder.Build();</a>
<a name="ln3699">  *next_col_id = builder.next_column_id();</a>
<a name="ln3700">  return Status::OK();</a>
<a name="ln3701">}</a>
<a name="ln3702"> </a>
<a name="ln3703">} // namespace</a>
<a name="ln3704"> </a>
<a name="ln3705">Status CatalogManager::AlterTable(const AlterTableRequestPB* req,</a>
<a name="ln3706">                                  AlterTableResponsePB* resp,</a>
<a name="ln3707">                                  rpc::RpcContext* rpc) {</a>
<a name="ln3708">  LOG(INFO) &lt;&lt; &quot;Servicing AlterTable request from &quot; &lt;&lt; RequestorString(rpc)</a>
<a name="ln3709">            &lt;&lt; &quot;: &quot; &lt;&lt; req-&gt;ShortDebugString();</a>
<a name="ln3710"> </a>
<a name="ln3711">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln3712"> </a>
<a name="ln3713">  scoped_refptr&lt;TableInfo&gt; table;</a>
<a name="ln3714"> </a>
<a name="ln3715">  // Lookup the table and verify if it exists.</a>
<a name="ln3716">  TRACE(&quot;Looking up table&quot;);</a>
<a name="ln3717">  RETURN_NOT_OK(FindTable(req-&gt;table(), &amp;table));</a>
<a name="ln3718">  if (table == nullptr) {</a>
<a name="ln3719">    Status s = STATUS(NotFound, &quot;The object does not exist&quot;, req-&gt;table().ShortDebugString());</a>
<a name="ln3720">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln3721">  }</a>
<a name="ln3722"> </a>
<a name="ln3723">  NamespaceId new_namespace_id;</a>
<a name="ln3724"> </a>
<a name="ln3725">  if (req-&gt;has_new_namespace()) {</a>
<a name="ln3726">    // Lookup the new namespace and verify if it exists.</a>
<a name="ln3727">    TRACE(&quot;Looking up new namespace&quot;);</a>
<a name="ln3728">    scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln3729">    NamespaceIdentifierPB namespace_identifier = req-&gt;new_namespace();</a>
<a name="ln3730">    // Use original namespace_id as new_namespace_id for YSQL tables.</a>
<a name="ln3731">    if (table-&gt;GetTableType() == PGSQL_TABLE_TYPE &amp;&amp; !namespace_identifier.has_id()) {</a>
<a name="ln3732">      namespace_identifier.set_id(table-&gt;namespace_id());</a>
<a name="ln3733">    }</a>
<a name="ln3734">    RETURN_NAMESPACE_NOT_FOUND(FindNamespace(namespace_identifier, &amp;ns), resp);</a>
<a name="ln3735"> </a>
<a name="ln3736">    auto ns_lock = ns-&gt;LockForRead();</a>
<a name="ln3737">    new_namespace_id = ns-&gt;id();</a>
<a name="ln3738">    // Don't use Namespaces that aren't running.</a>
<a name="ln3739">    if (ns-&gt;state() != SysNamespaceEntryPB::RUNNING) {</a>
<a name="ln3740">      Status s = STATUS_SUBSTITUTE(TryAgain,</a>
<a name="ln3741">          &quot;Namespace not running (State=$0).  Cannot create $1.$2&quot;,</a>
<a name="ln3742">          SysNamespaceEntryPB::State_Name(ns-&gt;state()), ns-&gt;name(), table-&gt;name() );</a>
<a name="ln3743">      return SetupError(resp-&gt;mutable_error(), NamespaceMasterError(ns-&gt;state()), s);</a>
<a name="ln3744">    }</a>
<a name="ln3745">  }</a>
<a name="ln3746"> </a>
<a name="ln3747">  TRACE(&quot;Locking table&quot;);</a>
<a name="ln3748">  auto l = table-&gt;LockForWrite();</a>
<a name="ln3749">  RETURN_NOT_OK(CheckIfTableDeletedOrNotRunning(l.get(), resp));</a>
<a name="ln3750"> </a>
<a name="ln3751">  bool has_changes = false;</a>
<a name="ln3752">  auto&amp; table_pb = l-&gt;mutable_data()-&gt;pb;</a>
<a name="ln3753">  const TableName table_name = l-&gt;data().name();</a>
<a name="ln3754">  const NamespaceId namespace_id = l-&gt;data().namespace_id();</a>
<a name="ln3755">  const TableName new_table_name = req-&gt;has_new_table_name() ? req-&gt;new_table_name() : table_name;</a>
<a name="ln3756"> </a>
<a name="ln3757">  // Calculate new schema for the on-disk state, not persisted yet.</a>
<a name="ln3758">  Schema new_schema;</a>
<a name="ln3759">  ColumnId next_col_id = ColumnId(l-&gt;data().pb.next_column_id());</a>
<a name="ln3760">  if (req-&gt;alter_schema_steps_size() || req-&gt;has_alter_properties()) {</a>
<a name="ln3761">    TRACE(&quot;Apply alter schema&quot;);</a>
<a name="ln3762">    Status s = ApplyAlterSteps(l-&gt;data().pb, req, &amp;new_schema, &amp;next_col_id);</a>
<a name="ln3763">    if (!s.ok()) {</a>
<a name="ln3764">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA, s);</a>
<a name="ln3765">    }</a>
<a name="ln3766">    DCHECK_NE(next_col_id, 0);</a>
<a name="ln3767">    DCHECK_EQ(new_schema.find_column_by_id(next_col_id),</a>
<a name="ln3768">              static_cast&lt;int&gt;(Schema::kColumnNotFound));</a>
<a name="ln3769">    has_changes = true;</a>
<a name="ln3770">  }</a>
<a name="ln3771"> </a>
<a name="ln3772">  // Try to acquire the new table name.</a>
<a name="ln3773">  if (req-&gt;has_new_namespace() || req-&gt;has_new_table_name()) {</a>
<a name="ln3774"> </a>
<a name="ln3775">    if (new_namespace_id.empty()) {</a>
<a name="ln3776">      const Status s = STATUS(InvalidArgument, &quot;No namespace used&quot;);</a>
<a name="ln3777">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NO_NAMESPACE_USED, s);</a>
<a name="ln3778">    }</a>
<a name="ln3779"> </a>
<a name="ln3780">    std::lock_guard&lt;LockType&gt; catalog_lock(lock_);</a>
<a name="ln3781">    VLOG(3) &lt;&lt; __func__ &lt;&lt; &quot;: Acquired the catalog manager lock_&quot;;</a>
<a name="ln3782"> </a>
<a name="ln3783">    TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln3784"> </a>
<a name="ln3785">    // Verify that the table does not exist.</a>
<a name="ln3786">    scoped_refptr&lt;TableInfo&gt; other_table = FindPtrOrNull(</a>
<a name="ln3787">        table_names_map_, {new_namespace_id, new_table_name});</a>
<a name="ln3788">    if (other_table != nullptr) {</a>
<a name="ln3789">      Status s = STATUS_SUBSTITUTE(AlreadyPresent,</a>
<a name="ln3790">          &quot;Object '$0.$1' already exists&quot;,</a>
<a name="ln3791">          GetNamespaceNameUnlocked(new_namespace_id), other_table-&gt;name());</a>
<a name="ln3792">      LOG(WARNING) &lt;&lt; &quot;Found table: &quot; &lt;&lt; other_table-&gt;ToStringWithState()</a>
<a name="ln3793">                   &lt;&lt; &quot;. Failed alterring table with error: &quot;</a>
<a name="ln3794">                   &lt;&lt; s.ToString() &lt;&lt; &quot; Request:\n&quot; &lt;&lt; req-&gt;DebugString();</a>
<a name="ln3795">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_ALREADY_PRESENT, s);</a>
<a name="ln3796">    }</a>
<a name="ln3797"> </a>
<a name="ln3798">    // Acquire the new table name (now we have 2 name for the same table).</a>
<a name="ln3799">    table_names_map_[{new_namespace_id, new_table_name}] = table;</a>
<a name="ln3800">    table_pb.set_namespace_id(new_namespace_id);</a>
<a name="ln3801">    table_pb.set_name(new_table_name);</a>
<a name="ln3802"> </a>
<a name="ln3803">    has_changes = true;</a>
<a name="ln3804">  }</a>
<a name="ln3805"> </a>
<a name="ln3806">  // TODO(hector): Simplify the AlterSchema workflow to avoid doing the same checks on every layer</a>
<a name="ln3807">  // this request goes through: https://github.com/YugaByte/yugabyte-db/issues/1882.</a>
<a name="ln3808">  if (req-&gt;has_wal_retention_secs()) {</a>
<a name="ln3809">    if (has_changes) {</a>
<a name="ln3810">      const Status s = STATUS(InvalidArgument,</a>
<a name="ln3811">          &quot;wal_retention_secs cannot be altered concurrently with other properties&quot;);</a>
<a name="ln3812">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_REQUEST, s);</a>
<a name="ln3813">    }</a>
<a name="ln3814">    // TODO(hector): Handle co-partitioned tables:</a>
<a name="ln3815">    // https://github.com/YugaByte/yugabyte-db/issues/1905.</a>
<a name="ln3816">    table_pb.set_wal_retention_secs(req-&gt;wal_retention_secs());</a>
<a name="ln3817">    has_changes = true;</a>
<a name="ln3818">  }</a>
<a name="ln3819"> </a>
<a name="ln3820">  if (!has_changes) {</a>
<a name="ln3821">    if (req-&gt;has_force_send_alter_request() &amp;&amp; req-&gt;force_send_alter_request()) {</a>
<a name="ln3822">      SendAlterTableRequest(table, req);</a>
<a name="ln3823">    }</a>
<a name="ln3824">    // Skip empty requests...</a>
<a name="ln3825">    return Status::OK();</a>
<a name="ln3826">  }</a>
<a name="ln3827"> </a>
<a name="ln3828">  // Serialize the schema Increment the version number.</a>
<a name="ln3829">  if (new_schema.initialized()) {</a>
<a name="ln3830">    if (!l-&gt;data().pb.has_fully_applied_schema()) {</a>
<a name="ln3831">      // The idea here is that if we are in the middle of updating the schema</a>
<a name="ln3832">      // from one state to another, then YBClients will be given the older</a>
<a name="ln3833">      // version until the schema is updated on all the tablets.</a>
<a name="ln3834">      // As of Dec 2019, this may lead to some rejected operations/retries during</a>
<a name="ln3835">      // the index backfill. See #3284 for possible optimizations.</a>
<a name="ln3836">      MultiStageAlterTable::CopySchemaDetailsToFullyApplied(&amp;table_pb);</a>
<a name="ln3837">    }</a>
<a name="ln3838">    SchemaToPB(new_schema, table_pb.mutable_schema());</a>
<a name="ln3839">  }</a>
<a name="ln3840"> </a>
<a name="ln3841">  // Only increment the version number if it is a schema change (AddTable change goes through a</a>
<a name="ln3842">  // different path and it's not processed here).</a>
<a name="ln3843">  if (!req-&gt;has_wal_retention_secs()) {</a>
<a name="ln3844">    table_pb.set_version(table_pb.version() + 1);</a>
<a name="ln3845">  }</a>
<a name="ln3846">  table_pb.set_next_column_id(next_col_id);</a>
<a name="ln3847">  l-&gt;mutable_data()-&gt;set_state(</a>
<a name="ln3848">      SysTablesEntryPB::ALTERING,</a>
<a name="ln3849">      Substitute(&quot;Alter table version=$0 ts=$1&quot;, table_pb.version(), LocalTimeAsString()));</a>
<a name="ln3850"> </a>
<a name="ln3851">  // Update sys-catalog with the new table schema.</a>
<a name="ln3852">  TRACE(&quot;Updating metadata on disk&quot;);</a>
<a name="ln3853">  Status s = sys_catalog_-&gt;UpdateItem(table.get(), leader_ready_term());</a>
<a name="ln3854">  if (!s.ok()) {</a>
<a name="ln3855">    s = s.CloneAndPrepend(</a>
<a name="ln3856">        Substitute(&quot;An error occurred while updating sys-catalog tables entry: $0&quot;,</a>
<a name="ln3857">                   s.ToString()));</a>
<a name="ln3858">    LOG(WARNING) &lt;&lt; s.ToString();</a>
<a name="ln3859">    if (table-&gt;GetTableType() != PGSQL_TABLE_TYPE &amp;&amp;</a>
<a name="ln3860">        (req-&gt;has_new_namespace() || req-&gt;has_new_table_name())) {</a>
<a name="ln3861">      std::lock_guard&lt;LockType&gt; catalog_lock(lock_);</a>
<a name="ln3862">      VLOG(3) &lt;&lt; __func__ &lt;&lt; &quot;: Acquired the catalog manager lock_&quot;;</a>
<a name="ln3863">      CHECK_EQ(table_names_map_.erase({new_namespace_id, new_table_name}), 1);</a>
<a name="ln3864">    }</a>
<a name="ln3865">    // TableMetadaLock follows RAII paradigm: when it leaves scope,</a>
<a name="ln3866">    // 'l' will be unlocked, and the mutation will be aborted.</a>
<a name="ln3867">    return CheckIfNoLongerLeaderAndSetupError(s, resp);</a>
<a name="ln3868">  }</a>
<a name="ln3869"> </a>
<a name="ln3870">  // Remove the old name.</a>
<a name="ln3871">  if (req-&gt;has_new_namespace() || req-&gt;has_new_table_name()) {</a>
<a name="ln3872">    TRACE(&quot;Removing (namespace, table) combination ($0, $1) from by-name map&quot;,</a>
<a name="ln3873">        namespace_id, table_name);</a>
<a name="ln3874">    std::lock_guard&lt;LockType&gt; l_map(lock_);</a>
<a name="ln3875">    if (table-&gt;GetTableType() != PGSQL_TABLE_TYPE &amp;&amp;</a>
<a name="ln3876">        table_names_map_.erase({namespace_id, table_name}) != 1) {</a>
<a name="ln3877">      PANIC_RPC(rpc, &quot;Could not remove table from map, name=&quot; + l-&gt;data().name());</a>
<a name="ln3878">    }</a>
<a name="ln3879">  }</a>
<a name="ln3880"> </a>
<a name="ln3881">  // Update the in-memory state.</a>
<a name="ln3882">  TRACE(&quot;Committing in-memory state&quot;);</a>
<a name="ln3883">  l-&gt;Commit();</a>
<a name="ln3884"> </a>
<a name="ln3885">  SendAlterTableRequest(table, req);</a>
<a name="ln3886"> </a>
<a name="ln3887">  LOG(INFO) &lt;&lt; &quot;Successfully initiated ALTER TABLE (pending tablet schema updates) for &quot;</a>
<a name="ln3888">            &lt;&lt; table-&gt;ToString() &lt;&lt; &quot; per request from &quot; &lt;&lt; RequestorString(rpc);</a>
<a name="ln3889">  return Status::OK();</a>
<a name="ln3890">}</a>
<a name="ln3891"> </a>
<a name="ln3892">Status CatalogManager::IsAlterTableDone(const IsAlterTableDoneRequestPB* req,</a>
<a name="ln3893">                                        IsAlterTableDoneResponsePB* resp) {</a>
<a name="ln3894">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln3895"> </a>
<a name="ln3896">  scoped_refptr&lt;TableInfo&gt; table;</a>
<a name="ln3897"> </a>
<a name="ln3898">  // 1. Lookup the table and verify if it exists.</a>
<a name="ln3899">  TRACE(&quot;Looking up table&quot;);</a>
<a name="ln3900">  RETURN_NOT_OK(FindTable(req-&gt;table(), &amp;table));</a>
<a name="ln3901">  if (table == nullptr) {</a>
<a name="ln3902">    Status s = STATUS(NotFound, &quot;The object does not exist&quot;, req-&gt;table().ShortDebugString());</a>
<a name="ln3903">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln3904">  }</a>
<a name="ln3905"> </a>
<a name="ln3906">  TRACE(&quot;Locking table&quot;);</a>
<a name="ln3907">  auto l = table-&gt;LockForRead();</a>
<a name="ln3908">  RETURN_NOT_OK(CheckIfTableDeletedOrNotRunning(l.get(), resp));</a>
<a name="ln3909"> </a>
<a name="ln3910">  // 2. Verify if the alter is in-progress.</a>
<a name="ln3911">  TRACE(&quot;Verify if there is an alter operation in progress for $0&quot;, table-&gt;ToString());</a>
<a name="ln3912">  resp-&gt;set_schema_version(l-&gt;data().pb.version());</a>
<a name="ln3913">  resp-&gt;set_done(l-&gt;data().pb.state() != SysTablesEntryPB::ALTERING);</a>
<a name="ln3914"> </a>
<a name="ln3915">  return Status::OK();</a>
<a name="ln3916">}</a>
<a name="ln3917"> </a>
<a name="ln3918">Result&lt;TabletInfo*&gt; CatalogManager::RegisterNewTabletForSplit(</a>
<a name="ln3919">    const TabletInfo&amp; source_tablet_info, const PartitionPB&amp; partition) {</a>
<a name="ln3920">  const auto tablet_lock = source_tablet_info.LockForRead();</a>
<a name="ln3921"> </a>
<a name="ln3922">  const auto&amp; table = source_tablet_info.table();</a>
<a name="ln3923">  TabletInfo* new_tablet;</a>
<a name="ln3924">  {</a>
<a name="ln3925">    std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln3926">    new_tablet = CreateTabletInfo(table.get(), partition);</a>
<a name="ln3927">  }</a>
<a name="ln3928">  const auto&amp; source_tablet_meta = tablet_lock-&gt;data().pb;</a>
<a name="ln3929"> </a>
<a name="ln3930">  auto&amp; new_tablet_meta = new_tablet-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb;</a>
<a name="ln3931">  new_tablet_meta.set_state(SysTabletsEntryPB::CREATING);</a>
<a name="ln3932">  new_tablet_meta.mutable_committed_consensus_state()-&gt;CopyFrom(</a>
<a name="ln3933">      source_tablet_meta.committed_consensus_state());</a>
<a name="ln3934">  new_tablet_meta.set_split_depth(source_tablet_meta.split_depth() + 1);</a>
<a name="ln3935">  // TODO(tsplit): consider and handle failure scenarios, for example:</a>
<a name="ln3936">  // - Crash or leader failover before sending out the split tasks.</a>
<a name="ln3937">  // - Long enough partition while trying to send out the splits so that they timeout and</a>
<a name="ln3938">  //   not get executed.</a>
<a name="ln3939">  {</a>
<a name="ln3940">    std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln3941">    auto table_lock = table-&gt;LockForWrite();</a>
<a name="ln3942"> </a>
<a name="ln3943">    auto&amp; table_pb = table_lock-&gt;mutable_data()-&gt;pb;</a>
<a name="ln3944">    table_pb.set_partitions_version(table_pb.partitions_version() + 1);</a>
<a name="ln3945"> </a>
<a name="ln3946">    RETURN_NOT_OK(sys_catalog_-&gt;UpdateItem(table.get(), leader_ready_term()));</a>
<a name="ln3947">    // If we crash here - we will have new partitions version with the same set of tablets which</a>
<a name="ln3948">    // is harmless.</a>
<a name="ln3949">    // If we first save new_tablet to syscatalog and then crash - we would have table with old</a>
<a name="ln3950">    // partitions version, but new set of tablets which would break invariant that table partitions</a>
<a name="ln3951">    // set is not changed within the same partitions version.</a>
<a name="ln3952">    // TODO: rework this after https://github.com/yugabyte/yugabyte-db/issues/4912 is implemented.</a>
<a name="ln3953">    RETURN_NOT_OK(sys_catalog_-&gt;AddItem(new_tablet, leader_ready_term()));</a>
<a name="ln3954"> </a>
<a name="ln3955">    table-&gt;AddTablet(new_tablet);</a>
<a name="ln3956">    // TODO: We use this pattern in other places, but what if concurrent thread accesses not yet</a>
<a name="ln3957">    // committed TabletInfo from the `table` ?</a>
<a name="ln3958">    new_tablet-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln3959"> </a>
<a name="ln3960">    table_lock-&gt;Commit();</a>
<a name="ln3961"> </a>
<a name="ln3962">    auto tablet_map_checkout = tablet_map_.CheckOut();</a>
<a name="ln3963">    (*tablet_map_checkout)[new_tablet-&gt;id()] = new_tablet;</a>
<a name="ln3964">  }</a>
<a name="ln3965">  LOG(INFO) &lt;&lt; &quot;Registered new tablet &quot; &lt;&lt; new_tablet-&gt;tablet_id()</a>
<a name="ln3966">            &lt;&lt; &quot; (&quot; &lt;&lt; AsString(partition) &lt;&lt; &quot;) to split the tablet &quot;</a>
<a name="ln3967">            &lt;&lt; source_tablet_info.tablet_id()</a>
<a name="ln3968">            &lt;&lt; &quot; (&quot; &lt;&lt; AsString(source_tablet_meta.partition())</a>
<a name="ln3969">            &lt;&lt; &quot;) for table &quot; &lt;&lt; table-&gt;ToString();</a>
<a name="ln3970"> </a>
<a name="ln3971">  return new_tablet;</a>
<a name="ln3972">}</a>
<a name="ln3973"> </a>
<a name="ln3974">Status CatalogManager::GetTableSchema(const GetTableSchemaRequestPB* req,</a>
<a name="ln3975">                                      GetTableSchemaResponsePB* resp) {</a>
<a name="ln3976">  VLOG(1) &lt;&lt; &quot;Servicing GetTableSchema request for &quot; &lt;&lt; req-&gt;ShortDebugString();</a>
<a name="ln3977"> </a>
<a name="ln3978">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln3979"> </a>
<a name="ln3980">  scoped_refptr&lt;TableInfo&gt; table;</a>
<a name="ln3981"> </a>
<a name="ln3982">  // Lookup the table and verify if it exists.</a>
<a name="ln3983">  TRACE(&quot;Looking up table&quot;);</a>
<a name="ln3984">  RETURN_NOT_OK(FindTable(req-&gt;table(), &amp;table));</a>
<a name="ln3985">  if (table == nullptr) {</a>
<a name="ln3986">    Status s = STATUS(NotFound, &quot;The object does not exist&quot;, req-&gt;table().ShortDebugString());</a>
<a name="ln3987">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln3988">  }</a>
<a name="ln3989"> </a>
<a name="ln3990">  TRACE(&quot;Locking table&quot;);</a>
<a name="ln3991">  auto l = table-&gt;LockForRead();</a>
<a name="ln3992">  RETURN_NOT_OK(CheckIfTableDeletedOrNotRunning(l.get(), resp));</a>
<a name="ln3993"> </a>
<a name="ln3994">  if (l-&gt;data().pb.has_fully_applied_schema()) {</a>
<a name="ln3995">    // An AlterTable is in progress; fully_applied_schema is the last</a>
<a name="ln3996">    // schema that has reached every TS.</a>
<a name="ln3997">    DCHECK(l-&gt;data().pb.state() == SysTablesEntryPB::ALTERING);</a>
<a name="ln3998">    resp-&gt;mutable_schema()-&gt;CopyFrom(l-&gt;data().pb.fully_applied_schema());</a>
<a name="ln3999">    resp-&gt;set_version(l-&gt;data().pb.fully_applied_schema_version());</a>
<a name="ln4000">    resp-&gt;mutable_indexes()-&gt;CopyFrom(l-&gt;data().pb.fully_applied_indexes());</a>
<a name="ln4001">    if (l-&gt;data().pb.has_fully_applied_index_info()) {</a>
<a name="ln4002">      resp-&gt;set_obsolete_indexed_table_id(PROTO_GET_INDEXED_TABLE_ID(l-&gt;data().pb));</a>
<a name="ln4003">      *resp-&gt;mutable_index_info() = l-&gt;data().pb.fully_applied_index_info();</a>
<a name="ln4004">    }</a>
<a name="ln4005">    VLOG(1) &lt;&lt; &quot; Returning &quot;</a>
<a name="ln4006">            &lt;&lt; &quot; fully_applied_schema with version &quot; &lt;&lt; l-&gt;data().pb.fully_applied_schema_version()</a>
<a name="ln4007">            &lt;&lt; &quot; : \n&quot;</a>
<a name="ln4008">            &lt;&lt; yb::ToString(l-&gt;data().pb.fully_applied_indexes()) &lt;&lt; &quot;\n instead of version &quot;</a>
<a name="ln4009">            &lt;&lt; l-&gt;data().pb.version() &lt;&lt; &quot;\n&quot;</a>
<a name="ln4010">            &lt;&lt; yb::ToString(l-&gt;data().pb.indexes());</a>
<a name="ln4011">  } else {</a>
<a name="ln4012">    // There's no AlterTable, the regular schema is &quot;fully applied&quot;.</a>
<a name="ln4013">    resp-&gt;mutable_schema()-&gt;CopyFrom(l-&gt;data().pb.schema());</a>
<a name="ln4014">    resp-&gt;set_version(l-&gt;data().pb.version());</a>
<a name="ln4015">    resp-&gt;mutable_indexes()-&gt;CopyFrom(l-&gt;data().pb.indexes());</a>
<a name="ln4016">    if (l-&gt;data().pb.has_index_info()) {</a>
<a name="ln4017">      resp-&gt;set_obsolete_indexed_table_id(PROTO_GET_INDEXED_TABLE_ID(l-&gt;data().pb));</a>
<a name="ln4018">      *resp-&gt;mutable_index_info() = l-&gt;data().pb.index_info();</a>
<a name="ln4019">    }</a>
<a name="ln4020">    VLOG(1) &lt;&lt; &quot; Returning pb.schema() &quot;;</a>
<a name="ln4021">  }</a>
<a name="ln4022">  resp-&gt;mutable_partition_schema()-&gt;CopyFrom(l-&gt;data().pb.partition_schema());</a>
<a name="ln4023">  // TODO(bogdan): add back in replication_info once we allow overrides!</a>
<a name="ln4024">  resp-&gt;set_create_table_done(!table-&gt;IsCreateInProgress());</a>
<a name="ln4025">  resp-&gt;set_table_type(table-&gt;metadata().state().pb.table_type());</a>
<a name="ln4026">  resp-&gt;mutable_identifier()-&gt;set_table_name(l-&gt;data().pb.name());</a>
<a name="ln4027">  resp-&gt;mutable_identifier()-&gt;set_table_id(table-&gt;id());</a>
<a name="ln4028">  resp-&gt;mutable_identifier()-&gt;mutable_namespace_()-&gt;set_id(table-&gt;namespace_id());</a>
<a name="ln4029">  NamespaceIdentifierPB nsid;</a>
<a name="ln4030">  nsid.set_id(table-&gt;namespace_id());</a>
<a name="ln4031">  scoped_refptr&lt;NamespaceInfo&gt; nsinfo;</a>
<a name="ln4032">  if (FindNamespace(nsid, &amp;nsinfo).ok()) {</a>
<a name="ln4033">    resp-&gt;mutable_identifier()-&gt;mutable_namespace_()-&gt;set_name(nsinfo-&gt;name());</a>
<a name="ln4034">  }</a>
<a name="ln4035"> </a>
<a name="ln4036">  // Get namespace name by id.</a>
<a name="ln4037">  SharedLock&lt;LockType&gt; l_map(lock_);</a>
<a name="ln4038">  TRACE(&quot;Looking up namespace&quot;);</a>
<a name="ln4039">  const scoped_refptr&lt;NamespaceInfo&gt; ns = FindPtrOrNull(namespace_ids_map_, table-&gt;namespace_id());</a>
<a name="ln4040"> </a>
<a name="ln4041">  if (ns == nullptr) {</a>
<a name="ln4042">    Status s = STATUS_SUBSTITUTE(</a>
<a name="ln4043">        NotFound, &quot;Could not find namespace by namespace id $0 for request $1.&quot;,</a>
<a name="ln4044">        table-&gt;namespace_id(), req-&gt;DebugString());</a>
<a name="ln4045">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_NOT_FOUND, s);</a>
<a name="ln4046">  }</a>
<a name="ln4047"> </a>
<a name="ln4048">  resp-&gt;mutable_identifier()-&gt;mutable_namespace_()-&gt;set_name(ns-&gt;name());</a>
<a name="ln4049"> </a>
<a name="ln4050">  resp-&gt;set_colocated(table-&gt;colocated());</a>
<a name="ln4051"> </a>
<a name="ln4052">  VLOG(1) &lt;&lt; &quot;Serviced GetTableSchema request for &quot; &lt;&lt; req-&gt;ShortDebugString() &lt;&lt; &quot; with &quot;</a>
<a name="ln4053">          &lt;&lt; yb::ToString(*resp);</a>
<a name="ln4054">  return Status::OK();</a>
<a name="ln4055">}</a>
<a name="ln4056"> </a>
<a name="ln4057">Status CatalogManager::ListTables(const ListTablesRequestPB* req,</a>
<a name="ln4058">                                  ListTablesResponsePB* resp) {</a>
<a name="ln4059">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln4060"> </a>
<a name="ln4061">  NamespaceId namespace_id;</a>
<a name="ln4062"> </a>
<a name="ln4063">  // Validate namespace.</a>
<a name="ln4064">  if (req-&gt;has_namespace_()) {</a>
<a name="ln4065">    scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln4066"> </a>
<a name="ln4067">    // Lookup the namespace and verify if it exists.</a>
<a name="ln4068">    RETURN_NAMESPACE_NOT_FOUND(FindNamespace(req-&gt;namespace_(), &amp;ns), resp);</a>
<a name="ln4069"> </a>
<a name="ln4070">    auto ns_lock = ns-&gt;LockForRead();</a>
<a name="ln4071">    namespace_id = ns-&gt;id();</a>
<a name="ln4072"> </a>
<a name="ln4073">    // Don't list tables with a namespace that isn't running.</a>
<a name="ln4074">    if (ns-&gt;state() != SysNamespaceEntryPB::RUNNING) {</a>
<a name="ln4075">      LOG(INFO) &lt;&lt; &quot;ListTables request for a Namespace not running (State=&quot;</a>
<a name="ln4076">                &lt;&lt; SysNamespaceEntryPB::State_Name(ns-&gt;state()) &lt;&lt; &quot;)&quot;;</a>
<a name="ln4077">      return Status::OK();</a>
<a name="ln4078">    }</a>
<a name="ln4079">  }</a>
<a name="ln4080"> </a>
<a name="ln4081">  bool has_rel_filter = req-&gt;relation_type_filter_size() &gt; 0;</a>
<a name="ln4082">  bool include_user_table = has_rel_filter ? false : true;</a>
<a name="ln4083">  bool include_user_index = has_rel_filter ? false : true;</a>
<a name="ln4084">  bool include_system_table = req-&gt;exclude_system_tables() ? false</a>
<a name="ln4085">      : (has_rel_filter ? false : true);</a>
<a name="ln4086"> </a>
<a name="ln4087">  for (const auto &amp;relation : req-&gt;relation_type_filter()) {</a>
<a name="ln4088">    if (relation == SYSTEM_TABLE_RELATION) {</a>
<a name="ln4089">      include_system_table = true;</a>
<a name="ln4090">    } else if (relation == USER_TABLE_RELATION) {</a>
<a name="ln4091">      include_user_table = true;</a>
<a name="ln4092">    } else if (relation == INDEX_TABLE_RELATION) {</a>
<a name="ln4093">      include_user_index = true;</a>
<a name="ln4094">    }</a>
<a name="ln4095">  }</a>
<a name="ln4096"> </a>
<a name="ln4097">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln4098">  RelationType relation_type;</a>
<a name="ln4099"> </a>
<a name="ln4100">  for (const auto&amp; entry : *table_ids_map_) {</a>
<a name="ln4101">    auto&amp; table_info = *entry.second;</a>
<a name="ln4102">    auto ltm = table_info.LockForRead();</a>
<a name="ln4103"> </a>
<a name="ln4104">    if (!ltm-&gt;data().is_running()) continue;</a>
<a name="ln4105"> </a>
<a name="ln4106">    if (!namespace_id.empty() &amp;&amp; namespace_id != table_info.namespace_id()) {</a>
<a name="ln4107">      continue; // Skip tables from other namespaces.</a>
<a name="ln4108">    }</a>
<a name="ln4109"> </a>
<a name="ln4110">    if (req-&gt;has_name_filter()) {</a>
<a name="ln4111">      size_t found = ltm-&gt;data().name().find(req-&gt;name_filter());</a>
<a name="ln4112">      if (found == string::npos) {</a>
<a name="ln4113">        continue;</a>
<a name="ln4114">      }</a>
<a name="ln4115">    }</a>
<a name="ln4116"> </a>
<a name="ln4117">    if (IsUserIndexUnlocked(table_info)) {</a>
<a name="ln4118">      if (!include_user_index) {</a>
<a name="ln4119">        continue;</a>
<a name="ln4120">      }</a>
<a name="ln4121">      relation_type = INDEX_TABLE_RELATION;</a>
<a name="ln4122">    } else if (IsUserTableUnlocked(table_info)) {</a>
<a name="ln4123">      if (!include_user_table) {</a>
<a name="ln4124">        continue;</a>
<a name="ln4125">      }</a>
<a name="ln4126">      relation_type = USER_TABLE_RELATION;</a>
<a name="ln4127">    } else {</a>
<a name="ln4128">      if (!include_system_table) {</a>
<a name="ln4129">        continue;</a>
<a name="ln4130">      }</a>
<a name="ln4131">      relation_type = SYSTEM_TABLE_RELATION;</a>
<a name="ln4132">    }</a>
<a name="ln4133"> </a>
<a name="ln4134">    scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln4135">    NamespaceIdentifierPB ns_identifier;</a>
<a name="ln4136">    ns_identifier.set_id(ltm-&gt;data().namespace_id());</a>
<a name="ln4137">    auto s = FindNamespaceUnlocked(ns_identifier, &amp;ns);</a>
<a name="ln4138">    if (ns.get() == nullptr || ns-&gt;state() != SysNamespaceEntryPB::RUNNING) {</a>
<a name="ln4139">      if (PREDICT_FALSE(FLAGS_TEST_return_error_if_namespace_not_found)) {</a>
<a name="ln4140">        RETURN_NAMESPACE_NOT_FOUND(s, resp);</a>
<a name="ln4141">      }</a>
<a name="ln4142">      LOG(ERROR) &lt;&lt; &quot;Unable to find namespace with id &quot; &lt;&lt; ltm-&gt;data().namespace_id()</a>
<a name="ln4143">                 &lt;&lt; &quot; for table &quot; &lt;&lt; ltm-&gt;data().name();</a>
<a name="ln4144">      continue;</a>
<a name="ln4145">    }</a>
<a name="ln4146"> </a>
<a name="ln4147">    ListTablesResponsePB::TableInfo *table = resp-&gt;add_tables();</a>
<a name="ln4148">    {</a>
<a name="ln4149">      auto l = ns-&gt;LockForRead();</a>
<a name="ln4150">      table-&gt;mutable_namespace_()-&gt;set_id(ns-&gt;id());</a>
<a name="ln4151">      table-&gt;mutable_namespace_()-&gt;set_name(ns-&gt;name());</a>
<a name="ln4152">      table-&gt;mutable_namespace_()-&gt;set_database_type(ns-&gt;database_type());</a>
<a name="ln4153">    }</a>
<a name="ln4154">    table-&gt;set_id(entry.second-&gt;id());</a>
<a name="ln4155">    table-&gt;set_name(ltm-&gt;data().name());</a>
<a name="ln4156">    table-&gt;set_table_type(ltm-&gt;data().table_type());</a>
<a name="ln4157">    table-&gt;set_relation_type(relation_type);</a>
<a name="ln4158">  }</a>
<a name="ln4159">  return Status::OK();</a>
<a name="ln4160">}</a>
<a name="ln4161"> </a>
<a name="ln4162">scoped_refptr&lt;TableInfo&gt; CatalogManager::GetTableInfo(const TableId&amp; table_id) {</a>
<a name="ln4163">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln4164">  return FindPtrOrNull(*table_ids_map_, table_id);</a>
<a name="ln4165">}</a>
<a name="ln4166"> </a>
<a name="ln4167">scoped_refptr&lt;TableInfo&gt; CatalogManager::GetTableInfoFromNamespaceNameAndTableName(</a>
<a name="ln4168">    YQLDatabase db_type, const NamespaceName&amp; namespace_name, const TableName&amp; table_name) {</a>
<a name="ln4169">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln4170">  const auto ns = FindPtrOrNull(namespace_names_mapper_[db_type], namespace_name);</a>
<a name="ln4171">  return ns</a>
<a name="ln4172">    ? FindPtrOrNull(table_names_map_, {ns-&gt;id(), table_name})</a>
<a name="ln4173">    : nullptr;</a>
<a name="ln4174">}</a>
<a name="ln4175"> </a>
<a name="ln4176">scoped_refptr&lt;TableInfo&gt; CatalogManager::GetTableInfoUnlocked(const TableId&amp; table_id) {</a>
<a name="ln4177">  return FindPtrOrNull(*table_ids_map_, table_id);</a>
<a name="ln4178">}</a>
<a name="ln4179"> </a>
<a name="ln4180">void CatalogManager::GetAllTables(std::vector&lt;scoped_refptr&lt;TableInfo&gt;&gt; *tables,</a>
<a name="ln4181">                                  bool includeOnlyRunningTables) {</a>
<a name="ln4182">  tables-&gt;clear();</a>
<a name="ln4183">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln4184">  for (const auto&amp; e : *table_ids_map_) {</a>
<a name="ln4185">    if (includeOnlyRunningTables &amp;&amp; !e.second-&gt;is_running()) {</a>
<a name="ln4186">      continue;</a>
<a name="ln4187">    }</a>
<a name="ln4188">    tables-&gt;push_back(e.second);</a>
<a name="ln4189">  }</a>
<a name="ln4190">}</a>
<a name="ln4191"> </a>
<a name="ln4192">void CatalogManager::GetAllNamespaces(std::vector&lt;scoped_refptr&lt;NamespaceInfo&gt;&gt;* namespaces,</a>
<a name="ln4193">                                      bool includeOnlyRunningNamespaces) {</a>
<a name="ln4194">  namespaces-&gt;clear();</a>
<a name="ln4195">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln4196">  for (const NamespaceInfoMap::value_type&amp; e : namespace_ids_map_) {</a>
<a name="ln4197">    if (includeOnlyRunningNamespaces &amp;&amp; e.second-&gt;state() != SysNamespaceEntryPB::RUNNING) {</a>
<a name="ln4198">      continue;</a>
<a name="ln4199">    }</a>
<a name="ln4200">    namespaces-&gt;push_back(e.second);</a>
<a name="ln4201">  }</a>
<a name="ln4202">}</a>
<a name="ln4203"> </a>
<a name="ln4204">void CatalogManager::GetAllUDTypes(std::vector&lt;scoped_refptr&lt;UDTypeInfo&gt;&gt;* types) {</a>
<a name="ln4205">  types-&gt;clear();</a>
<a name="ln4206">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln4207">  for (const UDTypeInfoMap::value_type&amp; e : udtype_ids_map_) {</a>
<a name="ln4208">    types-&gt;push_back(e.second);</a>
<a name="ln4209">  }</a>
<a name="ln4210">}</a>
<a name="ln4211"> </a>
<a name="ln4212">std::vector&lt;std::shared_ptr&lt;MonitoredTask&gt;&gt; CatalogManager::GetRecentTasks() {</a>
<a name="ln4213">  return tasks_tracker_-&gt;GetTasks();</a>
<a name="ln4214">}</a>
<a name="ln4215"> </a>
<a name="ln4216">std::vector&lt;std::shared_ptr&lt;MonitoredTask&gt;&gt; CatalogManager::GetRecentJobs() {</a>
<a name="ln4217">  return jobs_tracker_-&gt;GetTasks();</a>
<a name="ln4218">}</a>
<a name="ln4219"> </a>
<a name="ln4220">NamespaceName CatalogManager::GetNamespaceNameUnlocked(const NamespaceId&amp; id) const  {</a>
<a name="ln4221">  const scoped_refptr&lt;NamespaceInfo&gt; ns = FindPtrOrNull(namespace_ids_map_, id);</a>
<a name="ln4222">  return ns == nullptr ? NamespaceName() : ns-&gt;name();</a>
<a name="ln4223">}</a>
<a name="ln4224"> </a>
<a name="ln4225">NamespaceName CatalogManager::GetNamespaceName(const NamespaceId&amp; id) const {</a>
<a name="ln4226">  TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln4227">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln4228">  return GetNamespaceNameUnlocked(id);</a>
<a name="ln4229">}</a>
<a name="ln4230"> </a>
<a name="ln4231">NamespaceName CatalogManager::GetNamespaceNameUnlocked(</a>
<a name="ln4232">    const scoped_refptr&lt;TableInfo&gt;&amp; table) const  {</a>
<a name="ln4233">  return GetNamespaceNameUnlocked(table-&gt;namespace_id());</a>
<a name="ln4234">}</a>
<a name="ln4235"> </a>
<a name="ln4236">NamespaceName CatalogManager::GetNamespaceName(const scoped_refptr&lt;TableInfo&gt;&amp; table) const {</a>
<a name="ln4237">  return GetNamespaceName(table-&gt;namespace_id());</a>
<a name="ln4238">}</a>
<a name="ln4239"> </a>
<a name="ln4240">bool CatalogManager::IsSystemTable(const TableInfo&amp; table) const {</a>
<a name="ln4241">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln4242">  return IsSystemTableUnlocked(table);</a>
<a name="ln4243">}</a>
<a name="ln4244"> </a>
<a name="ln4245">bool CatalogManager::IsSystemTableUnlocked(const TableInfo&amp; table) const {</a>
<a name="ln4246">  TabletInfos tablets;</a>
<a name="ln4247">  table.GetAllTablets(&amp;tablets);</a>
<a name="ln4248">  for (const auto&amp; tablet : tablets) {</a>
<a name="ln4249">    if (system_tablets_.find(tablet-&gt;id()) != system_tablets_.end()) {</a>
<a name="ln4250">      return true;</a>
<a name="ln4251">    }</a>
<a name="ln4252">  }</a>
<a name="ln4253">  return false;</a>
<a name="ln4254">}</a>
<a name="ln4255"> </a>
<a name="ln4256">// True if table is created by user.</a>
<a name="ln4257">// Table can be regular table or index in this case.</a>
<a name="ln4258">bool CatalogManager::IsUserCreatedTable(const TableInfo&amp; table) const {</a>
<a name="ln4259">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln4260">  return IsUserCreatedTableUnlocked(table);</a>
<a name="ln4261">}</a>
<a name="ln4262"> </a>
<a name="ln4263">bool CatalogManager::IsUserCreatedTableUnlocked(const TableInfo&amp; table) const {</a>
<a name="ln4264">  if (table.GetTableType() == PGSQL_TABLE_TYPE || table.GetTableType() == YQL_TABLE_TYPE) {</a>
<a name="ln4265">    if (!IsSystemTableUnlocked(table) &amp;&amp; !IsSequencesSystemTable(table) &amp;&amp;</a>
<a name="ln4266">        GetNamespaceNameUnlocked(table.namespace_id()) != kSystemNamespaceName &amp;&amp;</a>
<a name="ln4267">        !IsColocatedParentTable(table) &amp;&amp;</a>
<a name="ln4268">        !IsTablegroupParentTable(table)) {</a>
<a name="ln4269">      return true;</a>
<a name="ln4270">    }</a>
<a name="ln4271">  }</a>
<a name="ln4272">  return false;</a>
<a name="ln4273">}</a>
<a name="ln4274"> </a>
<a name="ln4275">bool CatalogManager::IsUserTable(const TableInfo&amp; table) const {</a>
<a name="ln4276">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln4277">  return IsUserTableUnlocked(table);</a>
<a name="ln4278">}</a>
<a name="ln4279"> </a>
<a name="ln4280">bool CatalogManager::IsUserTableUnlocked(const TableInfo&amp; table) const {</a>
<a name="ln4281">  return IsUserCreatedTableUnlocked(table) &amp;&amp; table.indexed_table_id().empty();</a>
<a name="ln4282">}</a>
<a name="ln4283"> </a>
<a name="ln4284">bool CatalogManager::IsUserIndex(const TableInfo&amp; table) const {</a>
<a name="ln4285">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln4286">  return IsUserIndexUnlocked(table);</a>
<a name="ln4287">}</a>
<a name="ln4288"> </a>
<a name="ln4289">bool CatalogManager::IsUserIndexUnlocked(const TableInfo&amp; table) const {</a>
<a name="ln4290">  return IsUserCreatedTableUnlocked(table) &amp;&amp; !table.indexed_table_id().empty();</a>
<a name="ln4291">}</a>
<a name="ln4292"> </a>
<a name="ln4293">bool CatalogManager::IsColocatedParentTable(const TableInfo&amp; table) const {</a>
<a name="ln4294">  return table.id().find(kColocatedParentTableIdSuffix) != std::string::npos;</a>
<a name="ln4295">}</a>
<a name="ln4296"> </a>
<a name="ln4297">bool CatalogManager::IsTablegroupParentTable(const TableInfo&amp; table) const {</a>
<a name="ln4298">  return table.id().find(kTablegroupParentTableIdSuffix) != std::string::npos;</a>
<a name="ln4299">}</a>
<a name="ln4300"> </a>
<a name="ln4301">bool CatalogManager::IsColocatedUserTable(const TableInfo&amp; table) const {</a>
<a name="ln4302">  return table.colocated() &amp;&amp; !IsColocatedParentTable(table)</a>
<a name="ln4303">                           &amp;&amp; !IsTablegroupParentTable(table);</a>
<a name="ln4304">}</a>
<a name="ln4305"> </a>
<a name="ln4306">bool CatalogManager::IsSequencesSystemTable(const TableInfo&amp; table) const {</a>
<a name="ln4307">  if (table.GetTableType() == PGSQL_TABLE_TYPE &amp;&amp; !IsColocatedParentTable(table)</a>
<a name="ln4308">                                               &amp;&amp; !IsTablegroupParentTable(table)) {</a>
<a name="ln4309">    // This case commonly occurs during unit testing. Avoid unnecessary assert within Get().</a>
<a name="ln4310">    if (!IsPgsqlId(table.namespace_id()) || !IsPgsqlId(table.id())) {</a>
<a name="ln4311">      LOG(WARNING) &lt;&lt; &quot;Not PGSQL IDs &quot; &lt;&lt; table.namespace_id() &lt;&lt; &quot;, &quot; &lt;&lt; table.id();</a>
<a name="ln4312">      return false;</a>
<a name="ln4313">    }</a>
<a name="ln4314">    Result&lt;uint32_t&gt; database_oid = GetPgsqlDatabaseOid(table.namespace_id());</a>
<a name="ln4315">    if (!database_oid.ok()) {</a>
<a name="ln4316">      LOG(WARNING) &lt;&lt; &quot;Invalid Namespace ID &quot; &lt;&lt; table.namespace_id();</a>
<a name="ln4317">      return false;</a>
<a name="ln4318">    }</a>
<a name="ln4319">    Result&lt;uint32_t&gt; table_oid = GetPgsqlTableOid(table.id());</a>
<a name="ln4320">    if (!table_oid.ok()) {</a>
<a name="ln4321">      LOG(WARNING) &lt;&lt; &quot;Invalid Table ID &quot; &lt;&lt; table.id();</a>
<a name="ln4322">      return false;</a>
<a name="ln4323">    }</a>
<a name="ln4324">    if (*database_oid == kPgSequencesDataDatabaseOid &amp;&amp; *table_oid == kPgSequencesDataTableOid) {</a>
<a name="ln4325">      return true;</a>
<a name="ln4326">    }</a>
<a name="ln4327">  }</a>
<a name="ln4328">  return false;</a>
<a name="ln4329">}</a>
<a name="ln4330"> </a>
<a name="ln4331">void CatalogManager::NotifyTabletDeleteFinished(const TabletServerId&amp; tserver_uuid,</a>
<a name="ln4332">                                                const TabletId&amp; tablet_id) {</a>
<a name="ln4333">  shared_ptr&lt;TSDescriptor&gt; ts_desc;</a>
<a name="ln4334">  if (!master_-&gt;ts_manager()-&gt;LookupTSByUUID(tserver_uuid, &amp;ts_desc)) {</a>
<a name="ln4335">    LOG(WARNING) &lt;&lt; &quot;Unable to find tablet server &quot; &lt;&lt; tserver_uuid;</a>
<a name="ln4336">  } else if (!ts_desc-&gt;IsTabletDeletePending(tablet_id)) {</a>
<a name="ln4337">    LOG(WARNING) &lt;&lt; &quot;Pending delete for tablet &quot; &lt;&lt; tablet_id &lt;&lt; &quot; in ts &quot;</a>
<a name="ln4338">                 &lt;&lt; tserver_uuid &lt;&lt; &quot; doesn't exist&quot;;</a>
<a name="ln4339">  } else {</a>
<a name="ln4340">    LOG(INFO) &lt;&lt; &quot;Clearing pending delete for tablet &quot; &lt;&lt; tablet_id &lt;&lt; &quot; in ts &quot; &lt;&lt; tserver_uuid;</a>
<a name="ln4341">    ts_desc-&gt;ClearPendingTabletDelete(tablet_id);</a>
<a name="ln4342">  }</a>
<a name="ln4343">}</a>
<a name="ln4344"> </a>
<a name="ln4345">bool CatalogManager::ReplicaMapDiffersFromConsensusState(const scoped_refptr&lt;TabletInfo&gt;&amp; tablet,</a>
<a name="ln4346">                                                         const ConsensusStatePB&amp; cstate) {</a>
<a name="ln4347">  TabletInfo::ReplicaMap locs;</a>
<a name="ln4348">  tablet-&gt;GetReplicaLocations(&amp;locs);</a>
<a name="ln4349">  if (locs.size() != cstate.config().peers_size()) {</a>
<a name="ln4350">    return true;</a>
<a name="ln4351">  }</a>
<a name="ln4352">  for (auto iter = cstate.config().peers().begin(); iter != cstate.config().peers().end(); iter++) {</a>
<a name="ln4353">      if (locs.find(iter-&gt;permanent_uuid()) == locs.end()) {</a>
<a name="ln4354">        return true;</a>
<a name="ln4355">      }</a>
<a name="ln4356">  }</a>
<a name="ln4357">  return false;</a>
<a name="ln4358">}</a>
<a name="ln4359"> </a>
<a name="ln4360">Status CatalogManager::ProcessTabletReport(TSDescriptor* ts_desc,</a>
<a name="ln4361">                                           const TabletReportPB&amp; full_report,</a>
<a name="ln4362">                                           TabletReportUpdatesPB* full_report_update,</a>
<a name="ln4363">                                           RpcContext* rpc) {</a>
<a name="ln4364">  int num_tablets = full_report.updated_tablets_size();</a>
<a name="ln4365">  TRACE_EVENT2(&quot;master&quot;, &quot;ProcessTabletReport&quot;,</a>
<a name="ln4366">               &quot;requestor&quot;, rpc-&gt;requestor_string(),</a>
<a name="ln4367">               &quot;num_tablets&quot;, num_tablets);</a>
<a name="ln4368"> </a>
<a name="ln4369">  if (VLOG_IS_ON(2)) {</a>
<a name="ln4370">    VLOG(2) &lt;&lt; &quot;Received tablet report from &quot; &lt;&lt; RequestorString(rpc) &lt;&lt; &quot;(&quot;</a>
<a name="ln4371">            &lt;&lt; ts_desc-&gt;permanent_uuid() &lt;&lt; &quot;): &quot; &lt;&lt; full_report.DebugString();</a>
<a name="ln4372">  }</a>
<a name="ln4373"> </a>
<a name="ln4374">  if (!ts_desc-&gt;has_tablet_report() &amp;&amp; full_report.is_incremental()) {</a>
<a name="ln4375">    string msg = &quot;Received an incremental tablet report when a full one was needed&quot;;</a>
<a name="ln4376">    LOG(WARNING) &lt;&lt; &quot;Invalid tablet report from &quot; &lt;&lt; ts_desc-&gt;permanent_uuid() &lt;&lt; &quot;: &quot; &lt;&lt; msg;</a>
<a name="ln4377">    // We should respond with success in order to send reply that we need full report.</a>
<a name="ln4378">    return Status::OK();</a>
<a name="ln4379">  }</a>
<a name="ln4380"> </a>
<a name="ln4381">  // TODO: on a full tablet report, we may want to iterate over the tablets we think</a>
<a name="ln4382">  // the server should have, compare vs the ones being reported, and somehow mark</a>
<a name="ln4383">  // any that have been &quot;lost&quot; (eg somehow the tablet metadata got corrupted or something).</a>
<a name="ln4384"> </a>
<a name="ln4385">  // Maps a tablet ID to its corresponding tablet report (owned by 'full_report').</a>
<a name="ln4386">  map&lt;TabletId, const ReportedTabletPB*&gt; reports;</a>
<a name="ln4387"> </a>
<a name="ln4388">  // Maps a tablet ID to its corresponding tablet report update (owned by</a>
<a name="ln4389">  // 'full_report_update').</a>
<a name="ln4390">  map&lt;TabletId, ReportedTabletUpdatesPB*&gt; updates;</a>
<a name="ln4391"> </a>
<a name="ln4392">  // Maps a tablet ID to its corresponding TabletInfo.</a>
<a name="ln4393">  map&lt;TabletId, scoped_refptr&lt;TabletInfo&gt;&gt; tablet_infos;</a>
<a name="ln4394"> </a>
<a name="ln4395">  // Tablet Deletes to process after the catalog lock below.</a>
<a name="ln4396">  set&lt;TabletId&gt; tablets_to_delete;</a>
<a name="ln4397"> </a>
<a name="ln4398">  {</a>
<a name="ln4399">    // Lock the catalog to iterate over tablet_ids_map_ &amp; table_ids_map_.</a>
<a name="ln4400">    SharedLock&lt;LockType&gt; catalog_lock(lock_);</a>
<a name="ln4401"> </a>
<a name="ln4402">    // Fill the above variables before processing</a>
<a name="ln4403">    full_report_update-&gt;mutable_tablets()-&gt;Reserve(num_tablets);</a>
<a name="ln4404">    for (const ReportedTabletPB&amp; report : full_report.updated_tablets()) {</a>
<a name="ln4405">      const string&amp; tablet_id = report.tablet_id();</a>
<a name="ln4406"> </a>
<a name="ln4407">      // 1a. Prepare an update entry for this tablet. Every tablet in the</a>
<a name="ln4408">      // report gets one, even if there's no change to it.</a>
<a name="ln4409">      ReportedTabletUpdatesPB* update = full_report_update-&gt;add_tablets();</a>
<a name="ln4410">      update-&gt;set_tablet_id(tablet_id);</a>
<a name="ln4411"> </a>
<a name="ln4412">      // 1b. Find the tablet, deleting/skipping it if it can't be found.</a>
<a name="ln4413">      scoped_refptr&lt;TabletInfo&gt; tablet = FindPtrOrNull(*tablet_map_, tablet_id);</a>
<a name="ln4414">      if (!tablet) {</a>
<a name="ln4415">        // It'd be unsafe to ask the tserver to delete this tablet without first</a>
<a name="ln4416">        // replicating something to our followers (i.e. to guarantee that we're</a>
<a name="ln4417">        // the leader). For example, if we were a rogue master, we might be</a>
<a name="ln4418">        // deleting a tablet created by a new master accidentally. But masters</a>
<a name="ln4419">        // retain metadata for deleted tablets forever, so a tablet can only be</a>
<a name="ln4420">        // truly unknown in the event of a serious misconfiguration, such as a</a>
<a name="ln4421">        // tserver heartbeating to the wrong cluster. Therefore, it should be</a>
<a name="ln4422">        // reasonable to ignore it and wait for an operator fix the situation.</a>
<a name="ln4423">        LOG(WARNING) &lt;&lt; &quot;Ignoring report from unknown tablet &quot; &lt;&lt; tablet_id;</a>
<a name="ln4424">        continue;</a>
<a name="ln4425">      }</a>
<a name="ln4426">      if (!tablet-&gt;table() || FindOrNull(*table_ids_map_, tablet-&gt;table()-&gt;id()) == nullptr) {</a>
<a name="ln4427">        auto table_id = tablet-&gt;table() == nullptr ? &quot;(null)&quot; : tablet-&gt;table()-&gt;id();</a>
<a name="ln4428">        LOG(INFO) &lt;&lt; &quot;Got report from an orphaned tablet &quot; &lt;&lt; tablet_id &lt;&lt; &quot; on table &quot; &lt;&lt; table_id;</a>
<a name="ln4429">        tablets_to_delete.insert(tablet_id);</a>
<a name="ln4430">        continue;</a>
<a name="ln4431">      }</a>
<a name="ln4432"> </a>
<a name="ln4433">      // 1c. Found the tablet, update local state. If multiple tablets with the</a>
<a name="ln4434">      // same ID are in the report, all but the last one will be ignored.</a>
<a name="ln4435">      reports[tablet_id] = &amp;report;</a>
<a name="ln4436">      updates[tablet_id] = update;</a>
<a name="ln4437">      tablet_infos[tablet_id] = tablet;</a>
<a name="ln4438">    }</a>
<a name="ln4439">  }</a>
<a name="ln4440"> </a>
<a name="ln4441">  // Process any delete requests from orphaned tablets, identified above.</a>
<a name="ln4442">  for (auto tablet_id : tablets_to_delete) {</a>
<a name="ln4443">    SendDeleteTabletRequest(tablet_id, TABLET_DATA_DELETED, boost::none, nullptr, ts_desc,</a>
<a name="ln4444">        &quot;Report from an orphaned tablet&quot;);</a>
<a name="ln4445">  }</a>
<a name="ln4446"> </a>
<a name="ln4447">  // Doing batched processing with inner 'for' loops.  Ensure we iterate all tablets with 'while'.</a>
<a name="ln4448">  auto tablet_iter = tablet_infos.begin();</a>
<a name="ln4449">  while (tablet_iter != tablet_infos.end()) {</a>
<a name="ln4450">    // Keeps track of all RPCs that should be sent when we're done with a single batch.</a>
<a name="ln4451">    vector&lt;shared_ptr&lt;RetryingTSRpcTask&gt;&gt; rpcs;</a>
<a name="ln4452"> </a>
<a name="ln4453">    // 2a. First Pass. Iterate in TabletId Order to discover all Table locks we'll need.</a>
<a name="ln4454">    //     Need to acquire both types of locks in Id order to prevent deadlock.</a>
<a name="ln4455">    map&lt;TableId, unique_ptr&lt;TableInfo::lock_type&gt;&gt; table_read_locks; // used for unlock.</a>
<a name="ln4456">    map&lt;TabletId, unique_ptr&lt;TabletInfo::lock_type&gt;&gt; tablet_write_locks; // used for unlock.</a>
<a name="ln4457">    {</a>
<a name="ln4458">      map&lt;TableId, scoped_refptr&lt;TableInfo&gt;&gt; tables_to_lock;</a>
<a name="ln4459">      auto tablet_iter_for_table_locks = tablet_iter;</a>
<a name="ln4460">      for (auto i = 0;</a>
<a name="ln4461">          i &lt; FLAGS_catalog_manager_report_batch_size</a>
<a name="ln4462">            &amp;&amp; tablet_iter_for_table_locks != tablet_infos.end();</a>
<a name="ln4463">          ++i, ++tablet_iter_for_table_locks) {</a>
<a name="ln4464">        const scoped_refptr&lt;TabletInfo&gt;&amp; tablet = tablet_iter_for_table_locks-&gt;second;</a>
<a name="ln4465">        const scoped_refptr&lt;TableInfo&gt;&amp; table = tablet-&gt;table();</a>
<a name="ln4466">        tables_to_lock[table-&gt;id()] = table;</a>
<a name="ln4467">      }</a>
<a name="ln4468">      for (auto&amp; id_and_table : tables_to_lock) {</a>
<a name="ln4469">        table_read_locks[id_and_table.first] = id_and_table.second-&gt;LockForRead();</a>
<a name="ln4470">      }</a>
<a name="ln4471">    }</a>
<a name="ln4472">    // 2b. Second Pass.  Process each tablet. This may not be in the order that the tablets</a>
<a name="ln4473">    // appear in 'full_report', but that has no bearing on correctness.</a>
<a name="ln4474">    vector&lt;TabletInfo*&gt; mutated_tablets; // refcount protected by 'tablet_infos'</a>
<a name="ln4475">    auto tablet_iter_for_schema_changes = tablet_iter;</a>
<a name="ln4476">    for (auto i = 0;</a>
<a name="ln4477">         i &lt; FLAGS_catalog_manager_report_batch_size &amp;&amp; tablet_iter != tablet_infos.end();</a>
<a name="ln4478">         ++i, ++tablet_iter) {</a>
<a name="ln4479">      const string&amp; tablet_id = tablet_iter-&gt;first;</a>
<a name="ln4480">      const scoped_refptr&lt;TabletInfo&gt;&amp; tablet = tablet_iter-&gt;second;</a>
<a name="ln4481">      const scoped_refptr&lt;TableInfo&gt;&amp; table = tablet-&gt;table();</a>
<a name="ln4482">      const ReportedTabletPB&amp; report = *FindOrDie(reports, tablet_id);</a>
<a name="ln4483">      ReportedTabletUpdatesPB* update = FindOrDie(updates, tablet_id);</a>
<a name="ln4484">      // Get tablet lock on demand.  This works in the batch case because the loop is ordered.</a>
<a name="ln4485">      tablet_write_locks[tablet_id] = tablet-&gt;LockForWrite();</a>
<a name="ln4486">      auto&amp; table_lock = table_read_locks[table-&gt;id()];</a>
<a name="ln4487">      auto&amp; tablet_lock = tablet_write_locks[tablet_id];</a>
<a name="ln4488"> </a>
<a name="ln4489">      TRACE_EVENT1(&quot;master&quot;, &quot;HandleReportedTablet&quot;, &quot;tablet_id&quot;, report.tablet_id());</a>
<a name="ln4490">      RETURN_NOT_OK_PREPEND(CheckIsLeaderAndReady(),</a>
<a name="ln4491">          Substitute(&quot;This master is no longer the leader, unable to handle report for tablet $0&quot;,</a>
<a name="ln4492">              tablet_id));</a>
<a name="ln4493"> </a>
<a name="ln4494">      VLOG(3) &lt;&lt; &quot;tablet report: &quot; &lt;&lt; report.ShortDebugString();</a>
<a name="ln4495"> </a>
<a name="ln4496">      // 3. Delete the tablet if it (or its table) have been deleted.</a>
<a name="ln4497">      if (tablet_lock-&gt;data().is_deleted() ||</a>
<a name="ln4498">          table_lock-&gt;data().started_deleting()) {</a>
<a name="ln4499">        const string msg = tablet_lock-&gt;data().pb.state_msg();</a>
<a name="ln4500">        update-&gt;set_state_msg(msg);</a>
<a name="ln4501">        LOG(INFO) &lt;&lt; &quot;Got report from deleted tablet &quot; &lt;&lt; tablet-&gt;ToString()</a>
<a name="ln4502">                  &lt;&lt; &quot; (&quot; &lt;&lt; msg &lt;&lt; &quot;): Sending delete request for this tablet&quot;;</a>
<a name="ln4503">        // TODO(unknown): Cancel tablet creation, instead of deleting, in cases</a>
<a name="ln4504">        // where that might be possible (tablet creation timeout &amp; replacement).</a>
<a name="ln4505">        rpcs.emplace_back(std::make_shared&lt;AsyncDeleteReplica&gt;(</a>
<a name="ln4506">            master_, AsyncTaskPool(), ts_desc-&gt;permanent_uuid(), table, tablet_id,</a>
<a name="ln4507">            TABLET_DATA_DELETED, boost::none, msg));</a>
<a name="ln4508">        continue;</a>
<a name="ln4509">      }</a>
<a name="ln4510"> </a>
<a name="ln4511">      if (!table_lock-&gt;data().is_running()) {</a>
<a name="ln4512">        const string msg = tablet_lock-&gt;data().pb.state_msg();</a>
<a name="ln4513">        LOG(INFO) &lt;&lt; &quot;Got report from tablet &quot; &lt;&lt; tablet-&gt;tablet_id()</a>
<a name="ln4514">                  &lt;&lt; &quot; for non-running table &quot; &lt;&lt; table-&gt;ToString() &lt;&lt; &quot;: &quot; &lt;&lt; msg;</a>
<a name="ln4515">        update-&gt;set_state_msg(msg);</a>
<a name="ln4516">        continue;</a>
<a name="ln4517">      }</a>
<a name="ln4518"> </a>
<a name="ln4519">      // 4. Tombstone a replica that is no longer part of the Raft config (and</a>
<a name="ln4520">      // not already tombstoned or deleted outright).</a>
<a name="ln4521">      //</a>
<a name="ln4522">      // If the report includes a committed raft config, we only tombstone if</a>
<a name="ln4523">      // the opid_index is strictly less than the latest reported committed</a>
<a name="ln4524">      // config. This prevents us from spuriously deleting replicas that have</a>
<a name="ln4525">      // just been added to the committed config and are in the process of copying.</a>
<a name="ln4526">      const ConsensusStatePB &amp;prev_cstate = tablet_lock-&gt;data().pb.committed_consensus_state();</a>
<a name="ln4527">      const int64_t prev_opid_index = prev_cstate.config().opid_index();</a>
<a name="ln4528">      const int64_t report_opid_index = (report.has_committed_consensus_state() &amp;&amp;</a>
<a name="ln4529">          report.committed_consensus_state().config().has_opid_index()) ?</a>
<a name="ln4530">            report.committed_consensus_state().config().opid_index() :</a>
<a name="ln4531">            consensus::kInvalidOpIdIndex;</a>
<a name="ln4532">      if (FLAGS_master_tombstone_evicted_tablet_replicas &amp;&amp;</a>
<a name="ln4533">          report.tablet_data_state() != TABLET_DATA_TOMBSTONED &amp;&amp;</a>
<a name="ln4534">          report.tablet_data_state() != TABLET_DATA_DELETED &amp;&amp;</a>
<a name="ln4535">          report_opid_index &lt; prev_opid_index &amp;&amp;</a>
<a name="ln4536">          !IsRaftConfigMember(ts_desc-&gt;permanent_uuid(), prev_cstate.config())) {</a>
<a name="ln4537">        const string delete_msg = (report_opid_index == consensus::kInvalidOpIdIndex) ?</a>
<a name="ln4538">            &quot;Replica has no consensus available&quot; :</a>
<a name="ln4539">            Substitute(&quot;Replica with old config index $0&quot;, report_opid_index);</a>
<a name="ln4540">        rpcs.emplace_back(std::make_shared&lt;AsyncDeleteReplica&gt;(</a>
<a name="ln4541">            master_, AsyncTaskPool(), ts_desc-&gt;permanent_uuid(), table, tablet_id,</a>
<a name="ln4542">            TABLET_DATA_TOMBSTONED, prev_opid_index,</a>
<a name="ln4543">            Substitute(&quot;$0 (current committed config index is $1)&quot;,</a>
<a name="ln4544">                delete_msg, prev_opid_index)));</a>
<a name="ln4545">        continue;</a>
<a name="ln4546">      }</a>
<a name="ln4547"> </a>
<a name="ln4548">      // 5. Skip a non-deleted tablet which reports an error.</a>
<a name="ln4549">      if (report.has_error()) {</a>
<a name="ln4550">        Status s = StatusFromPB(report.error());</a>
<a name="ln4551">        DCHECK(!s.ok());</a>
<a name="ln4552">        DCHECK_EQ(report.state(), tablet::FAILED);</a>
<a name="ln4553">        LOG(WARNING) &lt;&lt; &quot;Tablet &quot; &lt;&lt; tablet-&gt;ToString() &lt;&lt; &quot; has failed on TS &quot;</a>
<a name="ln4554">                     &lt;&lt; ts_desc-&gt;permanent_uuid() &lt;&lt; &quot;: &quot; &lt;&lt; s.ToString();</a>
<a name="ln4555">        continue;</a>
<a name="ln4556">      }</a>
<a name="ln4557"> </a>
<a name="ln4558">      // 6. Process the report's consensus state.</a>
<a name="ln4559">      // The report will not have a committed_consensus_state if it is in the</a>
<a name="ln4560">      // middle of starting up, such as during tablet bootstrap.</a>
<a name="ln4561">      // If we received an incremental report, and the tablet is starting up, we will update the</a>
<a name="ln4562">      // replica so that the balancer knows how many tablets are in the middle of remote bootstrap.</a>
<a name="ln4563">      if (report.has_committed_consensus_state()) {</a>
<a name="ln4564">        ConsensusStatePB cstate = report.committed_consensus_state();</a>
<a name="ln4565">        bool tablet_was_mutated = false;</a>
<a name="ln4566"> </a>
<a name="ln4567">        // 6a. The master only processes reports for replicas with committed</a>
<a name="ln4568">        // consensus configurations since it needs the committed index to only</a>
<a name="ln4569">        // cache the most up-to-date config. Since it's possible for TOMBSTONED</a>
<a name="ln4570">        // replicas with no ConsensusMetadata on disk to be reported as having no</a>
<a name="ln4571">        // committed config opid_index, we skip over those replicas.</a>
<a name="ln4572">        if (!cstate.config().has_opid_index()) {</a>
<a name="ln4573">          LOG(WARNING) &lt;&lt; &quot;Missing opid_index in reported config:\n&quot; &lt;&lt; report.DebugString();</a>
<a name="ln4574">          continue;</a>
<a name="ln4575">        }</a>
<a name="ln4576">        if (PREDICT_TRUE(FLAGS_master_ignore_stale_cstate) &amp;&amp;</a>
<a name="ln4577">              (cstate.current_term() &lt; prev_cstate.current_term() ||</a>
<a name="ln4578">               report_opid_index &lt; prev_opid_index)) {</a>
<a name="ln4579">          LOG(WARNING) &lt;&lt; &quot;Stale heartbeat for Tablet &quot; &lt;&lt; tablet-&gt;ToString()</a>
<a name="ln4580">                       &lt;&lt; &quot; on TS &quot; &lt;&lt; ts_desc-&gt;permanent_uuid()</a>
<a name="ln4581">                       &lt;&lt; &quot;cstate=&quot; &lt;&lt; cstate.ShortDebugString()</a>
<a name="ln4582">                       &lt;&lt; &quot;, prev_cstate=&quot; &lt;&lt; prev_cstate.ShortDebugString();</a>
<a name="ln4583">          continue;</a>
<a name="ln4584">        }</a>
<a name="ln4585"> </a>
<a name="ln4586">        // 6b. Disregard the leader state if the reported leader is not a member</a>
<a name="ln4587">        // of the committed config.</a>
<a name="ln4588">        if (cstate.leader_uuid().empty() ||</a>
<a name="ln4589">            !IsRaftConfigMember(cstate.leader_uuid(), cstate.config())) {</a>
<a name="ln4590">          cstate.clear_leader_uuid();</a>
<a name="ln4591">          tablet_was_mutated = true;</a>
<a name="ln4592">        }</a>
<a name="ln4593"> </a>
<a name="ln4594">        // 6c. Mark the tablet as RUNNING if it makes sense to do so.</a>
<a name="ln4595">        //</a>
<a name="ln4596">        // We need to wait for a leader before marking a tablet as RUNNING, or</a>
<a name="ln4597">        // else we could incorrectly consider a tablet created when only a</a>
<a name="ln4598">        // minority of its replicas were successful. In that case, the tablet</a>
<a name="ln4599">        // would be stuck in this bad state forever.</a>
<a name="ln4600">        // - FLAG added to avoid waiting during mock tests.</a>
<a name="ln4601">        if (!tablet_lock-&gt;data().is_running() &amp;&amp;</a>
<a name="ln4602">            report.state() == tablet::RUNNING &amp;&amp;</a>
<a name="ln4603">              (cstate.has_leader_uuid() ||</a>
<a name="ln4604">              !FLAGS_catalog_manager_wait_for_new_tablets_to_elect_leader)) {</a>
<a name="ln4605">          DCHECK_EQ(SysTabletsEntryPB::CREATING, tablet_lock-&gt;data().pb.state())</a>
<a name="ln4606">              &lt;&lt; &quot;Tablet in unexpected state: &quot; &lt;&lt; tablet-&gt;ToString()</a>
<a name="ln4607">              &lt;&lt; &quot;: &quot; &lt;&lt; tablet_lock-&gt;data().pb.ShortDebugString();</a>
<a name="ln4608">          VLOG(1) &lt;&lt; &quot;Tablet &quot; &lt;&lt; tablet-&gt;ToString() &lt;&lt; &quot; is now online&quot;;</a>
<a name="ln4609">          tablet_lock-&gt;mutable_data()-&gt;set_state(SysTabletsEntryPB::RUNNING,</a>
<a name="ln4610">              &quot;Tablet reported with an active leader&quot;);</a>
<a name="ln4611">          tablet_was_mutated = true;</a>
<a name="ln4612">        }</a>
<a name="ln4613"> </a>
<a name="ln4614">        // 6d. Update the consensus state if:</a>
<a name="ln4615">        // - A config change operation was committed (reflected by a change to</a>
<a name="ln4616">        //   the committed config's opid_index).</a>
<a name="ln4617">        // - The new cstate has a leader, and either the old cstate didn't, or</a>
<a name="ln4618">        //   there was a term change.</a>
<a name="ln4619">        if (cstate.config().opid_index() &gt; prev_cstate.config().opid_index() ||</a>
<a name="ln4620">            (cstate.has_leader_uuid() &amp;&amp;</a>
<a name="ln4621">                (!prev_cstate.has_leader_uuid() ||</a>
<a name="ln4622">                    cstate.current_term() &gt; prev_cstate.current_term()))) {</a>
<a name="ln4623"> </a>
<a name="ln4624">          // 6d(i). Retain knowledge of the leader even if it wasn't reported in</a>
<a name="ln4625">          // the latest config.</a>
<a name="ln4626">          //</a>
<a name="ln4627">          // When a config change is reported to the master, it may not include the</a>
<a name="ln4628">          // leader because the follower doing the reporting may not know who the</a>
<a name="ln4629">          // leader is yet (it may have just started up). It is safe to reuse</a>
<a name="ln4630">          // the previous leader if the reported cstate has the same term as the</a>
<a name="ln4631">          // previous cstate, and the leader was known for that term.</a>
<a name="ln4632">          if (cstate.current_term() == prev_cstate.current_term()) {</a>
<a name="ln4633">            if (!cstate.has_leader_uuid() &amp;&amp; prev_cstate.has_leader_uuid()) {</a>
<a name="ln4634">              cstate.set_leader_uuid(prev_cstate.leader_uuid());</a>
<a name="ln4635">              // Sanity check to detect consensus divergence bugs.</a>
<a name="ln4636">            } else if (cstate.has_leader_uuid() &amp;&amp; prev_cstate.has_leader_uuid() &amp;&amp;</a>
<a name="ln4637">                cstate.leader_uuid() != prev_cstate.leader_uuid()) {</a>
<a name="ln4638">              string msg = Substitute(&quot;Previously reported cstate for tablet $0 gave &quot;</a>
<a name="ln4639">                                      &quot;a different leader for term $1 than the current cstate. &quot;</a>
<a name="ln4640">                                      &quot;Previous cstate: $2. Current cstate: $3.&quot;,</a>
<a name="ln4641">                  tablet-&gt;ToString(), cstate.current_term(),</a>
<a name="ln4642">                  prev_cstate.ShortDebugString(), cstate.ShortDebugString());</a>
<a name="ln4643">              LOG(DFATAL) &lt;&lt; msg;</a>
<a name="ln4644">              continue;</a>
<a name="ln4645">            }</a>
<a name="ln4646">          }</a>
<a name="ln4647"> </a>
<a name="ln4648">          // 6d(ii). Delete any replicas from the previous config that are not in the new one.</a>
<a name="ln4649">          if (FLAGS_master_tombstone_evicted_tablet_replicas) {</a>
<a name="ln4650">            unordered_set&lt;string&gt; current_member_uuids;</a>
<a name="ln4651">            for (const consensus::RaftPeerPB &amp;peer : cstate.config().peers()) {</a>
<a name="ln4652">              InsertOrDie(&amp;current_member_uuids, peer.permanent_uuid());</a>
<a name="ln4653">            }</a>
<a name="ln4654">            for (const consensus::RaftPeerPB &amp;prev_peer : prev_cstate.config().peers()) {</a>
<a name="ln4655">              const string&amp; peer_uuid = prev_peer.permanent_uuid();</a>
<a name="ln4656">              if (!ContainsKey(current_member_uuids, peer_uuid)) {</a>
<a name="ln4657">                // Don't delete a tablet server that hasn't reported in yet (Bootstrapping).</a>
<a name="ln4658">                shared_ptr&lt;TSDescriptor&gt; ts_desc;</a>
<a name="ln4659">                if (!master_-&gt;ts_manager()-&gt;LookupTSByUUID(peer_uuid, &amp;ts_desc)) {</a>
<a name="ln4660">                  continue;</a>
<a name="ln4661">                }</a>
<a name="ln4662">                // Otherwise, the TabletServer needs to remove this peer.</a>
<a name="ln4663">                rpcs.emplace_back(std::make_shared&lt;AsyncDeleteReplica&gt;(</a>
<a name="ln4664">                    master_, AsyncTaskPool(), peer_uuid, table, tablet_id,</a>
<a name="ln4665">                    TABLET_DATA_TOMBSTONED, prev_cstate.config().opid_index(),</a>
<a name="ln4666">                    Substitute(&quot;TS $0 not found in new config with opid_index $1&quot;,</a>
<a name="ln4667">                        peer_uuid, cstate.config().opid_index())));</a>
<a name="ln4668">              }</a>
<a name="ln4669">            }</a>
<a name="ln4670">          }</a>
<a name="ln4671">          // 6d(iii). Update the in-memory ReplicaLocations for this tablet using the new config.</a>
<a name="ln4672">          VLOG(2) &lt;&lt; &quot;Updating replicas for tablet &quot; &lt;&lt; tablet_id</a>
<a name="ln4673">                &lt;&lt; &quot; using config reported by &quot; &lt;&lt; ts_desc-&gt;permanent_uuid()</a>
<a name="ln4674">                &lt;&lt; &quot; to that committed in log index &quot; &lt;&lt; cstate.config().opid_index()</a>
<a name="ln4675">                &lt;&lt; &quot; with leader state from term &quot; &lt;&lt; cstate.current_term();</a>
<a name="ln4676">          ReconcileTabletReplicasInLocalMemoryWithReport(</a>
<a name="ln4677">            tablet, ts_desc-&gt;permanent_uuid(), cstate, report.state());</a>
<a name="ln4678"> </a>
<a name="ln4679">          // 6d(iv). Update the consensus state. Don't use 'prev_cstate' after this.</a>
<a name="ln4680">          LOG(INFO) &lt;&lt; &quot;Tablet: &quot; &lt;&lt; tablet-&gt;tablet_id() &lt;&lt; &quot; reported consensus state change.&quot;</a>
<a name="ln4681">                    &lt;&lt; &quot; New consensus state: &quot; &lt;&lt; cstate.ShortDebugString()</a>
<a name="ln4682">                    &lt;&lt; &quot; from &quot; &lt;&lt; ts_desc-&gt;permanent_uuid();</a>
<a name="ln4683">          DCHECK(tablet_lock-&gt;is_write_locked());</a>
<a name="ln4684">          *tablet_lock-&gt;mutable_data()-&gt;pb.mutable_committed_consensus_state() = cstate;</a>
<a name="ln4685">          tablet_was_mutated = true;</a>
<a name="ln4686">        } else {</a>
<a name="ln4687">          // Report opid_index is equal to the previous opid_index. If some</a>
<a name="ln4688">          // replica is reporting the same consensus configuration we already know about, but we</a>
<a name="ln4689">          // haven't yet heard from all the tservers in the config, update the in-memory</a>
<a name="ln4690">          // ReplicaLocations.</a>
<a name="ln4691">          LOG(INFO) &lt;&lt; &quot;Peer &quot; &lt;&lt; ts_desc-&gt;permanent_uuid() &lt;&lt; &quot; sent &quot;</a>
<a name="ln4692">                    &lt;&lt; (full_report.is_incremental() ? &quot;incremental&quot; : &quot;full tablet&quot;)</a>
<a name="ln4693">                    &lt;&lt; &quot; report for &quot; &lt;&lt; tablet-&gt;tablet_id()</a>
<a name="ln4694">                    &lt;&lt; &quot;, prev state op id: &quot; &lt;&lt; prev_cstate.config().opid_index()</a>
<a name="ln4695">                    &lt;&lt; &quot;, prev state term: &quot; &lt;&lt; prev_cstate.current_term()</a>
<a name="ln4696">                    &lt;&lt; &quot;, prev state has_leader_uuid: &quot; &lt;&lt; prev_cstate.has_leader_uuid()</a>
<a name="ln4697">                    &lt;&lt; &quot;. Consensus state: &quot; &lt;&lt; cstate.ShortDebugString();</a>
<a name="ln4698">          if (GetAtomicFlag(&amp;FLAGS_enable_register_ts_from_raft) &amp;&amp;</a>
<a name="ln4699">              ReplicaMapDiffersFromConsensusState(tablet, cstate)) {</a>
<a name="ln4700">             ReconcileTabletReplicasInLocalMemoryWithReport(</a>
<a name="ln4701">               tablet, ts_desc-&gt;permanent_uuid(), cstate, report.state());</a>
<a name="ln4702">          } else {</a>
<a name="ln4703">            UpdateTabletReplicaInLocalMemory(ts_desc, &amp;cstate, report.state(), tablet);</a>
<a name="ln4704">          }</a>
<a name="ln4705">        }</a>
<a name="ln4706"> </a>
<a name="ln4707">        // 7. Send an AlterSchema RPC if the tablet has an old schema version.</a>
<a name="ln4708">        if (report.has_schema_version() &amp;&amp;</a>
<a name="ln4709">            report.schema_version() != table_lock-&gt;data().pb.version()) {</a>
<a name="ln4710">          if (report.schema_version() &gt; table_lock-&gt;data().pb.version()) {</a>
<a name="ln4711">            LOG(ERROR) &lt;&lt; &quot;TS &quot; &lt;&lt; ts_desc-&gt;permanent_uuid()</a>
<a name="ln4712">                       &lt;&lt; &quot; has reported a schema version greater than the current one &quot;</a>
<a name="ln4713">                       &lt;&lt; &quot; for tablet &quot; &lt;&lt; tablet-&gt;ToString()</a>
<a name="ln4714">                       &lt;&lt; &quot;. Expected version &quot; &lt;&lt; table_lock-&gt;data().pb.version()</a>
<a name="ln4715">                       &lt;&lt; &quot; got &quot; &lt;&lt; report.schema_version()</a>
<a name="ln4716">                       &lt;&lt; &quot; (corruption)&quot;;</a>
<a name="ln4717">          } else {</a>
<a name="ln4718">            // TODO: For Alter (rolling apply to tablets), this is an expected transitory state.</a>
<a name="ln4719">            LOG(INFO) &lt;&lt; &quot;TS &quot; &lt;&lt; ts_desc-&gt;permanent_uuid()</a>
<a name="ln4720">                      &lt;&lt; &quot; does not have the latest schema for tablet &quot; &lt;&lt; tablet-&gt;ToString()</a>
<a name="ln4721">                      &lt;&lt; &quot;. Expected version &quot; &lt;&lt; table_lock-&gt;data().pb.version()</a>
<a name="ln4722">                      &lt;&lt; &quot; got &quot; &lt;&lt; report.schema_version();</a>
<a name="ln4723">          }</a>
<a name="ln4724">          // It's possible that the tablet being reported is a laggy replica, and in fact</a>
<a name="ln4725">          // the leader has already received an AlterTable RPC. That's OK, though --</a>
<a name="ln4726">          // it'll safely ignore it if we send another.</a>
<a name="ln4727">          rpcs.emplace_back(std::make_shared&lt;AsyncAlterTable&gt;(master_, AsyncTaskPool(), tablet));</a>
<a name="ln4728">        }</a>
<a name="ln4729"> </a>
<a name="ln4730">        // 8. If the tablet was mutated, add it to the tablets to be re-persisted.</a>
<a name="ln4731">        //</a>
<a name="ln4732">        // Done here and not on a per-mutation basis to avoid duplicate entries.</a>
<a name="ln4733">        if (tablet_was_mutated) {</a>
<a name="ln4734">          mutated_tablets.push_back(tablet.get());</a>
<a name="ln4735">        }</a>
<a name="ln4736">      } else if (full_report.is_incremental() &amp;&amp;</a>
<a name="ln4737">          (report.state() == tablet::NOT_STARTED || report.state() == tablet::BOOTSTRAPPING)) {</a>
<a name="ln4738">        // When a tablet server is restarted, it sends a full tablet report with all of its tablets</a>
<a name="ln4739">        // in the NOT_STARTED state, so this would make the load balancer think that all the</a>
<a name="ln4740">        // tablets are being remote bootstrapped at once, so only process incremental reports here.</a>
<a name="ln4741">        UpdateTabletReplicaInLocalMemory(ts_desc, nullptr /* consensus */, report.state(), tablet);</a>
<a name="ln4742">      }</a>
<a name="ln4743">    } // Finished one round of batch processing.</a>
<a name="ln4744"> </a>
<a name="ln4745">    // 9. Unlock the tables; we no longer need to access their state.</a>
<a name="ln4746">    for (auto&amp; l : table_read_locks) {</a>
<a name="ln4747">      l.second-&gt;Unlock();</a>
<a name="ln4748">    }</a>
<a name="ln4749">    table_read_locks.clear();</a>
<a name="ln4750"> </a>
<a name="ln4751">    // 10. Write all tablet mutations to the catalog table.</a>
<a name="ln4752">    //</a>
<a name="ln4753">    // SysCatalogTable::Write will short-circuit the case where the data has not</a>
<a name="ln4754">    // in fact changed since the previous version and avoid any unnecessary mutations.</a>
<a name="ln4755">    if (!mutated_tablets.empty()) {</a>
<a name="ln4756">      Status s = sys_catalog_-&gt;UpdateItems(mutated_tablets, leader_ready_term());</a>
<a name="ln4757">      if (!s.ok()) {</a>
<a name="ln4758">        LOG(WARNING) &lt;&lt; &quot;Error updating tablets: &quot; &lt;&lt; s.ToString() &lt;&lt; &quot;. Tablet report was: &quot;</a>
<a name="ln4759">                     &lt;&lt; full_report.ShortDebugString();</a>
<a name="ln4760">        return s;</a>
<a name="ln4761">      }</a>
<a name="ln4762">    }</a>
<a name="ln4763"> </a>
<a name="ln4764">    // 11. Publish the in-memory tablet mutations and release the locks.</a>
<a name="ln4765">    for (auto&amp; l : tablet_write_locks) {</a>
<a name="ln4766">      l.second-&gt;Commit();</a>
<a name="ln4767">    }</a>
<a name="ln4768">    tablet_write_locks.clear();</a>
<a name="ln4769"> </a>
<a name="ln4770">    // 12. Third Pass. Process all tablet schema version changes.</a>
<a name="ln4771">    // (This is separate from tablet state mutations because only table on-disk state is changed.)</a>
<a name="ln4772">    for (auto i = 0;</a>
<a name="ln4773">        i &lt; FLAGS_catalog_manager_report_batch_size</a>
<a name="ln4774">          &amp;&amp; tablet_iter_for_schema_changes != tablet_infos.end();</a>
<a name="ln4775">        ++i, ++tablet_iter_for_schema_changes) {</a>
<a name="ln4776">      const string&amp; tablet_id = tablet_iter_for_schema_changes-&gt;first;</a>
<a name="ln4777">      const scoped_refptr&lt;TabletInfo&gt;&amp; tablet = tablet_iter_for_schema_changes-&gt;second;</a>
<a name="ln4778">      const ReportedTabletPB&amp; report = *FindOrDie(reports, tablet_id);</a>
<a name="ln4779">      if (report.has_schema_version()) {</a>
<a name="ln4780">        auto leader = tablet-&gt;GetLeader();</a>
<a name="ln4781">        if (leader.ok() &amp;&amp; leader.get()-&gt;permanent_uuid() == ts_desc-&gt;permanent_uuid()) {</a>
<a name="ln4782">          RETURN_NOT_OK(HandleTabletSchemaVersionReport(tablet.get(), report.schema_version()));</a>
<a name="ln4783">        }</a>
<a name="ln4784">      }</a>
<a name="ln4785">    }</a>
<a name="ln4786"> </a>
<a name="ln4787">    // 13. Send all queued RPCs.</a>
<a name="ln4788">    for (auto&amp; rpc : rpcs) {</a>
<a name="ln4789">      DCHECK(rpc-&gt;table());</a>
<a name="ln4790">      rpc-&gt;table()-&gt;AddTask(rpc);</a>
<a name="ln4791">      WARN_NOT_OK(rpc-&gt;Run(), Substitute(&quot;Failed to send $0&quot;, rpc-&gt;description()));</a>
<a name="ln4792">    }</a>
<a name="ln4793">    rpcs.clear();</a>
<a name="ln4794">  } // Loop to process the next batch until fully iterated.</a>
<a name="ln4795"> </a>
<a name="ln4796">  if (!full_report.is_incremental()) {</a>
<a name="ln4797">    if (full_report.updated_tablets_size() == 0) {</a>
<a name="ln4798">      LOG(INFO) &lt;&lt; ts_desc-&gt;permanent_uuid() &lt;&lt; &quot; sent full tablet report with 0 tablets.&quot;;</a>
<a name="ln4799">    } else if (!ts_desc-&gt;has_tablet_report()) {</a>
<a name="ln4800">      LOG(INFO) &lt;&lt; ts_desc-&gt;permanent_uuid() &lt;&lt; &quot; now has it's first full report: &quot;</a>
<a name="ln4801">                &lt;&lt; full_report.updated_tablets_size() &lt;&lt; &quot; tablets.&quot;;</a>
<a name="ln4802">    }</a>
<a name="ln4803">    // Do not unset full tablet report missing for ts desc for an incremental case.</a>
<a name="ln4804">    ts_desc-&gt;set_has_tablet_report(true);</a>
<a name="ln4805">  }</a>
<a name="ln4806"> </a>
<a name="ln4807">  // 14. Queue background processing if we had updates.</a>
<a name="ln4808">  if (full_report.updated_tablets_size() &gt; 0) {</a>
<a name="ln4809">    background_tasks_-&gt;WakeIfHasPendingUpdates();</a>
<a name="ln4810">  }</a>
<a name="ln4811"> </a>
<a name="ln4812">  return Status::OK();</a>
<a name="ln4813">}</a>
<a name="ln4814"> </a>
<a name="ln4815">Status CatalogManager::CreateTablegroup(const CreateTablegroupRequestPB* req,</a>
<a name="ln4816">                                        CreateTablegroupResponsePB* resp,</a>
<a name="ln4817">                                        rpc::RpcContext* rpc) {</a>
<a name="ln4818"> </a>
<a name="ln4819">  CreateTableRequestPB ctreq;</a>
<a name="ln4820">  CreateTableResponsePB ctresp;</a>
<a name="ln4821"> </a>
<a name="ln4822">  // Sanity check for PB fields.</a>
<a name="ln4823">  if (!req-&gt;has_id() || !req-&gt;has_namespace_id() || !req-&gt;has_namespace_name()) {</a>
<a name="ln4824">    Status s = STATUS(InvalidArgument, &quot;Improper CREATE TABLEGROUP request (missing fields).&quot;);</a>
<a name="ln4825">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA, s);</a>
<a name="ln4826">  }</a>
<a name="ln4827"> </a>
<a name="ln4828">  // Use the tablegroup id as the prefix for the parent table id.</a>
<a name="ln4829">  const auto parent_table_id = req-&gt;id() + kTablegroupParentTableIdSuffix;</a>
<a name="ln4830">  const auto parent_table_name = req-&gt;id() + kTablegroupParentTableNameSuffix;</a>
<a name="ln4831">  ctreq.set_name(parent_table_name);</a>
<a name="ln4832">  ctreq.set_table_id(parent_table_id);</a>
<a name="ln4833">  ctreq.mutable_namespace_()-&gt;set_name(req-&gt;namespace_name());</a>
<a name="ln4834">  ctreq.mutable_namespace_()-&gt;set_id(req-&gt;namespace_id());</a>
<a name="ln4835">  ctreq.set_table_type(PGSQL_TABLE_TYPE);</a>
<a name="ln4836">  ctreq.set_tablegroup_id(req-&gt;id());</a>
<a name="ln4837"> </a>
<a name="ln4838">  YBSchemaBuilder schemaBuilder;</a>
<a name="ln4839">  schemaBuilder.AddColumn(&quot;parent_column&quot;)-&gt;Type(BINARY)-&gt;PrimaryKey()-&gt;NotNull();</a>
<a name="ln4840">  YBSchema ybschema;</a>
<a name="ln4841">  CHECK_OK(schemaBuilder.Build(&amp;ybschema));</a>
<a name="ln4842">  auto schema = yb::client::internal::GetSchema(ybschema);</a>
<a name="ln4843">  SchemaToPB(schema, ctreq.mutable_schema());</a>
<a name="ln4844">  if (!FLAGS_TEST_tablegroup_master_only) {</a>
<a name="ln4845">    ctreq.mutable_schema()-&gt;mutable_table_properties()-&gt;set_is_transactional(true);</a>
<a name="ln4846">  }</a>
<a name="ln4847"> </a>
<a name="ln4848">  // Create a parent table, which will create the tablet.</a>
<a name="ln4849">  Status s = CreateTable(&amp;ctreq, &amp;ctresp, rpc);</a>
<a name="ln4850">  resp-&gt;set_parent_table_id(ctresp.table_id());</a>
<a name="ln4851">  resp-&gt;set_parent_table_name(parent_table_name);</a>
<a name="ln4852"> </a>
<a name="ln4853">  // Carry over error.</a>
<a name="ln4854">  if (ctresp.has_error()) {</a>
<a name="ln4855">    resp-&gt;mutable_error()-&gt;Swap(ctresp.mutable_error());</a>
<a name="ln4856">  }</a>
<a name="ln4857"> </a>
<a name="ln4858">  // We do not lock here so it is technically possible that the table was already created.</a>
<a name="ln4859">  // If so, there is nothing to do so we just ignore the &quot;AlreadyPresent&quot; error.</a>
<a name="ln4860">  if (!s.ok() &amp;&amp; !s.IsAlreadyPresent()) {</a>
<a name="ln4861">    LOG(WARNING) &lt;&lt; &quot;Tablegroup creation failed: &quot; &lt;&lt; s.ToString();</a>
<a name="ln4862">    return s;</a>
<a name="ln4863">  }</a>
<a name="ln4864"> </a>
<a name="ln4865">  // Update catalog manager maps</a>
<a name="ln4866">  SharedLock&lt;LockType&gt; catalog_lock(lock_);</a>
<a name="ln4867">  TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln4868">  TablegroupInfo *tg = new TablegroupInfo(req-&gt;id(), req-&gt;namespace_id());</a>
<a name="ln4869">  tablegroup_ids_map_[req-&gt;id()] = tg;</a>
<a name="ln4870"> </a>
<a name="ln4871">  return s;</a>
<a name="ln4872">}</a>
<a name="ln4873"> </a>
<a name="ln4874">Status CatalogManager::DeleteTablegroup(const DeleteTablegroupRequestPB* req,</a>
<a name="ln4875">                                        DeleteTablegroupResponsePB* resp,</a>
<a name="ln4876">                                        rpc::RpcContext* rpc) {</a>
<a name="ln4877">  DeleteTableRequestPB dtreq;</a>
<a name="ln4878">  DeleteTableResponsePB dtresp;</a>
<a name="ln4879"> </a>
<a name="ln4880">  // Sanity check for PB fields</a>
<a name="ln4881">  if (!req-&gt;has_id() || !req-&gt;has_namespace_id()) {</a>
<a name="ln4882">    Status s = STATUS(InvalidArgument, &quot;Improper DELETE TABLEGROUP request (missing fields).&quot;);</a>
<a name="ln4883">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA, s);</a>
<a name="ln4884">  }</a>
<a name="ln4885"> </a>
<a name="ln4886">  // Use the tablegroup id as the prefix for the parent table id.</a>
<a name="ln4887">  const auto parent_table_id = req-&gt;id() + kTablegroupParentTableIdSuffix;</a>
<a name="ln4888">  const auto parent_table_name = req-&gt;id() + kTablegroupParentTableNameSuffix;</a>
<a name="ln4889"> </a>
<a name="ln4890">  dtreq.mutable_table()-&gt;set_table_name(parent_table_name);</a>
<a name="ln4891">  dtreq.mutable_table()-&gt;set_table_id(parent_table_id);</a>
<a name="ln4892">  dtreq.set_is_index_table(false);</a>
<a name="ln4893"> </a>
<a name="ln4894">  Status s = DeleteTable(&amp;dtreq, &amp;dtresp, rpc);</a>
<a name="ln4895">  resp-&gt;set_parent_table_id(dtresp.table_id());</a>
<a name="ln4896"> </a>
<a name="ln4897">  // Carry over error.</a>
<a name="ln4898">  if (dtresp.has_error()) {</a>
<a name="ln4899">    resp-&gt;mutable_error()-&gt;Swap(dtresp.mutable_error());</a>
<a name="ln4900">    return s;</a>
<a name="ln4901">  }</a>
<a name="ln4902"> </a>
<a name="ln4903">  // Perform map updates.</a>
<a name="ln4904">  SharedLock&lt;LockType&gt; catalog_lock(lock_);</a>
<a name="ln4905">  TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln4906">  tablegroup_ids_map_.erase(req-&gt;id());</a>
<a name="ln4907">  tablegroup_tablet_ids_map_[req-&gt;namespace_id()].erase(req-&gt;id());</a>
<a name="ln4908"> </a>
<a name="ln4909">  LOG(INFO) &lt;&lt; &quot;Deleted table &quot; &lt;&lt; parent_table_name;</a>
<a name="ln4910">  return s;</a>
<a name="ln4911">}</a>
<a name="ln4912"> </a>
<a name="ln4913">Status CatalogManager::ListTablegroups(const ListTablegroupsRequestPB* req,</a>
<a name="ln4914">                                       ListTablegroupsResponsePB* resp,</a>
<a name="ln4915">                                       rpc::RpcContext* rpc) {</a>
<a name="ln4916">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln4917"> </a>
<a name="ln4918">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln4919"> </a>
<a name="ln4920">  if (!req-&gt;has_namespace_id()) {</a>
<a name="ln4921">    Status s = STATUS(InvalidArgument, &quot;Improper ListTablegroups request (missing fields).&quot;);</a>
<a name="ln4922">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_SCHEMA, s);</a>
<a name="ln4923">  }</a>
<a name="ln4924"> </a>
<a name="ln4925">  if (tablegroup_tablet_ids_map_.find(req-&gt;namespace_id()) == tablegroup_tablet_ids_map_.end()) {</a>
<a name="ln4926">    return STATUS(NotFound, &quot;Tablegroups not found for namespace id: &quot;, req-&gt;namespace_id());</a>
<a name="ln4927">  }</a>
<a name="ln4928"> </a>
<a name="ln4929">  for (const auto&amp; entry : tablegroup_tablet_ids_map_[req-&gt;namespace_id()]) {</a>
<a name="ln4930">    const TablegroupId tgid = entry.first;</a>
<a name="ln4931">    if (tablegroup_ids_map_.find(tgid) == tablegroup_ids_map_.end()) {</a>
<a name="ln4932">      LOG(WARNING) &lt;&lt; &quot;Tablegroup info in &quot; &lt;&lt; req-&gt;namespace_id()</a>
<a name="ln4933">                   &lt;&lt; &quot; not found for tablegroup id: &quot; &lt;&lt; tgid;</a>
<a name="ln4934">      continue;</a>
<a name="ln4935">    }</a>
<a name="ln4936">    scoped_refptr&lt;TablegroupInfo&gt; tginfo = tablegroup_ids_map_[tgid];</a>
<a name="ln4937"> </a>
<a name="ln4938">    TablegroupIdentifierPB *tg = resp-&gt;add_tablegroups();</a>
<a name="ln4939">    tg-&gt;set_id(tginfo-&gt;id());</a>
<a name="ln4940">    tg-&gt;set_namespace_id(tginfo-&gt;namespace_id());</a>
<a name="ln4941">  }</a>
<a name="ln4942">  return Status::OK();</a>
<a name="ln4943">}</a>
<a name="ln4944"> </a>
<a name="ln4945">bool CatalogManager::HasTablegroups() {</a>
<a name="ln4946">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln4947">  return !tablegroup_ids_map_.empty();</a>
<a name="ln4948">}</a>
<a name="ln4949"> </a>
<a name="ln4950">Status CatalogManager::CreateNamespace(const CreateNamespaceRequestPB* req,</a>
<a name="ln4951">                                       CreateNamespaceResponsePB* resp,</a>
<a name="ln4952">                                       rpc::RpcContext* rpc) {</a>
<a name="ln4953">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln4954">  Status return_status;</a>
<a name="ln4955"> </a>
<a name="ln4956">  // Copy the request, so we can fill in some defaults.</a>
<a name="ln4957">  LOG(INFO) &lt;&lt; &quot;CreateNamespace from &quot; &lt;&lt; RequestorString(rpc)</a>
<a name="ln4958">            &lt;&lt; &quot;: &quot; &lt;&lt; req-&gt;DebugString();</a>
<a name="ln4959"> </a>
<a name="ln4960">  scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln4961">  std::vector&lt;scoped_refptr&lt;TableInfo&gt;&gt; pgsql_tables;</a>
<a name="ln4962">  const auto db_type = GetDatabaseType(*req);</a>
<a name="ln4963">  {</a>
<a name="ln4964">    std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln4965">    TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln4966"> </a>
<a name="ln4967">    // Validate the user request.</a>
<a name="ln4968"> </a>
<a name="ln4969">    // Verify that the namespace does not already exist.</a>
<a name="ln4970">    ns = FindPtrOrNull(namespace_ids_map_, req-&gt;namespace_id()); // Same ID.</a>
<a name="ln4971">    if (ns == nullptr &amp;&amp; db_type != YQL_DATABASE_PGSQL) {</a>
<a name="ln4972">      // PGSQL databases have name uniqueness handled at a different layer, so ignore overlaps.</a>
<a name="ln4973">      ns = FindPtrOrNull(namespace_names_mapper_[db_type], req-&gt;name());</a>
<a name="ln4974">    }</a>
<a name="ln4975">    if (ns != nullptr) {</a>
<a name="ln4976">      resp-&gt;set_id(ns-&gt;id());</a>
<a name="ln4977">      return_status = STATUS_SUBSTITUTE(AlreadyPresent, &quot;Keyspace '$0' already exists&quot;,</a>
<a name="ln4978">                                        req-&gt;name());</a>
<a name="ln4979">      LOG(WARNING) &lt;&lt; &quot;Found keyspace: &quot; &lt;&lt; ns-&gt;id() &lt;&lt; &quot;. Failed creating keyspace with error: &quot;</a>
<a name="ln4980">                   &lt;&lt; return_status.ToString() &lt;&lt; &quot; Request:\n&quot; &lt;&lt; req-&gt;DebugString();</a>
<a name="ln4981">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_ALREADY_PRESENT,</a>
<a name="ln4982">                        return_status);</a>
<a name="ln4983">    }</a>
<a name="ln4984"> </a>
<a name="ln4985">    // Add the new namespace.</a>
<a name="ln4986"> </a>
<a name="ln4987">    // Create unique id for this new namespace.</a>
<a name="ln4988">    NamespaceId new_id = !req-&gt;namespace_id().empty() ? req-&gt;namespace_id()</a>
<a name="ln4989">                                                      : GenerateIdUnlocked(SysRowEntry::NAMESPACE);</a>
<a name="ln4990">    ns = new NamespaceInfo(new_id);</a>
<a name="ln4991">    ns-&gt;mutable_metadata()-&gt;StartMutation();</a>
<a name="ln4992">    SysNamespaceEntryPB *metadata = &amp;ns-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb;</a>
<a name="ln4993">    metadata-&gt;set_name(req-&gt;name());</a>
<a name="ln4994">    metadata-&gt;set_database_type(db_type);</a>
<a name="ln4995">    metadata-&gt;set_colocated(req-&gt;colocated());</a>
<a name="ln4996">    metadata-&gt;set_state(SysNamespaceEntryPB::PREPARING);</a>
<a name="ln4997"> </a>
<a name="ln4998">    // For namespace created for a Postgres database, save the list of tables and indexes for</a>
<a name="ln4999">    // for the database that need to be copied.</a>
<a name="ln5000">    if (db_type == YQL_DATABASE_PGSQL) {</a>
<a name="ln5001">      if (req-&gt;source_namespace_id().empty()) {</a>
<a name="ln5002">        metadata-&gt;set_next_pg_oid(req-&gt;next_pg_oid());</a>
<a name="ln5003">      } else {</a>
<a name="ln5004">        const auto source_oid = GetPgsqlDatabaseOid(req-&gt;source_namespace_id());</a>
<a name="ln5005">        if (!source_oid.ok()) {</a>
<a name="ln5006">          return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_NOT_FOUND,</a>
<a name="ln5007">                            source_oid.status());</a>
<a name="ln5008">        }</a>
<a name="ln5009">        for (const auto&amp; iter : *table_ids_map_) {</a>
<a name="ln5010">          const auto&amp; table_id = iter.first;</a>
<a name="ln5011">          const auto&amp; table = iter.second;</a>
<a name="ln5012">          if (IsPgsqlId(table_id) &amp;&amp; CHECK_RESULT(GetPgsqlDatabaseOid(table_id)) == *source_oid) {</a>
<a name="ln5013">            // Since indexes have dependencies on the base tables, put the tables in the front.</a>
<a name="ln5014">            const bool is_table = table-&gt;indexed_table_id().empty();</a>
<a name="ln5015">            pgsql_tables.insert(is_table ? pgsql_tables.begin() : pgsql_tables.end(), table);</a>
<a name="ln5016">          }</a>
<a name="ln5017">        }</a>
<a name="ln5018"> </a>
<a name="ln5019">        scoped_refptr&lt;NamespaceInfo&gt; source_ns = FindPtrOrNull(namespace_ids_map_,</a>
<a name="ln5020">                                                               req-&gt;source_namespace_id());</a>
<a name="ln5021">        if (!source_ns) {</a>
<a name="ln5022">          return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_NOT_FOUND,</a>
<a name="ln5023">                            STATUS(NotFound, &quot;Source keyspace not found&quot;,</a>
<a name="ln5024">                                   req-&gt;source_namespace_id()));</a>
<a name="ln5025">        }</a>
<a name="ln5026">        auto source_ns_lock = source_ns-&gt;LockForRead();</a>
<a name="ln5027">        metadata-&gt;set_next_pg_oid(source_ns_lock-&gt;data().pb.next_pg_oid());</a>
<a name="ln5028">      }</a>
<a name="ln5029">    }</a>
<a name="ln5030"> </a>
<a name="ln5031">    // Add the namespace to the in-memory map for the assignment.</a>
<a name="ln5032">    namespace_ids_map_[ns-&gt;id()] = ns;</a>
<a name="ln5033">    namespace_names_mapper_[db_type][req-&gt;name()] = ns;</a>
<a name="ln5034"> </a>
<a name="ln5035">    resp-&gt;set_id(ns-&gt;id());</a>
<a name="ln5036">  }</a>
<a name="ln5037">  TRACE(&quot;Inserted new keyspace info into CatalogManager maps&quot;);</a>
<a name="ln5038"> </a>
<a name="ln5039">  // Update the on-disk system catalog.</a>
<a name="ln5040">  return_status = sys_catalog_-&gt;AddItem(ns.get(), leader_ready_term());</a>
<a name="ln5041">  if (!return_status.ok()) {</a>
<a name="ln5042">    LOG(WARNING) &lt;&lt; &quot;Keyspace creation failed:&quot; &lt;&lt; return_status.ToString();</a>
<a name="ln5043">    {</a>
<a name="ln5044">      std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln5045">      namespace_ids_map_.erase(ns-&gt;id());</a>
<a name="ln5046">      namespace_names_mapper_[db_type].erase(req-&gt;name());</a>
<a name="ln5047">    }</a>
<a name="ln5048">    ns-&gt;mutable_metadata()-&gt;AbortMutation();</a>
<a name="ln5049">    return CheckIfNoLongerLeaderAndSetupError(return_status, resp);</a>
<a name="ln5050">  }</a>
<a name="ln5051">  TRACE(&quot;Wrote keyspace to sys-catalog&quot;);</a>
<a name="ln5052">  // Commit the namespace in-memory state.</a>
<a name="ln5053">  ns-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln5054"> </a>
<a name="ln5055">  LOG(INFO) &lt;&lt; &quot;Created keyspace &quot; &lt;&lt; ns-&gt;ToString();</a>
<a name="ln5056"> </a>
<a name="ln5057">  if (req-&gt;has_creator_role_name()) {</a>
<a name="ln5058">    RETURN_NOT_OK(permissions_manager_-&gt;GrantPermissions(</a>
<a name="ln5059">        req-&gt;creator_role_name(),</a>
<a name="ln5060">        get_canonical_keyspace(req-&gt;name()),</a>
<a name="ln5061">        req-&gt;name() /* resource name */,</a>
<a name="ln5062">        req-&gt;name() /* keyspace name */,</a>
<a name="ln5063">        all_permissions_for_resource(ResourceType::KEYSPACE),</a>
<a name="ln5064">        ResourceType::KEYSPACE,</a>
<a name="ln5065">        resp));</a>
<a name="ln5066">  }</a>
<a name="ln5067"> </a>
<a name="ln5068">  // Colocated databases need to create a parent tablet to serve as the base storage location.</a>
<a name="ln5069">  if (req-&gt;colocated()) {</a>
<a name="ln5070">    CreateTableRequestPB req;</a>
<a name="ln5071">    CreateTableResponsePB resp;</a>
<a name="ln5072">    const auto parent_table_id = ns-&gt;id() + kColocatedParentTableIdSuffix;</a>
<a name="ln5073">    const auto parent_table_name = ns-&gt;id() + kColocatedParentTableNameSuffix;</a>
<a name="ln5074">    req.set_name(parent_table_name);</a>
<a name="ln5075">    req.set_table_id(parent_table_id);</a>
<a name="ln5076">    req.mutable_namespace_()-&gt;set_name(ns-&gt;name());</a>
<a name="ln5077">    req.mutable_namespace_()-&gt;set_id(ns-&gt;id());</a>
<a name="ln5078">    req.set_table_type(GetTableTypeForDatabase(ns-&gt;database_type()));</a>
<a name="ln5079">    req.set_colocated(true);</a>
<a name="ln5080"> </a>
<a name="ln5081">    YBSchemaBuilder schemaBuilder;</a>
<a name="ln5082">    schemaBuilder.AddColumn(&quot;parent_column&quot;)-&gt;Type(BINARY)-&gt;PrimaryKey()-&gt;NotNull();</a>
<a name="ln5083">    YBSchema ybschema;</a>
<a name="ln5084">    CHECK_OK(schemaBuilder.Build(&amp;ybschema));</a>
<a name="ln5085">    auto schema = yb::client::internal::GetSchema(ybschema);</a>
<a name="ln5086">    SchemaToPB(schema, req.mutable_schema());</a>
<a name="ln5087">    req.mutable_schema()-&gt;mutable_table_properties()-&gt;set_is_transactional(true);</a>
<a name="ln5088"> </a>
<a name="ln5089">    // create a parent table, which will create the tablet.</a>
<a name="ln5090">    Status s = CreateTable(&amp;req, &amp;resp, rpc);</a>
<a name="ln5091">    // We do not lock here so it is technically possible that the table was already created.</a>
<a name="ln5092">    // If so, there is nothing to do so we just ignore the &quot;AlreadyPresent&quot; error.</a>
<a name="ln5093">    if (!s.ok() &amp;&amp; !s.IsAlreadyPresent()) {</a>
<a name="ln5094">      LOG(WARNING) &lt;&lt; &quot;Keyspace creation failed:&quot; &lt;&lt; s.ToString();</a>
<a name="ln5095">      // TODO: We should verify this behavior works end-to-end.</a>
<a name="ln5096">      // Diverging in-memory state from disk so the user can issue a delete if no new leader.</a>
<a name="ln5097">      auto l = ns-&gt;LockForWrite();</a>
<a name="ln5098">      SysNamespaceEntryPB&amp; metadata = ns-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb;</a>
<a name="ln5099">      metadata.set_state(SysNamespaceEntryPB::FAILED);</a>
<a name="ln5100">      l-&gt;Commit();</a>
<a name="ln5101">      return s;</a>
<a name="ln5102">    }</a>
<a name="ln5103">  }</a>
<a name="ln5104"> </a>
<a name="ln5105">  if ((db_type == YQL_DATABASE_PGSQL &amp;&amp; !pgsql_tables.empty()) ||</a>
<a name="ln5106">      PREDICT_FALSE(GetAtomicFlag(&amp;FLAGS_TEST_hang_on_namespace_transition))) {</a>
<a name="ln5107">    // Process the subsequent work in the background thread (normally PGSQL).</a>
<a name="ln5108">    LOG(INFO) &lt;&lt; &quot;Keyspace create enqueued for later processing: &quot; &lt;&lt; ns-&gt;ToString();</a>
<a name="ln5109">    RETURN_NOT_OK(background_tasks_thread_pool_-&gt;SubmitFunc(</a>
<a name="ln5110">        std::bind(&amp;CatalogManager::ProcessPendingNamespace, this, ns-&gt;id(), pgsql_tables)));</a>
<a name="ln5111">    return Status::OK();</a>
<a name="ln5112">  } else {</a>
<a name="ln5113">    // All work is done, it's now safe to online the namespace (normally YQL).</a>
<a name="ln5114">    auto l = ns-&gt;LockForWrite();</a>
<a name="ln5115">    SysNamespaceEntryPB&amp; metadata = ns-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb;</a>
<a name="ln5116">    if (metadata.state() == SysNamespaceEntryPB::PREPARING) {</a>
<a name="ln5117">      metadata.set_state(SysNamespaceEntryPB::RUNNING);</a>
<a name="ln5118">      return_status = sys_catalog_-&gt;UpdateItem(ns.get(), leader_ready_term());</a>
<a name="ln5119">      if (!return_status.ok()) {</a>
<a name="ln5120">        // Diverging in-memory state from disk so the user can issue a delete if no new leader.</a>
<a name="ln5121">        LOG(WARNING) &lt;&lt; &quot;Keyspace creation failed:&quot; &lt;&lt; return_status.ToString();</a>
<a name="ln5122">        metadata.set_state(SysNamespaceEntryPB::FAILED);</a>
<a name="ln5123">        return_status = CheckIfNoLongerLeaderAndSetupError(return_status, resp);</a>
<a name="ln5124">      } else {</a>
<a name="ln5125">        TRACE(&quot;Activated keyspace in sys-catalog&quot;);</a>
<a name="ln5126">        LOG(INFO) &lt;&lt; &quot;Activated keyspace: &quot; &lt;&lt; ns-&gt;ToString();</a>
<a name="ln5127">      }</a>
<a name="ln5128">      // Commit the namespace in-memory state.</a>
<a name="ln5129">      l-&gt;Commit();</a>
<a name="ln5130">    } else {</a>
<a name="ln5131">      LOG(WARNING) &lt;&lt; &quot;Keyspace has invalid state (&quot; &lt;&lt; metadata.state() &lt;&lt; &quot;), aborting create&quot;;</a>
<a name="ln5132">    }</a>
<a name="ln5133">  }</a>
<a name="ln5134">  return return_status;</a>
<a name="ln5135">}</a>
<a name="ln5136"> </a>
<a name="ln5137">void CatalogManager::ProcessPendingNamespace(</a>
<a name="ln5138">    NamespaceId id, std::vector&lt;scoped_refptr&lt;TableInfo&gt;&gt; template_tables) {</a>
<a name="ln5139">  LOG(INFO) &lt;&lt; &quot;ProcessPendingNamespace started for &quot; &lt;&lt; id;</a>
<a name="ln5140"> </a>
<a name="ln5141">  // Ensure that we are currently the Leader before handling DDL operations.</a>
<a name="ln5142">  {</a>
<a name="ln5143">    ScopedLeaderSharedLock l(this);</a>
<a name="ln5144">    if (!l.catalog_status().ok() || !l.leader_status().ok()) {</a>
<a name="ln5145">      LOG(WARNING) &lt;&lt; &quot;Catalog status failure: &quot; &lt;&lt; l.catalog_status().ToString();</a>
<a name="ln5146">      // Don't try again, we have to reset in-memory state after losing leader election.</a>
<a name="ln5147">      return;</a>
<a name="ln5148">    }</a>
<a name="ln5149">  }</a>
<a name="ln5150"> </a>
<a name="ln5151">  if (PREDICT_FALSE(GetAtomicFlag(&amp;FLAGS_TEST_hang_on_namespace_transition))) {</a>
<a name="ln5152">    LOG(INFO) &lt;&lt; &quot;Artificially waiting (&quot; &lt;&lt; FLAGS_catalog_manager_bg_task_wait_ms</a>
<a name="ln5153">              &lt;&lt; &quot;ms) on namespace creation for &quot; &lt;&lt; id;</a>
<a name="ln5154">    SleepFor(MonoDelta::FromMilliseconds(FLAGS_catalog_manager_bg_task_wait_ms));</a>
<a name="ln5155">    WARN_NOT_OK(background_tasks_thread_pool_-&gt;SubmitFunc(</a>
<a name="ln5156">        std::bind(&amp;CatalogManager::ProcessPendingNamespace, this, id, template_tables)),</a>
<a name="ln5157">        &quot;Could not submit ProcessPendingNamespaces to thread pool&quot;);</a>
<a name="ln5158">    return;</a>
<a name="ln5159">  }</a>
<a name="ln5160"> </a>
<a name="ln5161">  scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln5162">  {</a>
<a name="ln5163">    std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln5164">    ns = FindPtrOrNull(namespace_ids_map_, id);;</a>
<a name="ln5165">  }</a>
<a name="ln5166">  if (ns == nullptr) {</a>
<a name="ln5167">    LOG(WARNING) &lt;&lt; &quot;Pending Namespace not found to finish creation: &quot; &lt;&lt; id;</a>
<a name="ln5168">    return;</a>
<a name="ln5169">  }</a>
<a name="ln5170"> </a>
<a name="ln5171">  // Copy the system tables necessary to create this namespace.  This can be time-intensive.</a>
<a name="ln5172">  bool success = true;</a>
<a name="ln5173">  if (!template_tables.empty()) {</a>
<a name="ln5174">    auto s = CopyPgsqlSysTables(ns-&gt;id(), template_tables);</a>
<a name="ln5175">    WARN_NOT_OK(s, &quot;Error Copying PGSQL System Tables for Pending Namespace&quot;);</a>
<a name="ln5176">    success = s.ok();</a>
<a name="ln5177">  }</a>
<a name="ln5178"> </a>
<a name="ln5179">  // All work is done, change the namespace state regardless of success or failure.</a>
<a name="ln5180">  {</a>
<a name="ln5181">    auto l = ns-&gt;LockForWrite();</a>
<a name="ln5182">    SysNamespaceEntryPB&amp; metadata = ns-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb;</a>
<a name="ln5183">    if (metadata.state() == SysNamespaceEntryPB::PREPARING) {</a>
<a name="ln5184">      metadata.set_state(success ? SysNamespaceEntryPB::RUNNING : SysNamespaceEntryPB::FAILED);</a>
<a name="ln5185">      auto s = sys_catalog_-&gt;UpdateItem(ns.get(), leader_ready_term());</a>
<a name="ln5186">      if (s.ok()) {</a>
<a name="ln5187">        TRACE(&quot;Done processing keyspace&quot;);</a>
<a name="ln5188">        LOG(INFO) &lt;&lt; (success ? &quot;Processed&quot; : &quot;Failed&quot;) &lt;&lt; &quot; keyspace: &quot; &lt;&lt; ns-&gt;ToString();</a>
<a name="ln5189">      } else {</a>
<a name="ln5190">        metadata.set_state(SysNamespaceEntryPB::FAILED);</a>
<a name="ln5191">        if (s.IsIllegalState() || s.IsAborted()) {</a>
<a name="ln5192">          s = STATUS(ServiceUnavailable,</a>
<a name="ln5193">              &quot;operation requested can only be executed on a leader master, but this&quot;</a>
<a name="ln5194">              &quot; master is no longer the leader&quot;, s.ToString());</a>
<a name="ln5195">        } else {</a>
<a name="ln5196">          s = s.CloneAndPrepend(Substitute(</a>
<a name="ln5197">              &quot;An error occurred while modifying keyspace to $0 in sys-catalog: $1&quot;,</a>
<a name="ln5198">              metadata.state(), s.ToString()));</a>
<a name="ln5199">        }</a>
<a name="ln5200">        LOG(WARNING) &lt;&lt; s.ToString();</a>
<a name="ln5201">      }</a>
<a name="ln5202">      // Commit the namespace in-memory state.</a>
<a name="ln5203">      l-&gt;Commit();</a>
<a name="ln5204">    } else {</a>
<a name="ln5205">      LOG(WARNING) &lt;&lt; &quot;Bad keyspace state (&quot; &lt;&lt; metadata.state()</a>
<a name="ln5206">                   &lt;&lt; &quot;), abandoning creation work for &quot; &lt;&lt; ns-&gt;ToString();</a>
<a name="ln5207">    }</a>
<a name="ln5208">  }</a>
<a name="ln5209">}</a>
<a name="ln5210"> </a>
<a name="ln5211">// Get the information about an in-progress create operation.</a>
<a name="ln5212">Status CatalogManager::IsCreateNamespaceDone(const IsCreateNamespaceDoneRequestPB* req,</a>
<a name="ln5213">                                             IsCreateNamespaceDoneResponsePB* resp) {</a>
<a name="ln5214">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln5215"> </a>
<a name="ln5216">  scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln5217">  auto ns_pb = req-&gt;namespace_();</a>
<a name="ln5218"> </a>
<a name="ln5219">  // 1. Lookup the namespace and verify it exists.</a>
<a name="ln5220">  TRACE(&quot;Looking up keyspace&quot;);</a>
<a name="ln5221">  RETURN_NAMESPACE_NOT_FOUND(FindNamespace(ns_pb, &amp;ns), resp);</a>
<a name="ln5222"> </a>
<a name="ln5223">  TRACE(&quot;Locking keyspace&quot;);</a>
<a name="ln5224">  auto l = ns-&gt;LockForRead();</a>
<a name="ln5225">  auto metadata = l-&gt;data().pb;</a>
<a name="ln5226"> </a>
<a name="ln5227">  switch (metadata.state()) {</a>
<a name="ln5228">    // Success cases. Done and working.</a>
<a name="ln5229">    case SysNamespaceEntryPB::RUNNING:</a>
<a name="ln5230">      if (!ns-&gt;colocated()) {</a>
<a name="ln5231">        resp-&gt;set_done(true);</a>
<a name="ln5232">      } else {</a>
<a name="ln5233">        // Verify system table created as well, if colocated.</a>
<a name="ln5234">        IsCreateTableDoneRequestPB table_req;</a>
<a name="ln5235">        IsCreateTableDoneResponsePB table_resp;</a>
<a name="ln5236">        const auto parent_table_id = ns-&gt;id() + kColocatedParentTableIdSuffix;</a>
<a name="ln5237">        table_req.mutable_table()-&gt;set_table_id(parent_table_id);</a>
<a name="ln5238">        auto s = IsCreateTableDone(&amp;table_req, &amp;table_resp);</a>
<a name="ln5239">        resp-&gt;set_done(table_resp.done());</a>
<a name="ln5240">        if (!s.ok()) {</a>
<a name="ln5241">          if (table_resp.has_error()) {</a>
<a name="ln5242">            resp-&gt;mutable_error()-&gt;Swap(table_resp.mutable_error());</a>
<a name="ln5243">          }</a>
<a name="ln5244">          return s;</a>
<a name="ln5245">        }</a>
<a name="ln5246">      }</a>
<a name="ln5247">      break;</a>
<a name="ln5248">    // These states indicate that a create completed but a subsequent remove was requested.</a>
<a name="ln5249">    case SysNamespaceEntryPB::DELETING:</a>
<a name="ln5250">    case SysNamespaceEntryPB::DELETED:</a>
<a name="ln5251">      resp-&gt;set_done(true);</a>
<a name="ln5252">      break;</a>
<a name="ln5253">    // Pending cases.  NOT DONE</a>
<a name="ln5254">    case SysNamespaceEntryPB::PREPARING:</a>
<a name="ln5255">      resp-&gt;set_done(false);</a>
<a name="ln5256">      break;</a>
<a name="ln5257">    // Failure cases.  Done, but we need to give the user an error message.</a>
<a name="ln5258">    case SysNamespaceEntryPB::FAILED:</a>
<a name="ln5259">      resp-&gt;set_done(true);</a>
<a name="ln5260">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::UNKNOWN_ERROR, STATUS(InternalError,</a>
<a name="ln5261">              &quot;Namespace Create Failed: not onlined.&quot;));</a>
<a name="ln5262">    default:</a>
<a name="ln5263">      Status s = STATUS_SUBSTITUTE(IllegalState,</a>
<a name="ln5264">          &quot;IsCreateNamespaceDone failure: state=$0&quot;, metadata.state());</a>
<a name="ln5265">      LOG(WARNING) &lt;&lt; s.ToString();</a>
<a name="ln5266">      resp-&gt;set_done(true);</a>
<a name="ln5267">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::UNKNOWN_ERROR, s);</a>
<a name="ln5268">  }</a>
<a name="ln5269"> </a>
<a name="ln5270">  return Status::OK();</a>
<a name="ln5271">}</a>
<a name="ln5272"> </a>
<a name="ln5273"> </a>
<a name="ln5274">Status CatalogManager::DeleteNamespace(const DeleteNamespaceRequestPB* req,</a>
<a name="ln5275">                                       DeleteNamespaceResponsePB* resp,</a>
<a name="ln5276">                                       rpc::RpcContext* rpc) {</a>
<a name="ln5277">  LOG(INFO) &lt;&lt; &quot;Servicing DeleteNamespace request from &quot; &lt;&lt; RequestorString(rpc)</a>
<a name="ln5278">            &lt;&lt; &quot;: &quot; &lt;&lt; req-&gt;ShortDebugString();</a>
<a name="ln5279"> </a>
<a name="ln5280">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln5281"> </a>
<a name="ln5282">  scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln5283"> </a>
<a name="ln5284">  // Lookup the namespace and verify if it exists.</a>
<a name="ln5285">  TRACE(&quot;Looking up keyspace&quot;);</a>
<a name="ln5286">  RETURN_NAMESPACE_NOT_FOUND(FindNamespace(req-&gt;namespace_(), &amp;ns), resp);</a>
<a name="ln5287"> </a>
<a name="ln5288">  if (req-&gt;has_database_type() &amp;&amp; req-&gt;database_type() != ns-&gt;database_type()) {</a>
<a name="ln5289">    // Could not find the right database to delete.</a>
<a name="ln5290">    Status s = STATUS(NotFound, &quot;Keyspace not found&quot;, ns-&gt;name());</a>
<a name="ln5291">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_NOT_FOUND, s);</a>
<a name="ln5292">  }</a>
<a name="ln5293">  {</a>
<a name="ln5294">    // Don't allow deletion if the namespace is in a transient state.</a>
<a name="ln5295">    auto cur_state = ns-&gt;state();</a>
<a name="ln5296">    if (cur_state != SysNamespaceEntryPB::RUNNING &amp;&amp; cur_state != SysNamespaceEntryPB::FAILED) {</a>
<a name="ln5297">      if (cur_state == SysNamespaceEntryPB::DELETED) {</a>
<a name="ln5298">        Status s = STATUS(NotFound, &quot;Keyspace already deleted&quot;, ns-&gt;name());</a>
<a name="ln5299">        return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_NOT_FOUND, s);</a>
<a name="ln5300">      } else {</a>
<a name="ln5301">        Status s = STATUS_SUBSTITUTE(</a>
<a name="ln5302">            TryAgain, &quot;Namespace deletion not allowed when State = $0&quot;,</a>
<a name="ln5303">            SysNamespaceEntryPB::State_Name(cur_state));</a>
<a name="ln5304">        return SetupError(resp-&gt;mutable_error(), MasterErrorPB::IN_TRANSITION_CAN_RETRY, s);</a>
<a name="ln5305">      }</a>
<a name="ln5306">    }</a>
<a name="ln5307">  }</a>
<a name="ln5308"> </a>
<a name="ln5309">  // PGSQL has a completely forked implementation because it allows non-empty namespaces on delete.</a>
<a name="ln5310">  if (ns-&gt;database_type() == YQL_DATABASE_PGSQL) {</a>
<a name="ln5311">    return DeleteYsqlDatabase(req, resp, rpc);</a>
<a name="ln5312">  }</a>
<a name="ln5313"> </a>
<a name="ln5314">  TRACE(&quot;Locking keyspace&quot;);</a>
<a name="ln5315">  auto l = ns-&gt;LockForWrite();</a>
<a name="ln5316"> </a>
<a name="ln5317">  // Only empty namespace can be deleted.</a>
<a name="ln5318">  TRACE(&quot;Looking for tables in the keyspace&quot;);</a>
<a name="ln5319">  {</a>
<a name="ln5320">    SharedLock&lt;LockType&gt; catalog_lock(lock_);</a>
<a name="ln5321">    VLOG(3) &lt;&lt; __func__ &lt;&lt; &quot;: Acquired the catalog manager lock_&quot;;</a>
<a name="ln5322"> </a>
<a name="ln5323">    for (const TableInfoMap::value_type&amp; entry : *table_ids_map_) {</a>
<a name="ln5324">      auto ltm = entry.second-&gt;LockForRead();</a>
<a name="ln5325"> </a>
<a name="ln5326">      if (!ltm-&gt;data().started_deleting() &amp;&amp; ltm-&gt;data().namespace_id() == ns-&gt;id()) {</a>
<a name="ln5327">        Status s = STATUS(InvalidArgument,</a>
<a name="ln5328">                          Substitute(&quot;Cannot delete keyspace which has $0: $1 [id=$2]&quot;,</a>
<a name="ln5329">                                     PROTO_IS_TABLE(ltm-&gt;data().pb) ? &quot;table&quot; : &quot;index&quot;,</a>
<a name="ln5330">                                     ltm-&gt;data().name(), entry.second-&gt;id()), req-&gt;DebugString());</a>
<a name="ln5331">        return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_IS_NOT_EMPTY, s);</a>
<a name="ln5332">      }</a>
<a name="ln5333">    }</a>
<a name="ln5334">  }</a>
<a name="ln5335"> </a>
<a name="ln5336">  // Only empty namespace can be deleted.</a>
<a name="ln5337">  TRACE(&quot;Looking for types in the keyspace&quot;);</a>
<a name="ln5338">  {</a>
<a name="ln5339">    SharedLock&lt;LockType&gt; catalog_lock(lock_);</a>
<a name="ln5340">    VLOG(3) &lt;&lt; __func__ &lt;&lt; &quot;: Acquired the catalog manager lock_&quot;;</a>
<a name="ln5341"> </a>
<a name="ln5342">    for (const UDTypeInfoMap::value_type&amp; entry : udtype_ids_map_) {</a>
<a name="ln5343">      auto ltm = entry.second-&gt;LockForRead();</a>
<a name="ln5344"> </a>
<a name="ln5345">      if (ltm-&gt;data().namespace_id() == ns-&gt;id()) {</a>
<a name="ln5346">        Status s = STATUS(InvalidArgument,</a>
<a name="ln5347">            Substitute(&quot;Cannot delete keyspace which has type: $0 [id=$1]&quot;,</a>
<a name="ln5348">                ltm-&gt;data().name(), entry.second-&gt;id()), req-&gt;DebugString());</a>
<a name="ln5349">        return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_IS_NOT_EMPTY, s);</a>
<a name="ln5350">      }</a>
<a name="ln5351">    }</a>
<a name="ln5352">  }</a>
<a name="ln5353"> </a>
<a name="ln5354">  // [Delete]. Skip the DELETING-&gt;DELETED state, since no tables are present in this namespace.</a>
<a name="ln5355">  TRACE(&quot;Updating metadata on disk&quot;);</a>
<a name="ln5356">  // Update sys-catalog.</a>
<a name="ln5357">  Status s = sys_catalog_-&gt;DeleteItem(ns.get(), leader_ready_term());</a>
<a name="ln5358">  if (!s.ok()) {</a>
<a name="ln5359">    // The mutation will be aborted when 'l' exits the scope on early return.</a>
<a name="ln5360">    s = s.CloneAndPrepend(Substitute(&quot;An error occurred while updating sys-catalog: $0&quot;,</a>
<a name="ln5361">                                     s.ToString()));</a>
<a name="ln5362">    LOG(WARNING) &lt;&lt; s.ToString();</a>
<a name="ln5363">    return CheckIfNoLongerLeaderAndSetupError(s, resp);</a>
<a name="ln5364">  }</a>
<a name="ln5365"> </a>
<a name="ln5366">  // Update the in-memory state.</a>
<a name="ln5367">  TRACE(&quot;Committing in-memory state&quot;);</a>
<a name="ln5368">  l-&gt;Commit();</a>
<a name="ln5369"> </a>
<a name="ln5370">  // Remove the namespace from all CatalogManager mappings.</a>
<a name="ln5371">  {</a>
<a name="ln5372">    std::lock_guard&lt;LockType&gt; l_map(lock_);</a>
<a name="ln5373">    namespace_names_mapper_[ns-&gt;database_type()].erase(ns-&gt;name());</a>
<a name="ln5374">    if (namespace_ids_map_.erase(ns-&gt;id()) &lt; 1) {</a>
<a name="ln5375">      LOG(WARNING) &lt;&lt; Format(&quot;Could not remove namespace from maps, id=$1&quot;, ns-&gt;id());</a>
<a name="ln5376">    }</a>
<a name="ln5377">  }</a>
<a name="ln5378"> </a>
<a name="ln5379">  // Delete any permissions granted on this keyspace to any role. See comment in DeleteTable() for</a>
<a name="ln5380">  // more details.</a>
<a name="ln5381">  string canonical_resource = get_canonical_keyspace(req-&gt;namespace_().name());</a>
<a name="ln5382">  RETURN_NOT_OK(permissions_manager_-&gt;RemoveAllPermissionsForResource(canonical_resource, resp));</a>
<a name="ln5383"> </a>
<a name="ln5384">  LOG(INFO) &lt;&lt; &quot;Successfully deleted keyspace &quot; &lt;&lt; ns-&gt;ToString()</a>
<a name="ln5385">            &lt;&lt; &quot; per request from &quot; &lt;&lt; RequestorString(rpc);</a>
<a name="ln5386">  return Status::OK();</a>
<a name="ln5387">}</a>
<a name="ln5388"> </a>
<a name="ln5389">Status CatalogManager::DeleteYsqlDatabase(const DeleteNamespaceRequestPB* req,</a>
<a name="ln5390">                                          DeleteNamespaceResponsePB* resp,</a>
<a name="ln5391">                                          rpc::RpcContext* rpc) {</a>
<a name="ln5392">  // Lookup database.</a>
<a name="ln5393">  scoped_refptr &lt;NamespaceInfo&gt; database;</a>
<a name="ln5394">  RETURN_NAMESPACE_NOT_FOUND(FindNamespace(req-&gt;namespace_(), &amp;database), resp);</a>
<a name="ln5395"> </a>
<a name="ln5396">  // Make sure this is a YSQL database.</a>
<a name="ln5397">  if (database-&gt;database_type() != YQL_DATABASE_PGSQL) {</a>
<a name="ln5398">    // A non-YSQL namespace is found, but the rpc requests to drop a YSQL database.</a>
<a name="ln5399">    Status s = STATUS(NotFound, &quot;YSQL database not found&quot;, database-&gt;name());</a>
<a name="ln5400">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_NOT_FOUND, s);</a>
<a name="ln5401">  }</a>
<a name="ln5402"> </a>
<a name="ln5403">  // Set the Namespace to DELETING.</a>
<a name="ln5404">  TRACE(&quot;Locking database&quot;);</a>
<a name="ln5405">  auto l = database-&gt;LockForWrite();</a>
<a name="ln5406">  SysNamespaceEntryPB &amp;metadata = database-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb;</a>
<a name="ln5407">  if (metadata.state() == SysNamespaceEntryPB::RUNNING ||</a>
<a name="ln5408">      metadata.state() == SysNamespaceEntryPB::FAILED) {</a>
<a name="ln5409">    metadata.set_state(SysNamespaceEntryPB::DELETING);</a>
<a name="ln5410">    RETURN_NOT_OK(sys_catalog_-&gt;UpdateItem(database.get(), leader_ready_term()));</a>
<a name="ln5411">    TRACE(&quot;Marked keyspace for deletion in sys-catalog&quot;);</a>
<a name="ln5412">    // Commit the namespace in-memory state.</a>
<a name="ln5413">    l-&gt;Commit();</a>
<a name="ln5414">  } else {</a>
<a name="ln5415">    Status s = STATUS_SUBSTITUTE(IllegalState,</a>
<a name="ln5416">        &quot;Keyspace ($0) has invalid state ($1), aborting delete&quot;,</a>
<a name="ln5417">        database-&gt;name(), metadata.state());</a>
<a name="ln5418">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INTERNAL_ERROR, s);</a>
<a name="ln5419">  }</a>
<a name="ln5420"> </a>
<a name="ln5421">  return background_tasks_thread_pool_-&gt;SubmitFunc(</a>
<a name="ln5422">    std::bind(&amp;CatalogManager::DeleteYsqlDatabaseAsync, this, database));</a>
<a name="ln5423">}</a>
<a name="ln5424"> </a>
<a name="ln5425">void CatalogManager::DeleteYsqlDatabaseAsync(scoped_refptr&lt;NamespaceInfo&gt; database) {</a>
<a name="ln5426">  TEST_PAUSE_IF_FLAG(TEST_hang_on_namespace_transition);</a>
<a name="ln5427"> </a>
<a name="ln5428">  // Lock database before removing content.</a>
<a name="ln5429">  TRACE(&quot;Locking database&quot;);</a>
<a name="ln5430">  auto l = database-&gt;LockForWrite();</a>
<a name="ln5431">  SysNamespaceEntryPB &amp;metadata = database-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb;</a>
<a name="ln5432"> </a>
<a name="ln5433">  // A DELETED Namespace has finished but was tombstoned to avoid immediately reusing the same ID.</a>
<a name="ln5434">  // We consider a restart enough time, so we just need to remove it from the SysCatalog.</a>
<a name="ln5435">  if (metadata.state() == SysNamespaceEntryPB::DELETED) {</a>
<a name="ln5436">    Status s = sys_catalog_-&gt;DeleteItem(database.get(), leader_ready_term());</a>
<a name="ln5437">    WARN_NOT_OK(s, &quot;SysCatalog DeleteItem for Namespace&quot;);</a>
<a name="ln5438">    if (!s.ok()) {</a>
<a name="ln5439">      return;</a>
<a name="ln5440">    }</a>
<a name="ln5441">  } else if (metadata.state() == SysNamespaceEntryPB::DELETING) {</a>
<a name="ln5442">    // Delete all tables in the database.</a>
<a name="ln5443">    TRACE(&quot;Delete all tables in YSQL database&quot;);</a>
<a name="ln5444">    Status s = DeleteYsqlDBTables(database);</a>
<a name="ln5445">    WARN_NOT_OK(s, &quot;DeleteYsqlDBTables failed&quot;);</a>
<a name="ln5446">    if (!s.ok()) {</a>
<a name="ln5447">      // Move to FAILED so DeleteNamespace can be reissued by the user.</a>
<a name="ln5448">      metadata.set_state(SysNamespaceEntryPB::FAILED);</a>
<a name="ln5449">      l-&gt;Commit();</a>
<a name="ln5450">      return;</a>
<a name="ln5451">    }</a>
<a name="ln5452"> </a>
<a name="ln5453">    // Once all user-facing data has been offlined, move the Namespace to DELETED state.</a>
<a name="ln5454">    metadata.set_state(SysNamespaceEntryPB::DELETED);</a>
<a name="ln5455">    s = sys_catalog_-&gt;UpdateItem(database.get(), leader_ready_term());</a>
<a name="ln5456">    WARN_NOT_OK(s, &quot;SysCatalog Update for Namespace&quot;);</a>
<a name="ln5457">    if (!s.ok()) {</a>
<a name="ln5458">      // Move to FAILED so DeleteNamespace can be reissued by the user.</a>
<a name="ln5459">      metadata.set_state(SysNamespaceEntryPB::FAILED);</a>
<a name="ln5460">      l-&gt;Commit();</a>
<a name="ln5461">      return;</a>
<a name="ln5462">    }</a>
<a name="ln5463">    TRACE(&quot;Marked keyspace as deleted in sys-catalog&quot;);</a>
<a name="ln5464">  } else {</a>
<a name="ln5465">    LOG(WARNING) &lt;&lt; &quot;Keyspace (&quot; &lt;&lt; database-&gt;name() &lt;&lt; &quot;) has invalid state (&quot;</a>
<a name="ln5466">                 &lt;&lt; metadata.state() &lt;&lt; &quot;), aborting delete&quot;;</a>
<a name="ln5467">    return;</a>
<a name="ln5468">  }</a>
<a name="ln5469"> </a>
<a name="ln5470">  // Remove namespace from CatalogManager name mapping.  Will remove ID map after all Tables gone.</a>
<a name="ln5471">  {</a>
<a name="ln5472">    std::lock_guard&lt;LockType&gt; l_map(lock_);</a>
<a name="ln5473">    if (namespace_names_mapper_[database-&gt;database_type()].erase(database-&gt;name()) &lt; 1) {</a>
<a name="ln5474">      LOG(WARNING) &lt;&lt; Format(&quot;Could not remove namespace from maps, name=$0, id=$1&quot;,</a>
<a name="ln5475">                             database-&gt;name(), database-&gt;id());</a>
<a name="ln5476">    }</a>
<a name="ln5477">  }</a>
<a name="ln5478"> </a>
<a name="ln5479">  // Update the in-memory state.</a>
<a name="ln5480">  TRACE(&quot;Committing in-memory state&quot;);</a>
<a name="ln5481">  l-&gt;Commit();</a>
<a name="ln5482"> </a>
<a name="ln5483">  // DROP completed. Return status.</a>
<a name="ln5484">  LOG(INFO) &lt;&lt; &quot;Successfully deleted YSQL database &quot; &lt;&lt; database-&gt;ToString();</a>
<a name="ln5485">}</a>
<a name="ln5486"> </a>
<a name="ln5487">// IMPORTANT: If modifying, consider updating DeleteTable(), the singular deletion API.</a>
<a name="ln5488">Status CatalogManager::DeleteYsqlDBTables(const scoped_refptr&lt;NamespaceInfo&gt;&amp; database) {</a>
<a name="ln5489">  TabletInfoPtr sys_tablet_info;</a>
<a name="ln5490">  vector&lt;pair&lt;scoped_refptr&lt;TableInfo&gt;, unique_ptr&lt;TableInfo::lock_type&gt;&gt;&gt; tables;</a>
<a name="ln5491">  unordered_set&lt;TableId&gt; sys_table_ids;</a>
<a name="ln5492">  {</a>
<a name="ln5493">    // Lock the catalog to iterate over table_ids_map_.</a>
<a name="ln5494">    SharedLock&lt;LockType&gt; catalog_lock(lock_);</a>
<a name="ln5495"> </a>
<a name="ln5496">    sys_tablet_info = tablet_map_-&gt;find(kSysCatalogTabletId)-&gt;second;</a>
<a name="ln5497"> </a>
<a name="ln5498">    // Populate tables and sys_table_ids.</a>
<a name="ln5499">    for (const TableInfoMap::value_type&amp; entry : *table_ids_map_) {</a>
<a name="ln5500">      scoped_refptr&lt;TableInfo&gt; table = entry.second;</a>
<a name="ln5501">      auto l = table-&gt;LockForWrite();</a>
<a name="ln5502">      if (l-&gt;data().namespace_id() != database-&gt;id() || l-&gt;data().started_deleting()) {</a>
<a name="ln5503">        continue;</a>
<a name="ln5504">      }</a>
<a name="ln5505">      DSCHECK(!l-&gt;data().pb.is_pg_shared_table(), Corruption, &quot;Shared table found in database&quot;);</a>
<a name="ln5506"> </a>
<a name="ln5507">      if (IsSystemTableUnlocked(*table)) {</a>
<a name="ln5508">        sys_table_ids.insert(table-&gt;id());</a>
<a name="ln5509">      }</a>
<a name="ln5510"> </a>
<a name="ln5511">      // For regular (indexed) table, insert table info and lock in the front of the list. Else for</a>
<a name="ln5512">      // index table, append them to the end. We do so so that we will commit and delete the indexed</a>
<a name="ln5513">      // table first before its indexes.</a>
<a name="ln5514">      if (PROTO_IS_TABLE(l-&gt;data().pb)) {</a>
<a name="ln5515">        tables.insert(tables.begin(), {table, std::move(l)});</a>
<a name="ln5516">      } else {</a>
<a name="ln5517">        tables.push_back({table, std::move(l)});</a>
<a name="ln5518">      }</a>
<a name="ln5519">    }</a>
<a name="ln5520">  }</a>
<a name="ln5521">  // Remove the system tables from RAFT.</a>
<a name="ln5522">  TRACE(&quot;Sending system table delete RPCs&quot;);</a>
<a name="ln5523">  for (auto &amp;table_id : sys_table_ids) {</a>
<a name="ln5524">    RETURN_NOT_OK(sys_catalog_-&gt;DeleteYsqlSystemTable(table_id));</a>
<a name="ln5525">  }</a>
<a name="ln5526">  // Remove the system tables from the system catalog TabletInfo.</a>
<a name="ln5527">  RETURN_NOT_OK(RemoveTableIdsFromTabletInfo(sys_tablet_info, sys_table_ids));</a>
<a name="ln5528"> </a>
<a name="ln5529">  // Batch remove all relevant CDC streams. Handle before we delete the tables they reference.</a>
<a name="ln5530">  TRACE(&quot;Deleting CDC streams on table&quot;);</a>
<a name="ln5531">  vector&lt;TableId&gt; id_list;</a>
<a name="ln5532">  id_list.reserve(tables.size());</a>
<a name="ln5533">  for (auto &amp;table_and_lock : tables) {</a>
<a name="ln5534">    id_list.push_back(table_and_lock.first-&gt;id());</a>
<a name="ln5535">  }</a>
<a name="ln5536">  RETURN_NOT_OK(DeleteCDCStreamsForTables(id_list));</a>
<a name="ln5537"> </a>
<a name="ln5538">  // Set all table states to DELETING as one batch RPC call.</a>
<a name="ln5539">  TRACE(&quot;Sending delete table batch RPC to sys catalog&quot;);</a>
<a name="ln5540">  vector&lt;TableInfo *&gt; tables_rpc;</a>
<a name="ln5541">  tables_rpc.reserve(tables.size());</a>
<a name="ln5542">  for (auto &amp;table_and_lock : tables) {</a>
<a name="ln5543">    tables_rpc.push_back(table_and_lock.first.get());</a>
<a name="ln5544">    auto &amp;l = table_and_lock.second;</a>
<a name="ln5545">    // Mark the table state as DELETING tablets.</a>
<a name="ln5546">    l-&gt;mutable_data()-&gt;set_state(SysTablesEntryPB::DELETING,</a>
<a name="ln5547">        Substitute(&quot;Started deleting at $0&quot;, LocalTimeAsString()));</a>
<a name="ln5548">  }</a>
<a name="ln5549">  // Update all the table states in raft in bulk.</a>
<a name="ln5550">  Status s = sys_catalog_-&gt;UpdateItems(tables_rpc, leader_ready_term());</a>
<a name="ln5551">  if (!s.ok()) {</a>
<a name="ln5552">    // The mutation will be aborted when 'l' exits the scope on early return.</a>
<a name="ln5553">    s = s.CloneAndPrepend(Substitute(&quot;An error occurred while updating sys tables: $0&quot;,</a>
<a name="ln5554">                                     s.ToString()));</a>
<a name="ln5555">    LOG(WARNING) &lt;&lt; s.ToString();</a>
<a name="ln5556">    return CheckIfNoLongerLeader(s);</a>
<a name="ln5557">  }</a>
<a name="ln5558">  for (auto &amp;table_and_lock : tables) {</a>
<a name="ln5559">    auto &amp;table = table_and_lock.first;</a>
<a name="ln5560">    auto &amp;l = table_and_lock.second;</a>
<a name="ln5561">    // Cancel all table busywork and commit the DELETING change.</a>
<a name="ln5562">    l-&gt;Commit();</a>
<a name="ln5563">    table-&gt;AbortTasks();</a>
<a name="ln5564">  }</a>
<a name="ln5565"> </a>
<a name="ln5566">  // Send a DeleteTablet() RPC request to each tablet replica in the table.</a>
<a name="ln5567">  for (auto &amp;table_and_lock : tables) {</a>
<a name="ln5568">    auto &amp;table = table_and_lock.first;</a>
<a name="ln5569">    DeleteTabletsAndSendRequests(table);</a>
<a name="ln5570">  }</a>
<a name="ln5571"> </a>
<a name="ln5572">  // Invoke any background tasks and return (notably, table cleanup).</a>
<a name="ln5573">  background_tasks_-&gt;Wake();</a>
<a name="ln5574">  return Status::OK();</a>
<a name="ln5575">}</a>
<a name="ln5576"> </a>
<a name="ln5577">// Get the information about an in-progress delete operation.</a>
<a name="ln5578">Status CatalogManager::IsDeleteNamespaceDone(const IsDeleteNamespaceDoneRequestPB* req,</a>
<a name="ln5579">                                             IsDeleteNamespaceDoneResponsePB* resp) {</a>
<a name="ln5580">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln5581"> </a>
<a name="ln5582">  scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln5583">  auto ns_pb = req-&gt;namespace_();</a>
<a name="ln5584"> </a>
<a name="ln5585">  // 1. Lookup the namespace and verify it exists.</a>
<a name="ln5586">  TRACE(&quot;Looking up keyspace&quot;);</a>
<a name="ln5587">  Status s = FindNamespace(ns_pb, &amp;ns);</a>
<a name="ln5588">  if (!s.ok()) {</a>
<a name="ln5589">    // Namespace no longer exists means success.</a>
<a name="ln5590">    LOG(INFO) &lt;&lt; &quot;Servicing IsDeleteNamespaceDone request for &quot;</a>
<a name="ln5591">              &lt;&lt; ns_pb.DebugString() &lt;&lt; &quot;: deleted (not found)&quot;;</a>
<a name="ln5592">    resp-&gt;set_done(true);</a>
<a name="ln5593">    return Status::OK();</a>
<a name="ln5594">  }</a>
<a name="ln5595"> </a>
<a name="ln5596">  TRACE(&quot;Locking keyspace&quot;);</a>
<a name="ln5597">  auto l = ns-&gt;LockForRead();</a>
<a name="ln5598">  auto&amp; metadata = l-&gt;data().pb;</a>
<a name="ln5599"> </a>
<a name="ln5600">  if (metadata.state() == SysNamespaceEntryPB::DELETED) {</a>
<a name="ln5601">    resp-&gt;set_done(true);</a>
<a name="ln5602">  } else if (metadata.state() == SysNamespaceEntryPB::DELETING) {</a>
<a name="ln5603">    resp-&gt;set_done(false);</a>
<a name="ln5604">  } else {</a>
<a name="ln5605">    Status s = STATUS_SUBSTITUTE(IllegalState,</a>
<a name="ln5606">        &quot;Servicing IsDeleteTableDone request for $0: NOT deleted (state=$1)&quot;,</a>
<a name="ln5607">        ns_pb.DebugString(), metadata.state());</a>
<a name="ln5608">    LOG(WARNING) &lt;&lt; s.ToString();</a>
<a name="ln5609">    // Done != Successful.  We just want to let the user know the delete has finished processing.</a>
<a name="ln5610">    resp-&gt;set_done(true);</a>
<a name="ln5611">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INTERNAL_ERROR, s);</a>
<a name="ln5612">  }</a>
<a name="ln5613">  return Status::OK();</a>
<a name="ln5614">}</a>
<a name="ln5615"> </a>
<a name="ln5616">Status CatalogManager::AlterNamespace(const AlterNamespaceRequestPB* req,</a>
<a name="ln5617">                                      AlterNamespaceResponsePB* resp,</a>
<a name="ln5618">                                      rpc::RpcContext* rpc) {</a>
<a name="ln5619">  LOG(INFO) &lt;&lt; &quot;Servicing AlterNamespace request from &quot; &lt;&lt; RequestorString(rpc)</a>
<a name="ln5620">            &lt;&lt; &quot;: &quot; &lt;&lt; req-&gt;ShortDebugString();</a>
<a name="ln5621"> </a>
<a name="ln5622">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln5623"> </a>
<a name="ln5624">  scoped_refptr&lt;NamespaceInfo&gt; database;</a>
<a name="ln5625">  RETURN_NAMESPACE_NOT_FOUND(FindNamespace(req-&gt;namespace_(), &amp;database), resp);</a>
<a name="ln5626"> </a>
<a name="ln5627">  if (req-&gt;namespace_().has_database_type() &amp;&amp;</a>
<a name="ln5628">      database-&gt;database_type() != req-&gt;namespace_().database_type()) {</a>
<a name="ln5629">    Status s = STATUS(NotFound, &quot;Database not found&quot;, database-&gt;name());</a>
<a name="ln5630">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_NOT_FOUND, s);</a>
<a name="ln5631">  }</a>
<a name="ln5632"> </a>
<a name="ln5633">  TRACE(&quot;Locking database&quot;);</a>
<a name="ln5634">  auto l = database-&gt;LockForWrite();</a>
<a name="ln5635"> </a>
<a name="ln5636">  // Don't allow an alter if the namespace isn't running.</a>
<a name="ln5637">  if (l-&gt;data().pb.state() != SysNamespaceEntryPB::RUNNING) {</a>
<a name="ln5638">    Status s = STATUS_SUBSTITUTE(TryAgain, &quot;Namespace not running.  State = $0&quot;,</a>
<a name="ln5639">                                 SysNamespaceEntryPB::State_Name(l-&gt;data().pb.state()));</a>
<a name="ln5640">    return SetupError(resp-&gt;mutable_error(), NamespaceMasterError(l-&gt;data().pb.state()), s);</a>
<a name="ln5641">  }</a>
<a name="ln5642"> </a>
<a name="ln5643">  const string old_name = l-&gt;data().pb.name();</a>
<a name="ln5644"> </a>
<a name="ln5645">  if (req-&gt;has_new_name() &amp;&amp; req-&gt;new_name() != old_name) {</a>
<a name="ln5646">    const string new_name = req-&gt;new_name();</a>
<a name="ln5647"> </a>
<a name="ln5648">    // Verify that the new name does not exist.</a>
<a name="ln5649">    scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln5650">    NamespaceIdentifierPB ns_identifier;</a>
<a name="ln5651">    ns_identifier.set_name(new_name);</a>
<a name="ln5652">    if (req-&gt;namespace_().has_database_type()) {</a>
<a name="ln5653">      ns_identifier.set_database_type(req-&gt;namespace_().database_type());</a>
<a name="ln5654">    }</a>
<a name="ln5655">    // TODO: This check will only work for YSQL once we add support for YSQL namespaces in</a>
<a name="ln5656">    // namespace_name_map (#1476).</a>
<a name="ln5657">    std::lock_guard&lt;LockType&gt; catalog_lock(lock_);</a>
<a name="ln5658">    TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln5659">    auto s = FindNamespaceUnlocked(ns_identifier, &amp;ns);</a>
<a name="ln5660">    if (ns != nullptr &amp;&amp; req-&gt;namespace_().has_database_type() &amp;&amp;</a>
<a name="ln5661">        ns-&gt;database_type() == req-&gt;namespace_().database_type()) {</a>
<a name="ln5662">      Status s = STATUS_SUBSTITUTE(AlreadyPresent,</a>
<a name="ln5663">          &quot;Keyspace '$0' already exists&quot;, ns-&gt;name());</a>
<a name="ln5664">      LOG(WARNING) &lt;&lt; &quot;Found keyspace: &quot; &lt;&lt; ns-&gt;id() &lt;&lt; &quot;. Failed altering keyspace with error: &quot;</a>
<a name="ln5665">                   &lt;&lt; s.ToString() &lt;&lt; &quot; Request:\n&quot; &lt;&lt; req-&gt;DebugString();</a>
<a name="ln5666">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_ALREADY_PRESENT, s);</a>
<a name="ln5667">    }</a>
<a name="ln5668"> </a>
<a name="ln5669">    namespace_names_mapper_[req-&gt;namespace_().database_type()][new_name] = database;</a>
<a name="ln5670">    namespace_names_mapper_[req-&gt;namespace_().database_type()].erase(old_name);</a>
<a name="ln5671"> </a>
<a name="ln5672">    l-&gt;mutable_data()-&gt;pb.set_name(new_name);</a>
<a name="ln5673">  }</a>
<a name="ln5674"> </a>
<a name="ln5675">  RETURN_NOT_OK(sys_catalog_-&gt;UpdateItem(database.get(), leader_ready_term()));</a>
<a name="ln5676"> </a>
<a name="ln5677">  TRACE(&quot;Committing in-memory state&quot;);</a>
<a name="ln5678">  l-&gt;Commit();</a>
<a name="ln5679"> </a>
<a name="ln5680">  LOG(INFO) &lt;&lt; &quot;Successfully altered keyspace &quot; &lt;&lt; req-&gt;namespace_().name()</a>
<a name="ln5681">            &lt;&lt; &quot; per request from &quot; &lt;&lt; RequestorString(rpc);</a>
<a name="ln5682">  return Status::OK();</a>
<a name="ln5683">}</a>
<a name="ln5684"> </a>
<a name="ln5685">Status CatalogManager::ListNamespaces(const ListNamespacesRequestPB* req,</a>
<a name="ln5686">                                      ListNamespacesResponsePB* resp) {</a>
<a name="ln5687">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln5688"> </a>
<a name="ln5689">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln5690"> </a>
<a name="ln5691">  for (const auto&amp; entry : namespace_ids_map_) {</a>
<a name="ln5692">    const auto&amp; namespace_info = *entry.second;</a>
<a name="ln5693">    auto ltm = namespace_info.LockForRead();</a>
<a name="ln5694">    // If the request asks for namespaces for a specific database type, filter by the type.</a>
<a name="ln5695">    if (req-&gt;has_database_type() &amp;&amp; namespace_info.database_type() != req-&gt;database_type()) {</a>
<a name="ln5696">      continue;</a>
<a name="ln5697">    }</a>
<a name="ln5698">    // Only return RUNNING namespaces.</a>
<a name="ln5699">    if (namespace_info.state() != SysNamespaceEntryPB::RUNNING) {</a>
<a name="ln5700">      continue;</a>
<a name="ln5701">    }</a>
<a name="ln5702"> </a>
<a name="ln5703">    NamespaceIdentifierPB *ns = resp-&gt;add_namespaces();</a>
<a name="ln5704">    ns-&gt;set_id(namespace_info.id());</a>
<a name="ln5705">    ns-&gt;set_name(namespace_info.name());</a>
<a name="ln5706">    ns-&gt;set_database_type(namespace_info.database_type());</a>
<a name="ln5707">  }</a>
<a name="ln5708">  return Status::OK();</a>
<a name="ln5709">}</a>
<a name="ln5710"> </a>
<a name="ln5711">Status CatalogManager::GetNamespaceInfo(const GetNamespaceInfoRequestPB* req,</a>
<a name="ln5712">                                        GetNamespaceInfoResponsePB* resp,</a>
<a name="ln5713">                                        rpc::RpcContext* rpc) {</a>
<a name="ln5714">  LOG(INFO) &lt;&lt; __func__ &lt;&lt; &quot; from &quot; &lt;&lt; RequestorString(rpc) &lt;&lt; &quot;: &quot; &lt;&lt; req-&gt;ShortDebugString();</a>
<a name="ln5715">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln5716"> </a>
<a name="ln5717">  scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln5718"> </a>
<a name="ln5719">  // Look up the namespace and verify if it exists.</a>
<a name="ln5720">  if (req-&gt;has_namespace_()) {</a>
<a name="ln5721">    TRACE(&quot;Looking up namespace&quot;);</a>
<a name="ln5722">    RETURN_NAMESPACE_NOT_FOUND(FindNamespace(req-&gt;namespace_(), &amp;ns), resp);</a>
<a name="ln5723">  }</a>
<a name="ln5724"> </a>
<a name="ln5725">  resp-&gt;mutable_namespace_()-&gt;set_id(ns-&gt;id());</a>
<a name="ln5726">  resp-&gt;mutable_namespace_()-&gt;set_name(ns-&gt;name());</a>
<a name="ln5727">  resp-&gt;mutable_namespace_()-&gt;set_database_type(ns-&gt;database_type());</a>
<a name="ln5728">  resp-&gt;set_colocated(ns-&gt;colocated());</a>
<a name="ln5729">  return Status::OK();</a>
<a name="ln5730">}</a>
<a name="ln5731"> </a>
<a name="ln5732">Status CatalogManager::RedisConfigSet(</a>
<a name="ln5733">    const RedisConfigSetRequestPB* req, RedisConfigSetResponsePB* resp, rpc::RpcContext* rpc) {</a>
<a name="ln5734">  DCHECK(req-&gt;has_keyword());</a>
<a name="ln5735">  const auto&amp; key = req-&gt;keyword();</a>
<a name="ln5736">  SysRedisConfigEntryPB config_entry;</a>
<a name="ln5737">  config_entry.set_key(key);</a>
<a name="ln5738">  *config_entry.mutable_args() = req-&gt;args();</a>
<a name="ln5739">  bool created = false;</a>
<a name="ln5740"> </a>
<a name="ln5741">  TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln5742">  std::lock_guard&lt;LockType&gt; l_big(lock_);</a>
<a name="ln5743">  scoped_refptr&lt;RedisConfigInfo&gt; cfg = FindPtrOrNull(redis_config_map_, req-&gt;keyword());</a>
<a name="ln5744">  if (cfg == nullptr) {</a>
<a name="ln5745">    created = true;</a>
<a name="ln5746">    cfg = new RedisConfigInfo(key);</a>
<a name="ln5747">    redis_config_map_[key] = cfg;</a>
<a name="ln5748">  }</a>
<a name="ln5749"> </a>
<a name="ln5750">  auto wl = cfg-&gt;LockForWrite();</a>
<a name="ln5751">  wl-&gt;mutable_data()-&gt;pb = std::move(config_entry);</a>
<a name="ln5752">  if (created) {</a>
<a name="ln5753">    CHECK_OK(sys_catalog_-&gt;AddItem(cfg.get(), leader_ready_term()));</a>
<a name="ln5754">  } else {</a>
<a name="ln5755">    CHECK_OK(sys_catalog_-&gt;UpdateItem(cfg.get(), leader_ready_term()));</a>
<a name="ln5756">  }</a>
<a name="ln5757">  wl-&gt;Commit();</a>
<a name="ln5758">  return Status::OK();</a>
<a name="ln5759">}</a>
<a name="ln5760"> </a>
<a name="ln5761">Status CatalogManager::RedisConfigGet(</a>
<a name="ln5762">    const RedisConfigGetRequestPB* req, RedisConfigGetResponsePB* resp, rpc::RpcContext* rpc) {</a>
<a name="ln5763">  DCHECK(req-&gt;has_keyword());</a>
<a name="ln5764">  resp-&gt;set_keyword(req-&gt;keyword());</a>
<a name="ln5765">  TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln5766">  std::lock_guard&lt;LockType&gt; l_big(lock_);</a>
<a name="ln5767">  scoped_refptr&lt;RedisConfigInfo&gt; cfg = FindPtrOrNull(redis_config_map_, req-&gt;keyword());</a>
<a name="ln5768">  if (cfg == nullptr) {</a>
<a name="ln5769">    Status s = STATUS_SUBSTITUTE(NotFound, &quot;Redis config for $0 does not exists&quot;, req-&gt;keyword());</a>
<a name="ln5770">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::REDIS_CONFIG_NOT_FOUND, s);</a>
<a name="ln5771">  }</a>
<a name="ln5772">  auto rci = cfg-&gt;LockForRead();</a>
<a name="ln5773">  resp-&gt;mutable_args()-&gt;CopyFrom(rci-&gt;data().pb.args());</a>
<a name="ln5774">  return Status::OK();</a>
<a name="ln5775">}</a>
<a name="ln5776"> </a>
<a name="ln5777">Status CatalogManager::CreateUDType(const CreateUDTypeRequestPB* req,</a>
<a name="ln5778">                                    CreateUDTypeResponsePB* resp,</a>
<a name="ln5779">                                    rpc::RpcContext* rpc) {</a>
<a name="ln5780">  LOG(INFO) &lt;&lt; &quot;CreateUDType from &quot; &lt;&lt; RequestorString(rpc)</a>
<a name="ln5781">            &lt;&lt; &quot;: &quot; &lt;&lt; req-&gt;DebugString();</a>
<a name="ln5782"> </a>
<a name="ln5783">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln5784">  Status s;</a>
<a name="ln5785">  scoped_refptr&lt;UDTypeInfo&gt; tp;</a>
<a name="ln5786">  scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln5787"> </a>
<a name="ln5788">  // Lookup the namespace and verify if it exists.</a>
<a name="ln5789">  if (req-&gt;has_namespace_()) {</a>
<a name="ln5790">    TRACE(&quot;Looking up namespace&quot;);</a>
<a name="ln5791">    RETURN_NAMESPACE_NOT_FOUND(FindNamespace(req-&gt;namespace_(), &amp;ns), resp);</a>
<a name="ln5792">    if (ns-&gt;database_type() != YQLDatabase::YQL_DATABASE_CQL) {</a>
<a name="ln5793">      Status s = STATUS(NotFound, &quot;Namespace not found&quot;);</a>
<a name="ln5794">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_NOT_FOUND, s);</a>
<a name="ln5795">    }</a>
<a name="ln5796">  }</a>
<a name="ln5797"> </a>
<a name="ln5798">  // Get all the referenced types (if any).</a>
<a name="ln5799">  std::vector&lt;std::string&gt; referenced_udts;</a>
<a name="ln5800">  for (const QLTypePB&amp; field_type : req-&gt;field_types()) {</a>
<a name="ln5801">    QLType::GetUserDefinedTypeIds(field_type, /* transitive = */ true, &amp;referenced_udts);</a>
<a name="ln5802">  }</a>
<a name="ln5803"> </a>
<a name="ln5804">  {</a>
<a name="ln5805">    TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln5806">    std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln5807"> </a>
<a name="ln5808">    // Verify that the type does not exist.</a>
<a name="ln5809">    tp = FindPtrOrNull(udtype_names_map_, std::make_pair(ns-&gt;id(), req-&gt;name()));</a>
<a name="ln5810"> </a>
<a name="ln5811">    if (tp != nullptr) {</a>
<a name="ln5812">      s = STATUS_SUBSTITUTE(AlreadyPresent,</a>
<a name="ln5813">          &quot;Type '$0.$1' already exists&quot;, ns-&gt;name(), req-&gt;name());</a>
<a name="ln5814">      LOG(WARNING) &lt;&lt; &quot;Found type: &quot; &lt;&lt; tp-&gt;id() &lt;&lt; &quot;. Failed creating type with error: &quot;</a>
<a name="ln5815">                   &lt;&lt; s.ToString() &lt;&lt; &quot; Request:\n&quot; &lt;&lt; req-&gt;DebugString();</a>
<a name="ln5816">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::TYPE_ALREADY_PRESENT, s);</a>
<a name="ln5817">    }</a>
<a name="ln5818"> </a>
<a name="ln5819">    // Verify that all referenced types actually exist.</a>
<a name="ln5820">    for (const auto&amp; udt_id : referenced_udts) {</a>
<a name="ln5821">      if (FindPtrOrNull(udtype_ids_map_, udt_id) == nullptr) {</a>
<a name="ln5822">          // This may be caused by a stale cache (e.g. referenced type name resolves to an old,</a>
<a name="ln5823">          // deleted type). Return InvalidArgument so query layer will clear cache and retry.</a>
<a name="ln5824">          s = STATUS_SUBSTITUTE(InvalidArgument,</a>
<a name="ln5825">          &quot;Type id '$0' referenced by type '$1' does not exist&quot;, udt_id, req-&gt;name());</a>
<a name="ln5826">        return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_REQUEST, s);</a>
<a name="ln5827">      }</a>
<a name="ln5828">    }</a>
<a name="ln5829"> </a>
<a name="ln5830">    // Construct the new type (generate fresh name and set fields).</a>
<a name="ln5831">    UDTypeId new_id = GenerateIdUnlocked(SysRowEntry::UDTYPE);</a>
<a name="ln5832">    tp = new UDTypeInfo(new_id);</a>
<a name="ln5833">    tp-&gt;mutable_metadata()-&gt;StartMutation();</a>
<a name="ln5834">    SysUDTypeEntryPB *metadata = &amp;tp-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;pb;</a>
<a name="ln5835">    metadata-&gt;set_name(req-&gt;name());</a>
<a name="ln5836">    metadata-&gt;set_namespace_id(ns-&gt;id());</a>
<a name="ln5837">    for (const string&amp; field_name : req-&gt;field_names()) {</a>
<a name="ln5838">      metadata-&gt;add_field_names(field_name);</a>
<a name="ln5839">    }</a>
<a name="ln5840"> </a>
<a name="ln5841">    for (const QLTypePB&amp; field_type : req-&gt;field_types()) {</a>
<a name="ln5842">      metadata-&gt;add_field_types()-&gt;CopyFrom(field_type);</a>
<a name="ln5843">    }</a>
<a name="ln5844"> </a>
<a name="ln5845">    // Add the type to the in-memory maps.</a>
<a name="ln5846">    udtype_ids_map_[tp-&gt;id()] = tp;</a>
<a name="ln5847">    udtype_names_map_[std::make_pair(ns-&gt;id(), req-&gt;name())] = tp;</a>
<a name="ln5848">    resp-&gt;set_id(tp-&gt;id());</a>
<a name="ln5849">  }</a>
<a name="ln5850">  TRACE(&quot;Inserted new user-defined type info into CatalogManager maps&quot;);</a>
<a name="ln5851"> </a>
<a name="ln5852">  // Update the on-disk system catalog.</a>
<a name="ln5853">  s = sys_catalog_-&gt;AddItem(tp.get(), leader_ready_term());</a>
<a name="ln5854">  if (!s.ok()) {</a>
<a name="ln5855">    s = s.CloneAndPrepend(Substitute(</a>
<a name="ln5856">        &quot;An error occurred while inserting user-defined type to sys-catalog: $0&quot;, s.ToString()));</a>
<a name="ln5857">    LOG(WARNING) &lt;&lt; s.ToString();</a>
<a name="ln5858">    return CheckIfNoLongerLeaderAndSetupError(s, resp);</a>
<a name="ln5859">  }</a>
<a name="ln5860">  TRACE(&quot;Wrote user-defined type to sys-catalog&quot;);</a>
<a name="ln5861"> </a>
<a name="ln5862">  // Commit the in-memory state.</a>
<a name="ln5863">  tp-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln5864">  LOG(INFO) &lt;&lt; &quot;Created user-defined type &quot; &lt;&lt; tp-&gt;ToString();</a>
<a name="ln5865">  return Status::OK();</a>
<a name="ln5866">}</a>
<a name="ln5867"> </a>
<a name="ln5868">Status CatalogManager::DeleteUDType(const DeleteUDTypeRequestPB* req,</a>
<a name="ln5869">                                    DeleteUDTypeResponsePB* resp,</a>
<a name="ln5870">                                    rpc::RpcContext* rpc) {</a>
<a name="ln5871">  LOG(INFO) &lt;&lt; &quot;Servicing DeleteUDType request from &quot; &lt;&lt; RequestorString(rpc)</a>
<a name="ln5872">            &lt;&lt; &quot;: &quot; &lt;&lt; req-&gt;ShortDebugString();</a>
<a name="ln5873"> </a>
<a name="ln5874">      RETURN_NOT_OK(CheckOnline());</a>
<a name="ln5875">  scoped_refptr&lt;UDTypeInfo&gt; tp;</a>
<a name="ln5876">  scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln5877"> </a>
<a name="ln5878">  if (!req-&gt;has_type()) {</a>
<a name="ln5879">    Status s = STATUS(InvalidArgument, &quot;No type given&quot;, req-&gt;DebugString());</a>
<a name="ln5880">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::NAMESPACE_NOT_FOUND, s);</a>
<a name="ln5881">  }</a>
<a name="ln5882"> </a>
<a name="ln5883">  // Validate namespace.</a>
<a name="ln5884">  if (req-&gt;type().has_namespace_()) {</a>
<a name="ln5885">    // Lookup the namespace and verify if it exists.</a>
<a name="ln5886">    TRACE(&quot;Looking up namespace&quot;);</a>
<a name="ln5887">    RETURN_NAMESPACE_NOT_FOUND(FindNamespace(req-&gt;type().namespace_(), &amp;ns), resp);</a>
<a name="ln5888">  }</a>
<a name="ln5889"> </a>
<a name="ln5890">  {</a>
<a name="ln5891">    std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln5892">    TRACE(&quot;Acquired catalog manager lock&quot;);</a>
<a name="ln5893"> </a>
<a name="ln5894">    if (req-&gt;type().has_type_id()) {</a>
<a name="ln5895">      tp = FindPtrOrNull(udtype_ids_map_, req-&gt;type().type_id());</a>
<a name="ln5896">    } else if (req-&gt;type().has_type_name()) {</a>
<a name="ln5897">      tp = FindPtrOrNull(udtype_names_map_, {ns-&gt;id(), req-&gt;type().type_name()});</a>
<a name="ln5898">    }</a>
<a name="ln5899"> </a>
<a name="ln5900">    if (tp == nullptr) {</a>
<a name="ln5901">      Status s = STATUS(NotFound, &quot;The type does not exist&quot;, req-&gt;DebugString());</a>
<a name="ln5902">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::TYPE_NOT_FOUND, s);</a>
<a name="ln5903">    }</a>
<a name="ln5904"> </a>
<a name="ln5905">    // Checking if any table uses this type.</a>
<a name="ln5906">    // TODO: this could be more efficient.</a>
<a name="ln5907">    for (const TableInfoMap::value_type&amp; entry : *table_ids_map_) {</a>
<a name="ln5908">      auto ltm = entry.second-&gt;LockForRead();</a>
<a name="ln5909">      if (!ltm-&gt;data().started_deleting()) {</a>
<a name="ln5910">        for (const auto &amp;col : ltm-&gt;data().schema().columns()) {</a>
<a name="ln5911">          if (col.type().main() == DataType::USER_DEFINED_TYPE &amp;&amp;</a>
<a name="ln5912">              col.type().udtype_info().id() == tp-&gt;id()) {</a>
<a name="ln5913">            Status s = STATUS(QLError,</a>
<a name="ln5914">                Substitute(&quot;Cannot delete type '$0.$1'. It is used in column $2 of table $3&quot;,</a>
<a name="ln5915">                    ns-&gt;name(), tp-&gt;name(), col.name(), ltm-&gt;data().name()));</a>
<a name="ln5916">            return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_REQUEST, s);</a>
<a name="ln5917">          }</a>
<a name="ln5918">        }</a>
<a name="ln5919">      }</a>
<a name="ln5920">    }</a>
<a name="ln5921"> </a>
<a name="ln5922">    // Checking if any other type uses this type (i.e. in the case of nested types).</a>
<a name="ln5923">    // TODO: this could be more efficient.</a>
<a name="ln5924">    for (const UDTypeInfoMap::value_type&amp; entry : udtype_ids_map_) {</a>
<a name="ln5925">      auto ltm = entry.second-&gt;LockForRead();</a>
<a name="ln5926"> </a>
<a name="ln5927">      for (int i = 0; i &lt; ltm-&gt;data().field_types_size(); i++) {</a>
<a name="ln5928">        std::vector&lt;std::string&gt; referenced_udts;</a>
<a name="ln5929">        // Only need to check direct (non-transitive) type dependencies here.</a>
<a name="ln5930">        // This also means we report more precise errors for in-use types.</a>
<a name="ln5931">        QLType::GetUserDefinedTypeIds(ltm-&gt;data().field_types(i),</a>
<a name="ln5932">                                      false /* transitive */,</a>
<a name="ln5933">                                      &amp;referenced_udts);</a>
<a name="ln5934">        auto it = std::find(referenced_udts.begin(), referenced_udts.end(), tp-&gt;id());</a>
<a name="ln5935">        if (it != referenced_udts.end()) {</a>
<a name="ln5936">          Status s = STATUS(QLError,</a>
<a name="ln5937">              Substitute(&quot;Cannot delete type '$0.$1'. It is used in field $2 of type '$3'&quot;,</a>
<a name="ln5938">                  ns-&gt;name(), tp-&gt;name(), ltm-&gt;data().field_names(i), ltm-&gt;data().name()));</a>
<a name="ln5939">          return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_REQUEST, s);</a>
<a name="ln5940">        }</a>
<a name="ln5941">      }</a>
<a name="ln5942">    }</a>
<a name="ln5943">  }</a>
<a name="ln5944"> </a>
<a name="ln5945">  auto l = tp-&gt;LockForWrite();</a>
<a name="ln5946"> </a>
<a name="ln5947">  Status s = sys_catalog_-&gt;DeleteItem(tp.get(), leader_ready_term());</a>
<a name="ln5948">  if (!s.ok()) {</a>
<a name="ln5949">    // The mutation will be aborted when 'l' exits the scope on early return.</a>
<a name="ln5950">    s = s.CloneAndPrepend(Substitute(&quot;An error occurred while updating sys-catalog: $0&quot;,</a>
<a name="ln5951">        s.ToString()));</a>
<a name="ln5952">    LOG(WARNING) &lt;&lt; s.ToString();</a>
<a name="ln5953">    return CheckIfNoLongerLeaderAndSetupError(s, resp);</a>
<a name="ln5954">  }</a>
<a name="ln5955"> </a>
<a name="ln5956">  // Remove it from the maps.</a>
<a name="ln5957">  {</a>
<a name="ln5958">    TRACE(&quot;Removing from maps&quot;);</a>
<a name="ln5959">    std::lock_guard&lt;LockType&gt; l_map(lock_);</a>
<a name="ln5960">    if (udtype_ids_map_.erase(tp-&gt;id()) &lt; 1) {</a>
<a name="ln5961">      PANIC_RPC(rpc, &quot;Could not remove user defined type from map, name=&quot; + l-&gt;data().name());</a>
<a name="ln5962">    }</a>
<a name="ln5963">    if (udtype_names_map_.erase({ns-&gt;id(), tp-&gt;name()}) &lt; 1) {</a>
<a name="ln5964">      PANIC_RPC(rpc, &quot;Could not remove user defined type from map, name=&quot; + l-&gt;data().name());</a>
<a name="ln5965">    }</a>
<a name="ln5966">  }</a>
<a name="ln5967"> </a>
<a name="ln5968">  // Update the in-memory state.</a>
<a name="ln5969">  TRACE(&quot;Committing in-memory state&quot;);</a>
<a name="ln5970">  l-&gt;Commit();</a>
<a name="ln5971"> </a>
<a name="ln5972">  LOG(INFO) &lt;&lt; &quot;Successfully deleted user-defined type &quot; &lt;&lt; tp-&gt;ToString()</a>
<a name="ln5973">            &lt;&lt; &quot; per request from &quot; &lt;&lt; RequestorString(rpc);</a>
<a name="ln5974"> </a>
<a name="ln5975">  return Status::OK();</a>
<a name="ln5976">}</a>
<a name="ln5977"> </a>
<a name="ln5978">Status CatalogManager::GetUDTypeInfo(const GetUDTypeInfoRequestPB* req,</a>
<a name="ln5979">                                     GetUDTypeInfoResponsePB* resp,</a>
<a name="ln5980">                                     rpc::RpcContext* rpc) {</a>
<a name="ln5981">  LOG(INFO) &lt;&lt; &quot;GetUDTypeInfo from &quot; &lt;&lt; RequestorString(rpc)</a>
<a name="ln5982">            &lt;&lt; &quot;: &quot; &lt;&lt; req-&gt;DebugString();</a>
<a name="ln5983">      RETURN_NOT_OK(CheckOnline());</a>
<a name="ln5984">  Status s;</a>
<a name="ln5985">  scoped_refptr&lt;UDTypeInfo&gt; tp;</a>
<a name="ln5986">  scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln5987"> </a>
<a name="ln5988">  if (!req-&gt;has_type()) {</a>
<a name="ln5989">    s = STATUS(InvalidArgument, &quot;Cannot get type, no type identifier given&quot;, req-&gt;DebugString());</a>
<a name="ln5990">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::TYPE_NOT_FOUND, s);</a>
<a name="ln5991">  }</a>
<a name="ln5992"> </a>
<a name="ln5993">  if (req-&gt;type().has_type_id()) {</a>
<a name="ln5994">    tp = FindPtrOrNull(udtype_ids_map_, req-&gt;type().type_id());</a>
<a name="ln5995">  } else if (req-&gt;type().has_type_name() &amp;&amp; req-&gt;type().has_namespace_()) {</a>
<a name="ln5996">    // Lookup the type and verify if it exists.</a>
<a name="ln5997">    TRACE(&quot;Looking up namespace&quot;);</a>
<a name="ln5998">    RETURN_NAMESPACE_NOT_FOUND(FindNamespace(req-&gt;type().namespace_(), &amp;ns), resp);</a>
<a name="ln5999"> </a>
<a name="ln6000">    tp = FindPtrOrNull(udtype_names_map_, std::make_pair(ns-&gt;id(), req-&gt;type().type_name()));</a>
<a name="ln6001">  }</a>
<a name="ln6002"> </a>
<a name="ln6003">  if (tp == nullptr) {</a>
<a name="ln6004">    s = STATUS(InvalidArgument, &quot;Couldn't find type&quot;, req-&gt;DebugString());</a>
<a name="ln6005">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::TYPE_NOT_FOUND, s);</a>
<a name="ln6006">  }</a>
<a name="ln6007"> </a>
<a name="ln6008">  {</a>
<a name="ln6009">    auto type_lock = tp-&gt;LockForRead();</a>
<a name="ln6010"> </a>
<a name="ln6011">    UDTypeInfoPB* type_info = resp-&gt;mutable_udtype();</a>
<a name="ln6012"> </a>
<a name="ln6013">    type_info-&gt;set_name(tp-&gt;name());</a>
<a name="ln6014">    type_info-&gt;set_id(tp-&gt;id());</a>
<a name="ln6015">    type_info-&gt;mutable_namespace_()-&gt;set_id(type_lock-&gt;data().namespace_id());</a>
<a name="ln6016"> </a>
<a name="ln6017">    for (int i = 0; i &lt; type_lock-&gt;data().field_names_size(); i++) {</a>
<a name="ln6018">      type_info-&gt;add_field_names(type_lock-&gt;data().field_names(i));</a>
<a name="ln6019">    }</a>
<a name="ln6020">    for (int i = 0; i &lt; type_lock-&gt;data().field_types_size(); i++) {</a>
<a name="ln6021">      type_info-&gt;add_field_types()-&gt;CopyFrom(type_lock-&gt;data().field_types(i));</a>
<a name="ln6022">    }</a>
<a name="ln6023"> </a>
<a name="ln6024">    LOG(INFO) &lt;&lt; &quot;Retrieved user-defined type &quot; &lt;&lt; tp-&gt;ToString();</a>
<a name="ln6025">  }</a>
<a name="ln6026">  return Status::OK();</a>
<a name="ln6027">}</a>
<a name="ln6028"> </a>
<a name="ln6029">Status CatalogManager::ListUDTypes(const ListUDTypesRequestPB* req,</a>
<a name="ln6030">                                   ListUDTypesResponsePB* resp) {</a>
<a name="ln6031"> </a>
<a name="ln6032">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln6033"> </a>
<a name="ln6034">  scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln6035"> </a>
<a name="ln6036">  // Validate namespace.</a>
<a name="ln6037">  if (req-&gt;has_namespace_()) {</a>
<a name="ln6038">    scoped_refptr&lt;NamespaceInfo&gt; ns;</a>
<a name="ln6039"> </a>
<a name="ln6040">    // Lookup the namespace and verify that it exists.</a>
<a name="ln6041">    RETURN_NAMESPACE_NOT_FOUND(FindNamespace(req-&gt;namespace_(), &amp;ns), resp);</a>
<a name="ln6042">  }</a>
<a name="ln6043"> </a>
<a name="ln6044">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln6045"> </a>
<a name="ln6046">  for (const UDTypeInfoByNameMap::value_type&amp; entry : udtype_names_map_) {</a>
<a name="ln6047">    auto ltm = entry.second-&gt;LockForRead();</a>
<a name="ln6048"> </a>
<a name="ln6049">    // key is a pair &lt;namespace_id, type_name&gt;.</a>
<a name="ln6050">    if (!ns-&gt;id().empty() &amp;&amp; ns-&gt;id() != entry.first.first) {</a>
<a name="ln6051">      continue; // Skip types from other namespaces.</a>
<a name="ln6052">    }</a>
<a name="ln6053"> </a>
<a name="ln6054">    UDTypeInfoPB* udtype = resp-&gt;add_udtypes();</a>
<a name="ln6055">    udtype-&gt;set_id(entry.second-&gt;id());</a>
<a name="ln6056">    udtype-&gt;set_name(ltm-&gt;data().name());</a>
<a name="ln6057">    for (size_t i = 0; i &lt;= ltm-&gt;data().field_names_size(); i++) {</a>
<a name="ln6058">      udtype-&gt;add_field_names(ltm-&gt;data().field_names(i));</a>
<a name="ln6059">    }</a>
<a name="ln6060">    for (size_t i = 0; i &lt;= ltm-&gt;data().field_types_size(); i++) {</a>
<a name="ln6061">      udtype-&gt;add_field_types()-&gt;CopyFrom(ltm-&gt;data().field_types(i));</a>
<a name="ln6062">    }</a>
<a name="ln6063"> </a>
<a name="ln6064">    if (CHECK_NOTNULL(ns.get())) {</a>
<a name="ln6065">      auto l = ns-&gt;LockForRead();</a>
<a name="ln6066">      udtype-&gt;mutable_namespace_()-&gt;set_id(ns-&gt;id());</a>
<a name="ln6067">      udtype-&gt;mutable_namespace_()-&gt;set_name(ns-&gt;name());</a>
<a name="ln6068">    }</a>
<a name="ln6069">  }</a>
<a name="ln6070">  return Status::OK();</a>
<a name="ln6071">}</a>
<a name="ln6072"> </a>
<a name="ln6073">// For non-enterprise builds, this is a no-op.</a>
<a name="ln6074">Status CatalogManager::DeleteCDCStreamsForTable(const TableId&amp; table) {</a>
<a name="ln6075">  return Status::OK();</a>
<a name="ln6076">}</a>
<a name="ln6077"> </a>
<a name="ln6078">Status CatalogManager::DeleteCDCStreamsForTables(const vector&lt;TableId&gt;&amp; table_ids) {</a>
<a name="ln6079">  return Status::OK();</a>
<a name="ln6080">}</a>
<a name="ln6081"> </a>
<a name="ln6082"> </a>
<a name="ln6083">bool CatalogManager::CDCStreamExistsUnlocked(const CDCStreamId&amp; stream_id) {</a>
<a name="ln6084">  return false;</a>
<a name="ln6085">}</a>
<a name="ln6086"> </a>
<a name="ln6087">Result&lt;uint64_t&gt; CatalogManager::IncrementYsqlCatalogVersion() {</a>
<a name="ln6088"> </a>
<a name="ln6089">  auto l = CHECK_NOTNULL(ysql_catalog_config_.get())-&gt;LockForWrite();</a>
<a name="ln6090">  uint64_t new_version = l-&gt;data().pb.ysql_catalog_config().version() + 1;</a>
<a name="ln6091">  l-&gt;mutable_data()-&gt;pb.mutable_ysql_catalog_config()-&gt;set_version(new_version);</a>
<a name="ln6092"> </a>
<a name="ln6093">  // Write to sys_catalog and in memory.</a>
<a name="ln6094">  RETURN_NOT_OK(sys_catalog_-&gt;UpdateItem(ysql_catalog_config_.get(), leader_ready_term()));</a>
<a name="ln6095">  l-&gt;Commit();</a>
<a name="ln6096"> </a>
<a name="ln6097">  return new_version;</a>
<a name="ln6098">}</a>
<a name="ln6099"> </a>
<a name="ln6100">Status CatalogManager::InitDbFinished(Status initdb_status, int64_t term) {</a>
<a name="ln6101">  if (initdb_status.ok()) {</a>
<a name="ln6102">    LOG(INFO) &lt;&lt; &quot;initdb completed successfully&quot;;</a>
<a name="ln6103">  } else {</a>
<a name="ln6104">    LOG(ERROR) &lt;&lt; &quot;initdb failed: &quot; &lt;&lt; initdb_status;</a>
<a name="ln6105">  }</a>
<a name="ln6106"> </a>
<a name="ln6107">  auto l = CHECK_NOTNULL(ysql_catalog_config_.get())-&gt;LockForWrite();</a>
<a name="ln6108">  auto* mutable_ysql_catalog_config = l-&gt;mutable_data()-&gt;pb.mutable_ysql_catalog_config();</a>
<a name="ln6109">  mutable_ysql_catalog_config-&gt;set_initdb_done(true);</a>
<a name="ln6110">  if (!initdb_status.ok()) {</a>
<a name="ln6111">    mutable_ysql_catalog_config-&gt;set_initdb_error(initdb_status.ToString());</a>
<a name="ln6112">  } else {</a>
<a name="ln6113">    mutable_ysql_catalog_config-&gt;clear_initdb_error();</a>
<a name="ln6114">  }</a>
<a name="ln6115"> </a>
<a name="ln6116">  RETURN_NOT_OK(sys_catalog_-&gt;AddItem(ysql_catalog_config_.get(), term));</a>
<a name="ln6117">  l-&gt;Commit();</a>
<a name="ln6118">  return Status::OK();</a>
<a name="ln6119">}</a>
<a name="ln6120"> </a>
<a name="ln6121">CHECKED_STATUS CatalogManager::IsInitDbDone(</a>
<a name="ln6122">    const IsInitDbDoneRequestPB* req,</a>
<a name="ln6123">    IsInitDbDoneResponsePB* resp) {</a>
<a name="ln6124">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln6125"> </a>
<a name="ln6126">  auto l = CHECK_NOTNULL(ysql_catalog_config_.get())-&gt;LockForRead();</a>
<a name="ln6127">  const auto&amp; ysql_catalog_config = l-&gt;data().pb.ysql_catalog_config();</a>
<a name="ln6128">  resp-&gt;set_pg_proc_exists(pg_proc_exists_.load(std::memory_order_acquire));</a>
<a name="ln6129">  resp-&gt;set_done(ysql_catalog_config.initdb_done());</a>
<a name="ln6130">  if (ysql_catalog_config.has_initdb_error() &amp;&amp;</a>
<a name="ln6131">      !ysql_catalog_config.initdb_error().empty()) {</a>
<a name="ln6132">    resp-&gt;set_initdb_error(ysql_catalog_config.initdb_error());</a>
<a name="ln6133">  }</a>
<a name="ln6134">  return Status::OK();</a>
<a name="ln6135">}</a>
<a name="ln6136"> </a>
<a name="ln6137">uint64_t CatalogManager::GetYsqlCatalogVersion() {</a>
<a name="ln6138">  auto l = ysql_catalog_config_-&gt;LockForRead();</a>
<a name="ln6139">  return l-&gt;data().pb.ysql_catalog_config().version();</a>
<a name="ln6140">}</a>
<a name="ln6141"> </a>
<a name="ln6142">Status CatalogManager::RegisterTsFromRaftConfig(const consensus::RaftPeerPB&amp; peer) {</a>
<a name="ln6143">  NodeInstancePB instance_pb;</a>
<a name="ln6144">  instance_pb.set_permanent_uuid(peer.permanent_uuid());</a>
<a name="ln6145">  instance_pb.set_instance_seqno(0);</a>
<a name="ln6146"> </a>
<a name="ln6147">  TSRegistrationPB registration_pb;</a>
<a name="ln6148">  auto* common = registration_pb.mutable_common();</a>
<a name="ln6149">  *common-&gt;mutable_private_rpc_addresses() = peer.last_known_private_addr();</a>
<a name="ln6150">  *common-&gt;mutable_broadcast_addresses() = peer.last_known_broadcast_addr();</a>
<a name="ln6151">  *common-&gt;mutable_cloud_info() = peer.cloud_info();</a>
<a name="ln6152"> </a>
<a name="ln6153">  return master_-&gt;ts_manager()-&gt;RegisterTS(instance_pb, registration_pb, master_-&gt;MakeCloudInfoPB(),</a>
<a name="ln6154">                                           &amp;master_-&gt;proxy_cache(),</a>
<a name="ln6155">                                           RegisteredThroughHeartbeat::kFalse);</a>
<a name="ln6156">}</a>
<a name="ln6157"> </a>
<a name="ln6158">void CatalogManager::ReconcileTabletReplicasInLocalMemoryWithReport(</a>
<a name="ln6159">    const scoped_refptr&lt;TabletInfo&gt;&amp; tablet,</a>
<a name="ln6160">    const std::string&amp; sender_uuid,</a>
<a name="ln6161">    const ConsensusStatePB&amp; consensus_state,</a>
<a name="ln6162">    const RaftGroupStatePB&amp; replica_state) {</a>
<a name="ln6163">  TabletInfo::ReplicaMap replica_locations;</a>
<a name="ln6164">  TabletInfo::ReplicaMap prev_rl;</a>
<a name="ln6165">  tablet-&gt;GetReplicaLocations(&amp;prev_rl);</a>
<a name="ln6166"> </a>
<a name="ln6167">  for (const consensus::RaftPeerPB&amp; peer : consensus_state.config().peers()) {</a>
<a name="ln6168">    shared_ptr&lt;TSDescriptor&gt; ts_desc;</a>
<a name="ln6169">    if (!peer.has_permanent_uuid()) {</a>
<a name="ln6170">      LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Missing UUID for peer&quot; &lt;&lt; peer.ShortDebugString();</a>
<a name="ln6171">      continue;</a>
<a name="ln6172">    }</a>
<a name="ln6173">    if (!master_-&gt;ts_manager()-&gt;LookupTSByUUID(peer.permanent_uuid(), &amp;ts_desc)) {</a>
<a name="ln6174">      if (!GetAtomicFlag(&amp;FLAGS_enable_register_ts_from_raft)) {</a>
<a name="ln6175">        LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Tablet server has never reported in. &quot;</a>
<a name="ln6176">        &lt;&lt; &quot;Not including in replica locations map yet. Peer: &quot; &lt;&lt; peer.ShortDebugString()</a>
<a name="ln6177">        &lt;&lt; &quot;; Tablet: &quot; &lt;&lt; tablet-&gt;ToString();</a>
<a name="ln6178">        continue;</a>
<a name="ln6179">      }</a>
<a name="ln6180"> </a>
<a name="ln6181">      LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Tablet server has never reported in. Registering the ts using &quot;</a>
<a name="ln6182">                            &lt;&lt; &quot;the raft config. Peer: &quot; &lt;&lt; peer.ShortDebugString()</a>
<a name="ln6183">                            &lt;&lt; &quot;; Tablet: &quot; &lt;&lt; tablet-&gt;ToString();</a>
<a name="ln6184">      Status s = RegisterTsFromRaftConfig(peer);</a>
<a name="ln6185">      if (!s.ok()) {</a>
<a name="ln6186">        LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Could not register ts from raft config: &quot; &lt;&lt; s</a>
<a name="ln6187">                                 &lt;&lt; &quot; Skip updating the replica map.&quot;;</a>
<a name="ln6188">        continue;</a>
<a name="ln6189">      }</a>
<a name="ln6190"> </a>
<a name="ln6191">      // Guaranteed to find the ts since we just registered.</a>
<a name="ln6192">      master_-&gt;ts_manager()-&gt;LookupTSByUUID(peer.permanent_uuid(), &amp;ts_desc);</a>
<a name="ln6193">      if (!ts_desc.get()) {</a>
<a name="ln6194">        LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Could not find ts with uuid &quot; &lt;&lt; peer.permanent_uuid()</a>
<a name="ln6195">                                 &lt;&lt; &quot; after registering from raft config. Skip updating the replica&quot;</a>
<a name="ln6196">                                 &lt;&lt; &quot; map.&quot;;</a>
<a name="ln6197">        continue;</a>
<a name="ln6198">      }</a>
<a name="ln6199">    }</a>
<a name="ln6200"> </a>
<a name="ln6201">    // Do not update replicas in the NOT_STARTED or BOOTSTRAPPING state (unless they are stale).</a>
<a name="ln6202">    bool use_existing = false;</a>
<a name="ln6203">    TabletReplica* existing_replica;</a>
<a name="ln6204">    if (peer.permanent_uuid() != sender_uuid) {</a>
<a name="ln6205">      auto it = prev_rl.find(ts_desc-&gt;permanent_uuid());</a>
<a name="ln6206">      if (it != prev_rl.end()) {</a>
<a name="ln6207">        existing_replica = &amp;it-&gt;second;</a>
<a name="ln6208">        // IsStarting returns true if state == NOT_STARTED or state == BOOTSTRAPPING.</a>
<a name="ln6209">        use_existing = existing_replica-&gt;IsStarting() &amp;&amp; !existing_replica-&gt;IsStale();</a>
<a name="ln6210">      }</a>
<a name="ln6211">    }</a>
<a name="ln6212">    if (use_existing) {</a>
<a name="ln6213">      InsertOrDie(&amp;replica_locations, existing_replica-&gt;ts_desc-&gt;permanent_uuid(),</a>
<a name="ln6214">          *existing_replica);</a>
<a name="ln6215">    } else {</a>
<a name="ln6216">      TabletReplica replica;</a>
<a name="ln6217">      CreateNewReplicaForLocalMemory(ts_desc.get(), &amp;consensus_state, replica_state, &amp;replica);</a>
<a name="ln6218">      InsertOrDie(&amp;replica_locations, replica.ts_desc-&gt;permanent_uuid(), replica);</a>
<a name="ln6219">    }</a>
<a name="ln6220">  }</a>
<a name="ln6221"> </a>
<a name="ln6222">  // Update the local tablet replica set. This deviates from persistent state during bootstrapping.</a>
<a name="ln6223">  tablet-&gt;SetReplicaLocations(std::move(replica_locations));</a>
<a name="ln6224">  tablet_locations_version_.fetch_add(1, std::memory_order_acq_rel);</a>
<a name="ln6225">}</a>
<a name="ln6226"> </a>
<a name="ln6227">void CatalogManager::UpdateTabletReplicaInLocalMemory(TSDescriptor* ts_desc,</a>
<a name="ln6228">                                                      const ConsensusStatePB* consensus_state,</a>
<a name="ln6229">                                                      const RaftGroupStatePB&amp; replica_state,</a>
<a name="ln6230">                                                      const scoped_refptr&lt;TabletInfo&gt;&amp; tablet) {</a>
<a name="ln6231">  TabletReplica replica;</a>
<a name="ln6232">  CreateNewReplicaForLocalMemory(ts_desc, consensus_state, replica_state, &amp;replica);</a>
<a name="ln6233">  tablet-&gt;UpdateReplicaLocations(replica);</a>
<a name="ln6234">  tablet_locations_version_.fetch_add(1, std::memory_order_acq_rel);</a>
<a name="ln6235">}</a>
<a name="ln6236"> </a>
<a name="ln6237">void CatalogManager::CreateNewReplicaForLocalMemory(TSDescriptor* ts_desc,</a>
<a name="ln6238">                                                    const ConsensusStatePB* consensus_state,</a>
<a name="ln6239">                                                    const RaftGroupStatePB&amp; replica_state,</a>
<a name="ln6240">                                                    TabletReplica* new_replica) {</a>
<a name="ln6241">  // Tablets in state NOT_STARTED or BOOTSTRAPPING don't have a consensus.</a>
<a name="ln6242">  if (consensus_state == nullptr) {</a>
<a name="ln6243">    new_replica-&gt;role = RaftPeerPB::NON_PARTICIPANT;</a>
<a name="ln6244">    new_replica-&gt;member_type = RaftPeerPB::UNKNOWN_MEMBER_TYPE;</a>
<a name="ln6245">  } else {</a>
<a name="ln6246">    CHECK(consensus_state != nullptr) &lt;&lt; &quot;No cstate: &quot; &lt;&lt; ts_desc-&gt;permanent_uuid()</a>
<a name="ln6247">                                      &lt;&lt; &quot; - &quot; &lt;&lt; replica_state;</a>
<a name="ln6248">    new_replica-&gt;role = GetConsensusRole(ts_desc-&gt;permanent_uuid(), *consensus_state);</a>
<a name="ln6249">    new_replica-&gt;member_type = GetConsensusMemberType(ts_desc-&gt;permanent_uuid(), *consensus_state);</a>
<a name="ln6250">  }</a>
<a name="ln6251">  new_replica-&gt;state = replica_state;</a>
<a name="ln6252">  new_replica-&gt;ts_desc = ts_desc;</a>
<a name="ln6253">  if (!ts_desc-&gt;registered_through_heartbeat()) {</a>
<a name="ln6254">    new_replica-&gt;time_updated = MonoTime::Now() - ts_desc-&gt;TimeSinceHeartbeat();</a>
<a name="ln6255">  }</a>
<a name="ln6256">}</a>
<a name="ln6257"> </a>
<a name="ln6258">Status CatalogManager::GetTabletPeer(const TabletId&amp; tablet_id,</a>
<a name="ln6259">                                     std::shared_ptr&lt;TabletPeer&gt;* ret_tablet_peer) const {</a>
<a name="ln6260">  // Note: CatalogManager has only one table, 'sys_catalog', with only</a>
<a name="ln6261">  // one tablet.</a>
<a name="ln6262"> </a>
<a name="ln6263">  if (PREDICT_FALSE(!IsInitialized())) {</a>
<a name="ln6264">    // Master puts up the consensus service first and then initiates catalog manager's creation</a>
<a name="ln6265">    // asynchronously. So this case is possible, but harmless. The RPC will simply be retried.</a>
<a name="ln6266">    // Previously, because we weren't checking for this condition, we would fatal down stream.</a>
<a name="ln6267">    const string&amp; reason = &quot;CatalogManager is not yet initialized&quot;;</a>
<a name="ln6268">    YB_LOG_EVERY_N(WARNING, 1000) &lt;&lt; reason;</a>
<a name="ln6269">    return STATUS(ServiceUnavailable, reason);</a>
<a name="ln6270">  }</a>
<a name="ln6271"> </a>
<a name="ln6272">  CHECK(sys_catalog_) &lt;&lt; &quot;sys_catalog_ must be initialized!&quot;;</a>
<a name="ln6273"> </a>
<a name="ln6274">  if (master_-&gt;opts().IsShellMode()) {</a>
<a name="ln6275">    return STATUS_SUBSTITUTE(NotFound,</a>
<a name="ln6276">        &quot;In shell mode: no tablet_id $0 exists in CatalogManager.&quot;, tablet_id);</a>
<a name="ln6277">  }</a>
<a name="ln6278"> </a>
<a name="ln6279">  if (sys_catalog_-&gt;tablet_id() == tablet_id &amp;&amp; sys_catalog_-&gt;tablet_peer().get() != nullptr &amp;&amp;</a>
<a name="ln6280">      sys_catalog_-&gt;tablet_peer()-&gt;CheckRunning().ok()) {</a>
<a name="ln6281">    *ret_tablet_peer = tablet_peer();</a>
<a name="ln6282">  } else {</a>
<a name="ln6283">    return STATUS_SUBSTITUTE(NotFound,</a>
<a name="ln6284">        &quot;no SysTable in the RUNNING state exists with tablet_id $0 in CatalogManager&quot;, tablet_id);</a>
<a name="ln6285">  }</a>
<a name="ln6286">  return Status::OK();</a>
<a name="ln6287">}</a>
<a name="ln6288"> </a>
<a name="ln6289">const NodeInstancePB&amp; CatalogManager::NodeInstance() const {</a>
<a name="ln6290">  return master_-&gt;instance_pb();</a>
<a name="ln6291">}</a>
<a name="ln6292"> </a>
<a name="ln6293">Status CatalogManager::GetRegistration(ServerRegistrationPB* reg) const {</a>
<a name="ln6294">  return master_-&gt;GetRegistration(reg, server::RpcOnly::kTrue);</a>
<a name="ln6295">}</a>
<a name="ln6296"> </a>
<a name="ln6297">Status CatalogManager::UpdateMastersListInMemoryAndDisk() {</a>
<a name="ln6298">  DCHECK(master_-&gt;opts().IsShellMode());</a>
<a name="ln6299"> </a>
<a name="ln6300">  if (!master_-&gt;opts().IsShellMode()) {</a>
<a name="ln6301">    return STATUS(IllegalState, &quot;Cannot update master's info when process is not in shell mode.&quot;);</a>
<a name="ln6302">  }</a>
<a name="ln6303"> </a>
<a name="ln6304">  consensus::ConsensusStatePB consensus_state;</a>
<a name="ln6305">  RETURN_NOT_OK(GetCurrentConfig(&amp;consensus_state));</a>
<a name="ln6306"> </a>
<a name="ln6307">  if (!consensus_state.has_config()) {</a>
<a name="ln6308">    return STATUS(NotFound, &quot;No Raft config found.&quot;);</a>
<a name="ln6309">  }</a>
<a name="ln6310"> </a>
<a name="ln6311">  RETURN_NOT_OK(sys_catalog_-&gt;ConvertConfigToMasterAddresses(consensus_state.config()));</a>
<a name="ln6312">  RETURN_NOT_OK(sys_catalog_-&gt;CreateAndFlushConsensusMeta(master_-&gt;fs_manager(),</a>
<a name="ln6313">                                                          consensus_state.config(),</a>
<a name="ln6314">                                                          consensus_state.current_term()));</a>
<a name="ln6315"> </a>
<a name="ln6316">  return Status::OK();</a>
<a name="ln6317">}</a>
<a name="ln6318"> </a>
<a name="ln6319">Status CatalogManager::EnableBgTasks() {</a>
<a name="ln6320">  std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln6321">  background_tasks_.reset(new CatalogManagerBgTasks(this));</a>
<a name="ln6322">  RETURN_NOT_OK_PREPEND(background_tasks_-&gt;Init(),</a>
<a name="ln6323">                        &quot;Failed to initialize catalog manager background tasks&quot;);</a>
<a name="ln6324">  return Status::OK();</a>
<a name="ln6325">}</a>
<a name="ln6326"> </a>
<a name="ln6327">Status CatalogManager::StartRemoteBootstrap(const StartRemoteBootstrapRequestPB&amp; req) {</a>
<a name="ln6328">  const TabletId&amp; tablet_id = req.tablet_id();</a>
<a name="ln6329">  std::unique_lock&lt;std::mutex&gt; l(remote_bootstrap_mtx_, std::try_to_lock);</a>
<a name="ln6330">  if (!l.owns_lock()) {</a>
<a name="ln6331">    return STATUS_SUBSTITUTE(AlreadyPresent,</a>
<a name="ln6332">        &quot;Remote bootstrap of tablet $0 already in progress&quot;, tablet_id);</a>
<a name="ln6333">  }</a>
<a name="ln6334"> </a>
<a name="ln6335">  if (!master_-&gt;opts().IsShellMode()) {</a>
<a name="ln6336">    return STATUS(IllegalState, &quot;Cannot bootstrap a master which is not in shell mode.&quot;);</a>
<a name="ln6337">  }</a>
<a name="ln6338"> </a>
<a name="ln6339">  LOG(INFO) &lt;&lt; &quot;Starting remote bootstrap: &quot; &lt;&lt; req.ShortDebugString();</a>
<a name="ln6340"> </a>
<a name="ln6341">  HostPort bootstrap_peer_addr = HostPortFromPB(DesiredHostPort(</a>
<a name="ln6342">      req.source_broadcast_addr(), req.source_private_addr(), req.source_cloud_info(),</a>
<a name="ln6343">      master_-&gt;MakeCloudInfoPB()));</a>
<a name="ln6344"> </a>
<a name="ln6345">  const string&amp; bootstrap_peer_uuid = req.bootstrap_peer_uuid();</a>
<a name="ln6346">  int64_t leader_term = req.caller_term();</a>
<a name="ln6347"> </a>
<a name="ln6348">  std::shared_ptr&lt;TabletPeer&gt; old_tablet_peer;</a>
<a name="ln6349">  RaftGroupMetadataPtr meta;</a>
<a name="ln6350">  bool replacing_tablet = false;</a>
<a name="ln6351"> </a>
<a name="ln6352">  if (tablet_exists_) {</a>
<a name="ln6353">    old_tablet_peer = tablet_peer();</a>
<a name="ln6354">    // Nothing to recover if the remote bootstrap client start failed the last time.</a>
<a name="ln6355">    if (old_tablet_peer) {</a>
<a name="ln6356">      meta = old_tablet_peer-&gt;tablet_metadata();</a>
<a name="ln6357">      replacing_tablet = true;</a>
<a name="ln6358">    }</a>
<a name="ln6359">  }</a>
<a name="ln6360"> </a>
<a name="ln6361">  if (replacing_tablet) {</a>
<a name="ln6362">    // Make sure the existing tablet peer is shut down and tombstoned.</a>
<a name="ln6363">    RETURN_NOT_OK(tserver::HandleReplacingStaleTablet(meta,</a>
<a name="ln6364">                                                      old_tablet_peer,</a>
<a name="ln6365">                                                      tablet_id,</a>
<a name="ln6366">                                                      master_-&gt;fs_manager()-&gt;uuid(),</a>
<a name="ln6367">                                                      leader_term));</a>
<a name="ln6368">  }</a>
<a name="ln6369"> </a>
<a name="ln6370">  LOG_WITH_PREFIX(INFO) &lt;&lt; &quot; Initiating remote bootstrap from peer &quot; &lt;&lt; bootstrap_peer_uuid</a>
<a name="ln6371">            &lt;&lt; &quot; (&quot; &lt;&lt; bootstrap_peer_addr.ToString() &lt;&lt; &quot;).&quot;;</a>
<a name="ln6372"> </a>
<a name="ln6373">  auto rb_client = std::make_unique&lt;tserver::RemoteBootstrapClient&gt;(</a>
<a name="ln6374">      tablet_id, master_-&gt;fs_manager());</a>
<a name="ln6375"> </a>
<a name="ln6376">  // Download and persist the remote superblock in TABLET_DATA_COPYING state.</a>
<a name="ln6377">  if (replacing_tablet) {</a>
<a name="ln6378">    RETURN_NOT_OK(rb_client-&gt;SetTabletToReplace(meta, leader_term));</a>
<a name="ln6379">  }</a>
<a name="ln6380">  RETURN_NOT_OK(rb_client-&gt;Start(</a>
<a name="ln6381">      bootstrap_peer_uuid, &amp;master_-&gt;proxy_cache(), bootstrap_peer_addr, &amp;meta));</a>
<a name="ln6382">  // This SetupTabletPeer is needed by rb_client to perform the remote bootstrap/fetch.</a>
<a name="ln6383">  // And the SetupTablet below to perform &quot;local bootstrap&quot; cannot be done until the remote fetch</a>
<a name="ln6384">  // has succeeded. So keeping them seperate for now.</a>
<a name="ln6385">  sys_catalog_-&gt;SetupTabletPeer(meta);</a>
<a name="ln6386">  if (PREDICT_FALSE(FLAGS_TEST_inject_latency_during_remote_bootstrap_secs)) {</a>
<a name="ln6387">    LOG(INFO) &lt;&lt; &quot;Injecting &quot; &lt;&lt; FLAGS_TEST_inject_latency_during_remote_bootstrap_secs</a>
<a name="ln6388">              &lt;&lt; &quot; seconds of latency for test&quot;;</a>
<a name="ln6389">    SleepFor(MonoDelta::FromSeconds(FLAGS_TEST_inject_latency_during_remote_bootstrap_secs));</a>
<a name="ln6390">  }</a>
<a name="ln6391"> </a>
<a name="ln6392">  // From this point onward, the superblock is persisted in TABLET_DATA_COPYING</a>
<a name="ln6393">  // state, and we need to tombstone the tablet if additional steps prior to</a>
<a name="ln6394">  // getting to a TABLET_DATA_READY state fail.</a>
<a name="ln6395">  tablet_exists_ = true;</a>
<a name="ln6396"> </a>
<a name="ln6397">  // Download all of the remote files.</a>
<a name="ln6398">  TOMBSTONE_NOT_OK(rb_client-&gt;FetchAll(tablet_peer()-&gt;status_listener()),</a>
<a name="ln6399">                   meta,</a>
<a name="ln6400">                   master_-&gt;fs_manager()-&gt;uuid(),</a>
<a name="ln6401">                   Substitute(&quot;Remote bootstrap: Unable to fetch data from remote peer $0 ($1)&quot;,</a>
<a name="ln6402">                              bootstrap_peer_uuid, bootstrap_peer_addr.ToString()),</a>
<a name="ln6403">                   nullptr);</a>
<a name="ln6404"> </a>
<a name="ln6405">  // Write out the last files to make the new replica visible and update the</a>
<a name="ln6406">  // TabletDataState in the superblock to TABLET_DATA_READY.</a>
<a name="ln6407">  // Finish() will call EndRemoteSession() and wait for the leader to successfully submit a</a>
<a name="ln6408">  // ChangeConfig request (to change this master's role from PRE_VOTER or PRE_OBSERVER to VOTER or</a>
<a name="ln6409">  // OBSERVER respectively). If the RPC times out, we will ignore the error (since the leader could</a>
<a name="ln6410">  // have successfully submitted the ChangeConfig request and failed to respond before in time)</a>
<a name="ln6411">  // and check the committed config until we find that this master's role has changed, or until we</a>
<a name="ln6412">  // time out which will cause us to tombstone the tablet.</a>
<a name="ln6413">  TOMBSTONE_NOT_OK(rb_client-&gt;Finish(),</a>
<a name="ln6414">                   meta,</a>
<a name="ln6415">                   master_-&gt;fs_manager()-&gt;uuid(),</a>
<a name="ln6416">                   &quot;Remote bootstrap: Failed calling Finish()&quot;,</a>
<a name="ln6417">                   nullptr);</a>
<a name="ln6418"> </a>
<a name="ln6419">  // Synchronous tablet open for &quot;local bootstrap&quot;.</a>
<a name="ln6420">  RETURN_NOT_OK(tserver::ShutdownAndTombstoneTabletPeerNotOk(</a>
<a name="ln6421">      sys_catalog_-&gt;OpenTablet(meta), sys_catalog_-&gt;tablet_peer(), meta,</a>
<a name="ln6422">      master_-&gt;fs_manager()-&gt;uuid(), &quot;Remote bootstrap: Failed opening sys catalog&quot;));</a>
<a name="ln6423"> </a>
<a name="ln6424">  // Set up the in-memory master list and also flush the cmeta.</a>
<a name="ln6425">  RETURN_NOT_OK(UpdateMastersListInMemoryAndDisk());</a>
<a name="ln6426"> </a>
<a name="ln6427">  master_-&gt;SetShellMode(false);</a>
<a name="ln6428"> </a>
<a name="ln6429">  // Call VerifyChangeRoleSucceeded only after we have set shell mode to false. Otherwise,</a>
<a name="ln6430">  // CatalogManager::GetTabletPeer will always return an error, and the consensus will never get</a>
<a name="ln6431">  // updated.</a>
<a name="ln6432">  auto status = rb_client-&gt;VerifyChangeRoleSucceeded(</a>
<a name="ln6433">      sys_catalog_-&gt;tablet_peer()-&gt;shared_consensus());</a>
<a name="ln6434"> </a>
<a name="ln6435">  if (!status.ok()) {</a>
<a name="ln6436">    LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Remote bootstrap finished. &quot;</a>
<a name="ln6437">                             &lt;&lt; &quot;Failed calling VerifyChangeRoleSucceeded: &quot;</a>
<a name="ln6438">                             &lt;&lt; status.ToString();</a>
<a name="ln6439">  } else {</a>
<a name="ln6440">    LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Remote bootstrap finished successfully&quot;;</a>
<a name="ln6441">  }</a>
<a name="ln6442"> </a>
<a name="ln6443">  LOG(INFO) &lt;&lt; &quot;Master completed remote bootstrap and is out of shell mode.&quot;;</a>
<a name="ln6444"> </a>
<a name="ln6445">  RETURN_NOT_OK(EnableBgTasks());</a>
<a name="ln6446"> </a>
<a name="ln6447">  return Status::OK();</a>
<a name="ln6448">}</a>
<a name="ln6449"> </a>
<a name="ln6450">void CatalogManager::SendAlterTableRequest(const scoped_refptr&lt;TableInfo&gt;&amp; table,</a>
<a name="ln6451">                                           const AlterTableRequestPB* req) {</a>
<a name="ln6452">  vector&lt;scoped_refptr&lt;TabletInfo&gt;&gt; tablets;</a>
<a name="ln6453">  table-&gt;GetAllTablets(&amp;tablets);</a>
<a name="ln6454"> </a>
<a name="ln6455">  for (const scoped_refptr&lt;TabletInfo&gt;&amp; tablet : tablets) {</a>
<a name="ln6456">    auto call = std::make_shared&lt;AsyncAlterTable&gt;(master_, AsyncTaskPool(), tablet, table);</a>
<a name="ln6457">    tablet-&gt;table()-&gt;AddTask(call);</a>
<a name="ln6458">    WARN_NOT_OK(ScheduleTask(call), &quot;Failed to send alter table request&quot;);</a>
<a name="ln6459">  }</a>
<a name="ln6460">}</a>
<a name="ln6461"> </a>
<a name="ln6462">void CatalogManager::SendCopartitionTabletRequest(const scoped_refptr&lt;TabletInfo&gt;&amp; tablet,</a>
<a name="ln6463">                                                  const scoped_refptr&lt;TableInfo&gt;&amp; table) {</a>
<a name="ln6464">  auto call = std::make_shared&lt;AsyncCopartitionTable&gt;(master_, AsyncTaskPool(), tablet, table);</a>
<a name="ln6465">  table-&gt;AddTask(call);</a>
<a name="ln6466">  WARN_NOT_OK(ScheduleTask(call), &quot;Failed to send copartition table request&quot;);</a>
<a name="ln6467">}</a>
<a name="ln6468"> </a>
<a name="ln6469">void CatalogManager::SendSplitTabletRequest(</a>
<a name="ln6470">    const scoped_refptr&lt;TabletInfo&gt;&amp; tablet, std::array&lt;TabletId, 2&gt; new_tablet_ids,</a>
<a name="ln6471">    const std::string&amp; split_encoded_key, const std::string&amp; split_partition_key) {</a>
<a name="ln6472">  VLOG(2) &lt;&lt; &quot;Scheduling SplitTablet request to leader tserver for source tablet ID: &quot;</a>
<a name="ln6473">          &lt;&lt; tablet-&gt;tablet_id() &lt;&lt; &quot;, after-split tablet IDs: &quot; &lt;&lt; AsString(new_tablet_ids);</a>
<a name="ln6474">  auto call = std::make_shared&lt;AsyncSplitTablet&gt;(</a>
<a name="ln6475">      master_, AsyncTaskPool(), tablet, new_tablet_ids, split_encoded_key, split_partition_key);</a>
<a name="ln6476">  tablet-&gt;table()-&gt;AddTask(call);</a>
<a name="ln6477">  WARN_NOT_OK(</a>
<a name="ln6478">      ScheduleTask(call),</a>
<a name="ln6479">      Format(&quot;Failed to send split tablet request for tablet $0&quot;, tablet-&gt;tablet_id()));</a>
<a name="ln6480">}</a>
<a name="ln6481"> </a>
<a name="ln6482">void CatalogManager::DeleteTabletReplicas(</a>
<a name="ln6483">    const TabletInfo* tablet,</a>
<a name="ln6484">    const std::string&amp; msg) {</a>
<a name="ln6485">  TabletInfo::ReplicaMap locations;</a>
<a name="ln6486">  tablet-&gt;GetReplicaLocations(&amp;locations);</a>
<a name="ln6487">  LOG(INFO) &lt;&lt; &quot;Sending DeleteTablet for &quot; &lt;&lt; locations.size()</a>
<a name="ln6488">            &lt;&lt; &quot; replicas of tablet &quot; &lt;&lt; tablet-&gt;tablet_id();</a>
<a name="ln6489">  for (const TabletInfo::ReplicaMap::value_type&amp; r : locations) {</a>
<a name="ln6490">    SendDeleteTabletRequest(tablet-&gt;tablet_id(), TABLET_DATA_DELETED,</a>
<a name="ln6491">                            boost::none, tablet-&gt;table(), r.second.ts_desc, msg);</a>
<a name="ln6492">  }</a>
<a name="ln6493">}</a>
<a name="ln6494"> </a>
<a name="ln6495">void CatalogManager::DeleteTabletsAndSendRequests(const scoped_refptr&lt;TableInfo&gt;&amp; table) {</a>
<a name="ln6496">  // Do not delete the system catalog tablet.</a>
<a name="ln6497">  {</a>
<a name="ln6498">    SharedLock&lt;LockType&gt; catalog_lock(lock_);</a>
<a name="ln6499">    if (IsSystemTableUnlocked(*table)) {</a>
<a name="ln6500">      return;</a>
<a name="ln6501">    }</a>
<a name="ln6502">  }</a>
<a name="ln6503">  // Do not delete the tablet of a colocated table.</a>
<a name="ln6504">  if (IsColocatedUserTable(*table)) {</a>
<a name="ln6505">    return;</a>
<a name="ln6506">  }</a>
<a name="ln6507"> </a>
<a name="ln6508">  vector&lt;scoped_refptr&lt;TabletInfo&gt;&gt; tablets;</a>
<a name="ln6509">  table-&gt;GetAllTablets(&amp;tablets);</a>
<a name="ln6510"> </a>
<a name="ln6511">  string deletion_msg = &quot;Table deleted at &quot; + LocalTimeAsString();</a>
<a name="ln6512"> </a>
<a name="ln6513">  for (const scoped_refptr&lt;TabletInfo&gt;&amp; tablet : tablets) {</a>
<a name="ln6514">    DeleteTabletReplicas(tablet.get(), deletion_msg);</a>
<a name="ln6515"> </a>
<a name="ln6516">    auto tablet_lock = tablet-&gt;LockForWrite();</a>
<a name="ln6517">    tablet_lock-&gt;mutable_data()-&gt;set_state(SysTabletsEntryPB::DELETED, deletion_msg);</a>
<a name="ln6518">    CHECK_OK(sys_catalog_-&gt;UpdateItem(tablet.get(), leader_ready_term()));</a>
<a name="ln6519">    tablet_lock-&gt;Commit();</a>
<a name="ln6520">  }</a>
<a name="ln6521">  if (IsColocatedParentTable(*table)) {</a>
<a name="ln6522">    SharedLock&lt;LockType&gt; catalog_lock(lock_);</a>
<a name="ln6523">    colocated_tablet_ids_map_.erase(table-&gt;namespace_id());</a>
<a name="ln6524">  } else if (IsTablegroupParentTable(*table)) {</a>
<a name="ln6525">    // In the case of dropped database/tablegroup parent table, need to delete tablegroup info.</a>
<a name="ln6526">    SharedLock&lt;LockType&gt; catalog_lock(lock_);</a>
<a name="ln6527">    for (auto tgroup : tablegroup_tablet_ids_map_[table-&gt;namespace_id()]) {</a>
<a name="ln6528">      tablegroup_ids_map_.erase(tgroup.first);</a>
<a name="ln6529">    }</a>
<a name="ln6530">    tablegroup_tablet_ids_map_.erase(table-&gt;namespace_id());</a>
<a name="ln6531">  }</a>
<a name="ln6532">}</a>
<a name="ln6533"> </a>
<a name="ln6534">void CatalogManager::SendDeleteTabletRequest(</a>
<a name="ln6535">    const TabletId&amp; tablet_id,</a>
<a name="ln6536">    TabletDataState delete_type,</a>
<a name="ln6537">    const boost::optional&lt;int64_t&gt;&amp; cas_config_opid_index_less_or_equal,</a>
<a name="ln6538">    const scoped_refptr&lt;TableInfo&gt;&amp; table,</a>
<a name="ln6539">    TSDescriptor* ts_desc,</a>
<a name="ln6540">    const string&amp; reason) {</a>
<a name="ln6541">  LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Deleting tablet &quot; &lt;&lt; tablet_id &lt;&lt; &quot; on peer &quot;</a>
<a name="ln6542">                        &lt;&lt; ts_desc-&gt;permanent_uuid() &lt;&lt; &quot; with delete type &quot;</a>
<a name="ln6543">                        &lt;&lt; TabletDataState_Name(delete_type) &lt;&lt; &quot; (&quot; &lt;&lt; reason &lt;&lt; &quot;)&quot;;</a>
<a name="ln6544">  auto call = std::make_shared&lt;AsyncDeleteReplica&gt;(master_, AsyncTaskPool(),</a>
<a name="ln6545">      ts_desc-&gt;permanent_uuid(), table, tablet_id, delete_type,</a>
<a name="ln6546">      cas_config_opid_index_less_or_equal, reason);</a>
<a name="ln6547">  if (table != nullptr) {</a>
<a name="ln6548">    table-&gt;AddTask(call);</a>
<a name="ln6549">  }</a>
<a name="ln6550"> </a>
<a name="ln6551">  auto status = ScheduleTask(call);</a>
<a name="ln6552">  WARN_NOT_OK(status, Substitute(&quot;Failed to send delete request for tablet $0&quot;, tablet_id));</a>
<a name="ln6553">  if (status.ok()) {</a>
<a name="ln6554">    ts_desc-&gt;AddPendingTabletDelete(tablet_id);</a>
<a name="ln6555">  }</a>
<a name="ln6556">}</a>
<a name="ln6557"> </a>
<a name="ln6558">void CatalogManager::SendLeaderStepDownRequest(</a>
<a name="ln6559">    const scoped_refptr&lt;TabletInfo&gt;&amp; tablet, const ConsensusStatePB&amp; cstate,</a>
<a name="ln6560">    const string&amp; change_config_ts_uuid, bool should_remove,</a>
<a name="ln6561">    const string&amp; new_leader_uuid) {</a>
<a name="ln6562">  auto task = std::make_shared&lt;AsyncTryStepDown&gt;(</a>
<a name="ln6563">      master_, AsyncTaskPool(), tablet, cstate, change_config_ts_uuid, should_remove,</a>
<a name="ln6564">      new_leader_uuid);</a>
<a name="ln6565">  tablet-&gt;table()-&gt;AddTask(task);</a>
<a name="ln6566">  Status status = task-&gt;Run();</a>
<a name="ln6567">  WARN_NOT_OK(status, Substitute(&quot;Failed to send new $0 request&quot;, task-&gt;type_name()));</a>
<a name="ln6568">}</a>
<a name="ln6569"> </a>
<a name="ln6570">// TODO: refactor this into a joint method with the add one.</a>
<a name="ln6571">void CatalogManager::SendRemoveServerRequest(</a>
<a name="ln6572">    const scoped_refptr&lt;TabletInfo&gt;&amp; tablet, const ConsensusStatePB&amp; cstate,</a>
<a name="ln6573">    const string&amp; change_config_ts_uuid) {</a>
<a name="ln6574">  // Check if the user wants the leader to be stepped down.</a>
<a name="ln6575">  auto task = std::make_shared&lt;AsyncRemoveServerTask&gt;(</a>
<a name="ln6576">      master_, AsyncTaskPool(), tablet, cstate, change_config_ts_uuid);</a>
<a name="ln6577">  tablet-&gt;table()-&gt;AddTask(task);</a>
<a name="ln6578">  Status status = task-&gt;Run();</a>
<a name="ln6579">  WARN_NOT_OK(status, Substitute(&quot;Failed to send new $0 request&quot;, task-&gt;type_name()));</a>
<a name="ln6580">}</a>
<a name="ln6581"> </a>
<a name="ln6582">void CatalogManager::SendAddServerRequest(</a>
<a name="ln6583">    const scoped_refptr&lt;TabletInfo&gt;&amp; tablet, RaftPeerPB::MemberType member_type,</a>
<a name="ln6584">    const ConsensusStatePB&amp; cstate, const string&amp; change_config_ts_uuid) {</a>
<a name="ln6585">  auto task = std::make_shared&lt;AsyncAddServerTask&gt;(master_, AsyncTaskPool(), tablet, member_type,</a>
<a name="ln6586">      cstate, change_config_ts_uuid);</a>
<a name="ln6587">  tablet-&gt;table()-&gt;AddTask(task);</a>
<a name="ln6588">  Status status = task-&gt;Run();</a>
<a name="ln6589">  WARN_NOT_OK(status, Substitute(&quot;Failed to send AddServer of tserver $0 to tablet $1&quot;,</a>
<a name="ln6590">                                 change_config_ts_uuid, tablet.get()-&gt;ToString()));</a>
<a name="ln6591">}</a>
<a name="ln6592"> </a>
<a name="ln6593">void CatalogManager::GetPendingServerTasksUnlocked(</a>
<a name="ln6594">    const TableId &amp;table_uuid,</a>
<a name="ln6595">    TabletToTabletServerMap *add_replica_tasks_map,</a>
<a name="ln6596">    TabletToTabletServerMap *remove_replica_tasks_map,</a>
<a name="ln6597">    TabletToTabletServerMap *stepdown_leader_tasks_map) {</a>
<a name="ln6598"> </a>
<a name="ln6599">  auto table = GetTableInfoUnlocked(table_uuid);</a>
<a name="ln6600">  for (const auto&amp; task : table-&gt;GetTasks()) {</a>
<a name="ln6601">    TabletToTabletServerMap* outputMap = nullptr;</a>
<a name="ln6602">    if (task-&gt;type() == MonitoredTask::ASYNC_ADD_SERVER) {</a>
<a name="ln6603">      outputMap = add_replica_tasks_map;</a>
<a name="ln6604">    } else if (task-&gt;type() == MonitoredTask::ASYNC_REMOVE_SERVER) {</a>
<a name="ln6605">      outputMap = remove_replica_tasks_map;</a>
<a name="ln6606">    } else if (task-&gt;type() == MonitoredTask::ASYNC_TRY_STEP_DOWN) {</a>
<a name="ln6607">      // Store new_leader_uuid instead of change_config_ts_uuid.</a>
<a name="ln6608">      auto raft_task = static_cast&lt;AsyncTryStepDown*&gt;(task.get());</a>
<a name="ln6609">      (*stepdown_leader_tasks_map)[raft_task-&gt;tablet_id()] = raft_task-&gt;new_leader_uuid();</a>
<a name="ln6610">      continue;</a>
<a name="ln6611">    }</a>
<a name="ln6612">    if (outputMap) {</a>
<a name="ln6613">      auto raft_task = static_cast&lt;CommonInfoForRaftTask*&gt;(task.get());</a>
<a name="ln6614">      (*outputMap)[raft_task-&gt;tablet_id()] = raft_task-&gt;change_config_ts_uuid();</a>
<a name="ln6615">    }</a>
<a name="ln6616">  }</a>
<a name="ln6617">}</a>
<a name="ln6618"> </a>
<a name="ln6619">void CatalogManager::ExtractTabletsToProcess(</a>
<a name="ln6620">    TabletInfos *tablets_to_delete,</a>
<a name="ln6621">    TabletInfos *tablets_to_process) {</a>
<a name="ln6622">  SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln6623"> </a>
<a name="ln6624">  // TODO: At the moment we loop through all the tablets</a>
<a name="ln6625">  //       we can keep a set of tablets waiting for &quot;assignment&quot;</a>
<a name="ln6626">  //       or just a counter to avoid to take the lock and loop through the tablets</a>
<a name="ln6627">  //       if everything is &quot;stable&quot;.</a>
<a name="ln6628"> </a>
<a name="ln6629">  for (const TabletInfoMap::value_type&amp; entry : *tablet_map_) {</a>
<a name="ln6630">    scoped_refptr&lt;TabletInfo&gt; tablet = entry.second;</a>
<a name="ln6631">    auto table = tablet-&gt;table();</a>
<a name="ln6632">    if (!table) {</a>
<a name="ln6633">      // Tablet is orphaned or in preparing state, continue.</a>
<a name="ln6634">      continue;</a>
<a name="ln6635">    }</a>
<a name="ln6636"> </a>
<a name="ln6637">    // acquire table lock before tablets.</a>
<a name="ln6638">    auto table_lock = table-&gt;LockForRead();</a>
<a name="ln6639">    auto tablet_lock = tablet-&gt;LockForRead();</a>
<a name="ln6640"> </a>
<a name="ln6641">    // If the table is deleted or the tablet was replaced at table creation time.</a>
<a name="ln6642">    if (tablet_lock-&gt;data().is_deleted() || table_lock-&gt;data().started_deleting()) {</a>
<a name="ln6643">      // Process this table deletion only once (tombstones for table may remain longer).</a>
<a name="ln6644">      if (table_ids_map_-&gt;find(tablet-&gt;table()-&gt;id()) != table_ids_map_-&gt;end()) {</a>
<a name="ln6645">        tablets_to_delete-&gt;push_back(tablet);</a>
<a name="ln6646">      }</a>
<a name="ln6647">      // Don't process deleted tables regardless.</a>
<a name="ln6648">      continue;</a>
<a name="ln6649">    }</a>
<a name="ln6650"> </a>
<a name="ln6651">    // Running tablets.</a>
<a name="ln6652">    if (tablet_lock-&gt;data().is_running()) {</a>
<a name="ln6653">      // TODO: handle last update &gt; not responding timeout?</a>
<a name="ln6654">      continue;</a>
<a name="ln6655">    }</a>
<a name="ln6656"> </a>
<a name="ln6657">    // Tablets not yet assigned or with a report just received.</a>
<a name="ln6658">    tablets_to_process-&gt;push_back(tablet);</a>
<a name="ln6659">  }</a>
<a name="ln6660">}</a>
<a name="ln6661"> </a>
<a name="ln6662">bool CatalogManager::AreTablesDeleting() {</a>
<a name="ln6663">  SharedLock&lt;LockType&gt; catalog_lock(lock_);</a>
<a name="ln6664"> </a>
<a name="ln6665">  for (const TableInfoMap::value_type&amp; entry : *table_ids_map_) {</a>
<a name="ln6666">    scoped_refptr&lt;TableInfo&gt; table(entry.second);</a>
<a name="ln6667">    auto table_lock = table-&gt;LockForRead();</a>
<a name="ln6668">    // TODO(jason): possibly change this to started_deleting when we begin removing DELETED tables</a>
<a name="ln6669">    // from table_ids_map_ (see CleanUpDeletedTables).</a>
<a name="ln6670">    if (table_lock-&gt;data().is_deleting()) {</a>
<a name="ln6671">      return true;</a>
<a name="ln6672">    }</a>
<a name="ln6673">  }</a>
<a name="ln6674">  return false;</a>
<a name="ln6675">}</a>
<a name="ln6676"> </a>
<a name="ln6677">struct DeferredAssignmentActions {</a>
<a name="ln6678">  vector&lt;TabletInfo*&gt; tablets_to_add;</a>
<a name="ln6679">  vector&lt;TabletInfo*&gt; tablets_to_update;</a>
<a name="ln6680">  vector&lt;TabletInfo*&gt; needs_create_rpc;</a>
<a name="ln6681">};</a>
<a name="ln6682"> </a>
<a name="ln6683">void CatalogManager::HandleAssignPreparingTablet(TabletInfo* tablet,</a>
<a name="ln6684">                                                 DeferredAssignmentActions* deferred) {</a>
<a name="ln6685">  // The tablet was just created (probably by a CreateTable RPC).</a>
<a name="ln6686">  // Update the state to &quot;creating&quot; to be ready for the creation request.</a>
<a name="ln6687">  tablet-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;set_state(</a>
<a name="ln6688">    SysTabletsEntryPB::CREATING, &quot;Sending initial creation of tablet&quot;);</a>
<a name="ln6689">  deferred-&gt;tablets_to_update.push_back(tablet);</a>
<a name="ln6690">  deferred-&gt;needs_create_rpc.push_back(tablet);</a>
<a name="ln6691">  VLOG(1) &lt;&lt; &quot;Assign new tablet &quot; &lt;&lt; tablet-&gt;ToString();</a>
<a name="ln6692">}</a>
<a name="ln6693"> </a>
<a name="ln6694">void CatalogManager::HandleAssignCreatingTablet(TabletInfo* tablet,</a>
<a name="ln6695">                                                DeferredAssignmentActions* deferred,</a>
<a name="ln6696">                                                vector&lt;scoped_refptr&lt;TabletInfo&gt;&gt;* new_tablets) {</a>
<a name="ln6697">  MonoDelta time_since_updated =</a>
<a name="ln6698">      MonoTime::Now().GetDeltaSince(tablet-&gt;last_update_time());</a>
<a name="ln6699">  int64_t remaining_timeout_ms =</a>
<a name="ln6700">      FLAGS_tablet_creation_timeout_ms - time_since_updated.ToMilliseconds();</a>
<a name="ln6701"> </a>
<a name="ln6702">  // Skip the tablet if the assignment timeout is not yet expired.</a>
<a name="ln6703">  if (remaining_timeout_ms &gt; 0) {</a>
<a name="ln6704">    VLOG(2) &lt;&lt; &quot;Tablet &quot; &lt;&lt; tablet-&gt;ToString() &lt;&lt; &quot; still being created. &quot;</a>
<a name="ln6705">            &lt;&lt; remaining_timeout_ms &lt;&lt; &quot;ms remain until timeout.&quot;;</a>
<a name="ln6706">    return;</a>
<a name="ln6707">  }</a>
<a name="ln6708"> </a>
<a name="ln6709">  const PersistentTabletInfo&amp; old_info = tablet-&gt;metadata().state();</a>
<a name="ln6710"> </a>
<a name="ln6711">  // The &quot;tablet creation&quot; was already sent, but we didn't receive an answer</a>
<a name="ln6712">  // within the timeout. So the tablet will be replaced by a new one.</a>
<a name="ln6713">  TabletInfo *replacement;</a>
<a name="ln6714">  {</a>
<a name="ln6715">    std::lock_guard&lt;LockType&gt; l_maps(lock_);</a>
<a name="ln6716">    replacement = CreateTabletInfo(tablet-&gt;table().get(), old_info.pb.partition());</a>
<a name="ln6717">  }</a>
<a name="ln6718">  LOG(WARNING) &lt;&lt; &quot;Tablet &quot; &lt;&lt; tablet-&gt;ToString() &lt;&lt; &quot; was not created within &quot;</a>
<a name="ln6719">               &lt;&lt; &quot;the allowed timeout. Replacing with a new tablet &quot;</a>
<a name="ln6720">               &lt;&lt; replacement-&gt;tablet_id();</a>
<a name="ln6721"> </a>
<a name="ln6722">  tablet-&gt;table()-&gt;AddTablet(replacement);</a>
<a name="ln6723">  {</a>
<a name="ln6724">    std::lock_guard&lt;LockType&gt; l_maps(lock_);</a>
<a name="ln6725">    auto tablet_map_checkout = tablet_map_.CheckOut();</a>
<a name="ln6726">    (*tablet_map_checkout)[replacement-&gt;tablet_id()] = replacement;</a>
<a name="ln6727">  }</a>
<a name="ln6728"> </a>
<a name="ln6729">  // Mark old tablet as replaced.</a>
<a name="ln6730">  tablet-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;set_state(</a>
<a name="ln6731">    SysTabletsEntryPB::REPLACED,</a>
<a name="ln6732">    Substitute(&quot;Replaced by $0 at $1&quot;,</a>
<a name="ln6733">               replacement-&gt;tablet_id(), LocalTimeAsString()));</a>
<a name="ln6734"> </a>
<a name="ln6735">  // Mark new tablet as being created.</a>
<a name="ln6736">  replacement-&gt;mutable_metadata()-&gt;mutable_dirty()-&gt;set_state(</a>
<a name="ln6737">    SysTabletsEntryPB::CREATING,</a>
<a name="ln6738">    Substitute(&quot;Replacement for $0&quot;, tablet-&gt;tablet_id()));</a>
<a name="ln6739"> </a>
<a name="ln6740">  deferred-&gt;tablets_to_update.push_back(tablet);</a>
<a name="ln6741">  deferred-&gt;tablets_to_add.push_back(replacement);</a>
<a name="ln6742">  deferred-&gt;needs_create_rpc.push_back(replacement);</a>
<a name="ln6743">  VLOG(1) &lt;&lt; &quot;Replaced tablet &quot; &lt;&lt; tablet-&gt;tablet_id()</a>
<a name="ln6744">          &lt;&lt; &quot; with &quot; &lt;&lt; replacement-&gt;tablet_id()</a>
<a name="ln6745">          &lt;&lt; &quot; (table &quot; &lt;&lt; tablet-&gt;table()-&gt;ToString() &lt;&lt; &quot;)&quot;;</a>
<a name="ln6746"> </a>
<a name="ln6747">  new_tablets-&gt;push_back(replacement);</a>
<a name="ln6748">}</a>
<a name="ln6749"> </a>
<a name="ln6750">// TODO: we could batch the IO onto a background thread.</a>
<a name="ln6751">Status CatalogManager::HandleTabletSchemaVersionReport(</a>
<a name="ln6752">    TabletInfo *tablet, uint32_t version, const scoped_refptr&lt;TableInfo&gt;&amp; table_info) {</a>
<a name="ln6753">  scoped_refptr&lt;TableInfo&gt; table;</a>
<a name="ln6754">  if (table_info) {</a>
<a name="ln6755">    table = table_info;</a>
<a name="ln6756">  } else {</a>
<a name="ln6757">    table = tablet-&gt;table();</a>
<a name="ln6758">  }</a>
<a name="ln6759"> </a>
<a name="ln6760">  // Update the schema version if it's the latest.</a>
<a name="ln6761">  tablet-&gt;set_reported_schema_version(table-&gt;id(), version);</a>
<a name="ln6762">  VLOG(1) &lt;&lt; &quot;Tablet &quot; &lt;&lt; tablet-&gt;tablet_id() &lt;&lt; &quot; reported version &quot; &lt;&lt; version;</a>
<a name="ln6763"> </a>
<a name="ln6764">  // Verify if it's the last tablet report, and the alter completed.</a>
<a name="ln6765">  {</a>
<a name="ln6766">    auto l = table-&gt;LockForRead();</a>
<a name="ln6767">    if (l-&gt;data().pb.state() != SysTablesEntryPB::ALTERING) {</a>
<a name="ln6768">      VLOG(2) &lt;&lt; &quot;Table &quot; &lt;&lt; table-&gt;ToString() &lt;&lt; &quot; is not altering&quot;;</a>
<a name="ln6769">      return Status::OK();</a>
<a name="ln6770">    }</a>
<a name="ln6771"> </a>
<a name="ln6772">    uint32_t current_version = l-&gt;data().pb.version();</a>
<a name="ln6773">    if (table-&gt;IsAlterInProgress(current_version)) {</a>
<a name="ln6774">      VLOG(2) &lt;&lt; &quot;Table &quot; &lt;&lt; table-&gt;ToString() &lt;&lt; &quot; has IsAlterInProgress (&quot;</a>
<a name="ln6775">              &lt;&lt; current_version &lt;&lt; &quot;)&quot;;</a>
<a name="ln6776">      return Status::OK();</a>
<a name="ln6777">    }</a>
<a name="ln6778">  }</a>
<a name="ln6779"> </a>
<a name="ln6780">  return MultiStageAlterTable::LaunchNextTableInfoVersionIfNecessary(this, table, version);</a>
<a name="ln6781">}</a>
<a name="ln6782"> </a>
<a name="ln6783">// Helper class to commit TabletInfo mutations at the end of a scope.</a>
<a name="ln6784">namespace {</a>
<a name="ln6785"> </a>
<a name="ln6786">class ScopedTabletInfoCommitter {</a>
<a name="ln6787"> public:</a>
<a name="ln6788">  explicit ScopedTabletInfoCommitter(const TabletInfos* tablets)</a>
<a name="ln6789">    : tablets_(DCHECK_NOTNULL(tablets)),</a>
<a name="ln6790">      aborted_(false) {</a>
<a name="ln6791">  }</a>
<a name="ln6792"> </a>
<a name="ln6793">  // This method is not thread safe. Must be called by the same thread</a>
<a name="ln6794">  // that would destroy this instance.</a>
<a name="ln6795">  void Abort() {</a>
<a name="ln6796">    for (const scoped_refptr&lt;TabletInfo&gt;&amp; tablet : *tablets_) {</a>
<a name="ln6797">      tablet-&gt;mutable_metadata()-&gt;AbortMutation();</a>
<a name="ln6798">    }</a>
<a name="ln6799">    aborted_ = true;</a>
<a name="ln6800">  }</a>
<a name="ln6801"> </a>
<a name="ln6802">  void Commit() {</a>
<a name="ln6803">    if (PREDICT_TRUE(!aborted_)) {</a>
<a name="ln6804">      for (const scoped_refptr&lt;TabletInfo&gt;&amp; tablet : *tablets_) {</a>
<a name="ln6805">        tablet-&gt;mutable_metadata()-&gt;CommitMutation();</a>
<a name="ln6806">      }</a>
<a name="ln6807">    }</a>
<a name="ln6808">  }</a>
<a name="ln6809"> </a>
<a name="ln6810">  // Commit the transactions.</a>
<a name="ln6811">  ~ScopedTabletInfoCommitter() {</a>
<a name="ln6812">    Commit();</a>
<a name="ln6813">  }</a>
<a name="ln6814"> </a>
<a name="ln6815"> private:</a>
<a name="ln6816">  const TabletInfos* tablets_;</a>
<a name="ln6817">  bool aborted_;</a>
<a name="ln6818">};</a>
<a name="ln6819">}  // anonymous namespace</a>
<a name="ln6820"> </a>
<a name="ln6821">Status CatalogManager::ProcessPendingAssignments(const TabletInfos&amp; tablets) {</a>
<a name="ln6822">  VLOG(1) &lt;&lt; &quot;Processing pending assignments&quot;;</a>
<a name="ln6823"> </a>
<a name="ln6824">  // Take write locks on all tablets to be processed, and ensure that they are</a>
<a name="ln6825">  // unlocked at the end of this scope.</a>
<a name="ln6826">  for (const scoped_refptr&lt;TabletInfo&gt;&amp; tablet : tablets) {</a>
<a name="ln6827">    tablet-&gt;mutable_metadata()-&gt;StartMutation();</a>
<a name="ln6828">  }</a>
<a name="ln6829">  ScopedTabletInfoCommitter unlocker_in(&amp;tablets);</a>
<a name="ln6830"> </a>
<a name="ln6831">  // Any tablets created by the helper functions will also be created in a</a>
<a name="ln6832">  // locked state, so we must ensure they are unlocked before we return to</a>
<a name="ln6833">  // avoid deadlocks.</a>
<a name="ln6834">  TabletInfos new_tablets;</a>
<a name="ln6835">  ScopedTabletInfoCommitter unlocker_out(&amp;new_tablets);</a>
<a name="ln6836"> </a>
<a name="ln6837">  DeferredAssignmentActions deferred;</a>
<a name="ln6838"> </a>
<a name="ln6839">  // Iterate over each of the tablets and handle it, whatever state</a>
<a name="ln6840">  // it may be in. The actions required for the tablet are collected</a>
<a name="ln6841">  // into 'deferred'.</a>
<a name="ln6842">  for (const scoped_refptr&lt;TabletInfo&gt;&amp; tablet : tablets) {</a>
<a name="ln6843">    SysTabletsEntryPB::State t_state = tablet-&gt;metadata().state().pb.state();</a>
<a name="ln6844"> </a>
<a name="ln6845">    switch (t_state) {</a>
<a name="ln6846">      case SysTabletsEntryPB::PREPARING:</a>
<a name="ln6847">        HandleAssignPreparingTablet(tablet.get(), &amp;deferred);</a>
<a name="ln6848">        break;</a>
<a name="ln6849"> </a>
<a name="ln6850">      case SysTabletsEntryPB::CREATING:</a>
<a name="ln6851">        HandleAssignCreatingTablet(tablet.get(), &amp;deferred, &amp;new_tablets);</a>
<a name="ln6852">        break;</a>
<a name="ln6853"> </a>
<a name="ln6854">      default:</a>
<a name="ln6855">        VLOG(2) &lt;&lt; &quot;Nothing to do for tablet &quot; &lt;&lt; tablet-&gt;tablet_id() &lt;&lt; &quot;: state = &quot;</a>
<a name="ln6856">                &lt;&lt; SysTabletsEntryPB_State_Name(t_state);</a>
<a name="ln6857">        break;</a>
<a name="ln6858">    }</a>
<a name="ln6859">  }</a>
<a name="ln6860"> </a>
<a name="ln6861">  // Nothing to do.</a>
<a name="ln6862">  if (deferred.tablets_to_add.empty() &amp;&amp;</a>
<a name="ln6863">      deferred.tablets_to_update.empty() &amp;&amp;</a>
<a name="ln6864">      deferred.needs_create_rpc.empty()) {</a>
<a name="ln6865">    return Status::OK();</a>
<a name="ln6866">  }</a>
<a name="ln6867"> </a>
<a name="ln6868">  // For those tablets which need to be created in this round, assign replicas.</a>
<a name="ln6869">  TSDescriptorVector ts_descs;</a>
<a name="ln6870">  {</a>
<a name="ln6871">    SharedLock&lt;LockType&gt; l(blacklist_lock_);</a>
<a name="ln6872">    master_-&gt;ts_manager()-&gt;GetAllLiveDescriptors(&amp;ts_descs, blacklistState.tservers_);</a>
<a name="ln6873">  }</a>
<a name="ln6874">  Status s;</a>
<a name="ln6875">  unordered_set&lt;TableInfo*&gt; ok_status_tables;</a>
<a name="ln6876">  for (TabletInfo *tablet : deferred.needs_create_rpc) {</a>
<a name="ln6877">    // NOTE: if we fail to select replicas on the first pass (due to</a>
<a name="ln6878">    // insufficient Tablet Servers being online), we will still try</a>
<a name="ln6879">    // again unless the tablet/table creation is cancelled.</a>
<a name="ln6880">    s = SelectReplicasForTablet(ts_descs, tablet);</a>
<a name="ln6881">    if (!s.ok()) {</a>
<a name="ln6882">      s = s.CloneAndPrepend(Substitute(</a>
<a name="ln6883">          &quot;An error occurred while selecting replicas for tablet $0: $1&quot;,</a>
<a name="ln6884">          tablet-&gt;tablet_id(), s.ToString()));</a>
<a name="ln6885">      tablet-&gt;table()-&gt;SetCreateTableErrorStatus(s);</a>
<a name="ln6886">      break;</a>
<a name="ln6887">    } else {</a>
<a name="ln6888">      ok_status_tables.emplace(tablet-&gt;table().get());</a>
<a name="ln6889">    }</a>
<a name="ln6890">  }</a>
<a name="ln6891"> </a>
<a name="ln6892">  // Update the sys catalog with the new set of tablets/metadata.</a>
<a name="ln6893">  if (s.ok()) {</a>
<a name="ln6894">    // If any of the ok_status_tables had an error in the previous iterations, we</a>
<a name="ln6895">    // need to clear up the error status to reflect that all the create tablets have now</a>
<a name="ln6896">    // succeded.</a>
<a name="ln6897">    for (TableInfo* table : ok_status_tables) {</a>
<a name="ln6898">      table-&gt;SetCreateTableErrorStatus(Status::OK());</a>
<a name="ln6899">    }</a>
<a name="ln6900"> </a>
<a name="ln6901">    s = sys_catalog_-&gt;AddAndUpdateItems(deferred.tablets_to_add,</a>
<a name="ln6902">                                        deferred.tablets_to_update,</a>
<a name="ln6903">                                        leader_ready_term());</a>
<a name="ln6904">    if (!s.ok()) {</a>
<a name="ln6905">      s = s.CloneAndPrepend(&quot;An error occurred while persisting the updated tablet metadata&quot;);</a>
<a name="ln6906">    }</a>
<a name="ln6907">  }</a>
<a name="ln6908"> </a>
<a name="ln6909">  if (!s.ok()) {</a>
<a name="ln6910">    LOG(WARNING) &lt;&lt; &quot;Aborting the current task due to error: &quot; &lt;&lt; s.ToString();</a>
<a name="ln6911">    // If there was an error, abort any mutations started by the current task.</a>
<a name="ln6912">    // NOTE: Lock order should be lock_ -&gt; table -&gt; tablet.</a>
<a name="ln6913">    // We currently have a bunch of tablets locked and need to unlock first to ensure this holds.</a>
<a name="ln6914">    map&lt;TabletId, pair&lt;scoped_refptr&lt;TableInfo&gt;, string /* partition key */&gt;&gt; tablet_ids_to_remove;</a>
<a name="ln6915">    for (scoped_refptr&lt;TabletInfo&gt;&amp; new_tablet : new_tablets) {</a>
<a name="ln6916">      tablet_ids_to_remove[new_tablet-&gt;tablet_id()] = make_pair(</a>
<a name="ln6917">          new_tablet-&gt;table(),</a>
<a name="ln6918">          new_tablet-&gt;metadata().dirty().pb.partition().partition_key_start()</a>
<a name="ln6919">          );</a>
<a name="ln6920">    }</a>
<a name="ln6921"> </a>
<a name="ln6922">    unlocker_out.Abort(); // tablet.unlock</a>
<a name="ln6923">    unlocker_in.Abort();</a>
<a name="ln6924">    for (auto &amp;tablet_id_to_remove : tablet_ids_to_remove) {</a>
<a name="ln6925">      TableInfo* table = tablet_id_to_remove.second.first.get();</a>
<a name="ln6926">      auto l_table = table-&gt;LockForWrite(); // table.lock</a>
<a name="ln6927">      if (table-&gt;RemoveTablet(tablet_id_to_remove.second.second)) {</a>
<a name="ln6928">        VLOG(1) &lt;&lt; &quot;Removed tablet &quot; &lt;&lt; tablet_id_to_remove.first &lt;&lt; &quot; from &quot;</a>
<a name="ln6929">            &quot;table &quot; &lt;&lt; l_table-&gt;data().name();</a>
<a name="ln6930">      }</a>
<a name="ln6931">    }</a>
<a name="ln6932">    {</a>
<a name="ln6933">      std::lock_guard &lt;LockType&gt; l(lock_); // lock_.lock</a>
<a name="ln6934">      auto tablet_map_checkout = tablet_map_.CheckOut();</a>
<a name="ln6935">      for (auto &amp;tablet_id_to_remove : tablet_ids_to_remove) {</a>
<a name="ln6936">        // Potential race condition above, but it's okay if a background thread deleted this.</a>
<a name="ln6937">        tablet_map_checkout-&gt;erase(tablet_id_to_remove.first);</a>
<a name="ln6938">      }</a>
<a name="ln6939">    }</a>
<a name="ln6940">    return s;</a>
<a name="ln6941">  }</a>
<a name="ln6942"> </a>
<a name="ln6943">  // Send DeleteTablet requests to tablet servers serving deleted tablets.</a>
<a name="ln6944">  // This is asynchronous / non-blocking.</a>
<a name="ln6945">  for (const TabletInfo* tablet : deferred.tablets_to_update) {</a>
<a name="ln6946">    if (tablet-&gt;metadata().dirty().is_deleted()) {</a>
<a name="ln6947">      DeleteTabletReplicas(tablet, tablet-&gt;metadata().dirty().pb.state_msg());</a>
<a name="ln6948">    }</a>
<a name="ln6949">  }</a>
<a name="ln6950">  // Send the CreateTablet() requests to the servers. This is asynchronous / non-blocking.</a>
<a name="ln6951">  SendCreateTabletRequests(deferred.needs_create_rpc);</a>
<a name="ln6952">  return Status::OK();</a>
<a name="ln6953">}</a>
<a name="ln6954"> </a>
<a name="ln6955">Status CatalogManager::SelectReplicasForTablet(const TSDescriptorVector&amp; ts_descs,</a>
<a name="ln6956">                                               TabletInfo* tablet) {</a>
<a name="ln6957">  auto table_guard = tablet-&gt;table()-&gt;LockForRead();</a>
<a name="ln6958"> </a>
<a name="ln6959">  if (!table_guard-&gt;data().pb.IsInitialized()) {</a>
<a name="ln6960">    return STATUS_SUBSTITUTE(InvalidArgument,</a>
<a name="ln6961">        &quot;TableInfo for tablet $0 is not initialized (aborted CreateTable attempt?)&quot;,</a>
<a name="ln6962">        tablet-&gt;tablet_id());</a>
<a name="ln6963">  }</a>
<a name="ln6964"> </a>
<a name="ln6965">  // Validate that we do not have placement blocks in both cluster and table data.</a>
<a name="ln6966">  RETURN_NOT_OK(ValidateTableReplicationInfo(table_guard-&gt;data().pb.replication_info()));</a>
<a name="ln6967"> </a>
<a name="ln6968">  // Default to the cluster placement object.</a>
<a name="ln6969">  ReplicationInfoPB replication_info;</a>
<a name="ln6970">  {</a>
<a name="ln6971">    auto l = cluster_config_-&gt;LockForRead();</a>
<a name="ln6972">    replication_info = l-&gt;data().pb.replication_info();</a>
<a name="ln6973">  }</a>
<a name="ln6974"> </a>
<a name="ln6975">  // Select the set of replicas for the tablet.</a>
<a name="ln6976">  ConsensusStatePB* cstate = tablet-&gt;mutable_metadata()-&gt;mutable_dirty()</a>
<a name="ln6977">          -&gt;pb.mutable_committed_consensus_state();</a>
<a name="ln6978">  VLOG_WITH_FUNC(3) &lt;&lt; &quot;Committed consensus state: &quot; &lt;&lt; AsString(cstate);</a>
<a name="ln6979">  cstate-&gt;set_current_term(kMinimumTerm);</a>
<a name="ln6980">  consensus::RaftConfigPB *config = cstate-&gt;mutable_config();</a>
<a name="ln6981">  config-&gt;set_opid_index(consensus::kInvalidOpIdIndex);</a>
<a name="ln6982"> </a>
<a name="ln6983">  // TODO: we do this defaulting to cluster if no table data in two places, should refactor and</a>
<a name="ln6984">  // have a centralized getter, that will ultimately do the subsetting as well.</a>
<a name="ln6985"> </a>
<a name="ln6986">  Status s = HandlePlacementUsingReplicationInfo(replication_info, ts_descs, config);</a>
<a name="ln6987">  if (!s.ok()) {</a>
<a name="ln6988">    return s;</a>
<a name="ln6989">  }</a>
<a name="ln6990"> </a>
<a name="ln6991">  std::ostringstream out;</a>
<a name="ln6992">  out &lt;&lt; &quot;Initial tserver uuids for tablet &quot; &lt;&lt; tablet-&gt;tablet_id() &lt;&lt; &quot;: &quot;;</a>
<a name="ln6993">  for (const RaftPeerPB&amp; peer : config-&gt;peers()) {</a>
<a name="ln6994">    out &lt;&lt; peer.permanent_uuid() &lt;&lt; &quot; &quot;;</a>
<a name="ln6995">  }</a>
<a name="ln6996"> </a>
<a name="ln6997">  if (VLOG_IS_ON(0)) {</a>
<a name="ln6998">    out.str();</a>
<a name="ln6999">  }</a>
<a name="ln7000"> </a>
<a name="ln7001">  VLOG_WITH_FUNC(3) &lt;&lt; &quot;Committed consensus state has been updated to: &quot; &lt;&lt; AsString(cstate);</a>
<a name="ln7002"> </a>
<a name="ln7003">  return Status::OK();</a>
<a name="ln7004">}</a>
<a name="ln7005"> </a>
<a name="ln7006">Status CatalogManager::HandlePlacementUsingReplicationInfo(</a>
<a name="ln7007">    const ReplicationInfoPB&amp; replication_info,</a>
<a name="ln7008">    const TSDescriptorVector&amp; all_ts_descs,</a>
<a name="ln7009">    consensus::RaftConfigPB* config) {</a>
<a name="ln7010">  return HandlePlacementUsingPlacementInfo(replication_info.live_replicas(),</a>
<a name="ln7011">                                           all_ts_descs, RaftPeerPB::VOTER, config);</a>
<a name="ln7012">}</a>
<a name="ln7013"> </a>
<a name="ln7014">Status CatalogManager::HandlePlacementUsingPlacementInfo(const PlacementInfoPB&amp; placement_info,</a>
<a name="ln7015">                                                         const TSDescriptorVector&amp; ts_descs,</a>
<a name="ln7016">                                                         RaftPeerPB::MemberType member_type,</a>
<a name="ln7017">                                                         consensus::RaftConfigPB* config) {</a>
<a name="ln7018">  int nreplicas = GetNumReplicasFromPlacementInfo(placement_info);</a>
<a name="ln7019">  if (ts_descs.size() &lt; nreplicas) {</a>
<a name="ln7020">    return STATUS_SUBSTITUTE(InvalidArgument,</a>
<a name="ln7021">        &quot;Not enough tablet servers in the requested placements. Need at least $0, have $1&quot;,</a>
<a name="ln7022">        nreplicas, ts_descs.size());</a>
<a name="ln7023">  }</a>
<a name="ln7024">  // Keep track of servers we've already selected, so that we don't attempt to</a>
<a name="ln7025">  // put two replicas on the same host.</a>
<a name="ln7026">  set&lt;shared_ptr&lt;TSDescriptor&gt;&gt; already_selected_ts;</a>
<a name="ln7027">  if (placement_info.placement_blocks().empty()) {</a>
<a name="ln7028">    // If we don't have placement info, just place the replicas as before, distributed across the</a>
<a name="ln7029">    // whole cluster.</a>
<a name="ln7030">    SelectReplicas(ts_descs, nreplicas, config, &amp;already_selected_ts, member_type);</a>
<a name="ln7031">  } else {</a>
<a name="ln7032">    // TODO(bogdan): move to separate function</a>
<a name="ln7033">    //</a>
<a name="ln7034">    // If we do have placement info, we'll try to use the same power of two algorithm, but also</a>
<a name="ln7035">    // match the requested policies. We'll assign the minimum requested replicas in each combination</a>
<a name="ln7036">    // of cloud.region.zone and then if we still have leftover replicas, we'll assign those</a>
<a name="ln7037">    // in any of the allowed areas.</a>
<a name="ln7038">    unordered_map&lt;string, vector&lt;shared_ptr&lt;TSDescriptor&gt;&gt;&gt; allowed_ts_by_pi;</a>
<a name="ln7039">    vector&lt;shared_ptr&lt;TSDescriptor&gt;&gt; all_allowed_ts;</a>
<a name="ln7040"> </a>
<a name="ln7041">    // Keep map from ID to PlacementBlockPB, as protos only have repeated, not maps.</a>
<a name="ln7042">    unordered_map&lt;string, PlacementBlockPB&gt; pb_by_id;</a>
<a name="ln7043">    for (const auto&amp; pb : placement_info.placement_blocks()) {</a>
<a name="ln7044">      const auto&amp; cloud_info = pb.cloud_info();</a>
<a name="ln7045">      string placement_id = TSDescriptor::generate_placement_id(cloud_info);</a>
<a name="ln7046">      pb_by_id[placement_id] = pb;</a>
<a name="ln7047">    }</a>
<a name="ln7048"> </a>
<a name="ln7049">    // Build the sets of allowed TSs.</a>
<a name="ln7050">    for (const auto&amp; ts : ts_descs) {</a>
<a name="ln7051">      bool added_to_all = false;</a>
<a name="ln7052">      for (const auto&amp; pi_entry : pb_by_id) {</a>
<a name="ln7053">        if (ts-&gt;MatchesCloudInfo(pi_entry.second.cloud_info())) {</a>
<a name="ln7054">          allowed_ts_by_pi[pi_entry.first].push_back(ts);</a>
<a name="ln7055"> </a>
<a name="ln7056">          if (!added_to_all) {</a>
<a name="ln7057">            added_to_all = true;</a>
<a name="ln7058">            all_allowed_ts.push_back(ts);</a>
<a name="ln7059">          }</a>
<a name="ln7060">        }</a>
<a name="ln7061">      }</a>
<a name="ln7062">    }</a>
<a name="ln7063"> </a>
<a name="ln7064">    // Fail early if we don't have enough tablet servers in the areas requested.</a>
<a name="ln7065">    if (all_allowed_ts.size() &lt; nreplicas) {</a>
<a name="ln7066">      return STATUS_SUBSTITUTE(InvalidArgument,</a>
<a name="ln7067">          &quot;Not enough tablet servers in the requested placements. Need at least $0, have $1&quot;,</a>
<a name="ln7068">          nreplicas, all_allowed_ts.size());</a>
<a name="ln7069">    }</a>
<a name="ln7070"> </a>
<a name="ln7071">    // Loop through placements and assign to respective available TSs.</a>
<a name="ln7072">    for (const auto&amp; entry : allowed_ts_by_pi) {</a>
<a name="ln7073">      const auto&amp; available_ts_descs = entry.second;</a>
<a name="ln7074">      int num_replicas = pb_by_id[entry.first].min_num_replicas();</a>
<a name="ln7075">      num_replicas = num_replicas &gt; 0 ? num_replicas : FLAGS_replication_factor;</a>
<a name="ln7076">      if (available_ts_descs.size() &lt; num_replicas) {</a>
<a name="ln7077">        return STATUS_SUBSTITUTE(InvalidArgument,</a>
<a name="ln7078">            &quot;Not enough tablet servers in $0. Need at least $1 but only have $2.&quot;, entry.first,</a>
<a name="ln7079">            num_replicas, available_ts_descs.size());</a>
<a name="ln7080">      }</a>
<a name="ln7081">      SelectReplicas(available_ts_descs, num_replicas, config, &amp;already_selected_ts, member_type);</a>
<a name="ln7082">    }</a>
<a name="ln7083"> </a>
<a name="ln7084">    int replicas_left = nreplicas - already_selected_ts.size();</a>
<a name="ln7085">    DCHECK_GE(replicas_left, 0);</a>
<a name="ln7086">    if (replicas_left &gt; 0) {</a>
<a name="ln7087">      // No need to do an extra check here, as we checked early if we have enough to cover all</a>
<a name="ln7088">      // requested placements and checked individually per placement info, if we could cover the</a>
<a name="ln7089">      // minimums.</a>
<a name="ln7090">      SelectReplicas(all_allowed_ts, replicas_left, config, &amp;already_selected_ts, member_type);</a>
<a name="ln7091">    }</a>
<a name="ln7092">  }</a>
<a name="ln7093">  return Status::OK();</a>
<a name="ln7094">}</a>
<a name="ln7095"> </a>
<a name="ln7096">void CatalogManager::SendCreateTabletRequests(const vector&lt;TabletInfo*&gt;&amp; tablets) {</a>
<a name="ln7097">  for (TabletInfo *tablet : tablets) {</a>
<a name="ln7098">    const consensus::RaftConfigPB&amp; config =</a>
<a name="ln7099">        tablet-&gt;metadata().dirty().pb.committed_consensus_state().config();</a>
<a name="ln7100">    tablet-&gt;set_last_update_time(MonoTime::Now());</a>
<a name="ln7101">    for (const RaftPeerPB&amp; peer : config.peers()) {</a>
<a name="ln7102">      auto task = std::make_shared&lt;AsyncCreateReplica&gt;(master_, AsyncTaskPool(),</a>
<a name="ln7103">          peer.permanent_uuid(), tablet);</a>
<a name="ln7104">      tablet-&gt;table()-&gt;AddTask(task);</a>
<a name="ln7105">      WARN_NOT_OK(task-&gt;Run(), &quot;Failed to send new tablet request&quot;);</a>
<a name="ln7106">    }</a>
<a name="ln7107">  }</a>
<a name="ln7108">}</a>
<a name="ln7109"> </a>
<a name="ln7110">shared_ptr&lt;TSDescriptor&gt; CatalogManager::PickBetterReplicaLocation(</a>
<a name="ln7111">    const TSDescriptorVector&amp; two_choices) {</a>
<a name="ln7112">  DCHECK_EQ(two_choices.size(), 2);</a>
<a name="ln7113"> </a>
<a name="ln7114">  const auto&amp; a = two_choices[0];</a>
<a name="ln7115">  const auto&amp; b = two_choices[1];</a>
<a name="ln7116"> </a>
<a name="ln7117">  // When creating replicas, we consider two aspects of load:</a>
<a name="ln7118">  //   (1) how many tablet replicas are already on the server, and</a>
<a name="ln7119">  //   (2) how often we've chosen this server recently.</a>
<a name="ln7120">  //</a>
<a name="ln7121">  // The first factor will attempt to put more replicas on servers that</a>
<a name="ln7122">  // are under-loaded (eg because they have newly joined an existing cluster, or have</a>
<a name="ln7123">  // been reformatted and re-joined).</a>
<a name="ln7124">  //</a>
<a name="ln7125">  // The second factor will ensure that we take into account the recent selection</a>
<a name="ln7126">  // decisions even if those replicas are still in the process of being created (and thus</a>
<a name="ln7127">  // not yet reported by the server). This is important because, while creating a table,</a>
<a name="ln7128">  // we batch the selection process before sending any creation commands to the</a>
<a name="ln7129">  // servers themselves.</a>
<a name="ln7130">  //</a>
<a name="ln7131">  // TODO: in the future we may want to factor in other items such as available disk space,</a>
<a name="ln7132">  // actual request load, etc.</a>
<a name="ln7133">  double load_a = a-&gt;RecentReplicaCreations() + a-&gt;num_live_replicas();</a>
<a name="ln7134">  double load_b = b-&gt;RecentReplicaCreations() + b-&gt;num_live_replicas();</a>
<a name="ln7135">  if (load_a &lt; load_b) {</a>
<a name="ln7136">    return a;</a>
<a name="ln7137">  } else if (load_b &lt; load_a) {</a>
<a name="ln7138">    return b;</a>
<a name="ln7139">  } else {</a>
<a name="ln7140">    // If the load is the same, we can just pick randomly.</a>
<a name="ln7141">    return two_choices[rng_.Uniform(2)];</a>
<a name="ln7142">  }</a>
<a name="ln7143">}</a>
<a name="ln7144"> </a>
<a name="ln7145">shared_ptr&lt;TSDescriptor&gt; CatalogManager::SelectReplica(</a>
<a name="ln7146">    const TSDescriptorVector&amp; ts_descs,</a>
<a name="ln7147">    const set&lt;shared_ptr&lt;TSDescriptor&gt;&gt;&amp; excluded) {</a>
<a name="ln7148">  // The replica selection algorithm follows the idea from</a>
<a name="ln7149">  // &quot;Power of Two Choices in Randomized Load Balancing&quot;[1]. For each replica,</a>
<a name="ln7150">  // we randomly select two tablet servers, and then assign the replica to the</a>
<a name="ln7151">  // less-loaded one of the two. This has some nice properties:</a>
<a name="ln7152">  //</a>
<a name="ln7153">  // 1) because the initial selection of two servers is random, we get good</a>
<a name="ln7154">  //    spreading of replicas across the cluster. In contrast if we sorted by</a>
<a name="ln7155">  //    load and always picked under-loaded servers first, we'd end up causing</a>
<a name="ln7156">  //    all tablets of a new table to be placed on an empty server. This wouldn't</a>
<a name="ln7157">  //    give good load balancing of that table.</a>
<a name="ln7158">  //</a>
<a name="ln7159">  // 2) because we pick the less-loaded of two random choices, we do end up with a</a>
<a name="ln7160">  //    weighting towards filling up the underloaded one over time, without</a>
<a name="ln7161">  //    the extreme scenario above.</a>
<a name="ln7162">  //</a>
<a name="ln7163">  // 3) because we don't follow any sequential pattern, every server is equally</a>
<a name="ln7164">  //    likely to replicate its tablets to every other server. In contrast, a</a>
<a name="ln7165">  //    round-robin design would enforce that each server only replicates to its</a>
<a name="ln7166">  //    adjacent nodes in the TS sort order, limiting recovery bandwidth (see</a>
<a name="ln7167">  //    KUDU-1317).</a>
<a name="ln7168">  //</a>
<a name="ln7169">  // [1] http://www.eecs.harvard.edu/~michaelm/postscripts/mythesis.pdf</a>
<a name="ln7170"> </a>
<a name="ln7171">  // Pick two random servers, excluding those we've already picked.</a>
<a name="ln7172">  // If we've only got one server left, 'two_choices' will actually</a>
<a name="ln7173">  // just contain one element.</a>
<a name="ln7174">  vector&lt;shared_ptr&lt;TSDescriptor&gt;&gt; two_choices;</a>
<a name="ln7175">  rng_.ReservoirSample(ts_descs, 2, excluded, &amp;two_choices);</a>
<a name="ln7176"> </a>
<a name="ln7177">  if (two_choices.size() == 2) {</a>
<a name="ln7178">    // Pick the better of the two.</a>
<a name="ln7179">    return PickBetterReplicaLocation(two_choices);</a>
<a name="ln7180">  }</a>
<a name="ln7181"> </a>
<a name="ln7182">  // If we couldn't randomly sample two servers, it's because we only had one</a>
<a name="ln7183">  // more non-excluded choice left.</a>
<a name="ln7184">  CHECK_EQ(1, two_choices.size()) &lt;&lt; &quot;ts_descs: &quot; &lt;&lt; ts_descs.size()</a>
<a name="ln7185">                                  &lt;&lt; &quot; already_sel: &quot; &lt;&lt; excluded.size();</a>
<a name="ln7186">  return two_choices[0];</a>
<a name="ln7187">}</a>
<a name="ln7188"> </a>
<a name="ln7189">void CatalogManager::SelectReplicas(</a>
<a name="ln7190">    const TSDescriptorVector&amp; ts_descs, int nreplicas, consensus::RaftConfigPB* config,</a>
<a name="ln7191">    set&lt;shared_ptr&lt;TSDescriptor&gt;&gt;* already_selected_ts, RaftPeerPB::MemberType member_type) {</a>
<a name="ln7192">  DCHECK_LE(nreplicas, ts_descs.size());</a>
<a name="ln7193"> </a>
<a name="ln7194">  for (int i = 0; i &lt; nreplicas; ++i) {</a>
<a name="ln7195">    // We have to derefence already_selected_ts here, as the inner mechanics uses ReservoirSample,</a>
<a name="ln7196">    // which in turn accepts only a reference to the set, not a pointer. Alternatively, we could</a>
<a name="ln7197">    // have passed it in as a non-const reference, but that goes against our argument passing</a>
<a name="ln7198">    // convention.</a>
<a name="ln7199">    //</a>
<a name="ln7200">    // TODO(bogdan): see if we indeed want to switch back to non-const reference.</a>
<a name="ln7201">    shared_ptr&lt;TSDescriptor&gt; ts = SelectReplica(ts_descs, *already_selected_ts);</a>
<a name="ln7202">    InsertOrDie(already_selected_ts, ts);</a>
<a name="ln7203"> </a>
<a name="ln7204">    // Increment the number of pending replicas so that we take this selection into</a>
<a name="ln7205">    // account when assigning replicas for other tablets of the same table. This</a>
<a name="ln7206">    // value decays back to 0 over time.</a>
<a name="ln7207">    ts-&gt;IncrementRecentReplicaCreations();</a>
<a name="ln7208"> </a>
<a name="ln7209">    TSRegistrationPB reg = ts-&gt;GetRegistration();</a>
<a name="ln7210"> </a>
<a name="ln7211">    RaftPeerPB *peer = config-&gt;add_peers();</a>
<a name="ln7212">    peer-&gt;set_permanent_uuid(ts-&gt;permanent_uuid());</a>
<a name="ln7213"> </a>
<a name="ln7214">    // TODO: This is temporary, we will use only UUIDs.</a>
<a name="ln7215">    TakeRegistration(reg.mutable_common(), peer);</a>
<a name="ln7216">    peer-&gt;set_member_type(member_type);</a>
<a name="ln7217">  }</a>
<a name="ln7218">}</a>
<a name="ln7219"> </a>
<a name="ln7220">Status CatalogManager::ConsensusStateToTabletLocations(const consensus::ConsensusStatePB&amp; cstate,</a>
<a name="ln7221">                                                       TabletLocationsPB* locs_pb) {</a>
<a name="ln7222">  for (const consensus::RaftPeerPB&amp; peer : cstate.config().peers()) {</a>
<a name="ln7223">    TabletLocationsPB_ReplicaPB* replica_pb = locs_pb-&gt;add_replicas();</a>
<a name="ln7224">    if (!peer.has_permanent_uuid()) {</a>
<a name="ln7225">      return STATUS_SUBSTITUTE(IllegalState, &quot;Missing UUID $0&quot;, peer.ShortDebugString());</a>
<a name="ln7226">    }</a>
<a name="ln7227">    replica_pb-&gt;set_role(GetConsensusRole(peer.permanent_uuid(), cstate));</a>
<a name="ln7228">    if (peer.has_member_type()) {</a>
<a name="ln7229">      replica_pb-&gt;set_member_type(peer.member_type());</a>
<a name="ln7230">    } else {</a>
<a name="ln7231">      replica_pb-&gt;set_member_type(RaftPeerPB::UNKNOWN_MEMBER_TYPE);</a>
<a name="ln7232">    }</a>
<a name="ln7233">    TSInfoPB* tsinfo_pb = replica_pb-&gt;mutable_ts_info();</a>
<a name="ln7234">    tsinfo_pb-&gt;set_permanent_uuid(peer.permanent_uuid());</a>
<a name="ln7235">    CopyRegistration(peer, tsinfo_pb);</a>
<a name="ln7236">  }</a>
<a name="ln7237">  return Status::OK();</a>
<a name="ln7238">}</a>
<a name="ln7239"> </a>
<a name="ln7240">Status CatalogManager::BuildLocationsForTablet(const scoped_refptr&lt;TabletInfo&gt;&amp; tablet,</a>
<a name="ln7241">                                               TabletLocationsPB* locs_pb) {</a>
<a name="ln7242">  {</a>
<a name="ln7243">    auto l_tablet = tablet-&gt;LockForRead();</a>
<a name="ln7244">    locs_pb-&gt;set_table_id(l_tablet-&gt;data().pb.table_id());</a>
<a name="ln7245">    *locs_pb-&gt;mutable_table_ids() = l_tablet-&gt;data().pb.table_ids();</a>
<a name="ln7246">  }</a>
<a name="ln7247"> </a>
<a name="ln7248">  // For system tables, the set of replicas is always the set of masters.</a>
<a name="ln7249">  if (system_tablets_.find(tablet-&gt;id()) != system_tablets_.end()) {</a>
<a name="ln7250">    consensus::ConsensusStatePB master_consensus;</a>
<a name="ln7251">    RETURN_NOT_OK(GetCurrentConfig(&amp;master_consensus));</a>
<a name="ln7252">    locs_pb-&gt;set_tablet_id(tablet-&gt;tablet_id());</a>
<a name="ln7253">    locs_pb-&gt;set_stale(false);</a>
<a name="ln7254">    RETURN_NOT_OK(ConsensusStateToTabletLocations(master_consensus, locs_pb));</a>
<a name="ln7255">    return Status::OK();</a>
<a name="ln7256">  }</a>
<a name="ln7257"> </a>
<a name="ln7258">  TSRegistrationPB reg;</a>
<a name="ln7259"> </a>
<a name="ln7260">  TabletInfo::ReplicaMap locs;</a>
<a name="ln7261">  consensus::ConsensusStatePB cstate;</a>
<a name="ln7262">  {</a>
<a name="ln7263">    auto l_tablet = tablet-&gt;LockForRead();</a>
<a name="ln7264">    if (PREDICT_FALSE(l_tablet-&gt;data().is_deleted())) {</a>
<a name="ln7265">      return STATUS(NotFound, &quot;Tablet deleted&quot;, l_tablet-&gt;data().pb.state_msg());</a>
<a name="ln7266">    }</a>
<a name="ln7267"> </a>
<a name="ln7268">    if (PREDICT_FALSE(!l_tablet-&gt;data().is_running())) {</a>
<a name="ln7269">      return STATUS(ServiceUnavailable, &quot;Tablet not running&quot;);</a>
<a name="ln7270">    }</a>
<a name="ln7271"> </a>
<a name="ln7272">    tablet-&gt;GetReplicaLocations(&amp;locs);</a>
<a name="ln7273">    if (locs.empty() &amp;&amp; l_tablet-&gt;data().pb.has_committed_consensus_state()) {</a>
<a name="ln7274">      cstate = l_tablet-&gt;data().pb.committed_consensus_state();</a>
<a name="ln7275">    }</a>
<a name="ln7276"> </a>
<a name="ln7277">    const auto&amp; metadata = tablet-&gt;metadata().state().pb;</a>
<a name="ln7278">    locs_pb-&gt;mutable_partition()-&gt;CopyFrom(metadata.partition());</a>
<a name="ln7279">    if (metadata.has_split_depth()) {</a>
<a name="ln7280">      locs_pb-&gt;set_split_depth(metadata.split_depth());</a>
<a name="ln7281">    }</a>
<a name="ln7282">  }</a>
<a name="ln7283"> </a>
<a name="ln7284">  locs_pb-&gt;set_tablet_id(tablet-&gt;tablet_id());</a>
<a name="ln7285">  locs_pb-&gt;set_stale(locs.empty());</a>
<a name="ln7286"> </a>
<a name="ln7287">  // If the locations are cached.</a>
<a name="ln7288">  if (!locs.empty()) {</a>
<a name="ln7289">    if (cstate.IsInitialized() &amp;&amp; locs.size() != cstate.config().peers_size()) {</a>
<a name="ln7290">      LOG(WARNING) &lt;&lt; &quot;Cached tablet replicas &quot; &lt;&lt; locs.size() &lt;&lt; &quot; does not match consensus &quot;</a>
<a name="ln7291">                   &lt;&lt; cstate.config().peers_size();</a>
<a name="ln7292">    }</a>
<a name="ln7293"> </a>
<a name="ln7294">    for (const TabletInfo::ReplicaMap::value_type&amp; replica : locs) {</a>
<a name="ln7295">      TabletLocationsPB_ReplicaPB* replica_pb = locs_pb-&gt;add_replicas();</a>
<a name="ln7296">      replica_pb-&gt;set_role(replica.second.role);</a>
<a name="ln7297">      replica_pb-&gt;set_member_type(replica.second.member_type);</a>
<a name="ln7298">      TSInformationPB tsinfo_pb = *replica.second.ts_desc-&gt;GetTSInformationPB();</a>
<a name="ln7299"> </a>
<a name="ln7300">      TSInfoPB* out_ts_info = replica_pb-&gt;mutable_ts_info();</a>
<a name="ln7301">      out_ts_info-&gt;set_permanent_uuid(tsinfo_pb.tserver_instance().permanent_uuid());</a>
<a name="ln7302">      TakeRegistration(tsinfo_pb.mutable_registration()-&gt;mutable_common(), out_ts_info);</a>
<a name="ln7303">      out_ts_info-&gt;set_placement_uuid(tsinfo_pb.registration().common().placement_uuid());</a>
<a name="ln7304">      *out_ts_info-&gt;mutable_capabilities() = std::move(</a>
<a name="ln7305">          *tsinfo_pb.mutable_registration()-&gt;mutable_capabilities());</a>
<a name="ln7306">    }</a>
<a name="ln7307">    return Status::OK();</a>
<a name="ln7308">  }</a>
<a name="ln7309"> </a>
<a name="ln7310">  // If the locations were not cached.</a>
<a name="ln7311">  // TODO: Why would this ever happen? See KUDU-759.</a>
<a name="ln7312">  if (cstate.IsInitialized()) {</a>
<a name="ln7313">    RETURN_NOT_OK(ConsensusStateToTabletLocations(cstate, locs_pb));</a>
<a name="ln7314">  }</a>
<a name="ln7315"> </a>
<a name="ln7316">  return Status::OK();</a>
<a name="ln7317">}</a>
<a name="ln7318"> </a>
<a name="ln7319">Result&lt;shared_ptr&lt;tablet::AbstractTablet&gt;&gt; CatalogManager::GetSystemTablet(const TabletId&amp; id) {</a>
<a name="ln7320">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln7321"> </a>
<a name="ln7322">  const auto iter = system_tablets_.find(id);</a>
<a name="ln7323">  if (iter == system_tablets_.end()) {</a>
<a name="ln7324">    return STATUS_SUBSTITUTE(InvalidArgument, &quot;$0 is not a valid system tablet id&quot;, id);</a>
<a name="ln7325">  }</a>
<a name="ln7326">  return iter-&gt;second;</a>
<a name="ln7327">}</a>
<a name="ln7328"> </a>
<a name="ln7329">Status CatalogManager::GetTabletLocations(const TabletId&amp; tablet_id, TabletLocationsPB* locs_pb) {</a>
<a name="ln7330">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln7331"> </a>
<a name="ln7332">  locs_pb-&gt;mutable_replicas()-&gt;Clear();</a>
<a name="ln7333">  scoped_refptr&lt;TabletInfo&gt; tablet_info;</a>
<a name="ln7334">  {</a>
<a name="ln7335">    SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln7336">    if (!FindCopy(*tablet_map_, tablet_id, &amp;tablet_info)) {</a>
<a name="ln7337">      return STATUS_SUBSTITUTE(NotFound, &quot;Unknown tablet $0&quot;, tablet_id);</a>
<a name="ln7338">    }</a>
<a name="ln7339">  }</a>
<a name="ln7340"> </a>
<a name="ln7341">  Status s = BuildLocationsForTablet(tablet_info, locs_pb);</a>
<a name="ln7342"> </a>
<a name="ln7343">  int num_replicas = 0;</a>
<a name="ln7344">  if (GetReplicationFactorForTablet(tablet_info, &amp;num_replicas).ok() &amp;&amp; num_replicas &gt; 0 &amp;&amp;</a>
<a name="ln7345">      locs_pb-&gt;replicas().size() != num_replicas) {</a>
<a name="ln7346">    YB_LOG_EVERY_N_SECS(WARNING, 1)</a>
<a name="ln7347">        &lt;&lt; &quot;Expected replicas &quot; &lt;&lt; num_replicas &lt;&lt; &quot; but found &quot;</a>
<a name="ln7348">        &lt;&lt; locs_pb-&gt;replicas().size() &lt;&lt; &quot; for tablet &quot; &lt;&lt; tablet_id &lt;&lt; &quot;: &quot;</a>
<a name="ln7349">        &lt;&lt; locs_pb-&gt;ShortDebugString() &lt;&lt; THROTTLE_MSG;</a>
<a name="ln7350">  }</a>
<a name="ln7351"> </a>
<a name="ln7352">  return s;</a>
<a name="ln7353">}</a>
<a name="ln7354"> </a>
<a name="ln7355">Status CatalogManager::GetTableLocations(const GetTableLocationsRequestPB* req,</a>
<a name="ln7356">                                         GetTableLocationsResponsePB* resp) {</a>
<a name="ln7357">  RETURN_NOT_OK(CheckOnline());</a>
<a name="ln7358">  VLOG(4) &lt;&lt; &quot;GetTableLocations: &quot; &lt;&lt; req-&gt;ShortDebugString();</a>
<a name="ln7359"> </a>
<a name="ln7360">  // If start-key is &gt; end-key report an error instead of swap the two</a>
<a name="ln7361">  // since probably there is something wrong app-side.</a>
<a name="ln7362">  if (req-&gt;has_partition_key_start() &amp;&amp; req-&gt;has_partition_key_end()</a>
<a name="ln7363">      &amp;&amp; req-&gt;partition_key_start() &gt; req-&gt;partition_key_end()) {</a>
<a name="ln7364">    return STATUS(InvalidArgument, &quot;start partition key is greater than the end partition key&quot;);</a>
<a name="ln7365">  }</a>
<a name="ln7366"> </a>
<a name="ln7367">  if (req-&gt;max_returned_locations() &lt;= 0) {</a>
<a name="ln7368">    return STATUS(InvalidArgument, &quot;max_returned_locations must be greater than 0&quot;);</a>
<a name="ln7369">  }</a>
<a name="ln7370"> </a>
<a name="ln7371">  scoped_refptr&lt;TableInfo&gt; table;</a>
<a name="ln7372">  RETURN_NOT_OK(FindTable(req-&gt;table(), &amp;table));</a>
<a name="ln7373"> </a>
<a name="ln7374">  if (table == nullptr) {</a>
<a name="ln7375">    Status s = STATUS(NotFound, &quot;The object does not exist&quot;, req-&gt;table().ShortDebugString());</a>
<a name="ln7376">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, s);</a>
<a name="ln7377">  }</a>
<a name="ln7378"> </a>
<a name="ln7379">  auto l = table-&gt;LockForRead();</a>
<a name="ln7380">  RETURN_NOT_OK(CheckIfTableDeletedOrNotRunning(l.get(), resp));</a>
<a name="ln7381"> </a>
<a name="ln7382">  vector&lt;scoped_refptr&lt;TabletInfo&gt;&gt; tablets_in_range;</a>
<a name="ln7383">  table-&gt;GetTabletsInRange(req, &amp;tablets_in_range);</a>
<a name="ln7384"> </a>
<a name="ln7385">  bool require_tablets_runnings = req-&gt;require_tablets_running();</a>
<a name="ln7386">  for (const scoped_refptr&lt;TabletInfo&gt;&amp; tablet : tablets_in_range) {</a>
<a name="ln7387">    auto status = BuildLocationsForTablet(tablet, resp-&gt;add_tablet_locations());</a>
<a name="ln7388">    if (!status.ok()) {</a>
<a name="ln7389">      // Not running.</a>
<a name="ln7390">      if (require_tablets_runnings) {</a>
<a name="ln7391">        resp-&gt;mutable_tablet_locations()-&gt;Clear();</a>
<a name="ln7392">        return SetupError(resp-&gt;mutable_error(), MasterErrorPB::OBJECT_NOT_FOUND, status);</a>
<a name="ln7393">      }</a>
<a name="ln7394">      resp-&gt;mutable_tablet_locations()-&gt;RemoveLast();</a>
<a name="ln7395">    }</a>
<a name="ln7396">  }</a>
<a name="ln7397"> </a>
<a name="ln7398">  resp-&gt;set_table_type(l-&gt;data().pb.table_type());</a>
<a name="ln7399">  resp-&gt;set_partitions_version(l-&gt;data().pb.partitions_version());</a>
<a name="ln7400"> </a>
<a name="ln7401">  return Status::OK();</a>
<a name="ln7402">}</a>
<a name="ln7403"> </a>
<a name="ln7404">Status CatalogManager::GetCurrentConfig(consensus::ConsensusStatePB* cpb) const {</a>
<a name="ln7405">  auto tablet_peer = sys_catalog_-&gt;tablet_peer();</a>
<a name="ln7406">  auto consensus = tablet_peer ? tablet_peer-&gt;shared_consensus() : nullptr;</a>
<a name="ln7407">  if (!consensus) {</a>
<a name="ln7408">    std::string uuid = master_-&gt;fs_manager()-&gt;uuid();</a>
<a name="ln7409">    return STATUS_FORMAT(IllegalState, &quot;Node $0 peer not initialized.&quot;, uuid);</a>
<a name="ln7410">  }</a>
<a name="ln7411"> </a>
<a name="ln7412">  *cpb = consensus-&gt;ConsensusState(CONSENSUS_CONFIG_COMMITTED);</a>
<a name="ln7413"> </a>
<a name="ln7414">  return Status::OK();</a>
<a name="ln7415">}</a>
<a name="ln7416"> </a>
<a name="ln7417">void CatalogManager::DumpState(std::ostream* out, bool on_disk_dump) const {</a>
<a name="ln7418">  NamespaceInfoMap namespace_ids_copy;</a>
<a name="ln7419">  TableInfoMap ids_copy;</a>
<a name="ln7420">  TableInfoByNameMap names_copy;</a>
<a name="ln7421">  TabletInfoMap tablets_copy;</a>
<a name="ln7422"> </a>
<a name="ln7423">  // Copy the internal state so that, if the output stream blocks,</a>
<a name="ln7424">  // we don't end up holding the lock for a long time.</a>
<a name="ln7425">  {</a>
<a name="ln7426">    SharedLock&lt;LockType&gt; l(lock_);</a>
<a name="ln7427">    namespace_ids_copy = namespace_ids_map_;</a>
<a name="ln7428">    ids_copy = *table_ids_map_;</a>
<a name="ln7429">    names_copy = table_names_map_;</a>
<a name="ln7430">    tablets_copy = *tablet_map_;</a>
<a name="ln7431">  }</a>
<a name="ln7432"> </a>
<a name="ln7433">  *out &lt;&lt; &quot;Dumping current state of master.\nNamespaces:\n&quot;;</a>
<a name="ln7434">  for (const NamespaceInfoMap::value_type&amp; e : namespace_ids_copy) {</a>
<a name="ln7435">    NamespaceInfo* t = e.second.get();</a>
<a name="ln7436">    auto l = t-&gt;LockForRead();</a>
<a name="ln7437">    const NamespaceName&amp; name = l-&gt;data().name();</a>
<a name="ln7438"> </a>
<a name="ln7439">    *out &lt;&lt; t-&gt;id() &lt;&lt; &quot;:\n&quot;;</a>
<a name="ln7440">    *out &lt;&lt; &quot;  name: \&quot;&quot; &lt;&lt; strings::CHexEscape(name) &lt;&lt; &quot;\&quot;\n&quot;;</a>
<a name="ln7441">    *out &lt;&lt; &quot;  metadata: &quot; &lt;&lt; l-&gt;data().pb.ShortDebugString() &lt;&lt; &quot;\n&quot;;</a>
<a name="ln7442">  }</a>
<a name="ln7443"> </a>
<a name="ln7444">  *out &lt;&lt; &quot;Tables:\n&quot;;</a>
<a name="ln7445">  for (const TableInfoMap::value_type&amp; e : ids_copy) {</a>
<a name="ln7446">    TableInfo* t = e.second.get();</a>
<a name="ln7447">    auto l = t-&gt;LockForRead();</a>
<a name="ln7448">    const TableName&amp; name = l-&gt;data().name();</a>
<a name="ln7449">    const NamespaceId&amp; namespace_id = l-&gt;data().namespace_id();</a>
<a name="ln7450">    // Find namespace by its ID.</a>
<a name="ln7451">    scoped_refptr&lt;NamespaceInfo&gt; ns = FindPtrOrNull(namespace_ids_copy, namespace_id);</a>
<a name="ln7452"> </a>
<a name="ln7453">    *out &lt;&lt; t-&gt;id() &lt;&lt; &quot;:\n&quot;;</a>
<a name="ln7454">    *out &lt;&lt; &quot;  namespace id: \&quot;&quot; &lt;&lt; strings::CHexEscape(namespace_id) &lt;&lt; &quot;\&quot;\n&quot;;</a>
<a name="ln7455"> </a>
<a name="ln7456">    if (ns != nullptr) {</a>
<a name="ln7457">      *out &lt;&lt; &quot;  namespace name: \&quot;&quot; &lt;&lt; strings::CHexEscape(ns-&gt;name()) &lt;&lt; &quot;\&quot;\n&quot;;</a>
<a name="ln7458">    }</a>
<a name="ln7459"> </a>
<a name="ln7460">    *out &lt;&lt; &quot;  name: \&quot;&quot; &lt;&lt; strings::CHexEscape(name) &lt;&lt; &quot;\&quot;\n&quot;;</a>
<a name="ln7461">    // Erase from the map, so later we can check that we don't have</a>
<a name="ln7462">    // any orphaned tables in the by-name map that aren't in the</a>
<a name="ln7463">    // by-id map.</a>
<a name="ln7464">    if (names_copy.erase({namespace_id, name}) != 1) {</a>
<a name="ln7465">      *out &lt;&lt; &quot;  [not present in by-name map]\n&quot;;</a>
<a name="ln7466">    }</a>
<a name="ln7467">    *out &lt;&lt; &quot;  metadata: &quot; &lt;&lt; l-&gt;data().pb.ShortDebugString() &lt;&lt; &quot;\n&quot;;</a>
<a name="ln7468"> </a>
<a name="ln7469">    *out &lt;&lt; &quot;  tablets:\n&quot;;</a>
<a name="ln7470"> </a>
<a name="ln7471">    vector&lt;scoped_refptr&lt;TabletInfo&gt;&gt; table_tablets;</a>
<a name="ln7472">    t-&gt;GetAllTablets(&amp;table_tablets);</a>
<a name="ln7473">    for (const scoped_refptr&lt;TabletInfo&gt;&amp; tablet : table_tablets) {</a>
<a name="ln7474">      auto l_tablet = tablet-&gt;LockForRead();</a>
<a name="ln7475">      *out &lt;&lt; &quot;    &quot; &lt;&lt; tablet-&gt;tablet_id() &lt;&lt; &quot;: &quot;</a>
<a name="ln7476">           &lt;&lt; l_tablet-&gt;data().pb.ShortDebugString() &lt;&lt; &quot;\n&quot;;</a>
<a name="ln7477"> </a>
<a name="ln7478">      if (tablets_copy.erase(tablet-&gt;tablet_id()) != 1) {</a>
<a name="ln7479">        *out &lt;&lt; &quot;  [ERROR: not present in CM tablet map!]\n&quot;;</a>
<a name="ln7480">      }</a>
<a name="ln7481">    }</a>
<a name="ln7482">  }</a>
<a name="ln7483"> </a>
<a name="ln7484">  if (!tablets_copy.empty()) {</a>
<a name="ln7485">    *out &lt;&lt; &quot;Orphaned tablets (not referenced by any table):\n&quot;;</a>
<a name="ln7486">    for (const TabletInfoMap::value_type&amp; entry : tablets_copy) {</a>
<a name="ln7487">      const scoped_refptr&lt;TabletInfo&gt;&amp; tablet = entry.second;</a>
<a name="ln7488">      auto l_tablet = tablet-&gt;LockForRead();</a>
<a name="ln7489">      *out &lt;&lt; &quot;    &quot; &lt;&lt; tablet-&gt;tablet_id() &lt;&lt; &quot;: &quot;</a>
<a name="ln7490">           &lt;&lt; l_tablet-&gt;data().pb.ShortDebugString() &lt;&lt; &quot;\n&quot;;</a>
<a name="ln7491">    }</a>
<a name="ln7492">  }</a>
<a name="ln7493"> </a>
<a name="ln7494">  if (!names_copy.empty()) {</a>
<a name="ln7495">    *out &lt;&lt; &quot;Orphaned tables (in by-name map, but not id map):\n&quot;;</a>
<a name="ln7496">    for (const TableInfoByNameMap::value_type&amp; e : names_copy) {</a>
<a name="ln7497">      *out &lt;&lt; e.second-&gt;id() &lt;&lt; &quot;:\n&quot;;</a>
<a name="ln7498">      *out &lt;&lt; &quot;  namespace id: \&quot;&quot; &lt;&lt; strings::CHexEscape(e.first.first) &lt;&lt; &quot;\&quot;\n&quot;;</a>
<a name="ln7499">      *out &lt;&lt; &quot;  name: \&quot;&quot; &lt;&lt; CHexEscape(e.first.second) &lt;&lt; &quot;\&quot;\n&quot;;</a>
<a name="ln7500">    }</a>
<a name="ln7501">  }</a>
<a name="ln7502"> </a>
<a name="ln7503">  master_-&gt;DumpMasterOptionsInfo(out);</a>
<a name="ln7504"> </a>
<a name="ln7505">  if (on_disk_dump) {</a>
<a name="ln7506">    consensus::ConsensusStatePB cur_consensus_state;</a>
<a name="ln7507">    // TODO: proper error handling below.</a>
<a name="ln7508">    CHECK_OK(GetCurrentConfig(&amp;cur_consensus_state));</a>
<a name="ln7509">    *out &lt;&lt; &quot;Current raft config: &quot; &lt;&lt; cur_consensus_state.ShortDebugString() &lt;&lt; &quot;\n&quot;;</a>
<a name="ln7510">  }</a>
<a name="ln7511">}</a>
<a name="ln7512"> </a>
<a name="ln7513">Status CatalogManager::PeerStateDump(const vector&lt;RaftPeerPB&gt;&amp; peers,</a>
<a name="ln7514">                                     const DumpMasterStateRequestPB* req,</a>
<a name="ln7515">                                     DumpMasterStateResponsePB* resp) {</a>
<a name="ln7516">  std::unique_ptr&lt;MasterServiceProxy&gt; peer_proxy;</a>
<a name="ln7517">  Endpoint sockaddr;</a>
<a name="ln7518">  MonoTime timeout = MonoTime::Now();</a>
<a name="ln7519">  DumpMasterStateRequestPB peer_req;</a>
<a name="ln7520">  rpc::RpcController rpc;</a>
<a name="ln7521"> </a>
<a name="ln7522">  timeout.AddDelta(MonoDelta::FromMilliseconds(FLAGS_master_ts_rpc_timeout_ms));</a>
<a name="ln7523">  rpc.set_deadline(timeout);</a>
<a name="ln7524">  peer_req.set_on_disk(req-&gt;on_disk());</a>
<a name="ln7525">  peer_req.set_return_dump_as_string(req-&gt;return_dump_as_string());</a>
<a name="ln7526">  string dump;</a>
<a name="ln7527"> </a>
<a name="ln7528">  for (const RaftPeerPB&amp; peer : peers) {</a>
<a name="ln7529">    HostPort hostport = HostPortFromPB(DesiredHostPort(peer, master_-&gt;MakeCloudInfoPB()));</a>
<a name="ln7530">    peer_proxy.reset(new MasterServiceProxy(&amp;master_-&gt;proxy_cache(), hostport));</a>
<a name="ln7531"> </a>
<a name="ln7532">    DumpMasterStateResponsePB peer_resp;</a>
<a name="ln7533">    rpc.Reset();</a>
<a name="ln7534"> </a>
<a name="ln7535">    RETURN_NOT_OK(peer_proxy-&gt;DumpState(peer_req, &amp;peer_resp, &amp;rpc));</a>
<a name="ln7536"> </a>
<a name="ln7537">    if (peer_resp.has_error()) {</a>
<a name="ln7538">      LOG(WARNING) &lt;&lt; &quot;Hit err &quot; &lt;&lt; peer_resp.ShortDebugString() &lt;&lt; &quot; during peer &quot;</a>
<a name="ln7539">        &lt;&lt; peer.ShortDebugString() &lt;&lt; &quot; state dump.&quot;;</a>
<a name="ln7540">      return StatusFromPB(peer_resp.error().status());</a>
<a name="ln7541">    } else if (req-&gt;return_dump_as_string()) {</a>
<a name="ln7542">      dump += peer_resp.dump();</a>
<a name="ln7543">    }</a>
<a name="ln7544">  }</a>
<a name="ln7545"> </a>
<a name="ln7546">  if (req-&gt;return_dump_as_string()) {</a>
<a name="ln7547">    resp-&gt;set_dump(resp-&gt;dump() + dump);</a>
<a name="ln7548">  }</a>
<a name="ln7549">  return Status::OK();</a>
<a name="ln7550">}</a>
<a name="ln7551"> </a>
<a name="ln7552">void CatalogManager::ReportMetrics() {</a>
<a name="ln7553">  // Report metrics on how many tservers are alive.</a>
<a name="ln7554">  TSDescriptorVector ts_descs;</a>
<a name="ln7555">  master_-&gt;ts_manager()-&gt;GetAllLiveDescriptors(&amp;ts_descs);</a>
<a name="ln7556">  const int32 num_live_servers = ts_descs.size();</a>
<a name="ln7557">  metric_num_tablet_servers_live_-&gt;set_value(num_live_servers);</a>
<a name="ln7558"> </a>
<a name="ln7559">  master_-&gt;ts_manager()-&gt;GetAllDescriptors(&amp;ts_descs);</a>
<a name="ln7560">  metric_num_tablet_servers_dead_-&gt;set_value(ts_descs.size() - num_live_servers);</a>
<a name="ln7561">}</a>
<a name="ln7562"> </a>
<a name="ln7563">std::string CatalogManager::LogPrefix() const {</a>
<a name="ln7564">  if (tablet_peer()) {</a>
<a name="ln7565">    return consensus::MakeTabletLogPrefix(</a>
<a name="ln7566">        tablet_peer()-&gt;tablet_id(), tablet_peer()-&gt;permanent_uuid());</a>
<a name="ln7567">  } else {</a>
<a name="ln7568">    return consensus::MakeTabletLogPrefix(</a>
<a name="ln7569">        kSysCatalogTabletId, master_-&gt;fs_manager()-&gt;uuid());</a>
<a name="ln7570">  }</a>
<a name="ln7571">}</a>
<a name="ln7572"> </a>
<a name="ln7573">void CatalogManager::SetLoadBalancerEnabled(bool is_enabled) {</a>
<a name="ln7574">  load_balance_policy_-&gt;SetLoadBalancerEnabled(is_enabled);</a>
<a name="ln7575">}</a>
<a name="ln7576"> </a>
<a name="ln7577">bool CatalogManager::IsLoadBalancerEnabled() {</a>
<a name="ln7578">  return load_balance_policy_-&gt;IsLoadBalancerEnabled();</a>
<a name="ln7579">}</a>
<a name="ln7580"> </a>
<a name="ln7581">MonoDelta CatalogManager::TimeSinceElectedLeader() {</a>
<a name="ln7582">  return MonoTime::Now() - time_elected_leader_;</a>
<a name="ln7583">}</a>
<a name="ln7584"> </a>
<a name="ln7585">Status CatalogManager::GoIntoShellMode() {</a>
<a name="ln7586">  if (master_-&gt;IsShellMode()) {</a>
<a name="ln7587">    return STATUS(IllegalState, &quot;Master is already in shell mode.&quot;);</a>
<a name="ln7588">  }</a>
<a name="ln7589"> </a>
<a name="ln7590">  LOG(INFO) &lt;&lt; &quot;Starting going into shell mode.&quot;;</a>
<a name="ln7591">  master_-&gt;SetShellMode(true);</a>
<a name="ln7592"> </a>
<a name="ln7593">  {</a>
<a name="ln7594">    std::lock_guard&lt;LockType&gt; l(lock_);</a>
<a name="ln7595">    RETURN_NOT_OK(sys_catalog_-&gt;GoIntoShellMode());</a>
<a name="ln7596">    background_tasks_-&gt;Shutdown();</a>
<a name="ln7597">    background_tasks_.reset();</a>
<a name="ln7598">  }</a>
<a name="ln7599">  {</a>
<a name="ln7600">    std::lock_guard&lt;std::mutex&gt; l(remote_bootstrap_mtx_);</a>
<a name="ln7601">    tablet_exists_ = false;</a>
<a name="ln7602">  }</a>
<a name="ln7603"> </a>
<a name="ln7604">  LOG(INFO) &lt;&lt; &quot;Done going into shell mode.&quot;;</a>
<a name="ln7605"> </a>
<a name="ln7606">  return Status::OK();</a>
<a name="ln7607">}</a>
<a name="ln7608"> </a>
<a name="ln7609">Status CatalogManager::GetClusterConfig(GetMasterClusterConfigResponsePB* resp) {</a>
<a name="ln7610">  return GetClusterConfig(resp-&gt;mutable_cluster_config());</a>
<a name="ln7611">}</a>
<a name="ln7612"> </a>
<a name="ln7613">Status CatalogManager::GetClusterConfig(SysClusterConfigEntryPB* config) {</a>
<a name="ln7614">  DCHECK(cluster_config_) &lt;&lt; &quot;Missing cluster config for master!&quot;;</a>
<a name="ln7615">  auto l = cluster_config_-&gt;LockForRead();</a>
<a name="ln7616">  *config = l-&gt;data().pb;</a>
<a name="ln7617">  return Status::OK();</a>
<a name="ln7618">}</a>
<a name="ln7619"> </a>
<a name="ln7620">Status CatalogManager::SetBlackList(const BlacklistPB&amp; blacklist) {</a>
<a name="ln7621">  if (!blacklistState.tservers_.empty()) {</a>
<a name="ln7622">    LOG(WARNING) &lt;&lt; &quot;Overwriting &quot; &lt;&lt; blacklistState.ToString()</a>
<a name="ln7623">                 &lt;&lt; &quot; with new size &quot; &lt;&lt; blacklist.hosts_size()</a>
<a name="ln7624">                 &lt;&lt; &quot; and initial load &quot; &lt;&lt; blacklist.initial_replica_load() &lt;&lt; &quot;.&quot;;</a>
<a name="ln7625">    blacklistState.Reset();</a>
<a name="ln7626">  }</a>
<a name="ln7627"> </a>
<a name="ln7628">  LOG(INFO) &lt;&lt; &quot;Set blacklist size = &quot; &lt;&lt; blacklist.hosts_size() &lt;&lt; &quot; with load &quot;</a>
<a name="ln7629">            &lt;&lt; blacklist.initial_replica_load();</a>
<a name="ln7630"> </a>
<a name="ln7631">  for (const auto&amp; pb : blacklist.hosts()) {</a>
<a name="ln7632">    blacklistState.tservers_.insert(HostPortFromPB(pb));</a>
<a name="ln7633">  }</a>
<a name="ln7634"> </a>
<a name="ln7635">  return Status::OK();</a>
<a name="ln7636">}</a>
<a name="ln7637"> </a>
<a name="ln7638">Status CatalogManager::SetLeaderBlacklist(const BlacklistPB&amp; leader_blacklist) {</a>
<a name="ln7639">  if (!leaderBlacklistState.tservers_.empty()) {</a>
<a name="ln7640">    LOG(WARNING) &lt;&lt; &quot;Overwriting &quot; &lt;&lt; leaderBlacklistState.ToString()</a>
<a name="ln7641">                 &lt;&lt; &quot; with new size &quot; &lt;&lt; leader_blacklist.hosts_size()</a>
<a name="ln7642">                 &lt;&lt; &quot; and initial load &quot; &lt;&lt; leader_blacklist.initial_leader_load() &lt;&lt; &quot;.&quot;;</a>
<a name="ln7643">    leaderBlacklistState.Reset();</a>
<a name="ln7644">  }</a>
<a name="ln7645"> </a>
<a name="ln7646">  LOG(INFO) &lt;&lt; &quot;Set leader blacklist size = &quot; &lt;&lt; leader_blacklist.hosts_size() &lt;&lt; &quot; with load &quot;</a>
<a name="ln7647">            &lt;&lt; leader_blacklist.initial_leader_load();</a>
<a name="ln7648"> </a>
<a name="ln7649">  for (const auto&amp; pb : leader_blacklist.hosts()) {</a>
<a name="ln7650">    leaderBlacklistState.tservers_.insert(HostPortFromPB(pb));</a>
<a name="ln7651">  }</a>
<a name="ln7652"> </a>
<a name="ln7653">  return Status::OK();</a>
<a name="ln7654">}</a>
<a name="ln7655"> </a>
<a name="ln7656">Status CatalogManager::SetClusterConfig(</a>
<a name="ln7657">    const ChangeMasterClusterConfigRequestPB* req, ChangeMasterClusterConfigResponsePB* resp) {</a>
<a name="ln7658">  SysClusterConfigEntryPB config(req-&gt;cluster_config());</a>
<a name="ln7659"> </a>
<a name="ln7660">  {</a>
<a name="ln7661">    std::lock_guard &lt;LockType&gt; blacklist_lock(blacklist_lock_);</a>
<a name="ln7662"> </a>
<a name="ln7663">    // Save the list of blacklisted servers to be used for completion checking.</a>
<a name="ln7664">    if (config.has_server_blacklist()) {</a>
<a name="ln7665">      RETURN_NOT_OK(SetBlackList(config.server_blacklist()));</a>
<a name="ln7666"> </a>
<a name="ln7667">      config.mutable_server_blacklist()-&gt;set_initial_replica_load(</a>
<a name="ln7668">          GetNumRelevantReplicas(blacklistState, false /* leaders_only */));</a>
<a name="ln7669">      blacklistState.initial_load_ = config.server_blacklist().initial_replica_load();</a>
<a name="ln7670">    }</a>
<a name="ln7671"> </a>
<a name="ln7672">    // Save the list of leader blacklist to be used for completion checking.</a>
<a name="ln7673">    if (config.has_leader_blacklist()) {</a>
<a name="ln7674">      RETURN_NOT_OK(SetLeaderBlacklist(config.leader_blacklist()));</a>
<a name="ln7675"> </a>
<a name="ln7676">      config.mutable_leader_blacklist()-&gt;set_initial_leader_load(</a>
<a name="ln7677">          GetNumRelevantReplicas(leaderBlacklistState, true /* leaders_only */));</a>
<a name="ln7678">      leaderBlacklistState.initial_load_ = config.leader_blacklist().initial_leader_load();</a>
<a name="ln7679">    }</a>
<a name="ln7680">  }</a>
<a name="ln7681"> </a>
<a name="ln7682">  auto l = cluster_config_-&gt;LockForWrite();</a>
<a name="ln7683">  // We should only set the config, if the caller provided us with a valid update to the</a>
<a name="ln7684">  // existing config.</a>
<a name="ln7685">  if (l-&gt;data().pb.version() != config.version()) {</a>
<a name="ln7686">    Status s = STATUS_SUBSTITUTE(IllegalState,</a>
<a name="ln7687">      &quot;Config version does not match, got $0, but most recent one is $1. Should call Get again&quot;,</a>
<a name="ln7688">      config.version(), l-&gt;data().pb.version());</a>
<a name="ln7689">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::CONFIG_VERSION_MISMATCH, s);</a>
<a name="ln7690">  }</a>
<a name="ln7691"> </a>
<a name="ln7692">  if (config.cluster_uuid() != l-&gt;data().pb.cluster_uuid()) {</a>
<a name="ln7693">    Status s = STATUS(InvalidArgument, &quot;Config cluster UUID cannot be updated&quot;);</a>
<a name="ln7694">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_CLUSTER_CONFIG, s);</a>
<a name="ln7695">  }</a>
<a name="ln7696"> </a>
<a name="ln7697">  // TODO(bogdan): should this live here?</a>
<a name="ln7698">  const ReplicationInfoPB&amp; replication_info = config.replication_info();</a>
<a name="ln7699">  for (int i = 0; i &lt; replication_info.read_replicas_size(); i++) {</a>
<a name="ln7700">    if (!replication_info.read_replicas(i).has_placement_uuid()) {</a>
<a name="ln7701">      Status s = STATUS(IllegalState,</a>
<a name="ln7702">                        &quot;All read-only clusters must have a placement uuid specified&quot;);</a>
<a name="ln7703">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_CLUSTER_CONFIG, s);</a>
<a name="ln7704">    }</a>
<a name="ln7705">  }</a>
<a name="ln7706"> </a>
<a name="ln7707">  l-&gt;mutable_data()-&gt;pb.CopyFrom(config);</a>
<a name="ln7708">  // Bump the config version, to indicate an update.</a>
<a name="ln7709">  l-&gt;mutable_data()-&gt;pb.set_version(config.version() + 1);</a>
<a name="ln7710"> </a>
<a name="ln7711">  LOG(INFO) &lt;&lt; &quot;Updating cluster config to &quot; &lt;&lt; config.version() + 1;</a>
<a name="ln7712"> </a>
<a name="ln7713">  RETURN_NOT_OK(sys_catalog_-&gt;UpdateItem(cluster_config_.get(), leader_ready_term()));</a>
<a name="ln7714"> </a>
<a name="ln7715">  l-&gt;Commit();</a>
<a name="ln7716"> </a>
<a name="ln7717">  return Status::OK();</a>
<a name="ln7718">}</a>
<a name="ln7719"> </a>
<a name="ln7720">Status CatalogManager::SetPreferredZones(</a>
<a name="ln7721">    const SetPreferredZonesRequestPB* req, SetPreferredZonesResponsePB* resp) {</a>
<a name="ln7722">  auto l = cluster_config_-&gt;LockForWrite();</a>
<a name="ln7723">  auto replication_info = l-&gt;mutable_data()-&gt;pb.mutable_replication_info();</a>
<a name="ln7724">  replication_info-&gt;clear_affinitized_leaders();</a>
<a name="ln7725"> </a>
<a name="ln7726">  Status s;</a>
<a name="ln7727">  for (const auto&amp; cloud_info : req-&gt;preferred_zones()) {</a>
<a name="ln7728">    s = CatalogManagerUtil::DoesPlacementInfoContainCloudInfo(replication_info-&gt;live_replicas(),</a>
<a name="ln7729">                                                              cloud_info);</a>
<a name="ln7730">    if (!s.ok()) {</a>
<a name="ln7731">      return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_CLUSTER_CONFIG, s);</a>
<a name="ln7732">    }</a>
<a name="ln7733">    *replication_info-&gt;add_affinitized_leaders() = cloud_info;</a>
<a name="ln7734">  }</a>
<a name="ln7735"> </a>
<a name="ln7736">  l-&gt;mutable_data()-&gt;pb.set_version(l-&gt;mutable_data()-&gt;pb.version() + 1);</a>
<a name="ln7737"> </a>
<a name="ln7738">  LOG(INFO) &lt;&lt; &quot;Updating cluster config to &quot; &lt;&lt; l-&gt;mutable_data()-&gt;pb.version();</a>
<a name="ln7739"> </a>
<a name="ln7740">  s = sys_catalog_-&gt;UpdateItem(cluster_config_.get(), leader_ready_term());</a>
<a name="ln7741">  if (!s.ok()) {</a>
<a name="ln7742">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::INVALID_CLUSTER_CONFIG, s);</a>
<a name="ln7743">  }</a>
<a name="ln7744"> </a>
<a name="ln7745">  l-&gt;Commit();</a>
<a name="ln7746"> </a>
<a name="ln7747">  return Status::OK();</a>
<a name="ln7748">}</a>
<a name="ln7749"> </a>
<a name="ln7750">Status CatalogManager::GetReplicationFactor(int* num_replicas) {</a>
<a name="ln7751">  DCHECK(cluster_config_) &lt;&lt; &quot;Missing cluster config for master!&quot;;</a>
<a name="ln7752">  auto l = cluster_config_-&gt;LockForRead();</a>
<a name="ln7753">  const ReplicationInfoPB&amp; replication_info = l-&gt;data().pb.replication_info();</a>
<a name="ln7754">  *num_replicas = GetNumReplicasFromPlacementInfo(replication_info.live_replicas());</a>
<a name="ln7755">  return Status::OK();</a>
<a name="ln7756">}</a>
<a name="ln7757"> </a>
<a name="ln7758">Status CatalogManager::GetReplicationFactorForTablet(const scoped_refptr&lt;TabletInfo&gt;&amp; tablet,</a>
<a name="ln7759">    int* num_replicas) {</a>
<a name="ln7760">  // For system tables, the set of replicas is always the set of masters.</a>
<a name="ln7761">  if (system_tablets_.find(tablet-&gt;id()) != system_tablets_.end()) {</a>
<a name="ln7762">    consensus::ConsensusStatePB master_consensus;</a>
<a name="ln7763">    RETURN_NOT_OK(GetCurrentConfig(&amp;master_consensus));</a>
<a name="ln7764">    *num_replicas = master_consensus.config().peers().size();</a>
<a name="ln7765">    return Status::OK();</a>
<a name="ln7766">  }</a>
<a name="ln7767">  return GetReplicationFactor(num_replicas);</a>
<a name="ln7768">}</a>
<a name="ln7769"> </a>
<a name="ln7770">string CatalogManager::placement_uuid() const {</a>
<a name="ln7771">  DCHECK(cluster_config_) &lt;&lt; &quot;Missing cluster config for master!&quot;;</a>
<a name="ln7772">  auto l = cluster_config_-&gt;LockForRead();</a>
<a name="ln7773">  const ReplicationInfoPB&amp; replication_info = l-&gt;data().pb.replication_info();</a>
<a name="ln7774">  return replication_info.live_replicas().placement_uuid();</a>
<a name="ln7775">}</a>
<a name="ln7776"> </a>
<a name="ln7777">Status CatalogManager::IsLoadBalanced(const IsLoadBalancedRequestPB* req,</a>
<a name="ln7778">                                      IsLoadBalancedResponsePB* resp) {</a>
<a name="ln7779">  TSDescriptorVector ts_descs;</a>
<a name="ln7780">  master_-&gt;ts_manager()-&gt;GetAllLiveDescriptors(&amp;ts_descs);</a>
<a name="ln7781"> </a>
<a name="ln7782">  if (req-&gt;has_expected_num_servers() &amp;&amp; req-&gt;expected_num_servers() &gt; ts_descs.size()) {</a>
<a name="ln7783">    Status s = STATUS_SUBSTITUTE(IllegalState,</a>
<a name="ln7784">        &quot;Found $0, which is below the expected number of servers $1.&quot;,</a>
<a name="ln7785">        ts_descs.size(), req-&gt;expected_num_servers());</a>
<a name="ln7786">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::CAN_RETRY_LOAD_BALANCE_CHECK, s);</a>
<a name="ln7787">  }</a>
<a name="ln7788"> </a>
<a name="ln7789">  Status s = load_balance_policy_-&gt;IsIdle();</a>
<a name="ln7790">  if (!s.ok()) {</a>
<a name="ln7791">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::CAN_RETRY_LOAD_BALANCE_CHECK, s);</a>
<a name="ln7792">  }</a>
<a name="ln7793"> </a>
<a name="ln7794">  return Status::OK();</a>
<a name="ln7795">}</a>
<a name="ln7796"> </a>
<a name="ln7797">Status CatalogManager::IsLoadBalancerIdle(const IsLoadBalancerIdleRequestPB* req,</a>
<a name="ln7798">                                          IsLoadBalancerIdleResponsePB* resp) {</a>
<a name="ln7799">  Status s = load_balance_policy_-&gt;IsIdle();</a>
<a name="ln7800">  if (!s.ok()) {</a>
<a name="ln7801">    return SetupError(resp-&gt;mutable_error(), MasterErrorPB::LOAD_BALANCER_RECENTLY_ACTIVE, s);</a>
<a name="ln7802">  }</a>
<a name="ln7803"> </a>
<a name="ln7804">  return Status::OK();</a>
<a name="ln7805">}</a>
<a name="ln7806"> </a>
<a name="ln7807">Status CatalogManager::AreLeadersOnPreferredOnly(const AreLeadersOnPreferredOnlyRequestPB* req,</a>
<a name="ln7808">                                                 AreLeadersOnPreferredOnlyResponsePB* resp) {</a>
<a name="ln7809">  TSDescriptorVector ts_descs;</a>
<a name="ln7810">  master_-&gt;ts_manager()-&gt;GetAllLiveDescriptors(&amp;ts_descs);</a>
<a name="ln7811"> </a>
<a name="ln7812">  SysClusterConfigEntryPB config;</a>
<a name="ln7813">  RETURN_NOT_OK(GetClusterConfig(&amp;config));</a>
<a name="ln7814"> </a>
<a name="ln7815">  // Only need to fetch if txn tables are not using preferred zones.</a>
<a name="ln7816">  vector&lt;scoped_refptr&lt;TableInfo&gt;&gt; tables;</a>
<a name="ln7817">  if (!FLAGS_transaction_tables_use_preferred_zones) {</a>
<a name="ln7818">    master_-&gt;catalog_manager()-&gt;GetAllTables(&amp;tables, true /* include only running tables */);</a>
<a name="ln7819">  }</a>
<a name="ln7820"> </a>
<a name="ln7821">  Status s = CatalogManagerUtil::AreLeadersOnPreferredOnly(ts_descs,</a>
<a name="ln7822">                                                           config.replication_info(),</a>
<a name="ln7823">                                                           tables);</a>
<a name="ln7824">  if (!s.ok()) {</a>
<a name="ln7825">    return SetupError(</a>
<a name="ln7826">        resp-&gt;mutable_error(), MasterErrorPB::CAN_RETRY_ARE_LEADERS_ON_PREFERRED_ONLY_CHECK, s);</a>
<a name="ln7827">  }</a>
<a name="ln7828"> </a>
<a name="ln7829">  return Status::OK();</a>
<a name="ln7830">}</a>
<a name="ln7831"> </a>
<a name="ln7832">void BlacklistState::Reset() {</a>
<a name="ln7833">  tservers_.clear();</a>
<a name="ln7834">  initial_load_ = 0;</a>
<a name="ln7835">}</a>
<a name="ln7836"> </a>
<a name="ln7837">std::string BlacklistState::ToString() {</a>
<a name="ln7838">  return Substitute(&quot;Blacklist has $0 servers, initial load is $1.&quot;,</a>
<a name="ln7839">                    tservers_.size(), initial_load_);</a>
<a name="ln7840">}</a>
<a name="ln7841"> </a>
<a name="ln7842">int64_t CatalogManager::GetNumRelevantReplicas(const BlacklistState&amp; state, bool leaders_only) {</a>
<a name="ln7843">  int64_t res = 0;</a>
<a name="ln7844">  std::lock_guard &lt;LockType&gt; tablet_map_lock(lock_);</a>
<a name="ln7845">  for (const TabletInfoMap::value_type&amp; entry : *tablet_map_) {</a>
<a name="ln7846">    scoped_refptr&lt;TabletInfo&gt; tablet = entry.second;</a>
<a name="ln7847">    auto l = tablet-&gt;LockForRead();</a>
<a name="ln7848">    // Not checking being created on purpose as we do not want initial load to be under accounted.</a>
<a name="ln7849">    if (!tablet-&gt;table() ||</a>
<a name="ln7850">        PREDICT_FALSE(l-&gt;data().is_deleted())) {</a>
<a name="ln7851">      continue;</a>
<a name="ln7852">    }</a>
<a name="ln7853"> </a>
<a name="ln7854">    TabletInfo::ReplicaMap locs;</a>
<a name="ln7855">    tablet-&gt;GetReplicaLocations(&amp;locs);</a>
<a name="ln7856">    for (const TabletInfo::ReplicaMap::value_type&amp; replica : locs) {</a>
<a name="ln7857">      if (leaders_only &amp;&amp; replica.second.role != RaftPeerPB::LEADER) {</a>
<a name="ln7858">        continue;</a>
<a name="ln7859">      }</a>
<a name="ln7860">      TSRegistrationPB reg = replica.second.ts_desc-&gt;GetRegistration();</a>
<a name="ln7861">      bool found = false;</a>
<a name="ln7862">      for (const auto&amp; hp : reg.common().private_rpc_addresses()) {</a>
<a name="ln7863">        if (state.tservers_.count(HostPortFromPB(hp)) != 0) {</a>
<a name="ln7864">          found = true;</a>
<a name="ln7865">          break;</a>
<a name="ln7866">        }</a>
<a name="ln7867">      }</a>
<a name="ln7868">      if (!found) {</a>
<a name="ln7869">        for (const auto&amp; hp : reg.common().broadcast_addresses()) {</a>
<a name="ln7870">          if (state.tservers_.count(HostPortFromPB(hp)) != 0) {</a>
<a name="ln7871">            found = true;</a>
<a name="ln7872">            break;</a>
<a name="ln7873">          }</a>
<a name="ln7874">        }</a>
<a name="ln7875">      }</a>
<a name="ln7876">      if (found) {</a>
<a name="ln7877">        res++;</a>
<a name="ln7878">      }</a>
<a name="ln7879">    }</a>
<a name="ln7880">  }</a>
<a name="ln7881"> </a>
<a name="ln7882">  return res;</a>
<a name="ln7883">}</a>
<a name="ln7884"> </a>
<a name="ln7885">Status CatalogManager::FillHeartbeatResponse(const TSHeartbeatRequestPB* req,</a>
<a name="ln7886">                                             TSHeartbeatResponsePB* resp) {</a>
<a name="ln7887">  return Status::OK();</a>
<a name="ln7888">}</a>
<a name="ln7889"> </a>
<a name="ln7890">Status CatalogManager::GetLoadMoveCompletionPercent(GetLoadMovePercentResponsePB* resp) {</a>
<a name="ln7891">  return GetLoadMoveCompletionPercent(resp, false);</a>
<a name="ln7892">}</a>
<a name="ln7893"> </a>
<a name="ln7894">Status CatalogManager::GetLeaderBlacklistCompletionPercent(GetLoadMovePercentResponsePB* resp) {</a>
<a name="ln7895">  return GetLoadMoveCompletionPercent(resp, true);</a>
<a name="ln7896">}</a>
<a name="ln7897"> </a>
<a name="ln7898">Status CatalogManager::GetLoadMoveCompletionPercent(GetLoadMovePercentResponsePB* resp,</a>
<a name="ln7899">    bool blacklist_leader) {</a>
<a name="ln7900">  SharedLock&lt;LockType&gt; l(blacklist_lock_);</a>
<a name="ln7901"> </a>
<a name="ln7902">  BlacklistState&amp; state = (blacklist_leader) ? leaderBlacklistState : blacklistState;</a>
<a name="ln7903">  int64_t blacklist_replicas = GetNumRelevantReplicas(state, blacklist_leader);</a>
<a name="ln7904"> </a>
<a name="ln7905">  // On change of master leader, initial_load_ information may be lost temporarily. Reset to</a>
<a name="ln7906">  // current value to avoid reporting progress percent as 100. Note that doing so will report</a>
<a name="ln7907">  // progress percent as 0 instead.</a>
<a name="ln7908">  if (state.initial_load_ &lt; blacklist_replicas) {</a>
<a name="ln7909">    LOG(INFO) &lt;&lt; &quot;Reset blacklist initial load from &quot; &lt;&lt; state.initial_load_</a>
<a name="ln7910">      &lt;&lt;  &quot; to &quot; &lt;&lt; blacklist_replicas;</a>
<a name="ln7911">    state.initial_load_ = blacklist_replicas;</a>
<a name="ln7912">  }</a>
<a name="ln7913"> </a>
<a name="ln7914">  LOG(INFO) &lt;&lt; &quot;Blacklisted count &quot; &lt;&lt; blacklist_replicas</a>
<a name="ln7915">            &lt;&lt; &quot;across &quot; &lt;&lt; state.tservers_.size()</a>
<a name="ln7916">            &lt;&lt; &quot; servers, with initial load &quot; &lt;&lt; state.initial_load_;</a>
<a name="ln7917"> </a>
<a name="ln7918">  // Case when a blacklisted servers did not have any starting load.</a>
<a name="ln7919">  if (state.initial_load_ == 0) {</a>
<a name="ln7920">    resp-&gt;set_percent(100);</a>
<a name="ln7921">    return Status::OK();</a>
<a name="ln7922">  }</a>
<a name="ln7923"> </a>
<a name="ln7924">  resp-&gt;set_percent(</a>
<a name="ln7925">      100 - (static_cast&lt;double&gt;(blacklist_replicas) * 100 / state.initial_load_));</a>
<a name="ln7926">  resp-&gt;set_remaining(blacklist_replicas);</a>
<a name="ln7927">  resp-&gt;set_total(state.initial_load_);</a>
<a name="ln7928"> </a>
<a name="ln7929">  return Status::OK();</a>
<a name="ln7930">}</a>
<a name="ln7931"> </a>
<a name="ln7932">void CatalogManager::AbortAndWaitForAllTasks(const vector&lt;scoped_refptr&lt;TableInfo&gt;&gt;&amp; tables) {</a>
<a name="ln7933">  for (const auto&amp; t : tables) {</a>
<a name="ln7934">    VLOG(1) &lt;&lt; &quot;Aborting tasks for table &quot; &lt;&lt; t-&gt;ToString();</a>
<a name="ln7935">    t-&gt;AbortTasksAndClose();</a>
<a name="ln7936">  }</a>
<a name="ln7937">  for (const auto&amp; t : tables) {</a>
<a name="ln7938">    VLOG(1) &lt;&lt; &quot;Waiting on Aborting tasks for table &quot; &lt;&lt; t-&gt;ToString();</a>
<a name="ln7939">    t-&gt;WaitTasksCompletion();</a>
<a name="ln7940">  }</a>
<a name="ln7941">  VLOG(1) &lt;&lt; &quot;Waiting on Aborting tasks done&quot;;</a>
<a name="ln7942">}</a>
<a name="ln7943"> </a>
<a name="ln7944">void CatalogManager::HandleNewTableId(const TableId&amp; table_id) {</a>
<a name="ln7945">  if (table_id == kPgProcTableId) {</a>
<a name="ln7946">    // Needed to track whether initdb has started running.</a>
<a name="ln7947">    pg_proc_exists_.store(true, std::memory_order_release);</a>
<a name="ln7948">  }</a>
<a name="ln7949">}</a>
<a name="ln7950"> </a>
<a name="ln7951">scoped_refptr&lt;TableInfo&gt; CatalogManager::NewTableInfo(TableId id) {</a>
<a name="ln7952">  return make_scoped_refptr&lt;TableInfo&gt;(id, tasks_tracker_);</a>
<a name="ln7953">}</a>
<a name="ln7954"> </a>
<a name="ln7955">Status CatalogManager::ScheduleTask(std::shared_ptr&lt;RetryingTSRpcTask&gt; task) {</a>
<a name="ln7956">  return task-&gt;Run();</a>
<a name="ln7957">}</a>
<a name="ln7958"> </a>
<a name="ln7959">Result&lt;vector&lt;TableDescription&gt;&gt; CatalogManager::CollectTables(</a>
<a name="ln7960">    const google::protobuf::RepeatedPtrField&lt;TableIdentifierPB&gt;&amp; tables, bool add_indexes) {</a>
<a name="ln7961">  vector&lt;TableDescription&gt; all_tables;</a>
<a name="ln7962"> </a>
<a name="ln7963">  for (const auto&amp; table_id_pb : tables) {</a>
<a name="ln7964">    TableDescription table_description = VERIFY_RESULT(DescribeTable(table_id_pb));</a>
<a name="ln7965">    all_tables.push_back(table_description);</a>
<a name="ln7966"> </a>
<a name="ln7967">    if (add_indexes) {</a>
<a name="ln7968">      TRACE(Substitute(&quot;Locking object with id $0&quot;, table_description.table_info-&gt;id()));</a>
<a name="ln7969">      auto l = table_description.table_info-&gt;LockForRead();</a>
<a name="ln7970"> </a>
<a name="ln7971">      if (table_description.table_info-&gt;is_index()) {</a>
<a name="ln7972">        return STATUS(InvalidArgument, &quot;Expected table, but found index&quot;,</a>
<a name="ln7973">                      table_description.table_info-&gt;id(),</a>
<a name="ln7974">                      MasterError(MasterErrorPB::INVALID_TABLE_TYPE));</a>
<a name="ln7975">      }</a>
<a name="ln7976"> </a>
<a name="ln7977">      if (l-&gt;data().table_type() == PGSQL_TABLE_TYPE) {</a>
<a name="ln7978">        return STATUS(InvalidArgument, &quot;Getting indexes for YSQL table is not supported&quot;,</a>
<a name="ln7979">                      table_description.table_info-&gt;id(),</a>
<a name="ln7980">                      MasterError(MasterErrorPB::INVALID_TABLE_TYPE));</a>
<a name="ln7981">      }</a>
<a name="ln7982"> </a>
<a name="ln7983">      for (const auto&amp; index_info : l-&gt;data().pb.indexes()) {</a>
<a name="ln7984">        LOG_IF(DFATAL, table_description.table_info-&gt;id() != index_info.indexed_table_id())</a>
<a name="ln7985">                &lt;&lt; &quot;Wrong indexed table id in index descriptor&quot;;</a>
<a name="ln7986">        TableIdentifierPB index_id_pb;</a>
<a name="ln7987">        index_id_pb.set_table_id(index_info.table_id());</a>
<a name="ln7988">        index_id_pb.mutable_namespace_()-&gt;set_id(table_description.namespace_info-&gt;id());</a>
<a name="ln7989">        all_tables.push_back(VERIFY_RESULT(DescribeTable(index_id_pb)));</a>
<a name="ln7990">      }</a>
<a name="ln7991">    }</a>
<a name="ln7992">  }</a>
<a name="ln7993"> </a>
<a name="ln7994">  return all_tables;</a>
<a name="ln7995">}</a>
<a name="ln7996"> </a>
<a name="ln7997">}  // namespace master</a>
<a name="ln7998">}  // namespace yb</a>

</code></pre>
<div class="balloon" rel="410"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="418"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="442"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="498"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="547"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="550"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="724"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1044"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1193"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1348"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1360"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1851"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1896"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1905"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1914"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1976"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1997"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2171"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2235"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v561/" target="_blank">V561</a> It's probably better to assign value to 'ns_lock' variable than to declare it anew. Previous declaration: catalog_manager.cc, line 2018.</p></div>
<div class="balloon" rel="2358"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2363"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2450"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2593"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2674"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2792"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2885"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="3119"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="3132"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="3781"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="3862"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="3976"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="3997"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="4005"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="4020"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="4052"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="4370"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="4494"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="4551"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="4608"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="4672"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="4683"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="4789"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="4841"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="5012"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="5084"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="5321"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="5340"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="5734"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="5753"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="5755"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="5763"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6246"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v547/" target="_blank">V547</a> Expression 'consensus_state != nullptr' is always true.</p></div>
<div class="balloon" rel="6246"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6272"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6298"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6472"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6518"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6691"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6704"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6743"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6762"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6768"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6774"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6822"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6855"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6928"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="6978"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="7001"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="7358"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="7508"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="7614"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="7751"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="7771"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="7934"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="7938"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="7941"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="7984"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
