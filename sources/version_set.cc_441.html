
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
  <title>version_set.cc</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">//  Copyright (c) 2011-present, Facebook, Inc.  All rights reserved.</a>
<a name="ln2">//  This source code is licensed under the BSD-style license found in the</a>
<a name="ln3">//  LICENSE file in the root directory of this source tree. An additional grant</a>
<a name="ln4">//  of patent rights can be found in the PATENTS file in the same directory.</a>
<a name="ln5">//</a>
<a name="ln6">// The following only applies to changes made to this file as part of YugaByte development.</a>
<a name="ln7">//</a>
<a name="ln8">// Portions Copyright (c) YugaByte, Inc.</a>
<a name="ln9">//</a>
<a name="ln10">// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except</a>
<a name="ln11">// in compliance with the License.  You may obtain a copy of the License at</a>
<a name="ln12">//</a>
<a name="ln13">// http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="ln14">//</a>
<a name="ln15">// Unless required by applicable law or agreed to in writing, software distributed under the License</a>
<a name="ln16">// is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express</a>
<a name="ln17">// or implied.  See the License for the specific language governing permissions and limitations</a>
<a name="ln18">// under the License.</a>
<a name="ln19">//</a>
<a name="ln20">// Copyright (c) 2011 The LevelDB Authors. All rights reserved.</a>
<a name="ln21">// Use of this source code is governed by a BSD-style license that can be</a>
<a name="ln22">// found in the LICENSE file. See the AUTHORS file for names of contributors.</a>
<a name="ln23"> </a>
<a name="ln24">#include &quot;yb/rocksdb/db/version_set.h&quot;</a>
<a name="ln25"> </a>
<a name="ln26">#ifndef __STDC_FORMAT_MACROS</a>
<a name="ln27">#define __STDC_FORMAT_MACROS</a>
<a name="ln28">#endif</a>
<a name="ln29"> </a>
<a name="ln30">#include &lt;inttypes.h&gt;</a>
<a name="ln31">#include &lt;stdio.h&gt;</a>
<a name="ln32">#include &lt;algorithm&gt;</a>
<a name="ln33">#include &lt;map&gt;</a>
<a name="ln34">#include &lt;set&gt;</a>
<a name="ln35">#include &lt;climits&gt;</a>
<a name="ln36">#include &lt;unordered_map&gt;</a>
<a name="ln37">#include &lt;vector&gt;</a>
<a name="ln38">#include &lt;string&gt;</a>
<a name="ln39"> </a>
<a name="ln40">#include &lt;glog/logging.h&gt;</a>
<a name="ln41">#include &lt;boost/container/small_vector.hpp&gt;</a>
<a name="ln42"> </a>
<a name="ln43">#include &quot;yb/gutil/casts.h&quot;</a>
<a name="ln44">#include &quot;yb/util/flags.h&quot;</a>
<a name="ln45"> </a>
<a name="ln46">#include &quot;yb/rocksdb/db/filename.h&quot;</a>
<a name="ln47">#include &quot;yb/rocksdb/db/file_numbers.h&quot;</a>
<a name="ln48">#include &quot;yb/rocksdb/db/internal_stats.h&quot;</a>
<a name="ln49">#include &quot;yb/rocksdb/db/log_reader.h&quot;</a>
<a name="ln50">#include &quot;yb/rocksdb/db/log_writer.h&quot;</a>
<a name="ln51">#include &quot;yb/rocksdb/db/memtable.h&quot;</a>
<a name="ln52">#include &quot;yb/rocksdb/db/merge_context.h&quot;</a>
<a name="ln53">#include &quot;yb/rocksdb/db/table_cache.h&quot;</a>
<a name="ln54">#include &quot;yb/rocksdb/db/compaction.h&quot;</a>
<a name="ln55">#include &quot;yb/rocksdb/db/version_builder.h&quot;</a>
<a name="ln56">#include &quot;yb/rocksdb/db/writebuffer.h&quot;</a>
<a name="ln57">#include &quot;yb/rocksdb/env.h&quot;</a>
<a name="ln58">#include &quot;yb/rocksdb/merge_operator.h&quot;</a>
<a name="ln59">#include &quot;yb/rocksdb/table/internal_iterator.h&quot;</a>
<a name="ln60">#include &quot;yb/rocksdb/table/table_reader.h&quot;</a>
<a name="ln61">#include &quot;yb/rocksdb/table/merger.h&quot;</a>
<a name="ln62">#include &quot;yb/rocksdb/table/two_level_iterator.h&quot;</a>
<a name="ln63">#include &quot;yb/rocksdb/table/format.h&quot;</a>
<a name="ln64">#include &quot;yb/rocksdb/table/plain_table_factory.h&quot;</a>
<a name="ln65">#include &quot;yb/rocksdb/table/meta_blocks.h&quot;</a>
<a name="ln66">#include &quot;yb/rocksdb/table/get_context.h&quot;</a>
<a name="ln67"> </a>
<a name="ln68">#include &quot;yb/rocksdb/util/coding.h&quot;</a>
<a name="ln69">#include &quot;yb/rocksdb/util/file_reader_writer.h&quot;</a>
<a name="ln70">#include &quot;yb/rocksdb/util/file_util.h&quot;</a>
<a name="ln71">#include &quot;yb/rocksdb/util/logging.h&quot;</a>
<a name="ln72">#include &quot;yb/rocksdb/util/stop_watch.h&quot;</a>
<a name="ln73">#include &quot;yb/rocksdb/util/sync_point.h&quot;</a>
<a name="ln74"> </a>
<a name="ln75">namespace rocksdb {</a>
<a name="ln76"> </a>
<a name="ln77">namespace {</a>
<a name="ln78"> </a>
<a name="ln79">// Find File in LevelFilesBrief data structure</a>
<a name="ln80">// Within an index range defined by left and right</a>
<a name="ln81">int FindFileInRange(const InternalKeyComparator&amp; icmp,</a>
<a name="ln82">    const LevelFilesBrief&amp; file_level,</a>
<a name="ln83">    const Slice&amp; key,</a>
<a name="ln84">    uint32_t left,</a>
<a name="ln85">    uint32_t right) {</a>
<a name="ln86">  while (left &lt; right) {</a>
<a name="ln87">    uint32_t mid = (left + right) / 2;</a>
<a name="ln88">    const FdWithBoundaries&amp; f = file_level.files[mid];</a>
<a name="ln89">    if (icmp.InternalKeyComparator::Compare(f.largest.key, key) &lt; 0) {</a>
<a name="ln90">      // Key at &quot;mid.largest&quot; is &lt; &quot;target&quot;.  Therefore all</a>
<a name="ln91">      // files at or before &quot;mid&quot; are uninteresting.</a>
<a name="ln92">      left = mid + 1;</a>
<a name="ln93">    } else {</a>
<a name="ln94">      // Key at &quot;mid.largest&quot; is &gt;= &quot;target&quot;.  Therefore all files</a>
<a name="ln95">      // after &quot;mid&quot; are uninteresting.</a>
<a name="ln96">      right = mid;</a>
<a name="ln97">    }</a>
<a name="ln98">  }</a>
<a name="ln99">  return right;</a>
<a name="ln100">}</a>
<a name="ln101"> </a>
<a name="ln102">// Class to help choose the next file to search for the particular key.</a>
<a name="ln103">// Searches and returns files level by level.</a>
<a name="ln104">// We can search level-by-level since entries never hop across</a>
<a name="ln105">// levels. Therefore we are guaranteed that if we find data</a>
<a name="ln106">// in a smaller level, later levels are irrelevant (unless we</a>
<a name="ln107">// are MergeInProgress).</a>
<a name="ln108">class FilePicker {</a>
<a name="ln109"> public:</a>
<a name="ln110">  FilePicker(std::vector&lt;FileMetaData*&gt;* files, const Slice&amp; user_key,</a>
<a name="ln111">             const Slice&amp; ikey, autovector&lt;LevelFilesBrief&gt;* file_levels,</a>
<a name="ln112">             unsigned int num_levels, FileIndexer* file_indexer,</a>
<a name="ln113">             const Comparator* user_comparator,</a>
<a name="ln114">             const InternalKeyComparator* internal_comparator)</a>
<a name="ln115">      : num_levels_(num_levels),</a>
<a name="ln116">        curr_level_(-1),</a>
<a name="ln117">        hit_file_level_(-1),</a>
<a name="ln118">        search_left_bound_(0),</a>
<a name="ln119">        search_right_bound_(FileIndexer::kLevelMaxIndex),</a>
<a name="ln120">#ifndef NDEBUG</a>
<a name="ln121">        files_(files),</a>
<a name="ln122">#endif</a>
<a name="ln123">        level_files_brief_(file_levels),</a>
<a name="ln124">        is_hit_file_last_in_level_(false),</a>
<a name="ln125">        user_key_(user_key),</a>
<a name="ln126">        ikey_(ikey),</a>
<a name="ln127">        file_indexer_(file_indexer),</a>
<a name="ln128">        user_comparator_(user_comparator),</a>
<a name="ln129">        internal_comparator_(internal_comparator) {</a>
<a name="ln130">    // Setup member variables to search first level.</a>
<a name="ln131">    search_ended_ = !PrepareNextLevel();</a>
<a name="ln132">    if (!search_ended_) {</a>
<a name="ln133">      // Prefetch Level 0 table data to avoid cache miss if possible.</a>
<a name="ln134">      for (unsigned int i = 0; i &lt; (*level_files_brief_)[0].num_files; ++i) {</a>
<a name="ln135">        auto* r = (*level_files_brief_)[0].files[i].fd.table_reader;</a>
<a name="ln136">        if (r) {</a>
<a name="ln137">          r-&gt;Prepare(ikey);</a>
<a name="ln138">        }</a>
<a name="ln139">      }</a>
<a name="ln140">    }</a>
<a name="ln141">  }</a>
<a name="ln142"> </a>
<a name="ln143">  FdWithBoundaries* GetNextFile() {</a>
<a name="ln144">    while (!search_ended_) {  // Loops over different levels.</a>
<a name="ln145">      while (curr_index_in_curr_level_ &lt; curr_file_level_-&gt;num_files) {</a>
<a name="ln146">        // Loops over all files in current level.</a>
<a name="ln147">        FdWithBoundaries* f = &amp;curr_file_level_-&gt;files[curr_index_in_curr_level_];</a>
<a name="ln148">        hit_file_level_ = curr_level_;</a>
<a name="ln149">        is_hit_file_last_in_level_ =</a>
<a name="ln150">            curr_index_in_curr_level_ == curr_file_level_-&gt;num_files - 1;</a>
<a name="ln151">        int cmp_largest = -1;</a>
<a name="ln152"> </a>
<a name="ln153">        // Do key range filtering of files or/and fractional cascading if:</a>
<a name="ln154">        // (1) not all the files are in level 0, or</a>
<a name="ln155">        // (2) there are more than 3 Level 0 files</a>
<a name="ln156">        // If there are only 3 or less level 0 files in the system, we skip</a>
<a name="ln157">        // the key range filtering. In this case, more likely, the system is</a>
<a name="ln158">        // highly tuned to minimize number of tables queried by each query,</a>
<a name="ln159">        // so it is unlikely that key range filtering is more efficient than</a>
<a name="ln160">        // querying the files.</a>
<a name="ln161">        if (num_levels_ &gt; 1 || curr_file_level_-&gt;num_files &gt; 3) {</a>
<a name="ln162">          // Check if key is within a file's range. If search left bound and</a>
<a name="ln163">          // right bound point to the same find, we are sure key falls in</a>
<a name="ln164">          // range.</a>
<a name="ln165">          assert(</a>
<a name="ln166">              curr_level_ == 0 ||</a>
<a name="ln167">              curr_index_in_curr_level_ == start_index_in_curr_level_ ||</a>
<a name="ln168">              user_comparator_-&gt;Compare(user_key_, f-&gt;smallest.user_key()) &lt;= 0);</a>
<a name="ln169"> </a>
<a name="ln170">          int cmp_smallest = user_comparator_-&gt;Compare(user_key_, f-&gt;smallest.user_key());</a>
<a name="ln171">          if (cmp_smallest &gt;= 0) {</a>
<a name="ln172">            cmp_largest = user_comparator_-&gt;Compare(user_key_, f-&gt;largest.user_key());</a>
<a name="ln173">          }</a>
<a name="ln174"> </a>
<a name="ln175">          // Setup file search bound for the next level based on the</a>
<a name="ln176">          // comparison results</a>
<a name="ln177">          if (curr_level_ &gt; 0) {</a>
<a name="ln178">            file_indexer_-&gt;GetNextLevelIndex(curr_level_,</a>
<a name="ln179">                                            curr_index_in_curr_level_,</a>
<a name="ln180">                                            cmp_smallest, cmp_largest,</a>
<a name="ln181">                                            &amp;search_left_bound_,</a>
<a name="ln182">                                            &amp;search_right_bound_);</a>
<a name="ln183">          }</a>
<a name="ln184">          // Key falls out of current file's range</a>
<a name="ln185">          if (cmp_smallest &lt; 0 || cmp_largest &gt; 0) {</a>
<a name="ln186">            if (curr_level_ == 0) {</a>
<a name="ln187">              ++curr_index_in_curr_level_;</a>
<a name="ln188">              continue;</a>
<a name="ln189">            } else {</a>
<a name="ln190">              // Search next level.</a>
<a name="ln191">              break;</a>
<a name="ln192">            }</a>
<a name="ln193">          }</a>
<a name="ln194">        }</a>
<a name="ln195">#ifndef NDEBUG</a>
<a name="ln196">        // Sanity check to make sure that the files are correctly sorted</a>
<a name="ln197">        if (prev_file_) {</a>
<a name="ln198">          if (curr_level_ != 0) {</a>
<a name="ln199">            int comp_sign = internal_comparator_-&gt;Compare(</a>
<a name="ln200">                prev_file_-&gt;largest.key, f-&gt;smallest.key);</a>
<a name="ln201">            assert(comp_sign &lt; 0);</a>
<a name="ln202">          } else {</a>
<a name="ln203">            // level == 0, the current file cannot be newer than the previous</a>
<a name="ln204">            // one. Use compressed data structure, has no attribute seqNo</a>
<a name="ln205">            assert(curr_index_in_curr_level_ &gt; 0);</a>
<a name="ln206">            assert(!NewestFirstBySeqNo(files_[0][curr_index_in_curr_level_],</a>
<a name="ln207">                  files_[0][curr_index_in_curr_level_-1]));</a>
<a name="ln208">          }</a>
<a name="ln209">        }</a>
<a name="ln210">        prev_file_ = f;</a>
<a name="ln211">#endif</a>
<a name="ln212">        if (curr_level_ &gt; 0 &amp;&amp; cmp_largest &lt; 0) {</a>
<a name="ln213">          // No more files to search in this level.</a>
<a name="ln214">          search_ended_ = !PrepareNextLevel();</a>
<a name="ln215">        } else {</a>
<a name="ln216">          ++curr_index_in_curr_level_;</a>
<a name="ln217">        }</a>
<a name="ln218">        return f;</a>
<a name="ln219">      }</a>
<a name="ln220">      // Start searching next level.</a>
<a name="ln221">      search_ended_ = !PrepareNextLevel();</a>
<a name="ln222">    }</a>
<a name="ln223">    // Search ended.</a>
<a name="ln224">    return nullptr;</a>
<a name="ln225">  }</a>
<a name="ln226"> </a>
<a name="ln227">  // getter for current file level</a>
<a name="ln228">  // for GET_HIT_L0, GET_HIT_L1 &amp; GET_HIT_L2_AND_UP counts</a>
<a name="ln229">  unsigned int GetHitFileLevel() { return hit_file_level_; }</a>
<a name="ln230"> </a>
<a name="ln231">  // Returns true if the most recent &quot;hit file&quot; (i.e., one returned by</a>
<a name="ln232">  // GetNextFile()) is at the last index in its level.</a>
<a name="ln233">  bool IsHitFileLastInLevel() { return is_hit_file_last_in_level_; }</a>
<a name="ln234"> </a>
<a name="ln235"> private:</a>
<a name="ln236">  unsigned int num_levels_;</a>
<a name="ln237">  unsigned int curr_level_;</a>
<a name="ln238">  unsigned int hit_file_level_;</a>
<a name="ln239">  int32_t search_left_bound_;</a>
<a name="ln240">  int32_t search_right_bound_;</a>
<a name="ln241">#ifndef NDEBUG</a>
<a name="ln242">  std::vector&lt;FileMetaData*&gt;* files_;</a>
<a name="ln243">#endif</a>
<a name="ln244">  autovector&lt;LevelFilesBrief&gt;* level_files_brief_;</a>
<a name="ln245">  bool search_ended_;</a>
<a name="ln246">  bool is_hit_file_last_in_level_;</a>
<a name="ln247">  LevelFilesBrief* curr_file_level_;</a>
<a name="ln248">  unsigned int curr_index_in_curr_level_;</a>
<a name="ln249">  unsigned int start_index_in_curr_level_;</a>
<a name="ln250">  Slice user_key_;</a>
<a name="ln251">  Slice ikey_;</a>
<a name="ln252">  FileIndexer* file_indexer_;</a>
<a name="ln253">  const Comparator* user_comparator_;</a>
<a name="ln254">  const InternalKeyComparator* internal_comparator_;</a>
<a name="ln255">#ifndef NDEBUG</a>
<a name="ln256">  FdWithBoundaries* prev_file_;</a>
<a name="ln257">#endif</a>
<a name="ln258"> </a>
<a name="ln259">  // Setup local variables to search next level.</a>
<a name="ln260">  // Returns false if there are no more levels to search.</a>
<a name="ln261">  bool PrepareNextLevel() {</a>
<a name="ln262">    curr_level_++;</a>
<a name="ln263">    while (curr_level_ &lt; num_levels_) {</a>
<a name="ln264">      curr_file_level_ = &amp;(*level_files_brief_)[curr_level_];</a>
<a name="ln265">      if (curr_file_level_-&gt;num_files == 0) {</a>
<a name="ln266">        // When current level is empty, the search bound generated from upper</a>
<a name="ln267">        // level must be [0, -1] or [0, FileIndexer::kLevelMaxIndex] if it is</a>
<a name="ln268">        // also empty.</a>
<a name="ln269">        assert(search_left_bound_ == 0);</a>
<a name="ln270">        assert(search_right_bound_ == -1 ||</a>
<a name="ln271">               search_right_bound_ == FileIndexer::kLevelMaxIndex);</a>
<a name="ln272">        // Since current level is empty, it will need to search all files in</a>
<a name="ln273">        // the next level</a>
<a name="ln274">        search_left_bound_ = 0;</a>
<a name="ln275">        search_right_bound_ = FileIndexer::kLevelMaxIndex;</a>
<a name="ln276">        curr_level_++;</a>
<a name="ln277">        continue;</a>
<a name="ln278">      }</a>
<a name="ln279"> </a>
<a name="ln280">      // Some files may overlap each other. We find</a>
<a name="ln281">      // all files that overlap user_key and process them in order from</a>
<a name="ln282">      // newest to oldest. In the context of merge-operator, this can occur at</a>
<a name="ln283">      // any level. Otherwise, it only occurs at Level-0 (since Put/Deletes</a>
<a name="ln284">      // are always compacted into a single entry).</a>
<a name="ln285">      int32_t start_index;</a>
<a name="ln286">      if (curr_level_ == 0) {</a>
<a name="ln287">        // On Level-0, we read through all files to check for overlap.</a>
<a name="ln288">        start_index = 0;</a>
<a name="ln289">      } else {</a>
<a name="ln290">        // On Level-n (n&gt;=1), files are sorted. Binary search to find the</a>
<a name="ln291">        // earliest file whose largest key &gt;= ikey. Search left bound and</a>
<a name="ln292">        // right bound are used to narrow the range.</a>
<a name="ln293">        if (search_left_bound_ == search_right_bound_) {</a>
<a name="ln294">          start_index = search_left_bound_;</a>
<a name="ln295">        } else if (search_left_bound_ &lt; search_right_bound_) {</a>
<a name="ln296">          if (search_right_bound_ == FileIndexer::kLevelMaxIndex) {</a>
<a name="ln297">            search_right_bound_ =</a>
<a name="ln298">                static_cast&lt;int32_t&gt;(curr_file_level_-&gt;num_files) - 1;</a>
<a name="ln299">          }</a>
<a name="ln300">          start_index =</a>
<a name="ln301">              FindFileInRange(*internal_comparator_, *curr_file_level_, ikey_,</a>
<a name="ln302">                              static_cast&lt;uint32_t&gt;(search_left_bound_),</a>
<a name="ln303">                              static_cast&lt;uint32_t&gt;(search_right_bound_));</a>
<a name="ln304">        } else {</a>
<a name="ln305">          // search_left_bound &gt; search_right_bound, key does not exist in</a>
<a name="ln306">          // this level. Since no comparison is done in this level, it will</a>
<a name="ln307">          // need to search all files in the next level.</a>
<a name="ln308">          search_left_bound_ = 0;</a>
<a name="ln309">          search_right_bound_ = FileIndexer::kLevelMaxIndex;</a>
<a name="ln310">          curr_level_++;</a>
<a name="ln311">          continue;</a>
<a name="ln312">        }</a>
<a name="ln313">      }</a>
<a name="ln314">      start_index_in_curr_level_ = start_index;</a>
<a name="ln315">      curr_index_in_curr_level_ = start_index;</a>
<a name="ln316">#ifndef NDEBUG</a>
<a name="ln317">      prev_file_ = nullptr;</a>
<a name="ln318">#endif</a>
<a name="ln319">      return true;</a>
<a name="ln320">    }</a>
<a name="ln321">    // curr_level_ = num_levels_. So, no more levels to search.</a>
<a name="ln322">    return false;</a>
<a name="ln323">  }</a>
<a name="ln324">};</a>
<a name="ln325"> </a>
<a name="ln326">SstFileMetaData::BoundaryValues ConvertBoundaryValues(const FileMetaData::BoundaryValues&amp; source) {</a>
<a name="ln327">  SstFileMetaData::BoundaryValues result;</a>
<a name="ln328">  result.key = source.key.user_key().ToBuffer();</a>
<a name="ln329">  result.seqno = source.seqno;</a>
<a name="ln330">  result.user_frontier = source.user_frontier;</a>
<a name="ln331">  result.user_values = source.user_values;</a>
<a name="ln332">  return result;</a>
<a name="ln333">}</a>
<a name="ln334"> </a>
<a name="ln335">}  // anonymous namespace</a>
<a name="ln336"> </a>
<a name="ln337">VersionStorageInfo::~VersionStorageInfo() { delete[] files_; }</a>
<a name="ln338"> </a>
<a name="ln339">uint64_t VersionStorageInfo::NumFiles() const {</a>
<a name="ln340">  uint64_t result = 0;</a>
<a name="ln341">  for (int level = num_non_empty_levels_; level-- &gt; 0;) {</a>
<a name="ln342">    result += files_[level].size();</a>
<a name="ln343">  }</a>
<a name="ln344">  return result;</a>
<a name="ln345">}</a>
<a name="ln346"> </a>
<a name="ln347">Version::~Version() {</a>
<a name="ln348">  assert(refs_ == 0);</a>
<a name="ln349"> </a>
<a name="ln350">  // Remove from linked list</a>
<a name="ln351">  prev_-&gt;next_ = next_;</a>
<a name="ln352">  next_-&gt;prev_ = prev_;</a>
<a name="ln353"> </a>
<a name="ln354">  // Drop references to files</a>
<a name="ln355">  for (int level = 0; level &lt; storage_info_.num_levels_; level++) {</a>
<a name="ln356">    for (size_t i = 0; i &lt; storage_info_.files_[level].size(); i++) {</a>
<a name="ln357">      FileMetaData* f = storage_info_.files_[level][i];</a>
<a name="ln358">      assert(f-&gt;refs &gt; 0);</a>
<a name="ln359">      vset_-&gt;UnrefFile(cfd_, f);</a>
<a name="ln360">    }</a>
<a name="ln361">  }</a>
<a name="ln362">}</a>
<a name="ln363"> </a>
<a name="ln364">int FindFile(const InternalKeyComparator&amp; icmp,</a>
<a name="ln365">             const LevelFilesBrief&amp; file_level,</a>
<a name="ln366">             const Slice&amp; key) {</a>
<a name="ln367">  return FindFileInRange(icmp, file_level, key, 0,</a>
<a name="ln368">                         static_cast&lt;uint32_t&gt;(file_level.num_files));</a>
<a name="ln369">}</a>
<a name="ln370"> </a>
<a name="ln371">void DoGenerateLevelFilesBrief(LevelFilesBrief* file_level,</a>
<a name="ln372">        const std::vector&lt;FileMetaData*&gt;&amp; files,</a>
<a name="ln373">        Arena* arena) {</a>
<a name="ln374">  assert(file_level);</a>
<a name="ln375">  assert(arena);</a>
<a name="ln376"> </a>
<a name="ln377">  size_t num = files.size();</a>
<a name="ln378">  file_level-&gt;num_files = num;</a>
<a name="ln379">  char* mem = arena-&gt;AllocateAligned(num * sizeof(FdWithBoundaries));</a>
<a name="ln380">  file_level-&gt;files = reinterpret_cast&lt;FdWithBoundaries*&gt;(mem);</a>
<a name="ln381"> </a>
<a name="ln382">  for (size_t i = 0; i &lt; num; i++) {</a>
<a name="ln383">    new (file_level-&gt;files + i) FdWithBoundaries(arena, *files[i]);</a>
<a name="ln384">  }</a>
<a name="ln385">}</a>
<a name="ln386"> </a>
<a name="ln387">static bool AfterFile(const Comparator* ucmp,</a>
<a name="ln388">                      const Slice* user_key, const FdWithBoundaries* f) {</a>
<a name="ln389">  // nullptr user_key occurs before all keys and is therefore never after *f</a>
<a name="ln390">  return (user_key != nullptr &amp;&amp;</a>
<a name="ln391">          ucmp-&gt;Compare(*user_key, f-&gt;largest.user_key()) &gt; 0);</a>
<a name="ln392">}</a>
<a name="ln393"> </a>
<a name="ln394">static bool BeforeFile(const Comparator* ucmp,</a>
<a name="ln395">                       const Slice* user_key, const FdWithBoundaries* f) {</a>
<a name="ln396">  // nullptr user_key occurs after all keys and is therefore never before *f</a>
<a name="ln397">  return (user_key != nullptr &amp;&amp;</a>
<a name="ln398">          ucmp-&gt;Compare(*user_key, f-&gt;smallest.user_key()) &lt; 0);</a>
<a name="ln399">}</a>
<a name="ln400"> </a>
<a name="ln401">bool SomeFileOverlapsRange(</a>
<a name="ln402">    const InternalKeyComparator&amp; icmp,</a>
<a name="ln403">    bool disjoint_sorted_files,</a>
<a name="ln404">    const LevelFilesBrief&amp; file_level,</a>
<a name="ln405">    const Slice* smallest_user_key,</a>
<a name="ln406">    const Slice* largest_user_key) {</a>
<a name="ln407">  const Comparator* ucmp = icmp.user_comparator();</a>
<a name="ln408">  if (!disjoint_sorted_files) {</a>
<a name="ln409">    // Need to check against all files</a>
<a name="ln410">    for (size_t i = 0; i &lt; file_level.num_files; i++) {</a>
<a name="ln411">      const FdWithBoundaries* f = file_level.files + i;</a>
<a name="ln412">      if (AfterFile(ucmp, smallest_user_key, f) ||</a>
<a name="ln413">          BeforeFile(ucmp, largest_user_key, f)) {</a>
<a name="ln414">        // No overlap</a>
<a name="ln415">      } else {</a>
<a name="ln416">        return true;  // Overlap</a>
<a name="ln417">      }</a>
<a name="ln418">    }</a>
<a name="ln419">    return false;</a>
<a name="ln420">  }</a>
<a name="ln421"> </a>
<a name="ln422">  // Binary search over file list</a>
<a name="ln423">  uint32_t index = 0;</a>
<a name="ln424">  if (smallest_user_key != nullptr) {</a>
<a name="ln425">    // Find the earliest possible internal key for smallest_user_key</a>
<a name="ln426">    InternalKey small = InternalKey::MaxPossibleForUserKey(*smallest_user_key);</a>
<a name="ln427">    index = FindFile(icmp, file_level, small.Encode());</a>
<a name="ln428">  }</a>
<a name="ln429"> </a>
<a name="ln430">  if (index &gt;= file_level.num_files) {</a>
<a name="ln431">    // beginning of range is after all files, so no overlap.</a>
<a name="ln432">    return false;</a>
<a name="ln433">  }</a>
<a name="ln434"> </a>
<a name="ln435">  return !BeforeFile(ucmp, largest_user_key, &amp;file_level.files[index]);</a>
<a name="ln436">}</a>
<a name="ln437"> </a>
<a name="ln438">namespace {</a>
<a name="ln439"> </a>
<a name="ln440">// An internal iterator.  For a given version/level pair, yields</a>
<a name="ln441">// information about the files in the level.  For a given entry, key()</a>
<a name="ln442">// is the largest key that occurs in the file, and value() is an</a>
<a name="ln443">// 16-byte value containing the file number and file size, both</a>
<a name="ln444">// encoded using EncodeFixed64.</a>
<a name="ln445">class LevelFileNumIterator : public InternalIterator {</a>
<a name="ln446"> public:</a>
<a name="ln447">  LevelFileNumIterator(const InternalKeyComparator&amp; icmp,</a>
<a name="ln448">                       const LevelFilesBrief* flevel)</a>
<a name="ln449">      : icmp_(icmp),</a>
<a name="ln450">        flevel_(flevel),</a>
<a name="ln451">        index_(static_cast&lt;uint32_t&gt;(flevel-&gt;num_files)),</a>
<a name="ln452">        current_value_(0, 0, 0, 0) {  // Marks as invalid</a>
<a name="ln453">  }</a>
<a name="ln454"> </a>
<a name="ln455">  bool Valid() const override { return index_ &lt; flevel_-&gt;num_files; }</a>
<a name="ln456"> </a>
<a name="ln457">  void Seek(const Slice&amp; target) override {</a>
<a name="ln458">    index_ = FindFile(icmp_, *flevel_, target);</a>
<a name="ln459">  }</a>
<a name="ln460"> </a>
<a name="ln461">  void SeekToFirst() override { index_ = 0; }</a>
<a name="ln462"> </a>
<a name="ln463">  void SeekToLast() override {</a>
<a name="ln464">    index_ = (flevel_-&gt;num_files == 0)</a>
<a name="ln465">                 ? 0</a>
<a name="ln466">                 : static_cast&lt;uint32_t&gt;(flevel_-&gt;num_files) - 1;</a>
<a name="ln467">  }</a>
<a name="ln468"> </a>
<a name="ln469">  void Next() override {</a>
<a name="ln470">    assert(Valid());</a>
<a name="ln471">    index_++;</a>
<a name="ln472">  }</a>
<a name="ln473"> </a>
<a name="ln474">  void Prev() override {</a>
<a name="ln475">    assert(Valid());</a>
<a name="ln476">    if (index_ == 0) {</a>
<a name="ln477">      index_ = static_cast&lt;uint32_t&gt;(flevel_-&gt;num_files);  // Marks as invalid</a>
<a name="ln478">    } else {</a>
<a name="ln479">      index_--;</a>
<a name="ln480">    }</a>
<a name="ln481">  }</a>
<a name="ln482"> </a>
<a name="ln483">  Slice key() const override {</a>
<a name="ln484">    assert(Valid());</a>
<a name="ln485">    return flevel_-&gt;files[index_].largest.key;</a>
<a name="ln486">  }</a>
<a name="ln487"> </a>
<a name="ln488">  Slice value() const override {</a>
<a name="ln489">    assert(Valid());</a>
<a name="ln490"> </a>
<a name="ln491">    auto file_meta = flevel_-&gt;files[index_];</a>
<a name="ln492">    current_value_ = file_meta.fd;</a>
<a name="ln493">    return Slice(reinterpret_cast&lt;const char*&gt;(&amp;current_value_),</a>
<a name="ln494">                 sizeof(FileDescriptor));</a>
<a name="ln495">  }</a>
<a name="ln496"> </a>
<a name="ln497">  Status status() const override { return Status::OK(); }</a>
<a name="ln498"> </a>
<a name="ln499"> private:</a>
<a name="ln500">  const InternalKeyComparator icmp_;</a>
<a name="ln501">  const LevelFilesBrief* flevel_;</a>
<a name="ln502">  uint32_t index_;</a>
<a name="ln503">  mutable FileDescriptor current_value_;</a>
<a name="ln504">};</a>
<a name="ln505"> </a>
<a name="ln506">class LevelFileIteratorState : public TwoLevelIteratorState {</a>
<a name="ln507"> public:</a>
<a name="ln508">  // @param skip_filters Disables loading/accessing the filter block</a>
<a name="ln509">  LevelFileIteratorState(TableCache* table_cache,</a>
<a name="ln510">                         const ReadOptions&amp; read_options,</a>
<a name="ln511">                         const EnvOptions&amp; env_options,</a>
<a name="ln512">                         const InternalKeyComparatorPtr&amp; icomparator,</a>
<a name="ln513">                         HistogramImpl* file_read_hist, bool for_compaction,</a>
<a name="ln514">                         bool prefix_enabled, bool skip_filters)</a>
<a name="ln515">      : TwoLevelIteratorState(prefix_enabled),</a>
<a name="ln516">        table_cache_(table_cache),</a>
<a name="ln517">        read_options_(read_options),</a>
<a name="ln518">        env_options_(env_options),</a>
<a name="ln519">        icomparator_(icomparator),</a>
<a name="ln520">        file_read_hist_(file_read_hist),</a>
<a name="ln521">        for_compaction_(for_compaction),</a>
<a name="ln522">        skip_filters_(skip_filters) {}</a>
<a name="ln523"> </a>
<a name="ln524">  InternalIterator* NewSecondaryIterator(const Slice&amp; meta_handle) override {</a>
<a name="ln525">    if (meta_handle.size() != sizeof(FileDescriptor)) {</a>
<a name="ln526">      return NewErrorInternalIterator(</a>
<a name="ln527">          STATUS(Corruption, &quot;FileReader invoked with unexpected value&quot;));</a>
<a name="ln528">    } else {</a>
<a name="ln529">      const FileDescriptor* fd =</a>
<a name="ln530">          reinterpret_cast&lt;const FileDescriptor*&gt;(meta_handle.data());</a>
<a name="ln531">      return table_cache_-&gt;NewIterator(</a>
<a name="ln532">          read_options_, env_options_, icomparator_, *fd, Slice() /* filter */,</a>
<a name="ln533">          nullptr /* don't need reference to table*/, file_read_hist_,</a>
<a name="ln534">          for_compaction_, nullptr /* arena */, skip_filters_);</a>
<a name="ln535">    }</a>
<a name="ln536">  }</a>
<a name="ln537"> </a>
<a name="ln538">  bool PrefixMayMatch(const Slice&amp; internal_key) override {</a>
<a name="ln539">    return true;</a>
<a name="ln540">  }</a>
<a name="ln541"> </a>
<a name="ln542"> private:</a>
<a name="ln543">  TableCache* table_cache_;</a>
<a name="ln544">  const ReadOptions read_options_;</a>
<a name="ln545">  const EnvOptions&amp; env_options_;</a>
<a name="ln546">  InternalKeyComparatorPtr icomparator_;</a>
<a name="ln547">  HistogramImpl* file_read_hist_;</a>
<a name="ln548">  bool for_compaction_;</a>
<a name="ln549">  bool skip_filters_;</a>
<a name="ln550">};</a>
<a name="ln551"> </a>
<a name="ln552">// A wrapper of version builder which references the current version in</a>
<a name="ln553">// constructor and unref it in the destructor.</a>
<a name="ln554">// Both of the constructor and destructor need to be called inside DB Mutex.</a>
<a name="ln555">class BaseReferencedVersionBuilder {</a>
<a name="ln556"> public:</a>
<a name="ln557">  explicit BaseReferencedVersionBuilder(ColumnFamilyData* cfd)</a>
<a name="ln558">      : version_builder_(new VersionBuilder(</a>
<a name="ln559">            cfd-&gt;current()-&gt;version_set()-&gt;env_options(), cfd-&gt;table_cache(),</a>
<a name="ln560">            cfd-&gt;current()-&gt;storage_info(), cfd-&gt;ioptions()-&gt;info_log)),</a>
<a name="ln561">        version_(cfd-&gt;current()) {</a>
<a name="ln562">    version_-&gt;Ref();</a>
<a name="ln563">  }</a>
<a name="ln564">  ~BaseReferencedVersionBuilder() {</a>
<a name="ln565">    delete version_builder_;</a>
<a name="ln566">    version_-&gt;Unref();</a>
<a name="ln567">  }</a>
<a name="ln568">  VersionBuilder* version_builder() { return version_builder_; }</a>
<a name="ln569"> </a>
<a name="ln570"> private:</a>
<a name="ln571">  VersionBuilder* version_builder_;</a>
<a name="ln572">  Version* version_;</a>
<a name="ln573">};</a>
<a name="ln574">}  // anonymous namespace</a>
<a name="ln575"> </a>
<a name="ln576">Status Version::GetTableProperties(std::shared_ptr&lt;const TableProperties&gt;* tp,</a>
<a name="ln577">                                   const FileMetaData* file_meta,</a>
<a name="ln578">                                   const std::string* fname) const {</a>
<a name="ln579">  auto table_cache = cfd_-&gt;table_cache();</a>
<a name="ln580">  auto ioptions = cfd_-&gt;ioptions();</a>
<a name="ln581">  Status s = table_cache-&gt;GetTableProperties(</a>
<a name="ln582">      vset_-&gt;env_options_, cfd_-&gt;internal_comparator(), file_meta-&gt;fd,</a>
<a name="ln583">      tp, true /* no io */);</a>
<a name="ln584">  if (s.ok()) {</a>
<a name="ln585">    return s;</a>
<a name="ln586">  }</a>
<a name="ln587"> </a>
<a name="ln588">  // We only ignore error type `Incomplete` since it's by design that we</a>
<a name="ln589">  // disallow table when it's not in table cache.</a>
<a name="ln590">  if (!s.IsIncomplete()) {</a>
<a name="ln591">    return s;</a>
<a name="ln592">  }</a>
<a name="ln593"> </a>
<a name="ln594">  // 2. Table is not present in table cache, we'll read the table properties</a>
<a name="ln595">  // directly from the properties block in the file.</a>
<a name="ln596">  std::unique_ptr&lt;RandomAccessFile&gt; file;</a>
<a name="ln597">  if (fname != nullptr) {</a>
<a name="ln598">    s = ioptions-&gt;env-&gt;NewRandomAccessFile(</a>
<a name="ln599">        *fname, &amp;file, vset_-&gt;env_options_);</a>
<a name="ln600">  } else {</a>
<a name="ln601">    s = ioptions-&gt;env-&gt;NewRandomAccessFile(</a>
<a name="ln602">        TableFileName(vset_-&gt;db_options_-&gt;db_paths, file_meta-&gt;fd.GetNumber(),</a>
<a name="ln603">                      file_meta-&gt;fd.GetPathId()),</a>
<a name="ln604">        &amp;file, vset_-&gt;env_options_);</a>
<a name="ln605">  }</a>
<a name="ln606">  if (!s.ok()) {</a>
<a name="ln607">    return s;</a>
<a name="ln608">  }</a>
<a name="ln609"> </a>
<a name="ln610">  TableProperties* raw_table_properties;</a>
<a name="ln611">  // By setting the magic number to kInvalidTableMagicNumber, we can by</a>
<a name="ln612">  // pass the magic number check in the footer.</a>
<a name="ln613">  std::unique_ptr&lt;RandomAccessFileReader&gt; file_reader(</a>
<a name="ln614">      new RandomAccessFileReader(std::move(file)));</a>
<a name="ln615">  s = ReadTableProperties(</a>
<a name="ln616">      file_reader.get(), file_meta-&gt;fd.GetBaseFileSize(),</a>
<a name="ln617">      Footer::kInvalidTableMagicNumber /* table's magic number */, vset_-&gt;env_,</a>
<a name="ln618">      ioptions-&gt;info_log, &amp;raw_table_properties);</a>
<a name="ln619">  if (!s.ok()) {</a>
<a name="ln620">    return s;</a>
<a name="ln621">  }</a>
<a name="ln622">  RecordTick(ioptions-&gt;statistics, NUMBER_DIRECT_LOAD_TABLE_PROPERTIES);</a>
<a name="ln623"> </a>
<a name="ln624">  *tp = std::shared_ptr&lt;const TableProperties&gt;(raw_table_properties);</a>
<a name="ln625">  return s;</a>
<a name="ln626">}</a>
<a name="ln627"> </a>
<a name="ln628">Status Version::GetPropertiesOfAllTables(TablePropertiesCollection* props) {</a>
<a name="ln629">  Status s;</a>
<a name="ln630">  for (int level = 0; level &lt; storage_info_.num_levels_; level++) {</a>
<a name="ln631">    s = GetPropertiesOfAllTables(props, level);</a>
<a name="ln632">    if (!s.ok()) {</a>
<a name="ln633">      return s;</a>
<a name="ln634">    }</a>
<a name="ln635">  }</a>
<a name="ln636"> </a>
<a name="ln637">  return Status::OK();</a>
<a name="ln638">}</a>
<a name="ln639"> </a>
<a name="ln640">Status Version::GetPropertiesOfAllTables(TablePropertiesCollection* props,</a>
<a name="ln641">                                         int level) {</a>
<a name="ln642">  for (const auto&amp; file_meta : storage_info_.files_[level]) {</a>
<a name="ln643">    auto fname =</a>
<a name="ln644">        TableFileName(vset_-&gt;db_options_-&gt;db_paths, file_meta-&gt;fd.GetNumber(),</a>
<a name="ln645">                      file_meta-&gt;fd.GetPathId());</a>
<a name="ln646">    // 1. If the table is already present in table cache, load table</a>
<a name="ln647">    // properties from there.</a>
<a name="ln648">    std::shared_ptr&lt;const TableProperties&gt; table_properties;</a>
<a name="ln649">    Status s = GetTableProperties(&amp;table_properties, file_meta, &amp;fname);</a>
<a name="ln650">    if (s.ok()) {</a>
<a name="ln651">      props-&gt;insert({fname, table_properties});</a>
<a name="ln652">    } else {</a>
<a name="ln653">      return s;</a>
<a name="ln654">    }</a>
<a name="ln655">  }</a>
<a name="ln656"> </a>
<a name="ln657">  return Status::OK();</a>
<a name="ln658">}</a>
<a name="ln659"> </a>
<a name="ln660">Status Version::GetPropertiesOfTablesInRange(</a>
<a name="ln661">    const Range* range, std::size_t n, TablePropertiesCollection* props) const {</a>
<a name="ln662">  for (int level = 0; level &lt; storage_info_.num_non_empty_levels(); level++) {</a>
<a name="ln663">    for (decltype(n) i = 0; i &lt; n; i++) {</a>
<a name="ln664">      // Convert user_key into a corresponding internal key.</a>
<a name="ln665">      const InternalKey k1(range[i].start, kMaxSequenceNumber, kValueTypeForSeek);</a>
<a name="ln666">      const InternalKey k2(range[i].limit, kMaxSequenceNumber, kValueTypeForSeek);</a>
<a name="ln667">      std::vector&lt;FileMetaData*&gt; files;</a>
<a name="ln668">      storage_info_.GetOverlappingInputs(level, &amp;k1, &amp;k2, &amp;files, -1, nullptr, false);</a>
<a name="ln669">      for (const auto&amp; file_meta : files) {</a>
<a name="ln670">        auto fname =</a>
<a name="ln671">            TableFileName(vset_-&gt;db_options_-&gt;db_paths,</a>
<a name="ln672">                          file_meta-&gt;fd.GetNumber(), file_meta-&gt;fd.GetPathId());</a>
<a name="ln673">        if (props-&gt;count(fname) == 0) {</a>
<a name="ln674">          // 1. If the table is already present in table cache, load table</a>
<a name="ln675">          // properties from there.</a>
<a name="ln676">          std::shared_ptr&lt;const TableProperties&gt; table_properties;</a>
<a name="ln677">          Status s = GetTableProperties(&amp;table_properties, file_meta, &amp;fname);</a>
<a name="ln678">          if (s.ok()) {</a>
<a name="ln679">            props-&gt;insert({fname, table_properties});</a>
<a name="ln680">          } else {</a>
<a name="ln681">            return s;</a>
<a name="ln682">          }</a>
<a name="ln683">        }</a>
<a name="ln684">      }</a>
<a name="ln685">    }</a>
<a name="ln686">  }</a>
<a name="ln687"> </a>
<a name="ln688">  return Status::OK();</a>
<a name="ln689">}</a>
<a name="ln690"> </a>
<a name="ln691">Status Version::GetAggregatedTableProperties(</a>
<a name="ln692">    std::shared_ptr&lt;const TableProperties&gt;* tp, int level) {</a>
<a name="ln693">  TablePropertiesCollection props;</a>
<a name="ln694">  Status s;</a>
<a name="ln695">  if (level &lt; 0) {</a>
<a name="ln696">    s = GetPropertiesOfAllTables(&amp;props);</a>
<a name="ln697">  } else {</a>
<a name="ln698">    s = GetPropertiesOfAllTables(&amp;props, level);</a>
<a name="ln699">  }</a>
<a name="ln700">  if (!s.ok()) {</a>
<a name="ln701">    return s;</a>
<a name="ln702">  }</a>
<a name="ln703"> </a>
<a name="ln704">  auto* new_tp = new TableProperties();</a>
<a name="ln705">  for (const auto&amp; item : props) {</a>
<a name="ln706">    new_tp-&gt;Add(*item.second);</a>
<a name="ln707">  }</a>
<a name="ln708">  tp-&gt;reset(new_tp);</a>
<a name="ln709">  return Status::OK();</a>
<a name="ln710">}</a>
<a name="ln711"> </a>
<a name="ln712">size_t Version::GetMemoryUsageByTableReaders() {</a>
<a name="ln713">  size_t total_usage = 0;</a>
<a name="ln714">  for (auto&amp; file_level : storage_info_.level_files_brief_) {</a>
<a name="ln715">    for (size_t i = 0; i &lt; file_level.num_files; i++) {</a>
<a name="ln716">      total_usage += cfd_-&gt;table_cache()-&gt;GetMemoryUsageByTableReader(</a>
<a name="ln717">          vset_-&gt;env_options_, cfd_-&gt;internal_comparator(),</a>
<a name="ln718">          file_level.files[i].fd);</a>
<a name="ln719">    }</a>
<a name="ln720">  }</a>
<a name="ln721">  return total_usage;</a>
<a name="ln722">}</a>
<a name="ln723"> </a>
<a name="ln724">void Version::GetColumnFamilyMetaData(ColumnFamilyMetaData* cf_meta) {</a>
<a name="ln725">  assert(cf_meta);</a>
<a name="ln726">  assert(cfd_);</a>
<a name="ln727"> </a>
<a name="ln728">  cf_meta-&gt;name = cfd_-&gt;GetName();</a>
<a name="ln729">  cf_meta-&gt;size = 0;</a>
<a name="ln730">  cf_meta-&gt;file_count = 0;</a>
<a name="ln731">  cf_meta-&gt;levels.clear();</a>
<a name="ln732"> </a>
<a name="ln733">  auto* ioptions = cfd_-&gt;ioptions();</a>
<a name="ln734">  auto* vstorage = storage_info();</a>
<a name="ln735"> </a>
<a name="ln736">  for (int level = 0; level &lt; cfd_-&gt;NumberLevels(); level++) {</a>
<a name="ln737">    uint64_t level_size = 0;</a>
<a name="ln738">    cf_meta-&gt;file_count += vstorage-&gt;LevelFiles(level).size();</a>
<a name="ln739">    std::vector&lt;SstFileMetaData&gt; files;</a>
<a name="ln740">    for (const auto&amp; file : vstorage-&gt;LevelFiles(level)) {</a>
<a name="ln741">      uint32_t path_id = file-&gt;fd.GetPathId();</a>
<a name="ln742">      std::string file_path;</a>
<a name="ln743">      if (path_id &lt; ioptions-&gt;db_paths.size()) {</a>
<a name="ln744">        file_path = ioptions-&gt;db_paths[path_id].path;</a>
<a name="ln745">      } else {</a>
<a name="ln746">        assert(!ioptions-&gt;db_paths.empty());</a>
<a name="ln747">        file_path = ioptions-&gt;db_paths.back().path;</a>
<a name="ln748">      }</a>
<a name="ln749">      files.emplace_back(</a>
<a name="ln750">          MakeTableFileName(&quot;&quot;, file-&gt;fd.GetNumber()),</a>
<a name="ln751">          file_path,</a>
<a name="ln752">          file-&gt;fd.GetTotalFileSize(),</a>
<a name="ln753">          file-&gt;fd.GetBaseFileSize(),</a>
<a name="ln754">          file-&gt;fd.GetBaseFileSize() +</a>
<a name="ln755">              file-&gt;raw_key_size + file-&gt;raw_value_size,</a>
<a name="ln756">          ConvertBoundaryValues(file-&gt;smallest),</a>
<a name="ln757">          ConvertBoundaryValues(file-&gt;largest),</a>
<a name="ln758">          file-&gt;being_compacted);</a>
<a name="ln759">      level_size += file-&gt;fd.GetTotalFileSize();</a>
<a name="ln760">    }</a>
<a name="ln761">    cf_meta-&gt;levels.emplace_back(</a>
<a name="ln762">        level, level_size, std::move(files));</a>
<a name="ln763">    cf_meta-&gt;size += level_size;</a>
<a name="ln764">  }</a>
<a name="ln765">}</a>
<a name="ln766"> </a>
<a name="ln767"> </a>
<a name="ln768">uint64_t VersionStorageInfo::GetEstimatedActiveKeys() const {</a>
<a name="ln769">  // Estimation will be inaccurate when:</a>
<a name="ln770">  // (1) there exist merge keys</a>
<a name="ln771">  // (2) keys are directly overwritten</a>
<a name="ln772">  // (3) deletion on non-existing keys</a>
<a name="ln773">  // (4) low number of samples</a>
<a name="ln774">  if (current_num_samples_ == 0) {</a>
<a name="ln775">    return 0;</a>
<a name="ln776">  }</a>
<a name="ln777"> </a>
<a name="ln778">  if (current_num_non_deletions_ &lt;= current_num_deletions_) {</a>
<a name="ln779">    return 0;</a>
<a name="ln780">  }</a>
<a name="ln781"> </a>
<a name="ln782">  uint64_t est = current_num_non_deletions_ - current_num_deletions_;</a>
<a name="ln783"> </a>
<a name="ln784">  uint64_t file_count = 0;</a>
<a name="ln785">  for (int level = 0; level &lt; num_levels_; ++level) {</a>
<a name="ln786">    file_count += files_[level].size();</a>
<a name="ln787">  }</a>
<a name="ln788"> </a>
<a name="ln789">  if (current_num_samples_ &lt; file_count) {</a>
<a name="ln790">    // casting to avoid overflowing</a>
<a name="ln791">    return</a>
<a name="ln792">      static_cast&lt;uint64_t&gt;(</a>
<a name="ln793">        (est * static_cast&lt;double&gt;(file_count) / current_num_samples_)</a>
<a name="ln794">      );</a>
<a name="ln795">  } else {</a>
<a name="ln796">    return est;</a>
<a name="ln797">  }</a>
<a name="ln798">}</a>
<a name="ln799"> </a>
<a name="ln800">void Version::AddIterators(const ReadOptions&amp; read_options,</a>
<a name="ln801">                           const EnvOptions&amp; soptions,</a>
<a name="ln802">                           MergeIteratorBuilder* merge_iter_builder) {</a>
<a name="ln803">  assert(storage_info_.finalized_);</a>
<a name="ln804"> </a>
<a name="ln805">  if (storage_info_.num_non_empty_levels() == 0) {</a>
<a name="ln806">    // No file in the Version.</a>
<a name="ln807">    return;</a>
<a name="ln808">  }</a>
<a name="ln809"> </a>
<a name="ln810">  auto* arena = merge_iter_builder-&gt;GetArena();</a>
<a name="ln811"> </a>
<a name="ln812">  // Merge all level zero files together since they may overlap</a>
<a name="ln813">  for (size_t i = 0; i &lt; storage_info_.LevelFilesBrief(0).num_files; i++) {</a>
<a name="ln814">    const auto&amp; file = storage_info_.LevelFilesBrief(0).files[i];</a>
<a name="ln815">    if (!read_options.file_filter || read_options.file_filter-&gt;Filter(file)) {</a>
<a name="ln816">      InternalIterator *file_iter;</a>
<a name="ln817">      TableCache::TableReaderWithHandle trwh;</a>
<a name="ln818">      Status s = cfd_-&gt;table_cache()-&gt;GetTableReaderForIterator(read_options, soptions,</a>
<a name="ln819">          cfd_-&gt;internal_comparator(), file.fd, &amp;trwh, cfd_-&gt;internal_stats()-&gt;GetFileReadHist(0),</a>
<a name="ln820">          false);</a>
<a name="ln821">      if (s.ok()) {</a>
<a name="ln822">        if (!read_options.table_aware_file_filter ||</a>
<a name="ln823">            read_options.table_aware_file_filter-&gt;Filter(trwh.table_reader)) {</a>
<a name="ln824">          file_iter = cfd_-&gt;table_cache()-&gt;NewIterator(</a>
<a name="ln825">              read_options, &amp;trwh, storage_info_.LevelFiles(0)[i]-&gt;UserFilter(), false, arena);</a>
<a name="ln826">        } else {</a>
<a name="ln827">          file_iter = nullptr;</a>
<a name="ln828">        }</a>
<a name="ln829">      } else {</a>
<a name="ln830">        file_iter = NewErrorInternalIterator(s, arena);</a>
<a name="ln831">      }</a>
<a name="ln832">      if (file_iter) {</a>
<a name="ln833">        merge_iter_builder-&gt;AddIterator(file_iter);</a>
<a name="ln834">      }</a>
<a name="ln835">    }</a>
<a name="ln836">  }</a>
<a name="ln837"> </a>
<a name="ln838">  // For levels &gt; 0, we can use a concatenating iterator that sequentially</a>
<a name="ln839">  // walks through the non-overlapping files in the level, opening them</a>
<a name="ln840">  // lazily.</a>
<a name="ln841">  for (int level = 1; level &lt; storage_info_.num_non_empty_levels(); level++) {</a>
<a name="ln842">    if (storage_info_.LevelFilesBrief(level).num_files != 0) {</a>
<a name="ln843">      auto* mem = arena-&gt;AllocateAligned(sizeof(LevelFileIteratorState));</a>
<a name="ln844">      auto* state = new (mem)</a>
<a name="ln845">          LevelFileIteratorState(cfd_-&gt;table_cache(), read_options, soptions,</a>
<a name="ln846">                                 cfd_-&gt;internal_comparator(),</a>
<a name="ln847">                                 cfd_-&gt;internal_stats()-&gt;GetFileReadHist(level),</a>
<a name="ln848">                                 false /* for_compaction */,</a>
<a name="ln849">                                 cfd_-&gt;ioptions()-&gt;prefix_extractor != nullptr,</a>
<a name="ln850">                                 IsFilterSkipped(level));</a>
<a name="ln851">      mem = arena-&gt;AllocateAligned(sizeof(LevelFileNumIterator));</a>
<a name="ln852">      auto* first_level_iter = new (mem) LevelFileNumIterator(</a>
<a name="ln853">          *cfd_-&gt;internal_comparator(), &amp;storage_info_.LevelFilesBrief(level));</a>
<a name="ln854">      merge_iter_builder-&gt;AddIterator(NewTwoLevelIterator(state, first_level_iter, arena, false));</a>
<a name="ln855">    }</a>
<a name="ln856">  }</a>
<a name="ln857">}</a>
<a name="ln858"> </a>
<a name="ln859">VersionStorageInfo::VersionStorageInfo(</a>
<a name="ln860">    const InternalKeyComparatorPtr&amp; internal_comparator,</a>
<a name="ln861">    const Comparator* user_comparator, int levels,</a>
<a name="ln862">    CompactionStyle compaction_style, VersionStorageInfo* ref_vstorage)</a>
<a name="ln863">    : internal_comparator_(internal_comparator),</a>
<a name="ln864">      user_comparator_(user_comparator),</a>
<a name="ln865">      // cfd is nullptr if Version is dummy</a>
<a name="ln866">      num_levels_(levels),</a>
<a name="ln867">      num_non_empty_levels_(0),</a>
<a name="ln868">      file_indexer_(user_comparator),</a>
<a name="ln869">      compaction_style_(compaction_style),</a>
<a name="ln870">      files_(new std::vector&lt;FileMetaData*&gt;[num_levels_]),</a>
<a name="ln871">      base_level_(num_levels_ == 1 ? -1 : 1),</a>
<a name="ln872">      files_by_compaction_pri_(num_levels_),</a>
<a name="ln873">      level0_non_overlapping_(false),</a>
<a name="ln874">      next_file_to_compact_by_size_(num_levels_),</a>
<a name="ln875">      compaction_score_(num_levels_),</a>
<a name="ln876">      compaction_level_(num_levels_),</a>
<a name="ln877">      l0_delay_trigger_count_(0),</a>
<a name="ln878">      accumulated_file_size_(0),</a>
<a name="ln879">      accumulated_raw_key_size_(0),</a>
<a name="ln880">      accumulated_raw_value_size_(0),</a>
<a name="ln881">      accumulated_num_non_deletions_(0),</a>
<a name="ln882">      accumulated_num_deletions_(0),</a>
<a name="ln883">      current_num_non_deletions_(0),</a>
<a name="ln884">      current_num_deletions_(0),</a>
<a name="ln885">      current_num_samples_(0),</a>
<a name="ln886">      estimated_compaction_needed_bytes_(0),</a>
<a name="ln887">      finalized_(false) {</a>
<a name="ln888">  if (ref_vstorage != nullptr) {</a>
<a name="ln889">    accumulated_file_size_ = ref_vstorage-&gt;accumulated_file_size_;</a>
<a name="ln890">    accumulated_raw_key_size_ = ref_vstorage-&gt;accumulated_raw_key_size_;</a>
<a name="ln891">    accumulated_raw_value_size_ = ref_vstorage-&gt;accumulated_raw_value_size_;</a>
<a name="ln892">    accumulated_num_non_deletions_ =</a>
<a name="ln893">        ref_vstorage-&gt;accumulated_num_non_deletions_;</a>
<a name="ln894">    accumulated_num_deletions_ = ref_vstorage-&gt;accumulated_num_deletions_;</a>
<a name="ln895">    current_num_non_deletions_ = ref_vstorage-&gt;current_num_non_deletions_;</a>
<a name="ln896">    current_num_deletions_ = ref_vstorage-&gt;current_num_deletions_;</a>
<a name="ln897">    current_num_samples_ = ref_vstorage-&gt;current_num_samples_;</a>
<a name="ln898">  }</a>
<a name="ln899">}</a>
<a name="ln900"> </a>
<a name="ln901">Version::Version(ColumnFamilyData* column_family_data, VersionSet* vset,</a>
<a name="ln902">                 uint64_t version_number)</a>
<a name="ln903">    : env_(vset-&gt;env_),</a>
<a name="ln904">      cfd_(column_family_data),</a>
<a name="ln905">      info_log_((cfd_ == nullptr) ? nullptr : cfd_-&gt;ioptions()-&gt;info_log),</a>
<a name="ln906">      db_statistics_((cfd_ == nullptr) ? nullptr</a>
<a name="ln907">                                       : cfd_-&gt;ioptions()-&gt;statistics),</a>
<a name="ln908">      table_cache_((cfd_ == nullptr) ? nullptr : cfd_-&gt;table_cache()),</a>
<a name="ln909">      merge_operator_((cfd_ == nullptr) ? nullptr</a>
<a name="ln910">                                        : cfd_-&gt;ioptions()-&gt;merge_operator),</a>
<a name="ln911">      storage_info_((cfd_ == nullptr) ? nullptr : cfd_-&gt;internal_comparator(),</a>
<a name="ln912">                    (cfd_ == nullptr) ? nullptr : cfd_-&gt;user_comparator(),</a>
<a name="ln913">                    cfd_ == nullptr ? 0 : cfd_-&gt;NumberLevels(),</a>
<a name="ln914">                    cfd_ == nullptr ? kCompactionStyleLevel</a>
<a name="ln915">                                    : cfd_-&gt;ioptions()-&gt;compaction_style,</a>
<a name="ln916">                    (cfd_ == nullptr || cfd_-&gt;current() == nullptr)</a>
<a name="ln917">                        ? nullptr</a>
<a name="ln918">                        : cfd_-&gt;current()-&gt;storage_info()),</a>
<a name="ln919">      vset_(vset),</a>
<a name="ln920">      next_(this),</a>
<a name="ln921">      prev_(this),</a>
<a name="ln922">      refs_(0),</a>
<a name="ln923">      version_number_(version_number) {}</a>
<a name="ln924"> </a>
<a name="ln925">void Version::Get(const ReadOptions&amp; read_options, const LookupKey&amp; k,</a>
<a name="ln926">                  std::string* value, Status* status,</a>
<a name="ln927">                  MergeContext* merge_context, bool* value_found,</a>
<a name="ln928">                  bool* key_exists, SequenceNumber* seq) {</a>
<a name="ln929">  Slice ikey = k.internal_key();</a>
<a name="ln930">  Slice user_key = k.user_key();</a>
<a name="ln931"> </a>
<a name="ln932">  assert(status-&gt;ok() || status-&gt;IsMergeInProgress());</a>
<a name="ln933"> </a>
<a name="ln934">  if (key_exists != nullptr) {</a>
<a name="ln935">    // will falsify below if not found</a>
<a name="ln936">    *key_exists = true;</a>
<a name="ln937">  }</a>
<a name="ln938"> </a>
<a name="ln939">  GetContext get_context(</a>
<a name="ln940">      user_comparator(), merge_operator_, info_log_, db_statistics_,</a>
<a name="ln941">      status-&gt;ok() ? GetContext::kNotFound : GetContext::kMerge, user_key,</a>
<a name="ln942">      value, value_found, merge_context, this-&gt;env_, seq);</a>
<a name="ln943"> </a>
<a name="ln944">  FilePicker fp(</a>
<a name="ln945">      storage_info_.files_, user_key, ikey, &amp;storage_info_.level_files_brief_,</a>
<a name="ln946">      storage_info_.num_non_empty_levels_, &amp;storage_info_.file_indexer_,</a>
<a name="ln947">      user_comparator(), internal_comparator().get());</a>
<a name="ln948">  FdWithBoundaries* f = fp.GetNextFile();</a>
<a name="ln949">  while (f != nullptr) {</a>
<a name="ln950">    *status = table_cache_-&gt;Get(</a>
<a name="ln951">        read_options, internal_comparator(), f-&gt;fd, ikey, &amp;get_context,</a>
<a name="ln952">        cfd_-&gt;internal_stats()-&gt;GetFileReadHist(fp.GetHitFileLevel()),</a>
<a name="ln953">        IsFilterSkipped(static_cast&lt;int&gt;(fp.GetHitFileLevel()),</a>
<a name="ln954">                        fp.IsHitFileLastInLevel()));</a>
<a name="ln955">    // TODO: examine the behavior for corrupted key</a>
<a name="ln956">    if (!status-&gt;ok()) {</a>
<a name="ln957">      return;</a>
<a name="ln958">    }</a>
<a name="ln959"> </a>
<a name="ln960">    switch (get_context.State()) {</a>
<a name="ln961">      case GetContext::kNotFound:</a>
<a name="ln962">        // Keep searching in other files</a>
<a name="ln963">        break;</a>
<a name="ln964">      case GetContext::kFound:</a>
<a name="ln965">        if (fp.GetHitFileLevel() == 0) {</a>
<a name="ln966">          RecordTick(db_statistics_, GET_HIT_L0);</a>
<a name="ln967">        } else if (fp.GetHitFileLevel() == 1) {</a>
<a name="ln968">          RecordTick(db_statistics_, GET_HIT_L1);</a>
<a name="ln969">        } else if (fp.GetHitFileLevel() &gt;= 2) {</a>
<a name="ln970">          RecordTick(db_statistics_, GET_HIT_L2_AND_UP);</a>
<a name="ln971">        }</a>
<a name="ln972">        return;</a>
<a name="ln973">      case GetContext::kDeleted:</a>
<a name="ln974">        // Use empty error message for speed</a>
<a name="ln975">        *status = STATUS(NotFound, &quot;&quot;);</a>
<a name="ln976">        return;</a>
<a name="ln977">      case GetContext::kCorrupt:</a>
<a name="ln978">        *status = STATUS(Corruption, &quot;corrupted key for &quot;, user_key);</a>
<a name="ln979">        return;</a>
<a name="ln980">      case GetContext::kMerge:</a>
<a name="ln981">        break;</a>
<a name="ln982">    }</a>
<a name="ln983">    f = fp.GetNextFile();</a>
<a name="ln984">  }</a>
<a name="ln985"> </a>
<a name="ln986">  if (GetContext::kMerge == get_context.State()) {</a>
<a name="ln987">    if (!merge_operator_) {</a>
<a name="ln988">      *status =  STATUS(InvalidArgument,</a>
<a name="ln989">          &quot;merge_operator is not properly initialized.&quot;);</a>
<a name="ln990">      return;</a>
<a name="ln991">    }</a>
<a name="ln992">    // merge_operands are in saver and we hit the beginning of the key history</a>
<a name="ln993">    // do a final merge of nullptr and operands;</a>
<a name="ln994">    if (merge_operator_-&gt;FullMerge(user_key, nullptr,</a>
<a name="ln995">                                   merge_context-&gt;GetOperands(), value,</a>
<a name="ln996">                                   info_log_)) {</a>
<a name="ln997">      *status = Status::OK();</a>
<a name="ln998">    } else {</a>
<a name="ln999">      RecordTick(db_statistics_, NUMBER_MERGE_FAILURES);</a>
<a name="ln1000">      *status = STATUS(Corruption, &quot;could not perform end-of-key merge for &quot;,</a>
<a name="ln1001">                                   user_key);</a>
<a name="ln1002">    }</a>
<a name="ln1003">  } else {</a>
<a name="ln1004">    if (key_exists != nullptr) {</a>
<a name="ln1005">      *key_exists = false;</a>
<a name="ln1006">    }</a>
<a name="ln1007">    *status = STATUS(NotFound, &quot;&quot;); // Use an empty error message for speed</a>
<a name="ln1008">  }</a>
<a name="ln1009">}</a>
<a name="ln1010"> </a>
<a name="ln1011">bool Version::IsFilterSkipped(int level, bool is_file_last_in_level) {</a>
<a name="ln1012">  // Reaching the bottom level implies misses at all upper levels, so we'll</a>
<a name="ln1013">  // skip checking the filters when we predict a hit.</a>
<a name="ln1014">  return cfd_-&gt;ioptions()-&gt;optimize_filters_for_hits &amp;&amp;</a>
<a name="ln1015">         (level &gt; 0 || is_file_last_in_level) &amp;&amp;</a>
<a name="ln1016">         level == storage_info_.num_non_empty_levels() - 1;</a>
<a name="ln1017">}</a>
<a name="ln1018"> </a>
<a name="ln1019">void VersionStorageInfo::GenerateLevelFilesBrief() {</a>
<a name="ln1020">  level_files_brief_.resize(num_non_empty_levels_);</a>
<a name="ln1021">  for (int level = 0; level &lt; num_non_empty_levels_; level++) {</a>
<a name="ln1022">    DoGenerateLevelFilesBrief(</a>
<a name="ln1023">        &amp;level_files_brief_[level], files_[level], &amp;arena_);</a>
<a name="ln1024">  }</a>
<a name="ln1025">}</a>
<a name="ln1026"> </a>
<a name="ln1027">void Version::PrepareApply(</a>
<a name="ln1028">    const MutableCFOptions&amp; mutable_cf_options,</a>
<a name="ln1029">    bool update_stats) {</a>
<a name="ln1030">  UpdateAccumulatedStats(update_stats);</a>
<a name="ln1031">  storage_info_.UpdateNumNonEmptyLevels();</a>
<a name="ln1032">  storage_info_.CalculateBaseBytes(*cfd_-&gt;ioptions(), mutable_cf_options);</a>
<a name="ln1033">  storage_info_.UpdateFilesByCompactionPri(mutable_cf_options);</a>
<a name="ln1034">  storage_info_.GenerateFileIndexer();</a>
<a name="ln1035">  storage_info_.GenerateLevelFilesBrief();</a>
<a name="ln1036">  storage_info_.GenerateLevel0NonOverlapping();</a>
<a name="ln1037">}</a>
<a name="ln1038"> </a>
<a name="ln1039">bool Version::MaybeInitializeFileMetaData(FileMetaData* file_meta) {</a>
<a name="ln1040">  if (file_meta-&gt;init_stats_from_file ||</a>
<a name="ln1041">      file_meta-&gt;compensated_file_size &gt; 0) {</a>
<a name="ln1042">    return false;</a>
<a name="ln1043">  }</a>
<a name="ln1044">  std::shared_ptr&lt;const TableProperties&gt; tp;</a>
<a name="ln1045">  Status s = GetTableProperties(&amp;tp, file_meta);</a>
<a name="ln1046">  file_meta-&gt;init_stats_from_file = true;</a>
<a name="ln1047">  if (!s.ok()) {</a>
<a name="ln1048">    RLOG(InfoLogLevel::ERROR_LEVEL, vset_-&gt;db_options_-&gt;info_log,</a>
<a name="ln1049">        &quot;Unable to load table properties for file %&quot; PRIu64 &quot; --- %s\n&quot;,</a>
<a name="ln1050">        file_meta-&gt;fd.GetNumber(), s.ToString().c_str());</a>
<a name="ln1051">    return false;</a>
<a name="ln1052">  }</a>
<a name="ln1053">  if (tp.get() == nullptr) return false;</a>
<a name="ln1054">  file_meta-&gt;num_entries = tp-&gt;num_entries;</a>
<a name="ln1055">  file_meta-&gt;num_deletions = GetDeletedKeys(tp-&gt;user_collected_properties);</a>
<a name="ln1056">  file_meta-&gt;raw_value_size = tp-&gt;raw_value_size;</a>
<a name="ln1057">  file_meta-&gt;raw_key_size = tp-&gt;raw_key_size;</a>
<a name="ln1058"> </a>
<a name="ln1059">  return true;</a>
<a name="ln1060">}</a>
<a name="ln1061"> </a>
<a name="ln1062">void VersionStorageInfo::UpdateAccumulatedStats(FileMetaData* file_meta) {</a>
<a name="ln1063">  assert(file_meta-&gt;init_stats_from_file);</a>
<a name="ln1064">  accumulated_file_size_ += file_meta-&gt;fd.GetTotalFileSize();</a>
<a name="ln1065">  accumulated_raw_key_size_ += file_meta-&gt;raw_key_size;</a>
<a name="ln1066">  accumulated_raw_value_size_ += file_meta-&gt;raw_value_size;</a>
<a name="ln1067">  accumulated_num_non_deletions_ +=</a>
<a name="ln1068">      file_meta-&gt;num_entries - file_meta-&gt;num_deletions;</a>
<a name="ln1069">  accumulated_num_deletions_ += file_meta-&gt;num_deletions;</a>
<a name="ln1070"> </a>
<a name="ln1071">  current_num_non_deletions_ +=</a>
<a name="ln1072">      file_meta-&gt;num_entries - file_meta-&gt;num_deletions;</a>
<a name="ln1073">  current_num_deletions_ += file_meta-&gt;num_deletions;</a>
<a name="ln1074">  current_num_samples_++;</a>
<a name="ln1075">}</a>
<a name="ln1076"> </a>
<a name="ln1077">void VersionStorageInfo::RemoveCurrentStats(FileMetaData* file_meta) {</a>
<a name="ln1078">  if (file_meta-&gt;init_stats_from_file) {</a>
<a name="ln1079">    current_num_non_deletions_ -=</a>
<a name="ln1080">        file_meta-&gt;num_entries - file_meta-&gt;num_deletions;</a>
<a name="ln1081">    current_num_deletions_ -= file_meta-&gt;num_deletions;</a>
<a name="ln1082">    current_num_samples_--;</a>
<a name="ln1083">  }</a>
<a name="ln1084">}</a>
<a name="ln1085"> </a>
<a name="ln1086">void Version::UpdateAccumulatedStats(bool update_stats) {</a>
<a name="ln1087">  if (update_stats) {</a>
<a name="ln1088">    // maximum number of table properties loaded from files.</a>
<a name="ln1089">    const int kMaxInitCount = 20;</a>
<a name="ln1090">    int init_count = 0;</a>
<a name="ln1091">    // here only the first kMaxInitCount files which haven't been</a>
<a name="ln1092">    // initialized from file will be updated with num_deletions.</a>
<a name="ln1093">    // The motivation here is to cap the maximum I/O per Version creation.</a>
<a name="ln1094">    // The reason for choosing files from lower-level instead of higher-level</a>
<a name="ln1095">    // is that such design is able to propagate the initialization from</a>
<a name="ln1096">    // lower-level to higher-level:  When the num_deletions of lower-level</a>
<a name="ln1097">    // files are updated, it will make the lower-level files have accurate</a>
<a name="ln1098">    // compensated_file_size, making lower-level to higher-level compaction</a>
<a name="ln1099">    // will be triggered, which creates higher-level files whose num_deletions</a>
<a name="ln1100">    // will be updated here.</a>
<a name="ln1101">    for (int level = 0;</a>
<a name="ln1102">         level &lt; storage_info_.num_levels_ &amp;&amp; init_count &lt; kMaxInitCount;</a>
<a name="ln1103">         ++level) {</a>
<a name="ln1104">      for (auto* file_meta : storage_info_.files_[level]) {</a>
<a name="ln1105">        if (MaybeInitializeFileMetaData(file_meta)) {</a>
<a name="ln1106">          // each FileMeta will be initialized only once.</a>
<a name="ln1107">          storage_info_.UpdateAccumulatedStats(file_meta);</a>
<a name="ln1108">          if (++init_count &gt;= kMaxInitCount) {</a>
<a name="ln1109">            break;</a>
<a name="ln1110">          }</a>
<a name="ln1111">        }</a>
<a name="ln1112">      }</a>
<a name="ln1113">    }</a>
<a name="ln1114">    // In case all sampled-files contain only deletion entries, then we</a>
<a name="ln1115">    // load the table-property of a file in higher-level to initialize</a>
<a name="ln1116">    // that value.</a>
<a name="ln1117">    for (int level = storage_info_.num_levels_ - 1;</a>
<a name="ln1118">         storage_info_.accumulated_raw_value_size_ == 0 &amp;&amp; level &gt;= 0;</a>
<a name="ln1119">         --level) {</a>
<a name="ln1120">      for (int i = static_cast&lt;int&gt;(storage_info_.files_[level].size()) - 1;</a>
<a name="ln1121">           storage_info_.accumulated_raw_value_size_ == 0 &amp;&amp; i &gt;= 0; --i) {</a>
<a name="ln1122">        if (MaybeInitializeFileMetaData(storage_info_.files_[level][i])) {</a>
<a name="ln1123">          storage_info_.UpdateAccumulatedStats(storage_info_.files_[level][i]);</a>
<a name="ln1124">        }</a>
<a name="ln1125">      }</a>
<a name="ln1126">    }</a>
<a name="ln1127">  }</a>
<a name="ln1128"> </a>
<a name="ln1129">  storage_info_.ComputeCompensatedSizes();</a>
<a name="ln1130">}</a>
<a name="ln1131"> </a>
<a name="ln1132">void VersionStorageInfo::ComputeCompensatedSizes() {</a>
<a name="ln1133">  static const int kDeletionWeightOnCompaction = 2;</a>
<a name="ln1134">  uint64_t average_value_size = GetAverageValueSize();</a>
<a name="ln1135"> </a>
<a name="ln1136">  // compute the compensated size</a>
<a name="ln1137">  for (int level = 0; level &lt; num_levels_; level++) {</a>
<a name="ln1138">    for (auto* file_meta : files_[level]) {</a>
<a name="ln1139">      // Here we only compute compensated_file_size for those file_meta</a>
<a name="ln1140">      // which compensated_file_size is uninitialized (== 0). This is true only</a>
<a name="ln1141">      // for files that have been created right now and no other thread has</a>
<a name="ln1142">      // access to them. That's why we can safely mutate compensated_file_size.</a>
<a name="ln1143">      if (file_meta-&gt;compensated_file_size == 0) {</a>
<a name="ln1144">        file_meta-&gt;compensated_file_size = file_meta-&gt;fd.GetTotalFileSize();</a>
<a name="ln1145">        // Here we only boost the size of deletion entries of a file only</a>
<a name="ln1146">        // when the number of deletion entries is greater than the number of</a>
<a name="ln1147">        // non-deletion entries in the file.  The motivation here is that in</a>
<a name="ln1148">        // a stable workload, the number of deletion entries should be roughly</a>
<a name="ln1149">        // equal to the number of non-deletion entries.  If we compensate the</a>
<a name="ln1150">        // size of deletion entries in a stable workload, the deletion</a>
<a name="ln1151">        // compensation logic might introduce unwanted effet which changes the</a>
<a name="ln1152">        // shape of LSM tree.</a>
<a name="ln1153">        if (file_meta-&gt;num_deletions * 2 &gt;= file_meta-&gt;num_entries) {</a>
<a name="ln1154">          file_meta-&gt;compensated_file_size +=</a>
<a name="ln1155">              (file_meta-&gt;num_deletions * 2 - file_meta-&gt;num_entries) *</a>
<a name="ln1156">              average_value_size * kDeletionWeightOnCompaction;</a>
<a name="ln1157">        }</a>
<a name="ln1158">      }</a>
<a name="ln1159">    }</a>
<a name="ln1160">  }</a>
<a name="ln1161">}</a>
<a name="ln1162"> </a>
<a name="ln1163">int VersionStorageInfo::MaxInputLevel() const {</a>
<a name="ln1164">  if (compaction_style_ == kCompactionStyleLevel) {</a>
<a name="ln1165">    return num_levels() - 2;</a>
<a name="ln1166">  }</a>
<a name="ln1167">  return 0;</a>
<a name="ln1168">}</a>
<a name="ln1169"> </a>
<a name="ln1170">void VersionStorageInfo::EstimateCompactionBytesNeeded(</a>
<a name="ln1171">    const MutableCFOptions&amp; mutable_cf_options) {</a>
<a name="ln1172">  // Only implemented for level-based compaction</a>
<a name="ln1173">  if (compaction_style_ != kCompactionStyleLevel) {</a>
<a name="ln1174">    estimated_compaction_needed_bytes_ = 0;</a>
<a name="ln1175">    return;</a>
<a name="ln1176">  }</a>
<a name="ln1177"> </a>
<a name="ln1178">  // Start from Level 0, if level 0 qualifies compaction to level 1,</a>
<a name="ln1179">  // we estimate the size of compaction.</a>
<a name="ln1180">  // Then we move on to the next level and see whether it qualifies compaction</a>
<a name="ln1181">  // to the next level. The size of the level is estimated as the actual size</a>
<a name="ln1182">  // on the level plus the input bytes from the previous level if there is any.</a>
<a name="ln1183">  // If it exceeds, take the exceeded bytes as compaction input and add the size</a>
<a name="ln1184">  // of the compaction size to tatal size.</a>
<a name="ln1185">  // We keep doing it to Level 2, 3, etc, until the last level and return the</a>
<a name="ln1186">  // accumulated bytes.</a>
<a name="ln1187"> </a>
<a name="ln1188">  uint64_t bytes_compact_to_next_level = 0;</a>
<a name="ln1189">  // Level 0</a>
<a name="ln1190">  bool level0_compact_triggered = false;</a>
<a name="ln1191">  if (static_cast&lt;int&gt;(files_[0].size()) &gt;</a>
<a name="ln1192">      mutable_cf_options.level0_file_num_compaction_trigger) {</a>
<a name="ln1193">    level0_compact_triggered = true;</a>
<a name="ln1194">    for (auto* f : files_[0]) {</a>
<a name="ln1195">      bytes_compact_to_next_level += f-&gt;fd.GetTotalFileSize();</a>
<a name="ln1196">    }</a>
<a name="ln1197">    estimated_compaction_needed_bytes_ = bytes_compact_to_next_level;</a>
<a name="ln1198">  } else {</a>
<a name="ln1199">    estimated_compaction_needed_bytes_ = 0;</a>
<a name="ln1200">  }</a>
<a name="ln1201"> </a>
<a name="ln1202">  // Level 1 and up.</a>
<a name="ln1203">  for (int level = base_level(); level &lt;= MaxInputLevel(); level++) {</a>
<a name="ln1204">    uint64_t level_size = 0;</a>
<a name="ln1205">    for (auto* f : files_[level]) {</a>
<a name="ln1206">      level_size += f-&gt;fd.GetTotalFileSize();</a>
<a name="ln1207">    }</a>
<a name="ln1208">    if (level == base_level() &amp;&amp; level0_compact_triggered) {</a>
<a name="ln1209">      // Add base level size to compaction if level0 compaction triggered.</a>
<a name="ln1210">      estimated_compaction_needed_bytes_ += level_size;</a>
<a name="ln1211">    }</a>
<a name="ln1212">    // Add size added by previous compaction</a>
<a name="ln1213">    level_size += bytes_compact_to_next_level;</a>
<a name="ln1214">    bytes_compact_to_next_level = 0;</a>
<a name="ln1215">    uint64_t level_target = MaxBytesForLevel(level);</a>
<a name="ln1216">    if (level_size &gt; level_target) {</a>
<a name="ln1217">      bytes_compact_to_next_level = level_size - level_target;</a>
<a name="ln1218">      // Simplify to assume the actual compaction fan-out ratio is always</a>
<a name="ln1219">      // mutable_cf_options.max_bytes_for_level_multiplier.</a>
<a name="ln1220">      estimated_compaction_needed_bytes_ +=</a>
<a name="ln1221">          bytes_compact_to_next_level *</a>
<a name="ln1222">          (1 + mutable_cf_options.max_bytes_for_level_multiplier);</a>
<a name="ln1223">    }</a>
<a name="ln1224">  }</a>
<a name="ln1225">}</a>
<a name="ln1226"> </a>
<a name="ln1227">void VersionStorageInfo::ComputeCompactionScore(</a>
<a name="ln1228">    const MutableCFOptions&amp; mutable_cf_options,</a>
<a name="ln1229">    const CompactionOptionsFIFO&amp; compaction_options_fifo) {</a>
<a name="ln1230">  for (int level = 0; level &lt;= MaxInputLevel(); level++) {</a>
<a name="ln1231">    double score;</a>
<a name="ln1232">    if (level == 0) {</a>
<a name="ln1233">      // We treat level-0 specially by bounding the number of files</a>
<a name="ln1234">      // instead of number of bytes for two reasons:</a>
<a name="ln1235">      //</a>
<a name="ln1236">      // (1) With larger write-buffer sizes, it is nice not to do too</a>
<a name="ln1237">      // many level-0 compactions.</a>
<a name="ln1238">      //</a>
<a name="ln1239">      // (2) The files in level-0 are merged on every read and</a>
<a name="ln1240">      // therefore we wish to avoid too many files when the individual</a>
<a name="ln1241">      // file size is small (perhaps because of a small write-buffer</a>
<a name="ln1242">      // setting, or very high compression ratios, or lots of</a>
<a name="ln1243">      // overwrites/deletions).</a>
<a name="ln1244">      int num_sorted_runs = 0;</a>
<a name="ln1245">      uint64_t total_size = 0;</a>
<a name="ln1246">      for (auto* f : files_[level]) {</a>
<a name="ln1247">        if (!f-&gt;being_compacted) {</a>
<a name="ln1248">          total_size += f-&gt;compensated_file_size;</a>
<a name="ln1249">          num_sorted_runs++;</a>
<a name="ln1250">        }</a>
<a name="ln1251">      }</a>
<a name="ln1252">      if (compaction_style_ == kCompactionStyleUniversal) {</a>
<a name="ln1253">        // For universal compaction, we use level0 score to indicate</a>
<a name="ln1254">        // compaction score for the whole DB. Adding other levels as if</a>
<a name="ln1255">        // they are L0 files.</a>
<a name="ln1256">        for (int i = 1; i &lt; num_levels(); i++) {</a>
<a name="ln1257">          if (!files_[i].empty() &amp;&amp; !files_[i][0]-&gt;being_compacted) {</a>
<a name="ln1258">            num_sorted_runs++;</a>
<a name="ln1259">          }</a>
<a name="ln1260">        }</a>
<a name="ln1261">      }</a>
<a name="ln1262"> </a>
<a name="ln1263">      if (compaction_style_ == kCompactionStyleFIFO) {</a>
<a name="ln1264">        score = static_cast&lt;double&gt;(total_size) /</a>
<a name="ln1265">                compaction_options_fifo.max_table_files_size;</a>
<a name="ln1266">      } else {</a>
<a name="ln1267">        score = static_cast&lt;double&gt;(num_sorted_runs) /</a>
<a name="ln1268">                mutable_cf_options.level0_file_num_compaction_trigger;</a>
<a name="ln1269">      }</a>
<a name="ln1270">    } else {</a>
<a name="ln1271">      // Compute the ratio of current size to size limit.</a>
<a name="ln1272">      uint64_t level_bytes_no_compacting = 0;</a>
<a name="ln1273">      for (auto f : files_[level]) {</a>
<a name="ln1274">        if (!f-&gt;being_compacted) {</a>
<a name="ln1275">          level_bytes_no_compacting += f-&gt;compensated_file_size;</a>
<a name="ln1276">        }</a>
<a name="ln1277">      }</a>
<a name="ln1278">      score = static_cast&lt;double&gt;(level_bytes_no_compacting) /</a>
<a name="ln1279">              MaxBytesForLevel(level);</a>
<a name="ln1280">    }</a>
<a name="ln1281">    compaction_level_[level] = level;</a>
<a name="ln1282">    compaction_score_[level] = score;</a>
<a name="ln1283">  }</a>
<a name="ln1284"> </a>
<a name="ln1285">  // sort all the levels based on their score. Higher scores get listed</a>
<a name="ln1286">  // first. Use bubble sort because the number of entries are small.</a>
<a name="ln1287">  for (int i = 0; i &lt; num_levels() - 2; i++) {</a>
<a name="ln1288">    for (int j = i + 1; j &lt; num_levels() - 1; j++) {</a>
<a name="ln1289">      if (compaction_score_[i] &lt; compaction_score_[j]) {</a>
<a name="ln1290">        double score = compaction_score_[i];</a>
<a name="ln1291">        int level = compaction_level_[i];</a>
<a name="ln1292">        compaction_score_[i] = compaction_score_[j];</a>
<a name="ln1293">        compaction_level_[i] = compaction_level_[j];</a>
<a name="ln1294">        compaction_score_[j] = score;</a>
<a name="ln1295">        compaction_level_[j] = level;</a>
<a name="ln1296">      }</a>
<a name="ln1297">    }</a>
<a name="ln1298">  }</a>
<a name="ln1299">  ComputeFilesMarkedForCompaction();</a>
<a name="ln1300">  EstimateCompactionBytesNeeded(mutable_cf_options);</a>
<a name="ln1301">}</a>
<a name="ln1302"> </a>
<a name="ln1303">void VersionStorageInfo::ComputeFilesMarkedForCompaction() {</a>
<a name="ln1304">  files_marked_for_compaction_.clear();</a>
<a name="ln1305">  int last_qualify_level = 0;</a>
<a name="ln1306"> </a>
<a name="ln1307">  // Do not include files from the last level with data</a>
<a name="ln1308">  // If table properties collector suggests a file on the last level,</a>
<a name="ln1309">  // we should not move it to a new level.</a>
<a name="ln1310">  for (int level = num_levels() - 1; level &gt;= 1; level--) {</a>
<a name="ln1311">    if (!files_[level].empty()) {</a>
<a name="ln1312">      last_qualify_level = level - 1;</a>
<a name="ln1313">      break;</a>
<a name="ln1314">    }</a>
<a name="ln1315">  }</a>
<a name="ln1316"> </a>
<a name="ln1317">  for (int level = 0; level &lt;= last_qualify_level; level++) {</a>
<a name="ln1318">    for (auto* f : files_[level]) {</a>
<a name="ln1319">      if (!f-&gt;being_compacted &amp;&amp; f-&gt;marked_for_compaction) {</a>
<a name="ln1320">        files_marked_for_compaction_.emplace_back(level, f);</a>
<a name="ln1321">      }</a>
<a name="ln1322">    }</a>
<a name="ln1323">  }</a>
<a name="ln1324">}</a>
<a name="ln1325"> </a>
<a name="ln1326">namespace {</a>
<a name="ln1327"> </a>
<a name="ln1328">// used to sort files by size</a>
<a name="ln1329">struct Fsize {</a>
<a name="ln1330">  size_t index;</a>
<a name="ln1331">  FileMetaData* file;</a>
<a name="ln1332">};</a>
<a name="ln1333"> </a>
<a name="ln1334">// Compator that is used to sort files based on their size</a>
<a name="ln1335">// In normal mode: descending size</a>
<a name="ln1336">bool CompareCompensatedSizeDescending(const Fsize&amp; first, const Fsize&amp; second) {</a>
<a name="ln1337">  return (first.file-&gt;compensated_file_size &gt;</a>
<a name="ln1338">      second.file-&gt;compensated_file_size);</a>
<a name="ln1339">}</a>
<a name="ln1340">} // anonymous namespace</a>
<a name="ln1341"> </a>
<a name="ln1342">void VersionStorageInfo::AddFile(int level, FileMetaData* f, Logger* info_log) {</a>
<a name="ln1343">  auto* level_files = &amp;files_[level];</a>
<a name="ln1344">  // Must not overlap</a>
<a name="ln1345">#ifndef NDEBUG</a>
<a name="ln1346">  if (level &gt; 0 &amp;&amp; !level_files-&gt;empty() &amp;&amp;</a>
<a name="ln1347">      internal_comparator_-&gt;Compare(</a>
<a name="ln1348">          (*level_files)[level_files-&gt;size() - 1]-&gt;largest.key, f-&gt;smallest.key) &gt;= 0) {</a>
<a name="ln1349">    auto* f2 = (*level_files)[level_files-&gt;size() - 1];</a>
<a name="ln1350">    if (info_log != nullptr) {</a>
<a name="ln1351">      RERROR(info_log, &quot;Adding new file %&quot; PRIu64</a>
<a name="ln1352">                      &quot; range (%s, %s) to level %d but overlapping &quot;</a>
<a name="ln1353">                      &quot;with existing file %&quot; PRIu64 &quot; %s %s&quot;,</a>
<a name="ln1354">            f-&gt;fd.GetNumber(),</a>
<a name="ln1355">            f-&gt;smallest.key.DebugString(true).c_str(),</a>
<a name="ln1356">            f-&gt;largest.key.DebugString(true).c_str(),</a>
<a name="ln1357">            level,</a>
<a name="ln1358">            f2-&gt;fd.GetNumber(),</a>
<a name="ln1359">            f2-&gt;smallest.key.DebugString(true).c_str(),</a>
<a name="ln1360">            f2-&gt;largest.key.DebugString(true).c_str());</a>
<a name="ln1361">      LogFlush(info_log);</a>
<a name="ln1362">    }</a>
<a name="ln1363">    assert(false);</a>
<a name="ln1364">  }</a>
<a name="ln1365">#endif</a>
<a name="ln1366">  f-&gt;refs++;</a>
<a name="ln1367">  level_files-&gt;push_back(f);</a>
<a name="ln1368">}</a>
<a name="ln1369"> </a>
<a name="ln1370">// Version::PrepareApply() need to be called before calling the function, or</a>
<a name="ln1371">// following functions called:</a>
<a name="ln1372">// 1. UpdateNumNonEmptyLevels();</a>
<a name="ln1373">// 2. CalculateBaseBytes();</a>
<a name="ln1374">// 3. UpdateFilesByCompactionPri();</a>
<a name="ln1375">// 4. GenerateFileIndexer();</a>
<a name="ln1376">// 5. GenerateLevelFilesBrief();</a>
<a name="ln1377">// 6. GenerateLevel0NonOverlapping();</a>
<a name="ln1378">void VersionStorageInfo::SetFinalized() {</a>
<a name="ln1379">  finalized_ = true;</a>
<a name="ln1380">#ifndef NDEBUG</a>
<a name="ln1381">  if (compaction_style_ != kCompactionStyleLevel) {</a>
<a name="ln1382">    // Not level based compaction.</a>
<a name="ln1383">    return;</a>
<a name="ln1384">  }</a>
<a name="ln1385">  assert(base_level_ &lt; 0 || num_levels() == 1 ||</a>
<a name="ln1386">         (base_level_ &gt;= 1 &amp;&amp; base_level_ &lt; num_levels()));</a>
<a name="ln1387">  // Verify all levels newer than base_level are empty except L0</a>
<a name="ln1388">  for (int level = 1; level &lt; base_level(); level++) {</a>
<a name="ln1389">    assert(NumLevelBytes(level) == 0);</a>
<a name="ln1390">  }</a>
<a name="ln1391">  uint64_t max_bytes_prev_level = 0;</a>
<a name="ln1392">  for (int level = base_level(); level &lt; num_levels() - 1; level++) {</a>
<a name="ln1393">    if (LevelFiles(level).size() == 0) {</a>
<a name="ln1394">      continue;</a>
<a name="ln1395">    }</a>
<a name="ln1396">    assert(MaxBytesForLevel(level) &gt;= max_bytes_prev_level);</a>
<a name="ln1397">    max_bytes_prev_level = MaxBytesForLevel(level);</a>
<a name="ln1398">  }</a>
<a name="ln1399">  int num_empty_non_l0_level = 0;</a>
<a name="ln1400">  for (int level = 0; level &lt; num_levels(); level++) {</a>
<a name="ln1401">    assert(LevelFiles(level).size() == 0 ||</a>
<a name="ln1402">           LevelFiles(level).size() == LevelFilesBrief(level).num_files);</a>
<a name="ln1403">    if (level &gt; 0 &amp;&amp; NumLevelBytes(level) &gt; 0) {</a>
<a name="ln1404">      num_empty_non_l0_level++;</a>
<a name="ln1405">    }</a>
<a name="ln1406">    if (LevelFiles(level).size() &gt; 0) {</a>
<a name="ln1407">      assert(level &lt; num_non_empty_levels());</a>
<a name="ln1408">    }</a>
<a name="ln1409">  }</a>
<a name="ln1410">  assert(compaction_level_.size() &gt; 0);</a>
<a name="ln1411">  assert(compaction_level_.size() == compaction_score_.size());</a>
<a name="ln1412">#endif</a>
<a name="ln1413">}</a>
<a name="ln1414"> </a>
<a name="ln1415">void VersionStorageInfo::UpdateNumNonEmptyLevels() {</a>
<a name="ln1416">  num_non_empty_levels_ = num_levels_;</a>
<a name="ln1417">  for (int i = num_levels_ - 1; i &gt;= 0; i--) {</a>
<a name="ln1418">    if (files_[i].size() != 0) {</a>
<a name="ln1419">      return;</a>
<a name="ln1420">    } else {</a>
<a name="ln1421">      num_non_empty_levels_ = i;</a>
<a name="ln1422">    }</a>
<a name="ln1423">  }</a>
<a name="ln1424">}</a>
<a name="ln1425"> </a>
<a name="ln1426">namespace {</a>
<a name="ln1427">// Sort `temp` based on ratio of overlapping size over file size</a>
<a name="ln1428">void SortFileByOverlappingRatio(</a>
<a name="ln1429">    const InternalKeyComparator&amp; icmp, const std::vector&lt;FileMetaData*&gt;&amp; files,</a>
<a name="ln1430">    const std::vector&lt;FileMetaData*&gt;&amp; next_level_files,</a>
<a name="ln1431">    std::vector&lt;Fsize&gt;* temp) {</a>
<a name="ln1432">  std::unordered_map&lt;uint64_t, uint64_t&gt; file_to_order;</a>
<a name="ln1433">  auto next_level_it = next_level_files.begin();</a>
<a name="ln1434"> </a>
<a name="ln1435">  for (auto&amp; file : files) {</a>
<a name="ln1436">    uint64_t overlapping_bytes = 0;</a>
<a name="ln1437">    // Skip files in next level that is smaller than current file</a>
<a name="ln1438">    while (next_level_it != next_level_files.end() &amp;&amp;</a>
<a name="ln1439">           icmp.Compare((*next_level_it)-&gt;largest.key, file-&gt;smallest.key) &lt; 0) {</a>
<a name="ln1440">      next_level_it++;</a>
<a name="ln1441">    }</a>
<a name="ln1442"> </a>
<a name="ln1443">    while (next_level_it != next_level_files.end() &amp;&amp;</a>
<a name="ln1444">           icmp.Compare((*next_level_it)-&gt;smallest.key, file-&gt;largest.key) &lt; 0) {</a>
<a name="ln1445">      overlapping_bytes += (*next_level_it)-&gt;fd.total_file_size;</a>
<a name="ln1446"> </a>
<a name="ln1447">      if (icmp.Compare((*next_level_it)-&gt;largest.key, file-&gt;largest.key) &gt; 0) {</a>
<a name="ln1448">        // next level file cross large boundary of current file.</a>
<a name="ln1449">        break;</a>
<a name="ln1450">      }</a>
<a name="ln1451">      next_level_it++;</a>
<a name="ln1452">    }</a>
<a name="ln1453"> </a>
<a name="ln1454">    assert(file-&gt;fd.total_file_size != 0);</a>
<a name="ln1455">    file_to_order[file-&gt;fd.GetNumber()] =</a>
<a name="ln1456">        overlapping_bytes * 1024u / file-&gt;fd.total_file_size;</a>
<a name="ln1457">  }</a>
<a name="ln1458"> </a>
<a name="ln1459">  std::sort(temp-&gt;begin(), temp-&gt;end(),</a>
<a name="ln1460">            [&amp;](const Fsize&amp; f1, const Fsize&amp; f2) -&gt; bool {</a>
<a name="ln1461">              return file_to_order[f1.file-&gt;fd.GetNumber()] &lt;</a>
<a name="ln1462">                     file_to_order[f2.file-&gt;fd.GetNumber()];</a>
<a name="ln1463">            });</a>
<a name="ln1464">}</a>
<a name="ln1465">}  // namespace</a>
<a name="ln1466"> </a>
<a name="ln1467">void VersionStorageInfo::UpdateFilesByCompactionPri(</a>
<a name="ln1468">    const MutableCFOptions&amp; mutable_cf_options) {</a>
<a name="ln1469">  if (compaction_style_ == kCompactionStyleFIFO ||</a>
<a name="ln1470">      compaction_style_ == kCompactionStyleUniversal) {</a>
<a name="ln1471">    // don't need this</a>
<a name="ln1472">    return;</a>
<a name="ln1473">  }</a>
<a name="ln1474">  // No need to sort the highest level because it is never compacted.</a>
<a name="ln1475">  for (int level = 0; level &lt; num_levels() - 1; level++) {</a>
<a name="ln1476">    const std::vector&lt;FileMetaData*&gt;&amp; files = files_[level];</a>
<a name="ln1477">    auto&amp; files_by_compaction_pri = files_by_compaction_pri_[level];</a>
<a name="ln1478">    assert(files_by_compaction_pri.size() == 0);</a>
<a name="ln1479"> </a>
<a name="ln1480">    // populate a temp vector for sorting based on size</a>
<a name="ln1481">    std::vector&lt;Fsize&gt; temp(files.size());</a>
<a name="ln1482">    for (size_t i = 0; i &lt; files.size(); i++) {</a>
<a name="ln1483">      temp[i].index = i;</a>
<a name="ln1484">      temp[i].file = files[i];</a>
<a name="ln1485">    }</a>
<a name="ln1486"> </a>
<a name="ln1487">    // sort the top number_of_files_to_sort_ based on file size</a>
<a name="ln1488">    size_t num = VersionStorageInfo::kNumberFilesToSort;</a>
<a name="ln1489">    if (num &gt; temp.size()) {</a>
<a name="ln1490">      num = temp.size();</a>
<a name="ln1491">    }</a>
<a name="ln1492">    switch (mutable_cf_options.compaction_pri) {</a>
<a name="ln1493">      case kByCompensatedSize:</a>
<a name="ln1494">        std::partial_sort(temp.begin(), temp.begin() + num, temp.end(),</a>
<a name="ln1495">                          CompareCompensatedSizeDescending);</a>
<a name="ln1496">        break;</a>
<a name="ln1497">      case kOldestLargestSeqFirst:</a>
<a name="ln1498">        std::sort(temp.begin(), temp.end(),</a>
<a name="ln1499">                  [](const Fsize&amp; f1, const Fsize&amp; f2) -&gt; bool {</a>
<a name="ln1500">                    return f1.file-&gt;largest.seqno &lt; f2.file-&gt;largest.seqno;</a>
<a name="ln1501">                  });</a>
<a name="ln1502">        break;</a>
<a name="ln1503">      case kOldestSmallestSeqFirst:</a>
<a name="ln1504">        std::sort(temp.begin(), temp.end(),</a>
<a name="ln1505">                  [](const Fsize&amp; f1, const Fsize&amp; f2) -&gt; bool {</a>
<a name="ln1506">                    return f1.file-&gt;smallest.seqno &lt; f2.file-&gt;smallest.seqno;</a>
<a name="ln1507">                  });</a>
<a name="ln1508">        break;</a>
<a name="ln1509">      case kMinOverlappingRatio:</a>
<a name="ln1510">        SortFileByOverlappingRatio(*internal_comparator_, files_[level],</a>
<a name="ln1511">                                   files_[level + 1], &amp;temp);</a>
<a name="ln1512">        break;</a>
<a name="ln1513">      default:</a>
<a name="ln1514">        assert(false);</a>
<a name="ln1515">    }</a>
<a name="ln1516">    assert(temp.size() == files.size());</a>
<a name="ln1517"> </a>
<a name="ln1518">    // initialize files_by_compaction_pri_</a>
<a name="ln1519">    for (size_t i = 0; i &lt; temp.size(); i++) {</a>
<a name="ln1520">      files_by_compaction_pri.push_back(static_cast&lt;int&gt;(temp[i].index));</a>
<a name="ln1521">    }</a>
<a name="ln1522">    next_file_to_compact_by_size_[level] = 0;</a>
<a name="ln1523">    assert(files_[level].size() == files_by_compaction_pri_[level].size());</a>
<a name="ln1524">  }</a>
<a name="ln1525">}</a>
<a name="ln1526"> </a>
<a name="ln1527">void VersionStorageInfo::GenerateLevel0NonOverlapping() {</a>
<a name="ln1528">  assert(!finalized_);</a>
<a name="ln1529">  level0_non_overlapping_ = true;</a>
<a name="ln1530">  if (level_files_brief_.size() == 0) {</a>
<a name="ln1531">    return;</a>
<a name="ln1532">  }</a>
<a name="ln1533"> </a>
<a name="ln1534">  // A copy of L0 files sorted by smallest key</a>
<a name="ln1535">  std::vector&lt;FdWithBoundaries&gt; level0_sorted_file(</a>
<a name="ln1536">      level_files_brief_[0].files,</a>
<a name="ln1537">      level_files_brief_[0].files + level_files_brief_[0].num_files);</a>
<a name="ln1538">  sort(level0_sorted_file.begin(), level0_sorted_file.end(),</a>
<a name="ln1539">       [this](const FdWithBoundaries&amp; f1, const FdWithBoundaries&amp; f2)-&gt;bool {</a>
<a name="ln1540">    return (internal_comparator_-&gt;Compare(f1.smallest.key, f2.smallest.key) &lt; 0);</a>
<a name="ln1541">  });</a>
<a name="ln1542"> </a>
<a name="ln1543">  for (size_t i = 1; i &lt; level0_sorted_file.size(); ++i) {</a>
<a name="ln1544">    auto&amp; f = level0_sorted_file[i];</a>
<a name="ln1545">    auto&amp; prev = level0_sorted_file[i - 1];</a>
<a name="ln1546">    if (internal_comparator_-&gt;Compare(prev.largest.key, f.smallest.key) &gt;= 0) {</a>
<a name="ln1547">      level0_non_overlapping_ = false;</a>
<a name="ln1548">      break;</a>
<a name="ln1549">    }</a>
<a name="ln1550">  }</a>
<a name="ln1551">}</a>
<a name="ln1552"> </a>
<a name="ln1553">void Version::Ref() {</a>
<a name="ln1554">  ++refs_;</a>
<a name="ln1555">}</a>
<a name="ln1556"> </a>
<a name="ln1557">bool Version::Unref() {</a>
<a name="ln1558">  assert(refs_ &gt;= 1);</a>
<a name="ln1559">  --refs_;</a>
<a name="ln1560">  if (refs_ == 0) {</a>
<a name="ln1561">    delete this;</a>
<a name="ln1562">    return true;</a>
<a name="ln1563">  }</a>
<a name="ln1564">  return false;</a>
<a name="ln1565">}</a>
<a name="ln1566"> </a>
<a name="ln1567">bool VersionStorageInfo::OverlapInLevel(int level,</a>
<a name="ln1568">                                        const Slice* smallest_user_key,</a>
<a name="ln1569">                                        const Slice* largest_user_key) {</a>
<a name="ln1570">  if (level &gt;= num_non_empty_levels_) {</a>
<a name="ln1571">    // empty level, no overlap</a>
<a name="ln1572">    return false;</a>
<a name="ln1573">  }</a>
<a name="ln1574">  return SomeFileOverlapsRange(*internal_comparator_, (level &gt; 0),</a>
<a name="ln1575">                               level_files_brief_[level], smallest_user_key,</a>
<a name="ln1576">                               largest_user_key);</a>
<a name="ln1577">}</a>
<a name="ln1578"> </a>
<a name="ln1579">// Store in &quot;*inputs&quot; all files in &quot;level&quot; that overlap [begin,end]</a>
<a name="ln1580">// If hint_index is specified, then it points to a file in the</a>
<a name="ln1581">// overlapping range.</a>
<a name="ln1582">// The file_index returns a pointer to any file in an overlapping range.</a>
<a name="ln1583">void VersionStorageInfo::GetOverlappingInputs(</a>
<a name="ln1584">    int level, const InternalKey* begin, const InternalKey* end,</a>
<a name="ln1585">    std::vector&lt;FileMetaData*&gt;* inputs, int hint_index, int* file_index,</a>
<a name="ln1586">    bool expand_range) const {</a>
<a name="ln1587">  if (level &gt;= num_non_empty_levels_) {</a>
<a name="ln1588">    // this level is empty, no overlapping inputs</a>
<a name="ln1589">    return;</a>
<a name="ln1590">  }</a>
<a name="ln1591"> </a>
<a name="ln1592">  inputs-&gt;clear();</a>
<a name="ln1593">  Slice user_begin, user_end;</a>
<a name="ln1594">  if (begin != nullptr) {</a>
<a name="ln1595">    user_begin = begin-&gt;user_key();</a>
<a name="ln1596">  }</a>
<a name="ln1597">  if (end != nullptr) {</a>
<a name="ln1598">    user_end = end-&gt;user_key();</a>
<a name="ln1599">  }</a>
<a name="ln1600">  if (file_index) {</a>
<a name="ln1601">    *file_index = -1;</a>
<a name="ln1602">  }</a>
<a name="ln1603">  const Comparator* user_cmp = user_comparator_;</a>
<a name="ln1604">  if (begin != nullptr &amp;&amp; end != nullptr &amp;&amp; level &gt; 0) {</a>
<a name="ln1605">    GetOverlappingInputsBinarySearch(level, user_begin, user_end, inputs,</a>
<a name="ln1606">      hint_index, file_index);</a>
<a name="ln1607">    return;</a>
<a name="ln1608">  }</a>
<a name="ln1609">  for (size_t i = 0; i &lt; level_files_brief_[level].num_files; ) {</a>
<a name="ln1610">    auto* f = &amp;(level_files_brief_[level].files[i++]);</a>
<a name="ln1611">    const Slice file_start = f-&gt;smallest.user_key();</a>
<a name="ln1612">    const Slice file_limit = f-&gt;largest.user_key();</a>
<a name="ln1613">    if (begin != nullptr &amp;&amp; user_cmp-&gt;Compare(file_limit, user_begin) &lt; 0) {</a>
<a name="ln1614">      // &quot;f&quot; is completely before specified range; skip it</a>
<a name="ln1615">    } else if (end != nullptr &amp;&amp; user_cmp-&gt;Compare(file_start, user_end) &gt; 0) {</a>
<a name="ln1616">      // &quot;f&quot; is completely after specified range; skip it</a>
<a name="ln1617">    } else {</a>
<a name="ln1618">      inputs-&gt;push_back(files_[level][i-1]);</a>
<a name="ln1619">      if (level == 0 &amp;&amp; expand_range) {</a>
<a name="ln1620">        // Level-0 files may overlap each other.  So check if the newly</a>
<a name="ln1621">        // added file has expanded the range.  If so, restart search.</a>
<a name="ln1622">        if (begin != nullptr &amp;&amp; user_cmp-&gt;Compare(file_start, user_begin) &lt; 0) {</a>
<a name="ln1623">          user_begin = file_start;</a>
<a name="ln1624">          inputs-&gt;clear();</a>
<a name="ln1625">          i = 0;</a>
<a name="ln1626">        } else if (end != nullptr</a>
<a name="ln1627">            &amp;&amp; user_cmp-&gt;Compare(file_limit, user_end) &gt; 0) {</a>
<a name="ln1628">          user_end = file_limit;</a>
<a name="ln1629">          inputs-&gt;clear();</a>
<a name="ln1630">          i = 0;</a>
<a name="ln1631">        }</a>
<a name="ln1632">      } else if (file_index) {</a>
<a name="ln1633">        *file_index = static_cast&lt;int&gt;(i) - 1;</a>
<a name="ln1634">      }</a>
<a name="ln1635">    }</a>
<a name="ln1636">  }</a>
<a name="ln1637">}</a>
<a name="ln1638"> </a>
<a name="ln1639">// Store in &quot;*inputs&quot; all files in &quot;level&quot; that overlap [begin,end]</a>
<a name="ln1640">// Employ binary search to find at least one file that overlaps the</a>
<a name="ln1641">// specified range. From that file, iterate backwards and</a>
<a name="ln1642">// forwards to find all overlapping files.</a>
<a name="ln1643">void VersionStorageInfo::GetOverlappingInputsBinarySearch(</a>
<a name="ln1644">    int level, const Slice&amp; user_begin, const Slice&amp; user_end,</a>
<a name="ln1645">    std::vector&lt;FileMetaData*&gt;* inputs, int hint_index, int* file_index) const {</a>
<a name="ln1646">  assert(level &gt; 0);</a>
<a name="ln1647">  int min = 0;</a>
<a name="ln1648">  int mid = 0;</a>
<a name="ln1649">  int max = static_cast&lt;int&gt;(files_[level].size()) - 1;</a>
<a name="ln1650">  bool foundOverlap = false;</a>
<a name="ln1651">  const Comparator* user_cmp = user_comparator_;</a>
<a name="ln1652"> </a>
<a name="ln1653">  // if the caller already knows the index of a file that has overlap,</a>
<a name="ln1654">  // then we can skip the binary search.</a>
<a name="ln1655">  if (hint_index != -1) {</a>
<a name="ln1656">    mid = hint_index;</a>
<a name="ln1657">    foundOverlap = true;</a>
<a name="ln1658">  }</a>
<a name="ln1659"> </a>
<a name="ln1660">  while (!foundOverlap &amp;&amp; min &lt;= max) {</a>
<a name="ln1661">    mid = (min + max)/2;</a>
<a name="ln1662">    FdWithBoundaries* f = level_files_brief_[level].files + mid;</a>
<a name="ln1663">    const Slice file_start = f-&gt;smallest.user_key();</a>
<a name="ln1664">    const Slice file_limit = f-&gt;largest.user_key();</a>
<a name="ln1665">    if (user_cmp-&gt;Compare(file_limit, user_begin) &lt; 0) {</a>
<a name="ln1666">      min = mid + 1;</a>
<a name="ln1667">    } else if (user_cmp-&gt;Compare(user_end, file_start) &lt; 0) {</a>
<a name="ln1668">      max = mid - 1;</a>
<a name="ln1669">    } else {</a>
<a name="ln1670">      foundOverlap = true;</a>
<a name="ln1671">      break;</a>
<a name="ln1672">    }</a>
<a name="ln1673">  }</a>
<a name="ln1674"> </a>
<a name="ln1675">  // If there were no overlapping files, return immediately.</a>
<a name="ln1676">  if (!foundOverlap) {</a>
<a name="ln1677">    return;</a>
<a name="ln1678">  }</a>
<a name="ln1679">  // returns the index where an overlap is found</a>
<a name="ln1680">  if (file_index) {</a>
<a name="ln1681">    *file_index = mid;</a>
<a name="ln1682">  }</a>
<a name="ln1683">  ExtendOverlappingInputs(level, user_begin, user_end, inputs, mid);</a>
<a name="ln1684">}</a>
<a name="ln1685"> </a>
<a name="ln1686">// Store in &quot;*inputs&quot; all files in &quot;level&quot; that overlap [begin,end]</a>
<a name="ln1687">// The midIndex specifies the index of at least one file that</a>
<a name="ln1688">// overlaps the specified range. From that file, iterate backward</a>
<a name="ln1689">// and forward to find all overlapping files.</a>
<a name="ln1690">// Use FileLevel in searching, make it faster</a>
<a name="ln1691">void VersionStorageInfo::ExtendOverlappingInputs(</a>
<a name="ln1692">    int level, const Slice&amp; user_begin, const Slice&amp; user_end,</a>
<a name="ln1693">    std::vector&lt;FileMetaData*&gt;* inputs, unsigned int midIndex) const {</a>
<a name="ln1694">  const Comparator* user_cmp = user_comparator_;</a>
<a name="ln1695">  const FdWithBoundaries* files = level_files_brief_[level].files;</a>
<a name="ln1696">#ifndef NDEBUG</a>
<a name="ln1697">  {</a>
<a name="ln1698">    // assert that the file at midIndex overlaps with the range</a>
<a name="ln1699">    assert(midIndex &lt; level_files_brief_[level].num_files);</a>
<a name="ln1700">    const auto* f = &amp;files[midIndex];</a>
<a name="ln1701">    const Slice fstart = f-&gt;smallest.user_key();</a>
<a name="ln1702">    const Slice flimit = f-&gt;largest.user_key();</a>
<a name="ln1703">    if (user_cmp-&gt;Compare(fstart, user_begin) &gt;= 0) {</a>
<a name="ln1704">      assert(user_cmp-&gt;Compare(fstart, user_end) &lt;= 0);</a>
<a name="ln1705">    } else {</a>
<a name="ln1706">      assert(user_cmp-&gt;Compare(flimit, user_begin) &gt;= 0);</a>
<a name="ln1707">    }</a>
<a name="ln1708">  }</a>
<a name="ln1709">#endif</a>
<a name="ln1710">  int startIndex = midIndex + 1;</a>
<a name="ln1711">  int endIndex = midIndex;</a>
<a name="ln1712">  int count __attribute__((unused)) = 0;</a>
<a name="ln1713"> </a>
<a name="ln1714">  // check backwards from 'mid' to lower indices</a>
<a name="ln1715">  for (int i = midIndex; i &gt;= 0 ; i--) {</a>
<a name="ln1716">    const auto* f = &amp;files[i];</a>
<a name="ln1717">    const Slice file_limit = f-&gt;largest.user_key();</a>
<a name="ln1718">    if (user_cmp-&gt;Compare(file_limit, user_begin) &gt;= 0) {</a>
<a name="ln1719">      startIndex = i;</a>
<a name="ln1720">      assert((count++, true));</a>
<a name="ln1721">    } else {</a>
<a name="ln1722">      break;</a>
<a name="ln1723">    }</a>
<a name="ln1724">  }</a>
<a name="ln1725">  // check forward from 'mid+1' to higher indices</a>
<a name="ln1726">  for (unsigned int i = midIndex+1;</a>
<a name="ln1727">       i &lt; level_files_brief_[level].num_files; i++) {</a>
<a name="ln1728">    const auto* f = &amp;files[i];</a>
<a name="ln1729">    const Slice file_start = f-&gt;smallest.user_key();</a>
<a name="ln1730">    if (user_cmp-&gt;Compare(file_start, user_end) &lt;= 0) {</a>
<a name="ln1731">      assert((count++, true));</a>
<a name="ln1732">      endIndex = i;</a>
<a name="ln1733">    } else {</a>
<a name="ln1734">      break;</a>
<a name="ln1735">    }</a>
<a name="ln1736">  }</a>
<a name="ln1737">  assert(count == endIndex - startIndex + 1);</a>
<a name="ln1738"> </a>
<a name="ln1739">  // insert overlapping files into vector</a>
<a name="ln1740">  for (int i = startIndex; i &lt;= endIndex; i++) {</a>
<a name="ln1741">    FileMetaData* f = files_[level][i];</a>
<a name="ln1742">    inputs-&gt;push_back(f);</a>
<a name="ln1743">  }</a>
<a name="ln1744">}</a>
<a name="ln1745"> </a>
<a name="ln1746">// Returns true iff the first or last file in inputs contains</a>
<a name="ln1747">// an overlapping user key to the file &quot;just outside&quot; of it (i.e.</a>
<a name="ln1748">// just after the last file, or just before the first file)</a>
<a name="ln1749">// REQUIRES: &quot;*inputs&quot; is a sorted list of non-overlapping files</a>
<a name="ln1750">bool VersionStorageInfo::HasOverlappingUserKey(</a>
<a name="ln1751">    const std::vector&lt;FileMetaData*&gt;* inputs, int level) {</a>
<a name="ln1752"> </a>
<a name="ln1753">  // If inputs empty, there is no overlap.</a>
<a name="ln1754">  // If level == 0, it is assumed that all needed files were already included.</a>
<a name="ln1755">  if (inputs-&gt;empty() || level == 0) {</a>
<a name="ln1756">    return false;</a>
<a name="ln1757">  }</a>
<a name="ln1758"> </a>
<a name="ln1759">  const Comparator* user_cmp = user_comparator_;</a>
<a name="ln1760">  const rocksdb::LevelFilesBrief&amp; file_level = level_files_brief_[level];</a>
<a name="ln1761">  const FdWithBoundaries* files = level_files_brief_[level].files;</a>
<a name="ln1762">  const size_t kNumFiles = file_level.num_files;</a>
<a name="ln1763"> </a>
<a name="ln1764">  // Check the last file in inputs against the file after it</a>
<a name="ln1765">  size_t last_file = FindFile(*internal_comparator_, file_level,</a>
<a name="ln1766">                              inputs-&gt;back()-&gt;largest.key.Encode());</a>
<a name="ln1767">  assert(last_file &lt; kNumFiles);  // File should exist!</a>
<a name="ln1768">  if (last_file &lt; kNumFiles-1) {                    // If not the last file</a>
<a name="ln1769">    const Slice last_key_in_input = files[last_file].largest.user_key();</a>
<a name="ln1770">    const Slice first_key_after = files[last_file+1].smallest.user_key();</a>
<a name="ln1771">    if (user_cmp-&gt;Equal(last_key_in_input, first_key_after)) {</a>
<a name="ln1772">      // The last user key in input overlaps with the next file's first key</a>
<a name="ln1773">      return true;</a>
<a name="ln1774">    }</a>
<a name="ln1775">  }</a>
<a name="ln1776"> </a>
<a name="ln1777">  // Check the first file in inputs against the file just before it</a>
<a name="ln1778">  size_t first_file = FindFile(*internal_comparator_, file_level,</a>
<a name="ln1779">                               inputs-&gt;front()-&gt;smallest.key.Encode());</a>
<a name="ln1780">  assert(first_file &lt;= last_file);   // File should exist!</a>
<a name="ln1781">  if (first_file &gt; 0) {                                 // If not first file</a>
<a name="ln1782">    const Slice&amp; first_key_in_input = files[first_file].smallest.user_key();</a>
<a name="ln1783">    const Slice&amp; last_key_before = files[first_file-1].largest.user_key();</a>
<a name="ln1784">    if (user_cmp-&gt;Equal(first_key_in_input, last_key_before)) {</a>
<a name="ln1785">      // The first user key in input overlaps with the previous file's last key</a>
<a name="ln1786">      return true;</a>
<a name="ln1787">    }</a>
<a name="ln1788">  }</a>
<a name="ln1789"> </a>
<a name="ln1790">  return false;</a>
<a name="ln1791">}</a>
<a name="ln1792"> </a>
<a name="ln1793">uint64_t VersionStorageInfo::NumLevelBytes(int level) const {</a>
<a name="ln1794">  assert(level &gt;= 0);</a>
<a name="ln1795">  assert(level &lt; num_levels());</a>
<a name="ln1796">  return TotalFileSize(files_[level]);</a>
<a name="ln1797">}</a>
<a name="ln1798"> </a>
<a name="ln1799">const char* VersionStorageInfo::LevelSummary(</a>
<a name="ln1800">    LevelSummaryStorage* scratch) const {</a>
<a name="ln1801">  int len = 0;</a>
<a name="ln1802">  if (compaction_style_ == kCompactionStyleLevel &amp;&amp; num_levels() &gt; 1) {</a>
<a name="ln1803">    assert(base_level_ &lt; static_cast&lt;int&gt;(level_max_bytes_.size()));</a>
<a name="ln1804">    len = snprintf(scratch-&gt;buffer, sizeof(scratch-&gt;buffer),</a>
<a name="ln1805">                   &quot;base level %d max bytes base %&quot; PRIu64 &quot; &quot;, base_level_,</a>
<a name="ln1806">                   level_max_bytes_[base_level_]);</a>
<a name="ln1807">  }</a>
<a name="ln1808">  len +=</a>
<a name="ln1809">      snprintf(scratch-&gt;buffer + len, sizeof(scratch-&gt;buffer) - len, &quot;files[&quot;);</a>
<a name="ln1810">  for (int i = 0; i &lt; num_levels(); i++) {</a>
<a name="ln1811">    int sz = sizeof(scratch-&gt;buffer) - len;</a>
<a name="ln1812">    int ret = snprintf(scratch-&gt;buffer + len, sz, &quot;%zd &quot;, files_[i].size());</a>
<a name="ln1813">    if (ret &lt; 0 || ret &gt;= sz) break;</a>
<a name="ln1814">    len += ret;</a>
<a name="ln1815">  }</a>
<a name="ln1816">  if (len &gt; 0) {</a>
<a name="ln1817">    // overwrite the last space</a>
<a name="ln1818">    --len;</a>
<a name="ln1819">  }</a>
<a name="ln1820">  len += snprintf(scratch-&gt;buffer + len, sizeof(scratch-&gt;buffer) - len,</a>
<a name="ln1821">                  &quot;] max score %.2f&quot;, compaction_score_[0]);</a>
<a name="ln1822"> </a>
<a name="ln1823">  if (!files_marked_for_compaction_.empty()) {</a>
<a name="ln1824">    snprintf(scratch-&gt;buffer + len, sizeof(scratch-&gt;buffer) - len,</a>
<a name="ln1825">             &quot; (%&quot; ROCKSDB_PRIszt &quot; files need compaction)&quot;,</a>
<a name="ln1826">             files_marked_for_compaction_.size());</a>
<a name="ln1827">  }</a>
<a name="ln1828"> </a>
<a name="ln1829">  return scratch-&gt;buffer;</a>
<a name="ln1830">}</a>
<a name="ln1831"> </a>
<a name="ln1832">const char* VersionStorageInfo::LevelFileSummary(FileSummaryStorage* scratch,</a>
<a name="ln1833">                                                 int level) const {</a>
<a name="ln1834">  int len = snprintf(scratch-&gt;buffer, sizeof(scratch-&gt;buffer), &quot;files_size[&quot;);</a>
<a name="ln1835">  for (const auto&amp; f : files_[level]) {</a>
<a name="ln1836">    int sz = sizeof(scratch-&gt;buffer) - len;</a>
<a name="ln1837">    char sztxt[16];</a>
<a name="ln1838">    AppendHumanBytes(f-&gt;fd.GetTotalFileSize(), sztxt, sizeof(sztxt));</a>
<a name="ln1839">    int ret = snprintf(scratch-&gt;buffer + len, sz,</a>
<a name="ln1840">                       &quot;#%&quot; PRIu64 &quot;(seq=%&quot; PRIu64 &quot;,sz=%s,%d) &quot;,</a>
<a name="ln1841">                       f-&gt;fd.GetNumber(), f-&gt;smallest.seqno, sztxt,</a>
<a name="ln1842">                       static_cast&lt;int&gt;(f-&gt;being_compacted));</a>
<a name="ln1843">    if (ret &lt; 0 || ret &gt;= sz)</a>
<a name="ln1844">      break;</a>
<a name="ln1845">    len += ret;</a>
<a name="ln1846">  }</a>
<a name="ln1847">  // overwrite the last space (only if files_[level].size() is non-zero)</a>
<a name="ln1848">  if (files_[level].size() &amp;&amp; len &gt; 0) {</a>
<a name="ln1849">    --len;</a>
<a name="ln1850">  }</a>
<a name="ln1851">  snprintf(scratch-&gt;buffer + len, sizeof(scratch-&gt;buffer) - len, &quot;]&quot;);</a>
<a name="ln1852">  return scratch-&gt;buffer;</a>
<a name="ln1853">}</a>
<a name="ln1854"> </a>
<a name="ln1855">int64_t VersionStorageInfo::MaxNextLevelOverlappingBytes() {</a>
<a name="ln1856">  uint64_t result = 0;</a>
<a name="ln1857">  std::vector&lt;FileMetaData*&gt; overlaps;</a>
<a name="ln1858">  for (int level = 1; level &lt; num_levels() - 1; level++) {</a>
<a name="ln1859">    for (const auto&amp; f : files_[level]) {</a>
<a name="ln1860">      GetOverlappingInputs(level + 1, &amp;f-&gt;smallest.key, &amp;f-&gt;largest.key, &amp;overlaps);</a>
<a name="ln1861">      const uint64_t sum = TotalFileSize(overlaps);</a>
<a name="ln1862">      if (sum &gt; result) {</a>
<a name="ln1863">        result = sum;</a>
<a name="ln1864">      }</a>
<a name="ln1865">    }</a>
<a name="ln1866">  }</a>
<a name="ln1867">  return result;</a>
<a name="ln1868">}</a>
<a name="ln1869"> </a>
<a name="ln1870">uint64_t VersionStorageInfo::MaxBytesForLevel(int level) const {</a>
<a name="ln1871">  // Note: the result for level zero is not really used since we set</a>
<a name="ln1872">  // the level-0 compaction threshold based on number of files.</a>
<a name="ln1873">  assert(level &gt;= 0);</a>
<a name="ln1874">  assert(level &lt; static_cast&lt;int&gt;(level_max_bytes_.size()));</a>
<a name="ln1875">  return level_max_bytes_[level];</a>
<a name="ln1876">}</a>
<a name="ln1877"> </a>
<a name="ln1878">void VersionStorageInfo::CalculateBaseBytes(const ImmutableCFOptions&amp; ioptions,</a>
<a name="ln1879">                                            const MutableCFOptions&amp; options) {</a>
<a name="ln1880">  // Special logic to set number of sorted runs.</a>
<a name="ln1881">  // It is to match the previous behavior when all files are in L0.</a>
<a name="ln1882">  int num_l0_count = 0;</a>
<a name="ln1883">  if (options.max_file_size_for_compaction == std::numeric_limits&lt;uint64_t&gt;::max()) {</a>
<a name="ln1884">    num_l0_count = static_cast&lt;int&gt;(files_[0].size());</a>
<a name="ln1885">  } else {</a>
<a name="ln1886">    for (const auto&amp; file : files_[0]) {</a>
<a name="ln1887">      if (file-&gt;fd.GetTotalFileSize() &lt;= options.max_file_size_for_compaction) {</a>
<a name="ln1888">        ++num_l0_count;</a>
<a name="ln1889">      }</a>
<a name="ln1890">    }</a>
<a name="ln1891">  }</a>
<a name="ln1892">  if (compaction_style_ == kCompactionStyleUniversal) {</a>
<a name="ln1893">    // For universal compaction, we use level0 score to indicate</a>
<a name="ln1894">    // compaction score for the whole DB. Adding other levels as if</a>
<a name="ln1895">    // they are L0 files.</a>
<a name="ln1896">    for (int i = 1; i &lt; num_levels(); i++) {</a>
<a name="ln1897">      if (!files_[i].empty()) {</a>
<a name="ln1898">        num_l0_count++;</a>
<a name="ln1899">      }</a>
<a name="ln1900">    }</a>
<a name="ln1901">  }</a>
<a name="ln1902">  set_l0_delay_trigger_count(num_l0_count);</a>
<a name="ln1903"> </a>
<a name="ln1904">  level_max_bytes_.resize(ioptions.num_levels);</a>
<a name="ln1905">  if (!ioptions.level_compaction_dynamic_level_bytes) {</a>
<a name="ln1906">    base_level_ = (ioptions.compaction_style == kCompactionStyleLevel) ? 1 : -1;</a>
<a name="ln1907"> </a>
<a name="ln1908">    // Calculate for static bytes base case</a>
<a name="ln1909">    for (int i = 0; i &lt; ioptions.num_levels; ++i) {</a>
<a name="ln1910">      if (i == 0 &amp;&amp; ioptions.compaction_style == kCompactionStyleUniversal) {</a>
<a name="ln1911">        level_max_bytes_[i] = options.max_bytes_for_level_base;</a>
<a name="ln1912">      } else if (i &gt; 1) {</a>
<a name="ln1913">        level_max_bytes_[i] = MultiplyCheckOverflow(</a>
<a name="ln1914">            MultiplyCheckOverflow(level_max_bytes_[i - 1],</a>
<a name="ln1915">                                  options.max_bytes_for_level_multiplier),</a>
<a name="ln1916">            options.MaxBytesMultiplerAdditional(i - 1));</a>
<a name="ln1917">      } else {</a>
<a name="ln1918">        level_max_bytes_[i] = options.max_bytes_for_level_base;</a>
<a name="ln1919">      }</a>
<a name="ln1920">    }</a>
<a name="ln1921">  } else {</a>
<a name="ln1922">    uint64_t max_level_size = 0;</a>
<a name="ln1923"> </a>
<a name="ln1924">    int first_non_empty_level = -1;</a>
<a name="ln1925">    // Find size of non-L0 level of most data.</a>
<a name="ln1926">    // Cannot use the size of the last level because it can be empty or less</a>
<a name="ln1927">    // than previous levels after compaction.</a>
<a name="ln1928">    for (int i = 1; i &lt; num_levels_; i++) {</a>
<a name="ln1929">      uint64_t total_size = 0;</a>
<a name="ln1930">      for (const auto&amp; f : files_[i]) {</a>
<a name="ln1931">        total_size += f-&gt;fd.GetTotalFileSize();</a>
<a name="ln1932">      }</a>
<a name="ln1933">      if (total_size &gt; 0 &amp;&amp; first_non_empty_level == -1) {</a>
<a name="ln1934">        first_non_empty_level = i;</a>
<a name="ln1935">      }</a>
<a name="ln1936">      if (total_size &gt; max_level_size) {</a>
<a name="ln1937">        max_level_size = total_size;</a>
<a name="ln1938">      }</a>
<a name="ln1939">    }</a>
<a name="ln1940"> </a>
<a name="ln1941">    // Prefill every level's max bytes to disallow compaction from there.</a>
<a name="ln1942">    for (int i = 0; i &lt; num_levels_; i++) {</a>
<a name="ln1943">      level_max_bytes_[i] = std::numeric_limits&lt;uint64_t&gt;::max();</a>
<a name="ln1944">    }</a>
<a name="ln1945"> </a>
<a name="ln1946">    if (max_level_size == 0) {</a>
<a name="ln1947">      // No data for L1 and up. L0 compacts to last level directly.</a>
<a name="ln1948">      // No compaction from L1+ needs to be scheduled.</a>
<a name="ln1949">      base_level_ = num_levels_ - 1;</a>
<a name="ln1950">    } else {</a>
<a name="ln1951">      uint64_t base_bytes_max = options.max_bytes_for_level_base;</a>
<a name="ln1952">      uint64_t base_bytes_min =</a>
<a name="ln1953">          base_bytes_max / options.max_bytes_for_level_multiplier;</a>
<a name="ln1954"> </a>
<a name="ln1955">      // Try whether we can make last level's target size to be max_level_size</a>
<a name="ln1956">      uint64_t cur_level_size = max_level_size;</a>
<a name="ln1957">      for (int i = num_levels_ - 2; i &gt;= first_non_empty_level; i--) {</a>
<a name="ln1958">        // Round up after dividing</a>
<a name="ln1959">        cur_level_size /= options.max_bytes_for_level_multiplier;</a>
<a name="ln1960">      }</a>
<a name="ln1961"> </a>
<a name="ln1962">      // Calculate base level and its size.</a>
<a name="ln1963">      uint64_t base_level_size;</a>
<a name="ln1964">      if (cur_level_size &lt;= base_bytes_min) {</a>
<a name="ln1965">        // Case 1. If we make target size of last level to be max_level_size,</a>
<a name="ln1966">        // target size of the first non-empty level would be smaller than</a>
<a name="ln1967">        // base_bytes_min. We set it be base_bytes_min.</a>
<a name="ln1968">        base_level_size = base_bytes_min + 1U;</a>
<a name="ln1969">        base_level_ = first_non_empty_level;</a>
<a name="ln1970">        RWARN(ioptions.info_log,</a>
<a name="ln1971">            &quot;More existing levels in DB than needed. &quot;</a>
<a name="ln1972">                &quot;max_bytes_for_level_multiplier may not be guaranteed.&quot;);</a>
<a name="ln1973">      } else {</a>
<a name="ln1974">        // Find base level (where L0 data is compacted to).</a>
<a name="ln1975">        base_level_ = first_non_empty_level;</a>
<a name="ln1976">        while (base_level_ &gt; 1 &amp;&amp; cur_level_size &gt; base_bytes_max) {</a>
<a name="ln1977">          --base_level_;</a>
<a name="ln1978">          cur_level_size =</a>
<a name="ln1979">              cur_level_size / options.max_bytes_for_level_multiplier;</a>
<a name="ln1980">        }</a>
<a name="ln1981">        if (cur_level_size &gt; base_bytes_max) {</a>
<a name="ln1982">          // Even L1 will be too large</a>
<a name="ln1983">          assert(base_level_ == 1);</a>
<a name="ln1984">          base_level_size = base_bytes_max;</a>
<a name="ln1985">        } else {</a>
<a name="ln1986">          base_level_size = cur_level_size;</a>
<a name="ln1987">        }</a>
<a name="ln1988">      }</a>
<a name="ln1989"> </a>
<a name="ln1990">      uint64_t level_size = base_level_size;</a>
<a name="ln1991">      for (int i = base_level_; i &lt; num_levels_; i++) {</a>
<a name="ln1992">        if (i &gt; base_level_) {</a>
<a name="ln1993">          level_size = MultiplyCheckOverflow(</a>
<a name="ln1994">              level_size, options.max_bytes_for_level_multiplier);</a>
<a name="ln1995">        }</a>
<a name="ln1996">        level_max_bytes_[i] = level_size;</a>
<a name="ln1997">      }</a>
<a name="ln1998">    }</a>
<a name="ln1999">  }</a>
<a name="ln2000">}</a>
<a name="ln2001"> </a>
<a name="ln2002">uint64_t VersionStorageInfo::EstimateLiveDataSize() const {</a>
<a name="ln2003">  // Estimate the live data size by adding up the size of the last level for all</a>
<a name="ln2004">  // key ranges. Note: Estimate depends on the ordering of files in level 0</a>
<a name="ln2005">  // because files in level 0 can be overlapping.</a>
<a name="ln2006">  uint64_t size = 0;</a>
<a name="ln2007"> </a>
<a name="ln2008">  auto ikey_lt = [this](InternalKey* x, InternalKey* y) {</a>
<a name="ln2009">    return internal_comparator_-&gt;Compare(*x, *y) &lt; 0;</a>
<a name="ln2010">  };</a>
<a name="ln2011">  // (Ordered) map of largest keys in non-overlapping files</a>
<a name="ln2012">  std::map&lt;InternalKey*, FileMetaData*, decltype(ikey_lt)&gt; ranges(ikey_lt);</a>
<a name="ln2013"> </a>
<a name="ln2014">  for (int l = num_levels_ - 1; l &gt;= 0; l--) {</a>
<a name="ln2015">    bool found_end = false;</a>
<a name="ln2016">    for (auto file : files_[l]) {</a>
<a name="ln2017">      // Find the first file where the largest key is larger than the smallest</a>
<a name="ln2018">      // key of the current file. If this file does not overlap with the</a>
<a name="ln2019">      // current file, none of the files in the map does. If there is</a>
<a name="ln2020">      // no potential overlap, we can safely insert the rest of this level</a>
<a name="ln2021">      // (if the level is not 0) into the map without checking again because</a>
<a name="ln2022">      // the elements in the level are sorted and non-overlapping.</a>
<a name="ln2023">      auto lb = (found_end &amp;&amp; l != 0) ?</a>
<a name="ln2024">        ranges.end() : ranges.lower_bound(&amp;file-&gt;smallest.key);</a>
<a name="ln2025">      found_end = (lb == ranges.end());</a>
<a name="ln2026">      if (found_end || internal_comparator_-&gt;Compare(</a>
<a name="ln2027">            file-&gt;largest.key, (*lb).second-&gt;smallest.key) &lt; 0) {</a>
<a name="ln2028">          ranges.emplace_hint(lb, &amp;file-&gt;largest.key, file);</a>
<a name="ln2029">          size += file-&gt;fd.total_file_size;</a>
<a name="ln2030">      }</a>
<a name="ln2031">    }</a>
<a name="ln2032">  }</a>
<a name="ln2033">  return size;</a>
<a name="ln2034">}</a>
<a name="ln2035"> </a>
<a name="ln2036"> </a>
<a name="ln2037">void Version::AddLiveFiles(std::vector&lt;FileDescriptor&gt;* live) {</a>
<a name="ln2038">  for (int level = 0; level &lt; storage_info_.num_levels(); level++) {</a>
<a name="ln2039">    const std::vector&lt;FileMetaData*&gt;&amp; files = storage_info_.files_[level];</a>
<a name="ln2040">    for (const auto&amp; file : files) {</a>
<a name="ln2041">      live-&gt;push_back(file-&gt;fd);</a>
<a name="ln2042">    }</a>
<a name="ln2043">  }</a>
<a name="ln2044">}</a>
<a name="ln2045"> </a>
<a name="ln2046">std::string Version::DebugString(bool hex) const {</a>
<a name="ln2047">  std::string r;</a>
<a name="ln2048">  for (int level = 0; level &lt; storage_info_.num_levels_; level++) {</a>
<a name="ln2049">    // E.g.,</a>
<a name="ln2050">    //   --- level 1 ---</a>
<a name="ln2051">    //   17:123['a' .. 'd']</a>
<a name="ln2052">    //   20:43['e' .. 'g']</a>
<a name="ln2053">    r.append(&quot;--- level &quot;);</a>
<a name="ln2054">    AppendNumberTo(&amp;r, level);</a>
<a name="ln2055">    r.append(&quot; --- version# &quot;);</a>
<a name="ln2056">    AppendNumberTo(&amp;r, version_number_);</a>
<a name="ln2057">    r.append(&quot; ---\n&quot;);</a>
<a name="ln2058">    const std::vector&lt;FileMetaData*&gt;&amp; files = storage_info_.files_[level];</a>
<a name="ln2059">    for (size_t i = 0; i &lt; files.size(); i++) {</a>
<a name="ln2060">      r.append(files[i]-&gt;ToString());</a>
<a name="ln2061">    }</a>
<a name="ln2062">  }</a>
<a name="ln2063">  return r;</a>
<a name="ln2064">}</a>
<a name="ln2065"> </a>
<a name="ln2066">Result&lt;std::string&gt; Version::GetMiddleKey() {</a>
<a name="ln2067">  // Largest files are at lowest level.</a>
<a name="ln2068">  const auto level = storage_info_.num_levels_ - 1;</a>
<a name="ln2069">  const FileMetaData* largest_sst_meta = nullptr;</a>
<a name="ln2070">  for (const auto* file : storage_info_.files_[level]) {</a>
<a name="ln2071">    if (!largest_sst_meta ||</a>
<a name="ln2072">        file-&gt;fd.GetTotalFileSize() &gt; largest_sst_meta-&gt;fd.GetTotalFileSize()) {</a>
<a name="ln2073">      largest_sst_meta = file;</a>
<a name="ln2074">    }</a>
<a name="ln2075">  }</a>
<a name="ln2076">  if (!largest_sst_meta) {</a>
<a name="ln2077">    return STATUS(Incomplete, &quot;No SST files.&quot;);</a>
<a name="ln2078">  }</a>
<a name="ln2079"> </a>
<a name="ln2080">  const auto trwh = VERIFY_RESULT(table_cache_-&gt;GetTableReader(</a>
<a name="ln2081">      vset_-&gt;env_options_, cfd_-&gt;internal_comparator(), largest_sst_meta-&gt;fd, kDefaultQueryId,</a>
<a name="ln2082">      /* no_io =*/ false, cfd_-&gt;internal_stats()-&gt;GetFileReadHist(level),</a>
<a name="ln2083">      IsFilterSkipped(level, /* is_file_last_in_level =*/ true)));</a>
<a name="ln2084">  return trwh.table_reader-&gt;GetMiddleKey();</a>
<a name="ln2085">}</a>
<a name="ln2086"> </a>
<a name="ln2087">// this is used to batch writes to the manifest file</a>
<a name="ln2088">struct VersionSet::ManifestWriter {</a>
<a name="ln2089">  Status status;</a>
<a name="ln2090">  bool done;</a>
<a name="ln2091">  InstrumentedCondVar cv;</a>
<a name="ln2092">  ColumnFamilyData* cfd;</a>
<a name="ln2093">  VersionEdit* edit;</a>
<a name="ln2094"> </a>
<a name="ln2095">  explicit ManifestWriter(InstrumentedMutex* mu, ColumnFamilyData* _cfd,</a>
<a name="ln2096">                          VersionEdit* e)</a>
<a name="ln2097">      : done(false), cv(mu), cfd(_cfd), edit(e) {}</a>
<a name="ln2098">};</a>
<a name="ln2099"> </a>
<a name="ln2100">constexpr uint64_t VersionSet::kInitialNextFileNumber;</a>
<a name="ln2101"> </a>
<a name="ln2102">VersionSet::VersionSet(const std::string&amp; dbname, const DBOptions* db_options,</a>
<a name="ln2103">                       const EnvOptions&amp; storage_options, Cache* table_cache,</a>
<a name="ln2104">                       WriteBuffer* write_buffer,</a>
<a name="ln2105">                       WriteController* write_controller)</a>
<a name="ln2106">    : column_family_set_(new ColumnFamilySet(</a>
<a name="ln2107">          dbname, db_options, storage_options, table_cache,</a>
<a name="ln2108">          write_buffer, write_controller)),</a>
<a name="ln2109">      env_(db_options-&gt;env),</a>
<a name="ln2110">      dbname_(dbname),</a>
<a name="ln2111">      db_options_(db_options),</a>
<a name="ln2112">      env_options_(storage_options),</a>
<a name="ln2113">      env_options_compactions_(env_options_) {}</a>
<a name="ln2114"> </a>
<a name="ln2115">VersionSet::~VersionSet() {</a>
<a name="ln2116">  // we need to delete column_family_set_ because its destructor depends on</a>
<a name="ln2117">  // VersionSet</a>
<a name="ln2118">  column_family_set_.reset();</a>
<a name="ln2119">  for (auto file : obsolete_files_) {</a>
<a name="ln2120">    delete file;</a>
<a name="ln2121">  }</a>
<a name="ln2122">  obsolete_files_.clear();</a>
<a name="ln2123">}</a>
<a name="ln2124"> </a>
<a name="ln2125">void VersionSet::AppendVersion(ColumnFamilyData* column_family_data,</a>
<a name="ln2126">                               Version* v) {</a>
<a name="ln2127">  // compute new compaction score</a>
<a name="ln2128">  v-&gt;storage_info()-&gt;ComputeCompactionScore(</a>
<a name="ln2129">      *column_family_data-&gt;GetLatestMutableCFOptions(),</a>
<a name="ln2130">      column_family_data-&gt;ioptions()-&gt;compaction_options_fifo);</a>
<a name="ln2131"> </a>
<a name="ln2132">  // Mark v finalized</a>
<a name="ln2133">  v-&gt;storage_info_.SetFinalized();</a>
<a name="ln2134"> </a>
<a name="ln2135">  // Make &quot;v&quot; current</a>
<a name="ln2136">  assert(v-&gt;refs_ == 0);</a>
<a name="ln2137">  Version* current = column_family_data-&gt;current();</a>
<a name="ln2138">  assert(v != current);</a>
<a name="ln2139">  if (current != nullptr) {</a>
<a name="ln2140">    assert(current-&gt;refs_ &gt; 0);</a>
<a name="ln2141">    current-&gt;Unref();</a>
<a name="ln2142">  }</a>
<a name="ln2143">  column_family_data-&gt;SetCurrent(v);</a>
<a name="ln2144">  v-&gt;Ref();</a>
<a name="ln2145"> </a>
<a name="ln2146">  // Append to linked list</a>
<a name="ln2147">  v-&gt;prev_ = column_family_data-&gt;dummy_versions()-&gt;prev_;</a>
<a name="ln2148">  v-&gt;next_ = column_family_data-&gt;dummy_versions();</a>
<a name="ln2149">  v-&gt;prev_-&gt;next_ = v;</a>
<a name="ln2150">  v-&gt;next_-&gt;prev_ = v;</a>
<a name="ln2151">}</a>
<a name="ln2152"> </a>
<a name="ln2153">Status VersionSet::LogAndApply(ColumnFamilyData* column_family_data,</a>
<a name="ln2154">                               const MutableCFOptions&amp; mutable_cf_options,</a>
<a name="ln2155">                               VersionEdit* edit, InstrumentedMutex* mu,</a>
<a name="ln2156">                               Directory* db_directory, bool new_descriptor_log,</a>
<a name="ln2157">                               const ColumnFamilyOptions* new_cf_options) {</a>
<a name="ln2158">  mu-&gt;AssertHeld();</a>
<a name="ln2159"> </a>
<a name="ln2160">  // column_family_data can be nullptr only if this is column_family_add.</a>
<a name="ln2161">  // in that case, we also need to specify ColumnFamilyOptions</a>
<a name="ln2162">  if (column_family_data == nullptr) {</a>
<a name="ln2163">    assert(edit-&gt;column_family_name_);</a>
<a name="ln2164">    assert(new_cf_options != nullptr);</a>
<a name="ln2165">  }</a>
<a name="ln2166"> </a>
<a name="ln2167">  // queue our request</a>
<a name="ln2168">  ManifestWriter w(mu, column_family_data, edit);</a>
<a name="ln2169">  manifest_writers_.push_back(&amp;w);</a>
<a name="ln2170">  while (!w.done &amp;&amp; &amp;w != manifest_writers_.front()) {</a>
<a name="ln2171">    w.cv.Wait();</a>
<a name="ln2172">  }</a>
<a name="ln2173">  if (w.done) {</a>
<a name="ln2174">    return w.status;</a>
<a name="ln2175">  }</a>
<a name="ln2176">  if (column_family_data != nullptr &amp;&amp; column_family_data-&gt;IsDropped()) {</a>
<a name="ln2177">    // if column family is dropped by the time we get here, no need to write</a>
<a name="ln2178">    // anything to the manifest</a>
<a name="ln2179">    manifest_writers_.pop_front();</a>
<a name="ln2180">    // Notify new head of write queue</a>
<a name="ln2181">    if (!manifest_writers_.empty()) {</a>
<a name="ln2182">      manifest_writers_.front()-&gt;cv.Signal();</a>
<a name="ln2183">    }</a>
<a name="ln2184">    // we steal this code to also inform about cf-drop</a>
<a name="ln2185">    return STATUS(ShutdownInProgress, &quot;&quot;);</a>
<a name="ln2186">  }</a>
<a name="ln2187"> </a>
<a name="ln2188">  std::vector&lt;VersionEdit*&gt; batch_edits;</a>
<a name="ln2189">  Version* v = nullptr;</a>
<a name="ln2190">  std::unique_ptr&lt;BaseReferencedVersionBuilder&gt; builder_guard(nullptr);</a>
<a name="ln2191"> </a>
<a name="ln2192">  // Process all requests in the queue.</a>
<a name="ln2193">  ManifestWriter* last_writer = &amp;w;</a>
<a name="ln2194">  assert(!manifest_writers_.empty());</a>
<a name="ln2195">  assert(manifest_writers_.front() == &amp;w);</a>
<a name="ln2196"> </a>
<a name="ln2197">  UserFrontierPtr flushed_frontier_override;</a>
<a name="ln2198">  if (edit-&gt;IsColumnFamilyManipulation()) {</a>
<a name="ln2199">    // No group commits for column family add or drop.</a>
<a name="ln2200">    LogAndApplyCFHelper(edit);</a>
<a name="ln2201">    batch_edits.push_back(edit);</a>
<a name="ln2202">  } else {</a>
<a name="ln2203">    v = new Version(column_family_data, this, current_version_number_++);</a>
<a name="ln2204">    builder_guard.reset(new BaseReferencedVersionBuilder(column_family_data));</a>
<a name="ln2205">    auto* builder = builder_guard-&gt;version_builder();</a>
<a name="ln2206">    for (const auto&amp; writer : manifest_writers_) {</a>
<a name="ln2207">      if (writer-&gt;edit-&gt;IsColumnFamilyManipulation() ||</a>
<a name="ln2208">          writer-&gt;cfd-&gt;GetID() != column_family_data-&gt;GetID()) {</a>
<a name="ln2209">        // No group commits for column family add or drop.</a>
<a name="ln2210">        // Also, group commits across column families are not supported.</a>
<a name="ln2211">        break;</a>
<a name="ln2212">      }</a>
<a name="ln2213">      FrontierModificationMode frontier_mode = FrontierModificationMode::kUpdate;</a>
<a name="ln2214">      const bool force_flushed_frontier = writer-&gt;edit-&gt;force_flushed_frontier_;</a>
<a name="ln2215">      if (force_flushed_frontier) {</a>
<a name="ln2216">        if (writer != &amp;w) {</a>
<a name="ln2217">          // No group commit for edits that force a particular value of flushed frontier, either.</a>
<a name="ln2218">          // (Also see the logic at the end of the for loop body.)</a>
<a name="ln2219">          break;</a>
<a name="ln2220">        }</a>
<a name="ln2221">        new_descriptor_log = true;</a>
<a name="ln2222">        flushed_frontier_override = edit-&gt;flushed_frontier_;</a>
<a name="ln2223">      }</a>
<a name="ln2224">      last_writer = writer;</a>
<a name="ln2225">      LogAndApplyHelper(column_family_data, builder, last_writer-&gt;edit, mu);</a>
<a name="ln2226">      batch_edits.push_back(last_writer-&gt;edit);</a>
<a name="ln2227"> </a>
<a name="ln2228">      if (force_flushed_frontier) {</a>
<a name="ln2229">        // This is also needed to disable group commit for flushed-frontier-forcing edits.</a>
<a name="ln2230">        break;</a>
<a name="ln2231">      }</a>
<a name="ln2232">    }</a>
<a name="ln2233"> </a>
<a name="ln2234">    builder-&gt;SaveTo(v-&gt;storage_info());</a>
<a name="ln2235">  }</a>
<a name="ln2236"> </a>
<a name="ln2237">  // Initialize new descriptor log file if necessary by creating</a>
<a name="ln2238">  // a temporary file that contains a snapshot of the current version.</a>
<a name="ln2239">  uint64_t new_manifest_file_size = 0;</a>
<a name="ln2240">  Status s;</a>
<a name="ln2241"> </a>
<a name="ln2242">  assert(pending_manifest_file_number_ == 0);</a>
<a name="ln2243">  if (!descriptor_log_ ||</a>
<a name="ln2244">      manifest_file_size_ &gt; db_options_-&gt;max_manifest_file_size) {</a>
<a name="ln2245">    pending_manifest_file_number_ = NewFileNumber();</a>
<a name="ln2246">    batch_edits.back()-&gt;SetNextFile(next_file_number_.load());</a>
<a name="ln2247">    new_descriptor_log = true;</a>
<a name="ln2248">  } else {</a>
<a name="ln2249">    pending_manifest_file_number_ = manifest_file_number_;</a>
<a name="ln2250">  }</a>
<a name="ln2251"> </a>
<a name="ln2252">  if (new_descriptor_log) {</a>
<a name="ln2253">    // If we're writing out new snapshot make sure to persist max column family.</a>
<a name="ln2254">    if (column_family_set_-&gt;GetMaxColumnFamily() &gt; 0) {</a>
<a name="ln2255">      edit-&gt;SetMaxColumnFamily(column_family_set_-&gt;GetMaxColumnFamily());</a>
<a name="ln2256">    }</a>
<a name="ln2257">  }</a>
<a name="ln2258"> </a>
<a name="ln2259">  // Unlock during expensive operations. New writes cannot get here</a>
<a name="ln2260">  // because &amp;w is ensuring that all new writes get queued.</a>
<a name="ln2261">  {</a>
<a name="ln2262"> </a>
<a name="ln2263">    mu-&gt;Unlock();</a>
<a name="ln2264"> </a>
<a name="ln2265">    TEST_SYNC_POINT(&quot;VersionSet::LogAndApply:WriteManifest&quot;);</a>
<a name="ln2266">    if (!edit-&gt;IsColumnFamilyManipulation() &amp;&amp;</a>
<a name="ln2267">        db_options_-&gt;max_open_files == -1) {</a>
<a name="ln2268">      // unlimited table cache. Pre-load table handle now.</a>
<a name="ln2269">      // Need to do it out of the mutex.</a>
<a name="ln2270">      builder_guard-&gt;version_builder()-&gt;LoadTableHandlers(</a>
<a name="ln2271">          column_family_data-&gt;internal_stats(),</a>
<a name="ln2272">          column_family_data-&gt;ioptions()-&gt;optimize_filters_for_hits);</a>
<a name="ln2273">    }</a>
<a name="ln2274"> </a>
<a name="ln2275">    // This is fine because everything inside of this block is serialized --</a>
<a name="ln2276">    // only one thread can be here at the same time.</a>
<a name="ln2277">    if (new_descriptor_log) {</a>
<a name="ln2278">      // Create a new manifest file.</a>
<a name="ln2279">      RLOG(InfoLogLevel::INFO_LEVEL, db_options_-&gt;info_log,</a>
<a name="ln2280">          &quot;Creating manifest %&quot; PRIu64 &quot;\n&quot;, pending_manifest_file_number_);</a>
<a name="ln2281">      unique_ptr&lt;WritableFile&gt; descriptor_file;</a>
<a name="ln2282">      EnvOptions opt_env_opts = env_-&gt;OptimizeForManifestWrite(env_options_);</a>
<a name="ln2283">      descriptor_log_file_name_ = DescriptorFileName(dbname_, pending_manifest_file_number_);</a>
<a name="ln2284">      s = NewWritableFile(</a>
<a name="ln2285">          env_, descriptor_log_file_name_,</a>
<a name="ln2286">          &amp;descriptor_file, opt_env_opts);</a>
<a name="ln2287">      if (s.ok()) {</a>
<a name="ln2288">        descriptor_file-&gt;SetPreallocationBlockSize(</a>
<a name="ln2289">            db_options_-&gt;manifest_preallocation_size);</a>
<a name="ln2290"> </a>
<a name="ln2291">        unique_ptr&lt;WritableFileWriter&gt; file_writer(</a>
<a name="ln2292">            new WritableFileWriter(std::move(descriptor_file), opt_env_opts));</a>
<a name="ln2293">        descriptor_log_.reset(new log::Writer(</a>
<a name="ln2294">            std::move(file_writer), /* log_number */ 0, /* recycle_log_files */ false));</a>
<a name="ln2295">        // This will write a snapshot containing metadata for all files in this DB. If we are</a>
<a name="ln2296">        // forcing a particular value of the flushed frontier, we need to set it in this snapshot</a>
<a name="ln2297">        // version edit as well.</a>
<a name="ln2298">        s = WriteSnapshot(descriptor_log_.get(), flushed_frontier_override);</a>
<a name="ln2299">      } else {</a>
<a name="ln2300">        descriptor_log_file_name_ = &quot;&quot;;</a>
<a name="ln2301">      }</a>
<a name="ln2302">    }</a>
<a name="ln2303"> </a>
<a name="ln2304">    if (!edit-&gt;IsColumnFamilyManipulation()) {</a>
<a name="ln2305">      // This is cpu-heavy operations, which should be called outside mutex.</a>
<a name="ln2306">      v-&gt;PrepareApply(mutable_cf_options, true);</a>
<a name="ln2307">    }</a>
<a name="ln2308"> </a>
<a name="ln2309">    // Write new records to MANIFEST log.</a>
<a name="ln2310">    if (s.ok()) {</a>
<a name="ln2311">      for (auto&amp; e : batch_edits) {</a>
<a name="ln2312">        std::string record;</a>
<a name="ln2313">        if (!e-&gt;AppendEncodedTo(&amp;record)) {</a>
<a name="ln2314">          s = STATUS(Corruption,</a>
<a name="ln2315">              &quot;Unable to Encode VersionEdit:&quot; + e-&gt;DebugString(true));</a>
<a name="ln2316">          break;</a>
<a name="ln2317">        }</a>
<a name="ln2318">        TEST_KILL_RANDOM(&quot;VersionSet::LogAndApply:BeforeAddRecord&quot;,</a>
<a name="ln2319">                         rocksdb_kill_odds * REDUCE_ODDS2);</a>
<a name="ln2320">        s = descriptor_log_-&gt;AddRecord(record);</a>
<a name="ln2321">        if (!s.ok()) {</a>
<a name="ln2322">          break;</a>
<a name="ln2323">        }</a>
<a name="ln2324">      }</a>
<a name="ln2325">      if (s.ok()) {</a>
<a name="ln2326">        s = SyncManifest(env_, db_options_, descriptor_log_-&gt;file());</a>
<a name="ln2327">      }</a>
<a name="ln2328">      if (!s.ok()) {</a>
<a name="ln2329">        RLOG(InfoLogLevel::ERROR_LEVEL, db_options_-&gt;info_log,</a>
<a name="ln2330">            &quot;MANIFEST write: %s\n&quot;, s.ToString().c_str());</a>
<a name="ln2331">      }</a>
<a name="ln2332">    }</a>
<a name="ln2333"> </a>
<a name="ln2334">    std::string obsolete_manifest;</a>
<a name="ln2335">    // If we just created a new descriptor file, install it by writing a</a>
<a name="ln2336">    // new CURRENT file that points to it.</a>
<a name="ln2337">    if (s.ok() &amp;&amp; new_descriptor_log) {</a>
<a name="ln2338">      s = SetCurrentFile(env_, dbname_, pending_manifest_file_number_, db_directory,</a>
<a name="ln2339">        db_options_-&gt;disableDataSync);</a>
<a name="ln2340">      // Leave the old file behind since PurgeObsoleteFiles will take care of it</a>
<a name="ln2341">      // later. It's unsafe to delete now since file deletion may be disabled.</a>
<a name="ln2342">      obsolete_manifest = DescriptorFileName(&quot;&quot;, manifest_file_number_);</a>
<a name="ln2343">    }</a>
<a name="ln2344"> </a>
<a name="ln2345">    if (s.ok()) {</a>
<a name="ln2346">      // find offset in manifest file where this version is stored.</a>
<a name="ln2347">      s = db_options_-&gt;get_checkpoint_env()-&gt;GetFileSize(</a>
<a name="ln2348">          descriptor_log_file_name_, &amp;new_manifest_file_size);</a>
<a name="ln2349">    }</a>
<a name="ln2350"> </a>
<a name="ln2351">    if (edit-&gt;is_column_family_drop_) {</a>
<a name="ln2352">      TEST_SYNC_POINT(&quot;VersionSet::LogAndApply::ColumnFamilyDrop:0&quot;);</a>
<a name="ln2353">      TEST_SYNC_POINT(&quot;VersionSet::LogAndApply::ColumnFamilyDrop:1&quot;);</a>
<a name="ln2354">      TEST_SYNC_POINT(&quot;VersionSet::LogAndApply::ColumnFamilyDrop:2&quot;);</a>
<a name="ln2355">    }</a>
<a name="ln2356"> </a>
<a name="ln2357">    LogFlush(db_options_-&gt;info_log);</a>
<a name="ln2358">    TEST_SYNC_POINT(&quot;VersionSet::LogAndApply:WriteManifestDone&quot;);</a>
<a name="ln2359">    mu-&gt;Lock();</a>
<a name="ln2360"> </a>
<a name="ln2361">    if (!obsolete_manifest.empty()) {</a>
<a name="ln2362">      obsolete_manifests_.push_back(std::move(obsolete_manifest));</a>
<a name="ln2363">    }</a>
<a name="ln2364">  }</a>
<a name="ln2365"> </a>
<a name="ln2366">  // Install the new version</a>
<a name="ln2367">  if (s.ok()) {</a>
<a name="ln2368">    if (edit-&gt;column_family_name_) {</a>
<a name="ln2369">      // no group commit on column family add</a>
<a name="ln2370">      assert(batch_edits.size() == 1);</a>
<a name="ln2371">      assert(new_cf_options != nullptr);</a>
<a name="ln2372">      CreateColumnFamily(*new_cf_options, edit);</a>
<a name="ln2373">    } else if (edit-&gt;is_column_family_drop_) {</a>
<a name="ln2374">      assert(batch_edits.size() == 1);</a>
<a name="ln2375">      column_family_data-&gt;SetDropped();</a>
<a name="ln2376">      if (column_family_data-&gt;Unref()) {</a>
<a name="ln2377">        delete column_family_data;</a>
<a name="ln2378">      }</a>
<a name="ln2379">    } else {</a>
<a name="ln2380">      uint64_t max_log_number_in_batch  = 0;</a>
<a name="ln2381">      for (auto&amp; e : batch_edits) {</a>
<a name="ln2382">        if (e-&gt;log_number_) {</a>
<a name="ln2383">          max_log_number_in_batch =</a>
<a name="ln2384">              std::max(max_log_number_in_batch, *e-&gt;log_number_);</a>
<a name="ln2385">        }</a>
<a name="ln2386">      }</a>
<a name="ln2387">      if (max_log_number_in_batch != 0) {</a>
<a name="ln2388">        assert(column_family_data-&gt;GetLogNumber() &lt;= max_log_number_in_batch);</a>
<a name="ln2389">        column_family_data-&gt;SetLogNumber(max_log_number_in_batch);</a>
<a name="ln2390">      }</a>
<a name="ln2391">      AppendVersion(column_family_data, v);</a>
<a name="ln2392">    }</a>
<a name="ln2393"> </a>
<a name="ln2394">    manifest_file_number_ = pending_manifest_file_number_;</a>
<a name="ln2395">    manifest_file_size_ = new_manifest_file_size;</a>
<a name="ln2396">    prev_log_number_ = edit-&gt;prev_log_number_.get_value_or(0);</a>
<a name="ln2397">    if (flushed_frontier_override) {</a>
<a name="ln2398">      flushed_frontier_ = flushed_frontier_override;</a>
<a name="ln2399">    } else if (edit-&gt;flushed_frontier_) {</a>
<a name="ln2400">      UpdateFlushedFrontier(edit-&gt;flushed_frontier_);</a>
<a name="ln2401">    }</a>
<a name="ln2402">  } else {</a>
<a name="ln2403">    RLOG(InfoLogLevel::ERROR_LEVEL, db_options_-&gt;info_log,</a>
<a name="ln2404">        &quot;Error in committing version %&quot; PRIu64 &quot; to [%s]&quot;,</a>
<a name="ln2405">        v-&gt;GetVersionNumber(),</a>
<a name="ln2406">        column_family_data ? column_family_data-&gt;GetName().c_str()</a>
<a name="ln2407">                           : &quot;&lt;null&gt;&quot;);</a>
<a name="ln2408">    delete v;</a>
<a name="ln2409">    if (new_descriptor_log) {</a>
<a name="ln2410">      RLOG(InfoLogLevel::INFO_LEVEL, db_options_-&gt;info_log,</a>
<a name="ln2411">        &quot;Deleting manifest %&quot; PRIu64 &quot; current manifest %&quot; PRIu64 &quot;\n&quot;,</a>
<a name="ln2412">        manifest_file_number_, pending_manifest_file_number_);</a>
<a name="ln2413">      descriptor_log_.reset();</a>
<a name="ln2414">      env_-&gt;CleanupFile(</a>
<a name="ln2415">          DescriptorFileName(dbname_, pending_manifest_file_number_));</a>
<a name="ln2416">    }</a>
<a name="ln2417">  }</a>
<a name="ln2418">  pending_manifest_file_number_ = 0;</a>
<a name="ln2419"> </a>
<a name="ln2420">  // wake up all the waiting writers</a>
<a name="ln2421">  while (true) {</a>
<a name="ln2422">    ManifestWriter* ready = manifest_writers_.front();</a>
<a name="ln2423">    manifest_writers_.pop_front();</a>
<a name="ln2424">    if (ready != &amp;w) {</a>
<a name="ln2425">      ready-&gt;status = s;</a>
<a name="ln2426">      ready-&gt;done = true;</a>
<a name="ln2427">      ready-&gt;cv.Signal();</a>
<a name="ln2428">    }</a>
<a name="ln2429">    if (ready == last_writer) break;</a>
<a name="ln2430">  }</a>
<a name="ln2431">  // Notify new head of write queue</a>
<a name="ln2432">  if (!manifest_writers_.empty()) {</a>
<a name="ln2433">    manifest_writers_.front()-&gt;cv.Signal();</a>
<a name="ln2434">  }</a>
<a name="ln2435">  return s;</a>
<a name="ln2436">}</a>
<a name="ln2437"> </a>
<a name="ln2438">void VersionSet::LogAndApplyCFHelper(VersionEdit* edit) {</a>
<a name="ln2439">  assert(edit-&gt;IsColumnFamilyManipulation());</a>
<a name="ln2440">  edit-&gt;SetNextFile(next_file_number_.load());</a>
<a name="ln2441">  edit-&gt;SetLastSequence(LastSequence());</a>
<a name="ln2442">  if (edit-&gt;is_column_family_drop_) {</a>
<a name="ln2443">    // if we drop column family, we have to make sure to save max column family,</a>
<a name="ln2444">    // so that we don't reuse existing ID</a>
<a name="ln2445">    edit-&gt;SetMaxColumnFamily(column_family_set_-&gt;GetMaxColumnFamily());</a>
<a name="ln2446">  }</a>
<a name="ln2447">}</a>
<a name="ln2448"> </a>
<a name="ln2449">void VersionSet::LogAndApplyHelper(</a>
<a name="ln2450">    ColumnFamilyData* cfd,</a>
<a name="ln2451">    VersionBuilder* builder,</a>
<a name="ln2452">    VersionEdit* edit,</a>
<a name="ln2453">    InstrumentedMutex* mu) {</a>
<a name="ln2454">  mu-&gt;AssertHeld();</a>
<a name="ln2455">  assert(!edit-&gt;IsColumnFamilyManipulation());</a>
<a name="ln2456"> </a>
<a name="ln2457">  if (edit-&gt;log_number_) {</a>
<a name="ln2458">    assert(edit-&gt;log_number_ &gt;= cfd-&gt;GetLogNumber());</a>
<a name="ln2459">    assert(edit-&gt;log_number_ &lt; next_file_number_.load());</a>
<a name="ln2460">  }</a>
<a name="ln2461"> </a>
<a name="ln2462">  if (!edit-&gt;prev_log_number_) {</a>
<a name="ln2463">    edit-&gt;SetPrevLogNumber(prev_log_number_);</a>
<a name="ln2464">  }</a>
<a name="ln2465">  edit-&gt;SetNextFile(next_file_number_.load());</a>
<a name="ln2466">  edit-&gt;SetLastSequence(LastSequence());</a>
<a name="ln2467"> </a>
<a name="ln2468">  if (flushed_frontier_ &amp;&amp; !edit-&gt;force_flushed_frontier_) {</a>
<a name="ln2469">    edit-&gt;UpdateFlushedFrontier(flushed_frontier_);</a>
<a name="ln2470">  }</a>
<a name="ln2471"> </a>
<a name="ln2472">  builder-&gt;Apply(edit);</a>
<a name="ln2473">}</a>
<a name="ln2474"> </a>
<a name="ln2475">namespace {</a>
<a name="ln2476"> </a>
<a name="ln2477">struct LogReporter : public log::Reader::Reporter {</a>
<a name="ln2478">  Status* status;</a>
<a name="ln2479">  virtual void Corruption(size_t bytes, const Status&amp; s) override {</a>
<a name="ln2480">    if (this-&gt;status-&gt;ok()) *this-&gt;status = s;</a>
<a name="ln2481">  }</a>
<a name="ln2482">};</a>
<a name="ln2483"> </a>
<a name="ln2484">class ManifestReader {</a>
<a name="ln2485"> public:</a>
<a name="ln2486">  ManifestReader(Env* env, Env* checkpoint_env, const EnvOptions&amp; env_options,</a>
<a name="ln2487">                 BoundaryValuesExtractor* extractor, const std::string&amp; dbname)</a>
<a name="ln2488">      : env_(env), checkpoint_env_(checkpoint_env), env_options_(env_options),</a>
<a name="ln2489">        extractor_(extractor), dbname_(dbname) {}</a>
<a name="ln2490"> </a>
<a name="ln2491">  Status OpenManifest() {</a>
<a name="ln2492">    auto status = ReadManifestFilename();</a>
<a name="ln2493">    if (!status.ok()) {</a>
<a name="ln2494">      return status;</a>
<a name="ln2495">    }</a>
<a name="ln2496">    FileType type;</a>
<a name="ln2497">    bool parse_ok = ParseFileName(manifest_filename_, &amp;manifest_file_number_, &amp;type);</a>
<a name="ln2498">    if (!parse_ok || type != kDescriptorFile) {</a>
<a name="ln2499">      return STATUS(Corruption, &quot;CURRENT file corrupted&quot;);</a>
<a name="ln2500">    }</a>
<a name="ln2501"> </a>
<a name="ln2502">    manifest_filename_ = dbname_ + &quot;/&quot; + manifest_filename_;</a>
<a name="ln2503">    std::unique_ptr&lt;SequentialFileReader&gt; manifest_file_reader;</a>
<a name="ln2504">    {</a>
<a name="ln2505">      std::unique_ptr&lt;SequentialFile&gt; manifest_file;</a>
<a name="ln2506">      status = env_-&gt;NewSequentialFile(manifest_filename_, &amp;manifest_file, env_options_);</a>
<a name="ln2507">      if (!status.ok()) {</a>
<a name="ln2508">        return status;</a>
<a name="ln2509">      }</a>
<a name="ln2510">      manifest_file_reader.reset(new SequentialFileReader(std::move(manifest_file)));</a>
<a name="ln2511">    }</a>
<a name="ln2512">    status = checkpoint_env_-&gt;GetFileSize(manifest_filename_, &amp;current_manifest_file_size_);</a>
<a name="ln2513">    if (!status.ok()) {</a>
<a name="ln2514">      return status;</a>
<a name="ln2515">    }</a>
<a name="ln2516"> </a>
<a name="ln2517">    reader_.emplace(nullptr, std::move(manifest_file_reader), &amp;reporter_, true /*checksum*/,</a>
<a name="ln2518">                    0 /*initial_offset*/, 0);</a>
<a name="ln2519">    reporter_.status = &amp;status_;</a>
<a name="ln2520"> </a>
<a name="ln2521">    return Status::OK();</a>
<a name="ln2522">  }</a>
<a name="ln2523"> </a>
<a name="ln2524">  CHECKED_STATUS Next() {</a>
<a name="ln2525">    Slice record;</a>
<a name="ln2526">    if (!reader_-&gt;ReadRecord(&amp;record, &amp;scratch_)) {</a>
<a name="ln2527">      return STATUS(EndOfFile, &quot;&quot;);</a>
<a name="ln2528">    }</a>
<a name="ln2529">    if (!status_.ok()) {</a>
<a name="ln2530">      return status_;</a>
<a name="ln2531">    }</a>
<a name="ln2532">    return edit_.DecodeFrom(extractor_, record);</a>
<a name="ln2533">  }</a>
<a name="ln2534"> </a>
<a name="ln2535">  VersionEdit&amp; operator*() {</a>
<a name="ln2536">    return edit_;</a>
<a name="ln2537">  }</a>
<a name="ln2538"> </a>
<a name="ln2539">  uint64_t manifest_file_number() const { return manifest_file_number_; }</a>
<a name="ln2540">  uint64_t current_manifest_file_size() const { return current_manifest_file_size_; }</a>
<a name="ln2541">  const std::string&amp; manifest_filename() const { return manifest_filename_; }</a>
<a name="ln2542"> private:</a>
<a name="ln2543">  CHECKED_STATUS ReadManifestFilename() {</a>
<a name="ln2544">    // Read &quot;CURRENT&quot; file, which contains a pointer to the current manifest file</a>
<a name="ln2545">    Status s = ReadFileToString(env_, CurrentFileName(dbname_), &amp;manifest_filename_);</a>
<a name="ln2546">    if (!s.ok()) {</a>
<a name="ln2547">      return s;</a>
<a name="ln2548">    }</a>
<a name="ln2549">    if (manifest_filename_.empty() || manifest_filename_.back() != '\n') {</a>
<a name="ln2550">      return STATUS(Corruption, &quot;CURRENT file does not end with newline&quot;);</a>
<a name="ln2551">    }</a>
<a name="ln2552">    // remove the trailing '\n'</a>
<a name="ln2553">    manifest_filename_.resize(manifest_filename_.size() - 1);</a>
<a name="ln2554">    return Status::OK();</a>
<a name="ln2555">  }</a>
<a name="ln2556"> </a>
<a name="ln2557">  // In plaintext cluster, this is a default env, but in encrypted cluster, this encrypts on write</a>
<a name="ln2558">  // and decrypts on read.</a>
<a name="ln2559">  Env* const env_;</a>
<a name="ln2560">  // Default env used to checkpoint files. In encrypted cluster, we don't want to decrypt</a>
<a name="ln2561">  // checkpointed files, so using the default env preserves file encryption.</a>
<a name="ln2562">  Env* const checkpoint_env_;</a>
<a name="ln2563">  const EnvOptions&amp; env_options_;</a>
<a name="ln2564">  BoundaryValuesExtractor* extractor_;</a>
<a name="ln2565">  std::string dbname_;</a>
<a name="ln2566">  std::string manifest_filename_;</a>
<a name="ln2567">  uint64_t manifest_file_number_ = 0;</a>
<a name="ln2568">  uint64_t current_manifest_file_size_ = 0;</a>
<a name="ln2569">  LogReporter reporter_;</a>
<a name="ln2570">  boost::optional&lt;log::Reader&gt; reader_;</a>
<a name="ln2571">  std::string scratch_;</a>
<a name="ln2572">  Status status_;</a>
<a name="ln2573">  VersionEdit edit_;</a>
<a name="ln2574">};</a>
<a name="ln2575"> </a>
<a name="ln2576">} // namespace</a>
<a name="ln2577"> </a>
<a name="ln2578">Status VersionSet::Recover(</a>
<a name="ln2579">    const std::vector&lt;ColumnFamilyDescriptor&gt;&amp; column_families,</a>
<a name="ln2580">    bool read_only) {</a>
<a name="ln2581">  std::unordered_map&lt;std::string, ColumnFamilyOptions&gt; cf_name_to_options;</a>
<a name="ln2582">  for (auto cf : column_families) {</a>
<a name="ln2583">    cf_name_to_options.insert({cf.name, cf.options});</a>
<a name="ln2584">  }</a>
<a name="ln2585">  // keeps track of column families in manifest that were not found in</a>
<a name="ln2586">  // column families parameters. if those column families are not dropped</a>
<a name="ln2587">  // by subsequent manifest records, Recover() will return failure status</a>
<a name="ln2588">  std::unordered_map&lt;int, std::string&gt; column_families_not_found;</a>
<a name="ln2589"> </a>
<a name="ln2590">  bool have_log_number = false;</a>
<a name="ln2591">  bool have_prev_log_number = false;</a>
<a name="ln2592">  bool have_next_file = false;</a>
<a name="ln2593">  bool have_last_sequence = false;</a>
<a name="ln2594">  UserFrontierPtr flushed_frontier;</a>
<a name="ln2595">  uint64_t next_file = 0;</a>
<a name="ln2596">  uint64_t last_sequence = 0;</a>
<a name="ln2597">  uint64_t log_number = 0;</a>
<a name="ln2598">  uint64_t previous_log_number = 0;</a>
<a name="ln2599">  uint32_t max_column_family = 0;</a>
<a name="ln2600">  std::unordered_map&lt;uint32_t, std::unique_ptr&lt;BaseReferencedVersionBuilder&gt;&gt; builders;</a>
<a name="ln2601"> </a>
<a name="ln2602">  // add default column family</a>
<a name="ln2603">  auto default_cf_iter = cf_name_to_options.find(kDefaultColumnFamilyName);</a>
<a name="ln2604">  if (default_cf_iter == cf_name_to_options.end()) {</a>
<a name="ln2605">    return STATUS(InvalidArgument, &quot;Default column family not specified&quot;);</a>
<a name="ln2606">  }</a>
<a name="ln2607">  VersionEdit default_cf_edit;</a>
<a name="ln2608">  default_cf_edit.AddColumnFamily(kDefaultColumnFamilyName);</a>
<a name="ln2609">  default_cf_edit.SetColumnFamily(0);</a>
<a name="ln2610">  ColumnFamilyData* default_cfd =</a>
<a name="ln2611">      CreateColumnFamily(default_cf_iter-&gt;second, &amp;default_cf_edit);</a>
<a name="ln2612">  builders.emplace(0, std::make_unique&lt;BaseReferencedVersionBuilder&gt;(default_cfd));</a>
<a name="ln2613"> </a>
<a name="ln2614">  Status s;</a>
<a name="ln2615">  uint64_t current_manifest_file_size;</a>
<a name="ln2616">  std::string current_manifest_filename;</a>
<a name="ln2617">  {</a>
<a name="ln2618">    ManifestReader manifest_reader(env_, db_options_-&gt;get_checkpoint_env(), env_options_,</a>
<a name="ln2619">                                   db_options_-&gt;boundary_extractor.get(), dbname_);</a>
<a name="ln2620">    auto status = manifest_reader.OpenManifest();</a>
<a name="ln2621">    if (!status.ok()) {</a>
<a name="ln2622">      return status;</a>
<a name="ln2623">    }</a>
<a name="ln2624">    current_manifest_file_size = manifest_reader.current_manifest_file_size();</a>
<a name="ln2625">    current_manifest_filename = manifest_reader.manifest_filename();</a>
<a name="ln2626">    manifest_file_number_ = manifest_reader.manifest_file_number();</a>
<a name="ln2627"> </a>
<a name="ln2628">    for (;;) {</a>
<a name="ln2629">      s = manifest_reader.Next();</a>
<a name="ln2630">      if (!s.ok()) {</a>
<a name="ln2631">        break;</a>
<a name="ln2632">      }</a>
<a name="ln2633">      auto&amp; edit = *manifest_reader;</a>
<a name="ln2634">      // Not found means that user didn't supply that column</a>
<a name="ln2635">      // family option AND we encountered column family add</a>
<a name="ln2636">      // record. Once we encounter column family drop record,</a>
<a name="ln2637">      // we will delete the column family from</a>
<a name="ln2638">      // column_families_not_found.</a>
<a name="ln2639">      bool cf_in_not_found =</a>
<a name="ln2640">          column_families_not_found.find(edit.column_family_) !=</a>
<a name="ln2641">          column_families_not_found.end();</a>
<a name="ln2642">      // in builders means that user supplied that column family</a>
<a name="ln2643">      // option AND that we encountered column family add record</a>
<a name="ln2644">      bool cf_in_builders =</a>
<a name="ln2645">          builders.find(edit.column_family_) != builders.end();</a>
<a name="ln2646"> </a>
<a name="ln2647">      // they can't both be true</a>
<a name="ln2648">      assert(!(cf_in_not_found &amp;&amp; cf_in_builders));</a>
<a name="ln2649"> </a>
<a name="ln2650">      ColumnFamilyData* cfd = nullptr;</a>
<a name="ln2651"> </a>
<a name="ln2652">      if (edit.column_family_name_) {</a>
<a name="ln2653">        if (cf_in_builders || cf_in_not_found) {</a>
<a name="ln2654">          s = STATUS(Corruption,</a>
<a name="ln2655">              &quot;Manifest adding the same column family twice&quot;);</a>
<a name="ln2656">          break;</a>
<a name="ln2657">        }</a>
<a name="ln2658">        auto cf_options = cf_name_to_options.find(*edit.column_family_name_);</a>
<a name="ln2659">        if (cf_options == cf_name_to_options.end()) {</a>
<a name="ln2660">          column_families_not_found.emplace(edit.column_family_, *edit.column_family_name_);</a>
<a name="ln2661">        } else {</a>
<a name="ln2662">          cfd = CreateColumnFamily(cf_options-&gt;second, &amp;edit);</a>
<a name="ln2663">          builders.emplace(edit.column_family_,</a>
<a name="ln2664">                           std::make_unique&lt;BaseReferencedVersionBuilder&gt;(cfd));</a>
<a name="ln2665">        }</a>
<a name="ln2666">      } else if (edit.is_column_family_drop_) {</a>
<a name="ln2667">        if (cf_in_builders) {</a>
<a name="ln2668">          auto builder = builders.find(edit.column_family_);</a>
<a name="ln2669">          assert(builder != builders.end());</a>
<a name="ln2670">          builders.erase(builder);</a>
<a name="ln2671">          cfd = column_family_set_-&gt;GetColumnFamily(edit.column_family_);</a>
<a name="ln2672">          if (cfd-&gt;Unref()) {</a>
<a name="ln2673">            delete cfd;</a>
<a name="ln2674">            cfd = nullptr;</a>
<a name="ln2675">          } else {</a>
<a name="ln2676">            // who else can have reference to cfd!?</a>
<a name="ln2677">            assert(false);</a>
<a name="ln2678">          }</a>
<a name="ln2679">        } else if (cf_in_not_found) {</a>
<a name="ln2680">          column_families_not_found.erase(edit.column_family_);</a>
<a name="ln2681">        } else {</a>
<a name="ln2682">          s = STATUS(Corruption,</a>
<a name="ln2683">              &quot;Manifest - dropping non-existing column family&quot;);</a>
<a name="ln2684">          break;</a>
<a name="ln2685">        }</a>
<a name="ln2686">      } else if (!cf_in_not_found) {</a>
<a name="ln2687">        if (!cf_in_builders) {</a>
<a name="ln2688">          s = STATUS(Corruption,</a>
<a name="ln2689">              &quot;Manifest record referencing unknown column family&quot;);</a>
<a name="ln2690">          break;</a>
<a name="ln2691">        }</a>
<a name="ln2692"> </a>
<a name="ln2693">        cfd = column_family_set_-&gt;GetColumnFamily(edit.column_family_);</a>
<a name="ln2694">        // this should never happen since cf_in_builders is true</a>
<a name="ln2695">        assert(cfd != nullptr);</a>
<a name="ln2696">        if (edit.max_level_ &gt;= cfd-&gt;current()-&gt;storage_info()-&gt;num_levels()) {</a>
<a name="ln2697">          s = STATUS(InvalidArgument,</a>
<a name="ln2698">              &quot;db has more levels than options.num_levels&quot;);</a>
<a name="ln2699">          break;</a>
<a name="ln2700">        }</a>
<a name="ln2701"> </a>
<a name="ln2702">        // if it is not column family add or column family drop,</a>
<a name="ln2703">        // then it's a file add/delete, which should be forwarded</a>
<a name="ln2704">        // to builder</a>
<a name="ln2705">        auto builder = builders.find(edit.column_family_);</a>
<a name="ln2706">        assert(builder != builders.end());</a>
<a name="ln2707">        builder-&gt;second-&gt;version_builder()-&gt;Apply(&amp;edit);</a>
<a name="ln2708">      }</a>
<a name="ln2709"> </a>
<a name="ln2710">      if (cfd != nullptr) {</a>
<a name="ln2711">        if (edit.log_number_) {</a>
<a name="ln2712">          if (cfd-&gt;GetLogNumber() &gt; edit.log_number_) {</a>
<a name="ln2713">            RLOG(InfoLogLevel::WARN_LEVEL, db_options_-&gt;info_log,</a>
<a name="ln2714">                &quot;MANIFEST corruption detected, but ignored - Log numbers in &quot;</a>
<a name="ln2715">                &quot;records NOT monotonically increasing&quot;);</a>
<a name="ln2716">          } else {</a>
<a name="ln2717">            cfd-&gt;SetLogNumber(*edit.log_number_);</a>
<a name="ln2718">            have_log_number = true;</a>
<a name="ln2719">          }</a>
<a name="ln2720">        }</a>
<a name="ln2721">        if (edit.comparator_ &amp;&amp;</a>
<a name="ln2722">            *edit.comparator_ != cfd-&gt;user_comparator()-&gt;Name()) {</a>
<a name="ln2723">          s = STATUS(InvalidArgument,</a>
<a name="ln2724">              cfd-&gt;user_comparator()-&gt;Name(),</a>
<a name="ln2725">              &quot;does not match existing comparator &quot; + *edit.comparator_);</a>
<a name="ln2726">          break;</a>
<a name="ln2727">        }</a>
<a name="ln2728">      }</a>
<a name="ln2729"> </a>
<a name="ln2730">      if (edit.prev_log_number_) {</a>
<a name="ln2731">        previous_log_number = *edit.prev_log_number_;</a>
<a name="ln2732">        have_prev_log_number = true;</a>
<a name="ln2733">      }</a>
<a name="ln2734"> </a>
<a name="ln2735">      if (edit.next_file_number_) {</a>
<a name="ln2736">        next_file = *edit.next_file_number_;</a>
<a name="ln2737">        have_next_file = true;</a>
<a name="ln2738">      }</a>
<a name="ln2739"> </a>
<a name="ln2740">      if (edit.max_column_family_) {</a>
<a name="ln2741">        max_column_family = *edit.max_column_family_;</a>
<a name="ln2742">      }</a>
<a name="ln2743"> </a>
<a name="ln2744">      if (edit.last_sequence_) {</a>
<a name="ln2745">        last_sequence = *edit.last_sequence_;</a>
<a name="ln2746">        have_last_sequence = true;</a>
<a name="ln2747">      }</a>
<a name="ln2748"> </a>
<a name="ln2749">      if (edit.flushed_frontier_) {</a>
<a name="ln2750">        UpdateUserFrontier(</a>
<a name="ln2751">            &amp;flushed_frontier, edit.flushed_frontier_, UpdateUserValueType::kLargest);</a>
<a name="ln2752">        VLOG(1) &lt;&lt; &quot;Updating flushed frontier with that from edit: &quot;</a>
<a name="ln2753">                &lt;&lt; edit.flushed_frontier_-&gt;ToString()</a>
<a name="ln2754">                &lt;&lt; &quot;, new flushed froniter: &quot; &lt;&lt; flushed_frontier-&gt;ToString();</a>
<a name="ln2755">      } else {</a>
<a name="ln2756">        VLOG(1) &lt;&lt; &quot;No flushed frontier found in edit&quot;;</a>
<a name="ln2757">      }</a>
<a name="ln2758">    }</a>
<a name="ln2759">    if (s.IsEndOfFile()) {</a>
<a name="ln2760">      s = Status::OK();</a>
<a name="ln2761">    }</a>
<a name="ln2762">  }</a>
<a name="ln2763"> </a>
<a name="ln2764">  if (s.ok()) {</a>
<a name="ln2765">    if (!have_next_file) {</a>
<a name="ln2766">      s = STATUS(Corruption, &quot;no meta-nextfile entry in descriptor&quot;);</a>
<a name="ln2767">    } else if (!have_log_number) {</a>
<a name="ln2768">      s = STATUS(Corruption, &quot;no meta-lognumber entry in descriptor&quot;);</a>
<a name="ln2769">    } else if (!have_last_sequence) {</a>
<a name="ln2770">      s = STATUS(Corruption, &quot;no last-sequence-number entry in descriptor&quot;);</a>
<a name="ln2771">    }</a>
<a name="ln2772"> </a>
<a name="ln2773">    if (!have_prev_log_number) {</a>
<a name="ln2774">      previous_log_number = 0;</a>
<a name="ln2775">    }</a>
<a name="ln2776"> </a>
<a name="ln2777">    column_family_set_-&gt;UpdateMaxColumnFamily(max_column_family);</a>
<a name="ln2778"> </a>
<a name="ln2779">    MarkFileNumberUsedDuringRecovery(previous_log_number);</a>
<a name="ln2780">    MarkFileNumberUsedDuringRecovery(log_number);</a>
<a name="ln2781">  }</a>
<a name="ln2782"> </a>
<a name="ln2783">  // there were some column families in the MANIFEST that weren't specified</a>
<a name="ln2784">  // in the argument. This is OK in read_only mode</a>
<a name="ln2785">  if (read_only == false &amp;&amp; !column_families_not_found.empty()) {</a>
<a name="ln2786">    std::string list_of_not_found;</a>
<a name="ln2787">    for (const auto&amp; cf : column_families_not_found) {</a>
<a name="ln2788">      list_of_not_found += &quot;, &quot; + cf.second;</a>
<a name="ln2789">    }</a>
<a name="ln2790">    list_of_not_found = list_of_not_found.substr(2);</a>
<a name="ln2791">    s = STATUS(InvalidArgument,</a>
<a name="ln2792">        &quot;You have to open all column families. Column families not opened: &quot; +</a>
<a name="ln2793">        list_of_not_found);</a>
<a name="ln2794">  }</a>
<a name="ln2795"> </a>
<a name="ln2796">  if (s.ok()) {</a>
<a name="ln2797">    for (auto cfd : *column_family_set_) {</a>
<a name="ln2798">      if (cfd-&gt;IsDropped()) {</a>
<a name="ln2799">        continue;</a>
<a name="ln2800">      }</a>
<a name="ln2801">      auto builders_iter = builders.find(cfd-&gt;GetID());</a>
<a name="ln2802">      assert(builders_iter != builders.end());</a>
<a name="ln2803">      auto* builder = builders_iter-&gt;second-&gt;version_builder();</a>
<a name="ln2804"> </a>
<a name="ln2805">      if (db_options_-&gt;max_open_files == -1) {</a>
<a name="ln2806">        // unlimited table cache. Pre-load table handle now.</a>
<a name="ln2807">        // Need to do it out of the mutex.</a>
<a name="ln2808">        builder-&gt;LoadTableHandlers(cfd-&gt;internal_stats(),</a>
<a name="ln2809">                                   db_options_-&gt;max_file_opening_threads);</a>
<a name="ln2810">      }</a>
<a name="ln2811"> </a>
<a name="ln2812">      Version* v = new Version(cfd, this, current_version_number_++);</a>
<a name="ln2813">      builder-&gt;SaveTo(v-&gt;storage_info());</a>
<a name="ln2814"> </a>
<a name="ln2815">      // Install recovered version</a>
<a name="ln2816">      v-&gt;PrepareApply(*cfd-&gt;GetLatestMutableCFOptions(),</a>
<a name="ln2817">          !(db_options_-&gt;skip_stats_update_on_db_open));</a>
<a name="ln2818">      AppendVersion(cfd, v);</a>
<a name="ln2819">    }</a>
<a name="ln2820"> </a>
<a name="ln2821">    manifest_file_size_ = current_manifest_file_size;</a>
<a name="ln2822">    next_file_number_.store(next_file + 1);</a>
<a name="ln2823">    SetLastSequenceNoSanityChecking(last_sequence);</a>
<a name="ln2824">    prev_log_number_ = previous_log_number;</a>
<a name="ln2825">    if (flushed_frontier) {</a>
<a name="ln2826">      UpdateFlushedFrontierNoSanityChecking(std::move(flushed_frontier));</a>
<a name="ln2827">    }</a>
<a name="ln2828"> </a>
<a name="ln2829">    RLOG(InfoLogLevel::INFO_LEVEL, db_options_-&gt;info_log,</a>
<a name="ln2830">        &quot;Recovered from manifest file:%s succeeded,&quot;</a>
<a name="ln2831">        &quot;manifest_file_number is %&quot; PRIu64 &quot;, next_file_number is %lu, &quot;</a>
<a name="ln2832">        &quot;last_sequence is %&quot; PRIu64 &quot;, log_number is %&quot; PRIu64 &quot;,&quot;</a>
<a name="ln2833">        &quot;prev_log_number is %&quot; PRIu64 &quot;,&quot;</a>
<a name="ln2834">        &quot;max_column_family is %u, flushed_values is %s\n&quot;,</a>
<a name="ln2835">        current_manifest_filename.c_str(), manifest_file_number_,</a>
<a name="ln2836">        next_file_number_.load(), LastSequence(),</a>
<a name="ln2837">        log_number, prev_log_number_,</a>
<a name="ln2838">        column_family_set_-&gt;GetMaxColumnFamily(),</a>
<a name="ln2839">        yb::ToString(flushed_frontier_).c_str());</a>
<a name="ln2840"> </a>
<a name="ln2841">    for (auto cfd : *column_family_set_) {</a>
<a name="ln2842">      if (cfd-&gt;IsDropped()) {</a>
<a name="ln2843">        continue;</a>
<a name="ln2844">      }</a>
<a name="ln2845">      RLOG(InfoLogLevel::INFO_LEVEL, db_options_-&gt;info_log,</a>
<a name="ln2846">          &quot;Column family [%s] (ID %u), log number is %&quot; PRIu64 &quot;\n&quot;,</a>
<a name="ln2847">          cfd-&gt;GetName().c_str(), cfd-&gt;GetID(), cfd-&gt;GetLogNumber());</a>
<a name="ln2848">    }</a>
<a name="ln2849">  }</a>
<a name="ln2850"> </a>
<a name="ln2851">  return s;</a>
<a name="ln2852">}</a>
<a name="ln2853"> </a>
<a name="ln2854">Status VersionSet::Import(const std::string&amp; source_dir,</a>
<a name="ln2855">                          SequenceNumber seqno,</a>
<a name="ln2856">                          VersionEdit* edit) {</a>
<a name="ln2857">  ManifestReader manifest_reader(env_, db_options_-&gt;get_checkpoint_env(), env_options_,</a>
<a name="ln2858">                                 db_options_-&gt;boundary_extractor.get(), source_dir);</a>
<a name="ln2859">  auto status = manifest_reader.OpenManifest();</a>
<a name="ln2860">  if (!status.ok()) {</a>
<a name="ln2861">    return status;</a>
<a name="ln2862">  }</a>
<a name="ln2863">  std::vector&lt;FileMetaData&gt; files;</a>
<a name="ln2864">  std::vector&lt;std::pair&lt;SequenceNumber, SequenceNumber&gt;&gt; segments;</a>
<a name="ln2865">  for (;;) {</a>
<a name="ln2866">    status = manifest_reader.Next();</a>
<a name="ln2867">    if (!status.ok()) {</a>
<a name="ln2868">      break;</a>
<a name="ln2869">    }</a>
<a name="ln2870">    auto&amp; current = *manifest_reader;</a>
<a name="ln2871">    if (!current.GetDeletedFiles().empty()) {</a>
<a name="ln2872">      return STATUS(Corruption, &quot;Deleted files should be empty&quot;);</a>
<a name="ln2873">    }</a>
<a name="ln2874">    for (const auto&amp; file : current.GetNewFiles()) {</a>
<a name="ln2875">      auto filemeta = file.second;</a>
<a name="ln2876">      filemeta.largest.user_frontier.reset();</a>
<a name="ln2877">      filemeta.smallest.user_frontier.reset();</a>
<a name="ln2878">      filemeta.imported = true;</a>
<a name="ln2879">      if (filemeta.largest.seqno &gt;= seqno) {</a>
<a name="ln2880">        return STATUS_FORMAT(InvalidArgument,</a>
<a name="ln2881">                             &quot;Imported DB contains seqno ($0) greater than active seqno ($1)&quot;,</a>
<a name="ln2882">                             filemeta.largest.seqno,</a>
<a name="ln2883">                             seqno);</a>
<a name="ln2884">      }</a>
<a name="ln2885">      files.push_back(filemeta);</a>
<a name="ln2886">      segments.emplace_back(filemeta.smallest.seqno, filemeta.largest.seqno);</a>
<a name="ln2887">    }</a>
<a name="ln2888">  }</a>
<a name="ln2889">  if (!status.IsEndOfFile()) {</a>
<a name="ln2890">    return status;</a>
<a name="ln2891">  }</a>
<a name="ln2892"> </a>
<a name="ln2893">  if (files.empty()) {</a>
<a name="ln2894">    return STATUS_FORMAT(NotFound, &quot;Imported DB is empty: $0&quot;, source_dir);</a>
<a name="ln2895">  }</a>
<a name="ln2896"> </a>
<a name="ln2897">  std::vector&lt;LiveFileMetaData&gt; live_files;</a>
<a name="ln2898">  GetLiveFilesMetaData(&amp;live_files);</a>
<a name="ln2899">  for (const auto&amp; file : live_files) {</a>
<a name="ln2900">    segments.emplace_back(file.smallest.seqno, file.largest.seqno);</a>
<a name="ln2901">  }</a>
<a name="ln2902"> </a>
<a name="ln2903">  std::sort(segments.begin(), segments.end(), [](const auto&amp; lhs, const auto&amp; rhs) {</a>
<a name="ln2904">    return lhs.first &lt; rhs.first;</a>
<a name="ln2905">  });</a>
<a name="ln2906">  auto prev = segments.front();</a>
<a name="ln2907">  for (size_t i = 1; i != segments.size(); ++i) {</a>
<a name="ln2908">    const auto&amp; segment = segments[i];</a>
<a name="ln2909">    if (segment.first &lt;= prev.second) {</a>
<a name="ln2910">      return STATUS_FORMAT(Corruption,</a>
<a name="ln2911">                           &quot;Overlapping seqno ranges: [$0, $1] and [$2, $3]&quot;,</a>
<a name="ln2912">                           prev.first,</a>
<a name="ln2913">                           prev.second,</a>
<a name="ln2914">                           segment.first,</a>
<a name="ln2915">                           segment.second);</a>
<a name="ln2916">    }</a>
<a name="ln2917">    prev = segment;</a>
<a name="ln2918">  }</a>
<a name="ln2919"> </a>
<a name="ln2920">  std::vector&lt;std::string&gt; revert_list;</a>
<a name="ln2921">  for (auto file : files) {</a>
<a name="ln2922">    auto source_base = MakeTableFileName(source_dir, file.fd.GetNumber());</a>
<a name="ln2923">    auto source_data = TableBaseToDataFileName(source_base);</a>
<a name="ln2924">    auto new_number = NewFileNumber();</a>
<a name="ln2925">    auto dest_base = MakeTableFileName(dbname_, new_number);</a>
<a name="ln2926">    auto dest_data = TableBaseToDataFileName(dest_base);</a>
<a name="ln2927">    LOG(INFO) &lt;&lt; &quot;Importing: &quot; &lt;&lt; source_base &lt;&lt; &quot; =&gt; &quot; &lt;&lt; dest_base;</a>
<a name="ln2928">    status = env_-&gt;LinkFile(source_base, dest_base);</a>
<a name="ln2929">    if (!status.ok()) {</a>
<a name="ln2930">      break;</a>
<a name="ln2931">    }</a>
<a name="ln2932">    revert_list.push_back(dest_base);</a>
<a name="ln2933">    status = env_-&gt;LinkFile(source_data, dest_data);</a>
<a name="ln2934">    if (!status.ok()) {</a>
<a name="ln2935">      break;</a>
<a name="ln2936">    }</a>
<a name="ln2937">    revert_list.push_back(dest_data);</a>
<a name="ln2938">    file.fd.packed_number_and_path_id = new_number; // path is 0</a>
<a name="ln2939">    file.marked_for_compaction = false;</a>
<a name="ln2940">    edit-&gt;AddCleanedFile(0, file);</a>
<a name="ln2941">  }</a>
<a name="ln2942"> </a>
<a name="ln2943">  if (!status.ok()) {</a>
<a name="ln2944">    for (const auto&amp; file : revert_list) {</a>
<a name="ln2945">      auto delete_status = env_-&gt;DeleteFile(file);</a>
<a name="ln2946">      LOG(ERROR) &lt;&lt; &quot;Failed to delete file: &quot; &lt;&lt; file &lt;&lt; &quot;, status: &quot; &lt;&lt; delete_status.ToString();</a>
<a name="ln2947">    }</a>
<a name="ln2948">    return status;</a>
<a name="ln2949">  }</a>
<a name="ln2950"> </a>
<a name="ln2951">  return Status::OK();</a>
<a name="ln2952">}</a>
<a name="ln2953"> </a>
<a name="ln2954">Status VersionSet::ListColumnFamilies(std::vector&lt;std::string&gt;* column_families,</a>
<a name="ln2955">                                      const std::string&amp; dbname,</a>
<a name="ln2956">                                      BoundaryValuesExtractor* extractor,</a>
<a name="ln2957">                                      Env* env) {</a>
<a name="ln2958">  // these are just for performance reasons, not correctness,</a>
<a name="ln2959">  // so we're fine using the defaults</a>
<a name="ln2960">  EnvOptions soptions;</a>
<a name="ln2961">  // Read &quot;CURRENT&quot; file, which contains a pointer to the current manifest file</a>
<a name="ln2962">  std::string current;</a>
<a name="ln2963">  Status s = ReadFileToString(env, CurrentFileName(dbname), &amp;current);</a>
<a name="ln2964">  if (!s.ok()) {</a>
<a name="ln2965">    return s;</a>
<a name="ln2966">  }</a>
<a name="ln2967">  if (current.empty() || current[current.size()-1] != '\n') {</a>
<a name="ln2968">    return STATUS(Corruption, &quot;CURRENT file does not end with newline&quot;);</a>
<a name="ln2969">  }</a>
<a name="ln2970">  current.resize(current.size() - 1);</a>
<a name="ln2971"> </a>
<a name="ln2972">  std::string dscname = dbname + &quot;/&quot; + current;</a>
<a name="ln2973"> </a>
<a name="ln2974">  unique_ptr&lt;SequentialFileReader&gt; file_reader;</a>
<a name="ln2975">  {</a>
<a name="ln2976">    unique_ptr&lt;SequentialFile&gt; file;</a>
<a name="ln2977">    s = env-&gt;NewSequentialFile(dscname, &amp;file, soptions);</a>
<a name="ln2978">    if (!s.ok()) {</a>
<a name="ln2979">      return s;</a>
<a name="ln2980">    }</a>
<a name="ln2981">    file_reader.reset(new SequentialFileReader(std::move(file)));</a>
<a name="ln2982">  }</a>
<a name="ln2983"> </a>
<a name="ln2984">  std::map&lt;uint32_t, std::string&gt; column_family_names;</a>
<a name="ln2985">  // default column family is always implicitly there</a>
<a name="ln2986">  column_family_names.insert({0, kDefaultColumnFamilyName});</a>
<a name="ln2987">  LogReporter reporter;</a>
<a name="ln2988">  reporter.status = &amp;s;</a>
<a name="ln2989">  log::Reader reader(NULL, std::move(file_reader), &amp;reporter, true /*checksum*/,</a>
<a name="ln2990">                     0 /*initial_offset*/, 0);</a>
<a name="ln2991">  Slice record;</a>
<a name="ln2992">  std::string scratch;</a>
<a name="ln2993">  while (reader.ReadRecord(&amp;record, &amp;scratch) &amp;&amp; s.ok()) {</a>
<a name="ln2994">    VersionEdit edit;</a>
<a name="ln2995">    s = edit.DecodeFrom(extractor, record);</a>
<a name="ln2996">    if (!s.ok()) {</a>
<a name="ln2997">      break;</a>
<a name="ln2998">    }</a>
<a name="ln2999">    if (edit.column_family_name_) {</a>
<a name="ln3000">      if (column_family_names.find(edit.column_family_) !=</a>
<a name="ln3001">          column_family_names.end()) {</a>
<a name="ln3002">        s = STATUS(Corruption, &quot;Manifest adding the same column family twice&quot;);</a>
<a name="ln3003">        break;</a>
<a name="ln3004">      }</a>
<a name="ln3005">      column_family_names.emplace(edit.column_family_, *edit.column_family_name_);</a>
<a name="ln3006">    } else if (edit.is_column_family_drop_) {</a>
<a name="ln3007">      if (column_family_names.find(edit.column_family_) ==</a>
<a name="ln3008">          column_family_names.end()) {</a>
<a name="ln3009">        s = STATUS(Corruption,</a>
<a name="ln3010">            &quot;Manifest - dropping non-existing column family&quot;);</a>
<a name="ln3011">        break;</a>
<a name="ln3012">      }</a>
<a name="ln3013">      column_family_names.erase(edit.column_family_);</a>
<a name="ln3014">    }</a>
<a name="ln3015">  }</a>
<a name="ln3016"> </a>
<a name="ln3017">  column_families-&gt;clear();</a>
<a name="ln3018">  if (s.ok()) {</a>
<a name="ln3019">    for (const auto&amp; iter : column_family_names) {</a>
<a name="ln3020">      column_families-&gt;push_back(iter.second);</a>
<a name="ln3021">    }</a>
<a name="ln3022">  }</a>
<a name="ln3023"> </a>
<a name="ln3024">  return s;</a>
<a name="ln3025">}</a>
<a name="ln3026"> </a>
<a name="ln3027">#ifndef ROCKSDB_LITE</a>
<a name="ln3028">Status VersionSet::ReduceNumberOfLevels(const std::string&amp; dbname,</a>
<a name="ln3029">                                        const Options* options,</a>
<a name="ln3030">                                        const EnvOptions&amp; env_options,</a>
<a name="ln3031">                                        int new_levels) {</a>
<a name="ln3032">  if (new_levels &lt;= 1) {</a>
<a name="ln3033">    return STATUS(InvalidArgument,</a>
<a name="ln3034">        &quot;Number of levels needs to be bigger than 1&quot;);</a>
<a name="ln3035">  }</a>
<a name="ln3036"> </a>
<a name="ln3037">  ColumnFamilyOptions cf_options(*options);</a>
<a name="ln3038">  std::shared_ptr&lt;Cache&gt; tc(NewLRUCache(options-&gt;max_open_files - 10,</a>
<a name="ln3039">                                        options-&gt;table_cache_numshardbits));</a>
<a name="ln3040">  WriteController wc(options-&gt;delayed_write_rate);</a>
<a name="ln3041">  WriteBuffer wb(options-&gt;db_write_buffer_size);</a>
<a name="ln3042">  VersionSet versions(dbname, options, env_options, tc.get(), &amp;wb, &amp;wc);</a>
<a name="ln3043">  Status status;</a>
<a name="ln3044"> </a>
<a name="ln3045">  std::vector&lt;ColumnFamilyDescriptor&gt; dummy;</a>
<a name="ln3046">  ColumnFamilyDescriptor dummy_descriptor(kDefaultColumnFamilyName,</a>
<a name="ln3047">                                          ColumnFamilyOptions(*options));</a>
<a name="ln3048">  dummy.push_back(dummy_descriptor);</a>
<a name="ln3049">  status = versions.Recover(dummy);</a>
<a name="ln3050">  if (!status.ok()) {</a>
<a name="ln3051">    return status;</a>
<a name="ln3052">  }</a>
<a name="ln3053"> </a>
<a name="ln3054">  Version* current_version =</a>
<a name="ln3055">      versions.GetColumnFamilySet()-&gt;GetDefault()-&gt;current();</a>
<a name="ln3056">  auto* vstorage = current_version-&gt;storage_info();</a>
<a name="ln3057">  int current_levels = vstorage-&gt;num_levels();</a>
<a name="ln3058"> </a>
<a name="ln3059">  if (current_levels &lt;= new_levels) {</a>
<a name="ln3060">    return Status::OK();</a>
<a name="ln3061">  }</a>
<a name="ln3062"> </a>
<a name="ln3063">  // Make sure there are file only on one level from</a>
<a name="ln3064">  // (new_levels-1) to (current_levels-1)</a>
<a name="ln3065">  int first_nonempty_level = -1;</a>
<a name="ln3066">  int first_nonempty_level_filenum = 0;</a>
<a name="ln3067">  for (int i = new_levels - 1; i &lt; current_levels; i++) {</a>
<a name="ln3068">    int file_num = vstorage-&gt;NumLevelFiles(i);</a>
<a name="ln3069">    if (file_num != 0) {</a>
<a name="ln3070">      if (first_nonempty_level &lt; 0) {</a>
<a name="ln3071">        first_nonempty_level = i;</a>
<a name="ln3072">        first_nonempty_level_filenum = file_num;</a>
<a name="ln3073">      } else {</a>
<a name="ln3074">        char msg[255];</a>
<a name="ln3075">        snprintf(msg, sizeof(msg),</a>
<a name="ln3076">                 &quot;Found at least two levels containing files: &quot;</a>
<a name="ln3077">                 &quot;[%d:%d],[%d:%d].\n&quot;,</a>
<a name="ln3078">                 first_nonempty_level, first_nonempty_level_filenum, i,</a>
<a name="ln3079">                 file_num);</a>
<a name="ln3080">        return STATUS(InvalidArgument, msg);</a>
<a name="ln3081">      }</a>
<a name="ln3082">    }</a>
<a name="ln3083">  }</a>
<a name="ln3084"> </a>
<a name="ln3085">  // we need to allocate an array with the old number of levels size to</a>
<a name="ln3086">  // avoid SIGSEGV in WriteSnapshot()</a>
<a name="ln3087">  // however, all levels bigger or equal to new_levels will be empty</a>
<a name="ln3088">  std::vector&lt;FileMetaData*&gt;* new_files_list =</a>
<a name="ln3089">      new std::vector&lt;FileMetaData*&gt;[current_levels];</a>
<a name="ln3090">  for (int i = 0; i &lt; new_levels - 1; i++) {</a>
<a name="ln3091">    new_files_list[i] = vstorage-&gt;LevelFiles(i);</a>
<a name="ln3092">  }</a>
<a name="ln3093"> </a>
<a name="ln3094">  if (first_nonempty_level &gt; 0) {</a>
<a name="ln3095">    new_files_list[new_levels - 1] = vstorage-&gt;LevelFiles(first_nonempty_level);</a>
<a name="ln3096">  }</a>
<a name="ln3097"> </a>
<a name="ln3098">  delete[] vstorage -&gt; files_;</a>
<a name="ln3099">  vstorage-&gt;files_ = new_files_list;</a>
<a name="ln3100">  vstorage-&gt;num_levels_ = new_levels;</a>
<a name="ln3101"> </a>
<a name="ln3102">  MutableCFOptions mutable_cf_options(*options, ImmutableCFOptions(*options));</a>
<a name="ln3103">  VersionEdit ve;</a>
<a name="ln3104">  InstrumentedMutex dummy_mutex;</a>
<a name="ln3105">  InstrumentedMutexLock l(&amp;dummy_mutex);</a>
<a name="ln3106">  return versions.LogAndApply(</a>
<a name="ln3107">      versions.GetColumnFamilySet()-&gt;GetDefault(),</a>
<a name="ln3108">      mutable_cf_options, &amp;ve, &amp;dummy_mutex, nullptr, true);</a>
<a name="ln3109">}</a>
<a name="ln3110"> </a>
<a name="ln3111">Status VersionSet::DumpManifest(const Options&amp; options, const std::string&amp; dscname,</a>
<a name="ln3112">                                bool verbose, bool hex) {</a>
<a name="ln3113">  // Open the specified manifest file.</a>
<a name="ln3114">  unique_ptr&lt;SequentialFileReader&gt; file_reader;</a>
<a name="ln3115">  Status s;</a>
<a name="ln3116">  {</a>
<a name="ln3117">    unique_ptr&lt;SequentialFile&gt; file;</a>
<a name="ln3118">    s = options.env-&gt;NewSequentialFile(dscname, &amp;file, env_options_);</a>
<a name="ln3119">    if (!s.ok()) {</a>
<a name="ln3120">      return s;</a>
<a name="ln3121">    }</a>
<a name="ln3122">    file_reader.reset(new SequentialFileReader(std::move(file)));</a>
<a name="ln3123">  }</a>
<a name="ln3124"> </a>
<a name="ln3125">  bool have_prev_log_number = false;</a>
<a name="ln3126">  bool have_next_file = false;</a>
<a name="ln3127">  bool have_last_sequence = false;</a>
<a name="ln3128">  uint64_t next_file = 0;</a>
<a name="ln3129">  uint64_t last_sequence = 0;</a>
<a name="ln3130">  uint64_t previous_log_number = 0;</a>
<a name="ln3131">  UserFrontier* flushed_frontier = nullptr;</a>
<a name="ln3132">  int count = 0;</a>
<a name="ln3133">  std::unordered_map&lt;uint32_t, std::string&gt; comparators;</a>
<a name="ln3134">  std::unordered_map&lt;uint32_t, BaseReferencedVersionBuilder*&gt; builders;</a>
<a name="ln3135"> </a>
<a name="ln3136">  // add default column family</a>
<a name="ln3137">  VersionEdit default_cf_edit;</a>
<a name="ln3138">  default_cf_edit.AddColumnFamily(kDefaultColumnFamilyName);</a>
<a name="ln3139">  default_cf_edit.SetColumnFamily(0);</a>
<a name="ln3140">  ColumnFamilyData* default_cfd =</a>
<a name="ln3141">      CreateColumnFamily(ColumnFamilyOptions(options), &amp;default_cf_edit);</a>
<a name="ln3142">  builders.insert({0, new BaseReferencedVersionBuilder(default_cfd)});</a>
<a name="ln3143"> </a>
<a name="ln3144">  {</a>
<a name="ln3145">    LogReporter reporter;</a>
<a name="ln3146">    reporter.status = &amp;s;</a>
<a name="ln3147">    log::Reader reader(NULL, std::move(file_reader), &amp;reporter,</a>
<a name="ln3148">                       true /*checksum*/, 0 /*initial_offset*/, 0);</a>
<a name="ln3149">    Slice record;</a>
<a name="ln3150">    std::string scratch;</a>
<a name="ln3151">    while (reader.ReadRecord(&amp;record, &amp;scratch) &amp;&amp; s.ok()) {</a>
<a name="ln3152">      VersionEdit edit;</a>
<a name="ln3153">      s = edit.DecodeFrom(db_options_-&gt;boundary_extractor.get(), record);</a>
<a name="ln3154">      if (!s.ok()) {</a>
<a name="ln3155">        break;</a>
<a name="ln3156">      }</a>
<a name="ln3157"> </a>
<a name="ln3158">      // Write out each individual edit</a>
<a name="ln3159">      if (verbose) {</a>
<a name="ln3160">        printf(&quot;%s\n&quot;, edit.DebugString(hex).c_str());</a>
<a name="ln3161">      }</a>
<a name="ln3162">      count++;</a>
<a name="ln3163"> </a>
<a name="ln3164">      bool cf_in_builders =</a>
<a name="ln3165">          builders.find(edit.column_family_) != builders.end();</a>
<a name="ln3166"> </a>
<a name="ln3167">      if (edit.comparator_) {</a>
<a name="ln3168">        comparators.emplace(edit.column_family_, *edit.comparator_);</a>
<a name="ln3169">      }</a>
<a name="ln3170"> </a>
<a name="ln3171">      ColumnFamilyData* cfd = nullptr;</a>
<a name="ln3172"> </a>
<a name="ln3173">      if (edit.column_family_name_) {</a>
<a name="ln3174">        if (cf_in_builders) {</a>
<a name="ln3175">          s = STATUS(Corruption,</a>
<a name="ln3176">              &quot;Manifest adding the same column family twice&quot;);</a>
<a name="ln3177">          break;</a>
<a name="ln3178">        }</a>
<a name="ln3179">        cfd = CreateColumnFamily(ColumnFamilyOptions(options), &amp;edit);</a>
<a name="ln3180">        builders.insert(</a>
<a name="ln3181">            {edit.column_family_, new BaseReferencedVersionBuilder(cfd)});</a>
<a name="ln3182">      } else if (edit.is_column_family_drop_) {</a>
<a name="ln3183">        if (!cf_in_builders) {</a>
<a name="ln3184">          s = STATUS(Corruption,</a>
<a name="ln3185">              &quot;Manifest - dropping non-existing column family&quot;);</a>
<a name="ln3186">          break;</a>
<a name="ln3187">        }</a>
<a name="ln3188">        auto builder_iter = builders.find(edit.column_family_);</a>
<a name="ln3189">        delete builder_iter-&gt;second;</a>
<a name="ln3190">        builders.erase(builder_iter);</a>
<a name="ln3191">        comparators.erase(edit.column_family_);</a>
<a name="ln3192">        cfd = column_family_set_-&gt;GetColumnFamily(edit.column_family_);</a>
<a name="ln3193">        assert(cfd != nullptr);</a>
<a name="ln3194">        cfd-&gt;Unref();</a>
<a name="ln3195">        delete cfd;</a>
<a name="ln3196">        cfd = nullptr;</a>
<a name="ln3197">      } else {</a>
<a name="ln3198">        if (!cf_in_builders) {</a>
<a name="ln3199">          s = STATUS(Corruption,</a>
<a name="ln3200">              &quot;Manifest record referencing unknown column family&quot;);</a>
<a name="ln3201">          break;</a>
<a name="ln3202">        }</a>
<a name="ln3203"> </a>
<a name="ln3204">        cfd = column_family_set_-&gt;GetColumnFamily(edit.column_family_);</a>
<a name="ln3205">        // this should never happen since cf_in_builders is true</a>
<a name="ln3206">        assert(cfd != nullptr);</a>
<a name="ln3207"> </a>
<a name="ln3208">        // if it is not column family add or column family drop,</a>
<a name="ln3209">        // then it's a file add/delete, which should be forwarded</a>
<a name="ln3210">        // to builder</a>
<a name="ln3211">        auto builder = builders.find(edit.column_family_);</a>
<a name="ln3212">        assert(builder != builders.end());</a>
<a name="ln3213">        builder-&gt;second-&gt;version_builder()-&gt;Apply(&amp;edit);</a>
<a name="ln3214">      }</a>
<a name="ln3215"> </a>
<a name="ln3216">      if (cfd != nullptr &amp;&amp; edit.log_number_) {</a>
<a name="ln3217">        cfd-&gt;SetLogNumber(*edit.log_number_);</a>
<a name="ln3218">      }</a>
<a name="ln3219"> </a>
<a name="ln3220">      if (edit.prev_log_number_) {</a>
<a name="ln3221">        previous_log_number = *edit.prev_log_number_;</a>
<a name="ln3222">        have_prev_log_number = true;</a>
<a name="ln3223">      }</a>
<a name="ln3224"> </a>
<a name="ln3225">      if (edit.next_file_number_) {</a>
<a name="ln3226">        next_file = *edit.next_file_number_;</a>
<a name="ln3227">        have_next_file = true;</a>
<a name="ln3228">      }</a>
<a name="ln3229"> </a>
<a name="ln3230">      if (edit.last_sequence_) {</a>
<a name="ln3231">        last_sequence = *edit.last_sequence_;</a>
<a name="ln3232">        have_last_sequence = true;</a>
<a name="ln3233">      }</a>
<a name="ln3234"> </a>
<a name="ln3235">      if (edit.flushed_frontier_) {</a>
<a name="ln3236">        flushed_frontier = edit.flushed_frontier_.get();</a>
<a name="ln3237">      }</a>
<a name="ln3238"> </a>
<a name="ln3239">      if (edit.max_column_family_) {</a>
<a name="ln3240">        column_family_set_-&gt;UpdateMaxColumnFamily(*edit.max_column_family_);</a>
<a name="ln3241">      }</a>
<a name="ln3242">    }</a>
<a name="ln3243">  }</a>
<a name="ln3244">  file_reader.reset();</a>
<a name="ln3245"> </a>
<a name="ln3246">  if (s.ok()) {</a>
<a name="ln3247">    if (!have_next_file) {</a>
<a name="ln3248">      s = STATUS(Corruption, &quot;no meta-nextfile entry in descriptor&quot;);</a>
<a name="ln3249">      printf(&quot;no meta-nextfile entry in descriptor&quot;);</a>
<a name="ln3250">    } else if (!have_last_sequence) {</a>
<a name="ln3251">      printf(&quot;no last-sequence-number entry in descriptor&quot;);</a>
<a name="ln3252">      s = STATUS(Corruption, &quot;no last-sequence-number entry in descriptor&quot;);</a>
<a name="ln3253">    }</a>
<a name="ln3254"> </a>
<a name="ln3255">    if (!have_prev_log_number) {</a>
<a name="ln3256">      previous_log_number = 0;</a>
<a name="ln3257">    }</a>
<a name="ln3258">  }</a>
<a name="ln3259"> </a>
<a name="ln3260">  if (s.ok()) {</a>
<a name="ln3261">    for (auto cfd : *column_family_set_) {</a>
<a name="ln3262">      if (cfd-&gt;IsDropped()) {</a>
<a name="ln3263">        continue;</a>
<a name="ln3264">      }</a>
<a name="ln3265">      auto builders_iter = builders.find(cfd-&gt;GetID());</a>
<a name="ln3266">      assert(builders_iter != builders.end());</a>
<a name="ln3267">      auto builder = builders_iter-&gt;second-&gt;version_builder();</a>
<a name="ln3268"> </a>
<a name="ln3269">      Version* v = new Version(cfd, this, current_version_number_++);</a>
<a name="ln3270">      builder-&gt;SaveTo(v-&gt;storage_info());</a>
<a name="ln3271">      v-&gt;PrepareApply(*cfd-&gt;GetLatestMutableCFOptions(), false);</a>
<a name="ln3272"> </a>
<a name="ln3273">      printf(&quot;--------------- Column family \&quot;%s\&quot;  (ID %u) --------------\n&quot;,</a>
<a name="ln3274">             cfd-&gt;GetName().c_str(), (unsigned int)cfd-&gt;GetID());</a>
<a name="ln3275">      printf(&quot;log number: %&quot; PRIu64 &quot;\n&quot;, cfd-&gt;GetLogNumber());</a>
<a name="ln3276">      auto comparator = comparators.find(cfd-&gt;GetID());</a>
<a name="ln3277">      if (comparator != comparators.end()) {</a>
<a name="ln3278">        printf(&quot;comparator: %s\n&quot;, comparator-&gt;second.c_str());</a>
<a name="ln3279">      } else {</a>
<a name="ln3280">        printf(&quot;comparator: &lt;NO COMPARATOR&gt;\n&quot;);</a>
<a name="ln3281">      }</a>
<a name="ln3282">      printf(&quot;%s \n&quot;, v-&gt;DebugString(hex).c_str());</a>
<a name="ln3283">      delete v;</a>
<a name="ln3284">    }</a>
<a name="ln3285"> </a>
<a name="ln3286">    // Free builders</a>
<a name="ln3287">    for (auto&amp; builder : builders) {</a>
<a name="ln3288">      delete builder.second;</a>
<a name="ln3289">    }</a>
<a name="ln3290"> </a>
<a name="ln3291">    next_file_number_.store(next_file + 1);</a>
<a name="ln3292">    SetLastSequenceNoSanityChecking(last_sequence);</a>
<a name="ln3293">    if (flushed_frontier) {</a>
<a name="ln3294">      DCHECK_EQ(*flushed_frontier, *FlushedFrontier());</a>
<a name="ln3295">    }</a>
<a name="ln3296">    prev_log_number_ = previous_log_number;</a>
<a name="ln3297"> </a>
<a name="ln3298">    printf(</a>
<a name="ln3299">        &quot;next_file_number %&quot; PRIu64 &quot; last_sequence &quot;</a>
<a name="ln3300">        &quot;%&quot; PRIu64 &quot; prev_log_number %&quot; PRIu64 &quot; max_column_family %u flushed_values %s\n&quot;,</a>
<a name="ln3301">        next_file_number_.load(), last_sequence, previous_log_number,</a>
<a name="ln3302">        column_family_set_-&gt;GetMaxColumnFamily(),</a>
<a name="ln3303">        yb::ToString(flushed_frontier).c_str());</a>
<a name="ln3304">  }</a>
<a name="ln3305"> </a>
<a name="ln3306">  return s;</a>
<a name="ln3307">}</a>
<a name="ln3308">#endif  // ROCKSDB_LITE</a>
<a name="ln3309"> </a>
<a name="ln3310">// Set the last sequence number to s.</a>
<a name="ln3311">void VersionSet::SetLastSequence(SequenceNumber s) {</a>
<a name="ln3312">#ifndef NDEBUG</a>
<a name="ln3313">  EnsureNonDecreasingLastSequence(LastSequence(), s);</a>
<a name="ln3314">#endif</a>
<a name="ln3315">  SetLastSequenceNoSanityChecking(s);</a>
<a name="ln3316">}</a>
<a name="ln3317"> </a>
<a name="ln3318">// Set last sequence number without verifying that it always keeps increasing.</a>
<a name="ln3319">void VersionSet::SetLastSequenceNoSanityChecking(SequenceNumber s) {</a>
<a name="ln3320">  last_sequence_.store(s, std::memory_order_release);</a>
<a name="ln3321">}</a>
<a name="ln3322"> </a>
<a name="ln3323">// Set the last flushed op id / hybrid time / history cutoff to the specified set of values.</a>
<a name="ln3324">void VersionSet::UpdateFlushedFrontier(UserFrontierPtr values) {</a>
<a name="ln3325">  EnsureNonDecreasingFlushedFrontier(FlushedFrontier(), *values);</a>
<a name="ln3326">  UpdateFlushedFrontierNoSanityChecking(std::move(values));</a>
<a name="ln3327">}</a>
<a name="ln3328"> </a>
<a name="ln3329">void VersionSet::MarkFileNumberUsedDuringRecovery(uint64_t number) {</a>
<a name="ln3330">  // only called during recovery which is single threaded, so this works because</a>
<a name="ln3331">  // there can't be concurrent calls</a>
<a name="ln3332">  if (next_file_number_.load(std::memory_order_relaxed) &lt;= number) {</a>
<a name="ln3333">    next_file_number_.store(number + 1, std::memory_order_relaxed);</a>
<a name="ln3334">  }</a>
<a name="ln3335">}</a>
<a name="ln3336"> </a>
<a name="ln3337">namespace {</a>
<a name="ln3338"> </a>
<a name="ln3339">CHECKED_STATUS AddEdit(const VersionEdit&amp; edit, const DBOptions* db_options, log::Writer* log) {</a>
<a name="ln3340">  std::string record;</a>
<a name="ln3341">  if (!edit.AppendEncodedTo(&amp;record)) {</a>
<a name="ln3342">    return STATUS(Corruption,</a>
<a name="ln3343">        &quot;Unable to Encode VersionEdit:&quot; + edit.DebugString(true));</a>
<a name="ln3344">  }</a>
<a name="ln3345">  RLOG(InfoLogLevel::INFO_LEVEL, db_options-&gt;info_log,</a>
<a name="ln3346">      &quot;Writing version edit: %s\n&quot;, edit.DebugString().c_str());</a>
<a name="ln3347">  return log-&gt;AddRecord(record);</a>
<a name="ln3348">}</a>
<a name="ln3349"> </a>
<a name="ln3350">} // namespace</a>
<a name="ln3351"> </a>
<a name="ln3352">Status VersionSet::WriteSnapshot(log::Writer* log, UserFrontierPtr flushed_frontier_override) {</a>
<a name="ln3353">  // TODO: Break up into multiple records to reduce memory usage on recovery?</a>
<a name="ln3354"> </a>
<a name="ln3355">  // WARNING: This method doesn't hold a mutex!</a>
<a name="ln3356"> </a>
<a name="ln3357">  // This is done without DB mutex lock held, but only within single-threaded</a>
<a name="ln3358">  // LogAndApply. Column family manipulations can only happen within LogAndApply</a>
<a name="ln3359">  // (the same single thread), so we're safe to iterate.</a>
<a name="ln3360">  for (auto cfd : *column_family_set_) {</a>
<a name="ln3361">    if (cfd-&gt;IsDropped()) {</a>
<a name="ln3362">      continue;</a>
<a name="ln3363">    }</a>
<a name="ln3364">    {</a>
<a name="ln3365">      // Store column family info</a>
<a name="ln3366">      VersionEdit edit;</a>
<a name="ln3367">      if (cfd-&gt;GetID() != 0) {</a>
<a name="ln3368">        // default column family is always there,</a>
<a name="ln3369">        // no need to explicitly write it</a>
<a name="ln3370">        edit.AddColumnFamily(cfd-&gt;GetName());</a>
<a name="ln3371">        edit.SetColumnFamily(cfd-&gt;GetID());</a>
<a name="ln3372">      }</a>
<a name="ln3373">      edit.SetComparatorName(</a>
<a name="ln3374">          cfd-&gt;internal_comparator()-&gt;user_comparator()-&gt;Name());</a>
<a name="ln3375">      RETURN_NOT_OK(AddEdit(edit, db_options_, log));</a>
<a name="ln3376">    }</a>
<a name="ln3377"> </a>
<a name="ln3378">    {</a>
<a name="ln3379">      // Save files</a>
<a name="ln3380">      VersionEdit edit;</a>
<a name="ln3381">      edit.SetColumnFamily(cfd-&gt;GetID());</a>
<a name="ln3382"> </a>
<a name="ln3383">      const bool frontier_overridden = !!flushed_frontier_override;</a>
<a name="ln3384">      for (int level = 0; level &lt; cfd-&gt;NumberLevels(); level++) {</a>
<a name="ln3385">        for (const auto&amp; f :</a>
<a name="ln3386">             cfd-&gt;current()-&gt;storage_info()-&gt;LevelFiles(level)) {</a>
<a name="ln3387"> </a>
<a name="ln3388">          edit.AddCleanedFile(level, *f, /* suppress_frontiers */ frontier_overridden);</a>
<a name="ln3389">        }</a>
<a name="ln3390">      }</a>
<a name="ln3391">      edit.SetLogNumber(cfd-&gt;GetLogNumber());</a>
<a name="ln3392">      if (flushed_frontier_override) {</a>
<a name="ln3393">        edit.flushed_frontier_ = flushed_frontier_override;</a>
<a name="ln3394">      } else {</a>
<a name="ln3395">        edit.flushed_frontier_ = flushed_frontier_;</a>
<a name="ln3396">      }</a>
<a name="ln3397">      RETURN_NOT_OK(AddEdit(edit, db_options_, log));</a>
<a name="ln3398">    }</a>
<a name="ln3399">  }</a>
<a name="ln3400"> </a>
<a name="ln3401">  return Status::OK();</a>
<a name="ln3402">}</a>
<a name="ln3403"> </a>
<a name="ln3404">// TODO(aekmekji): in CompactionJob::GenSubcompactionBoundaries(), this</a>
<a name="ln3405">// function is called repeatedly with consecutive pairs of slices. For example</a>
<a name="ln3406">// if the slice list is [a, b, c, d] this function is called with arguments</a>
<a name="ln3407">// (a,b) then (b,c) then (c,d). Knowing this, an optimization is possible where</a>
<a name="ln3408">// we avoid doing binary search for the keys b and c twice and instead somehow</a>
<a name="ln3409">// maintain state of where they first appear in the files.</a>
<a name="ln3410">uint64_t VersionSet::ApproximateSize(Version* v, const Slice&amp; start,</a>
<a name="ln3411">                                     const Slice&amp; end, int start_level,</a>
<a name="ln3412">                                     int end_level) {</a>
<a name="ln3413">  // pre-condition</a>
<a name="ln3414">  assert(v-&gt;cfd_-&gt;internal_comparator()-&gt;Compare(start, end) &lt;= 0);</a>
<a name="ln3415"> </a>
<a name="ln3416">  uint64_t size = 0;</a>
<a name="ln3417">  const auto* vstorage = v-&gt;storage_info();</a>
<a name="ln3418">  end_level = end_level == -1</a>
<a name="ln3419">                  ? vstorage-&gt;num_non_empty_levels()</a>
<a name="ln3420">                  : std::min(end_level, vstorage-&gt;num_non_empty_levels());</a>
<a name="ln3421"> </a>
<a name="ln3422">  assert(start_level &lt;= end_level);</a>
<a name="ln3423"> </a>
<a name="ln3424">  for (int level = start_level; level &lt; end_level; level++) {</a>
<a name="ln3425">    const LevelFilesBrief&amp; files_brief = vstorage-&gt;LevelFilesBrief(level);</a>
<a name="ln3426">    if (!files_brief.num_files) {</a>
<a name="ln3427">      // empty level, skip exploration</a>
<a name="ln3428">      continue;</a>
<a name="ln3429">    }</a>
<a name="ln3430"> </a>
<a name="ln3431">    if (!level) {</a>
<a name="ln3432">      // level 0 data is sorted order, handle the use case explicitly</a>
<a name="ln3433">      size += ApproximateSizeLevel0(v, files_brief, start, end);</a>
<a name="ln3434">      continue;</a>
<a name="ln3435">    }</a>
<a name="ln3436"> </a>
<a name="ln3437">    assert(level &gt; 0);</a>
<a name="ln3438">    assert(files_brief.num_files &gt; 0);</a>
<a name="ln3439"> </a>
<a name="ln3440">    // identify the file position for starting key</a>
<a name="ln3441">    const uint64_t idx_start = FindFileInRange(</a>
<a name="ln3442">        *v-&gt;cfd_-&gt;internal_comparator(), files_brief, start,</a>
<a name="ln3443">        /*start=*/0, static_cast&lt;uint32_t&gt;(files_brief.num_files - 1));</a>
<a name="ln3444">    assert(idx_start &lt; files_brief.num_files);</a>
<a name="ln3445"> </a>
<a name="ln3446">    // scan all files from the starting position until the ending position</a>
<a name="ln3447">    // inferred from the sorted order</a>
<a name="ln3448">    for (uint64_t i = idx_start; i &lt; files_brief.num_files; i++) {</a>
<a name="ln3449">      uint64_t val;</a>
<a name="ln3450">      val = ApproximateSize(v, files_brief.files[i], end);</a>
<a name="ln3451">      if (!val) {</a>
<a name="ln3452">        // the files after this will not have the range</a>
<a name="ln3453">        break;</a>
<a name="ln3454">      }</a>
<a name="ln3455"> </a>
<a name="ln3456">      size += val;</a>
<a name="ln3457"> </a>
<a name="ln3458">      if (i == idx_start) {</a>
<a name="ln3459">        // subtract the bytes needed to be scanned to get to the starting</a>
<a name="ln3460">        // key</a>
<a name="ln3461">        val = ApproximateSize(v, files_brief.files[i], start);</a>
<a name="ln3462">        assert(size &gt;= val);</a>
<a name="ln3463">        size -= val;</a>
<a name="ln3464">      }</a>
<a name="ln3465">    }</a>
<a name="ln3466">  }</a>
<a name="ln3467"> </a>
<a name="ln3468">  return size;</a>
<a name="ln3469">}</a>
<a name="ln3470"> </a>
<a name="ln3471">uint64_t VersionSet::ApproximateSizeLevel0(Version* v,</a>
<a name="ln3472">                                           const LevelFilesBrief&amp; files_brief,</a>
<a name="ln3473">                                           const Slice&amp; key_start,</a>
<a name="ln3474">                                           const Slice&amp; key_end) {</a>
<a name="ln3475">  // level 0 files are not in sorted order, we need to iterate through</a>
<a name="ln3476">  // the list to compute the total bytes that require scanning</a>
<a name="ln3477">  uint64_t size = 0;</a>
<a name="ln3478">  for (size_t i = 0; i &lt; files_brief.num_files; i++) {</a>
<a name="ln3479">    const uint64_t start = ApproximateSize(v, files_brief.files[i], key_start);</a>
<a name="ln3480">    const uint64_t end = ApproximateSize(v, files_brief.files[i], key_end);</a>
<a name="ln3481">    assert(end &gt;= start);</a>
<a name="ln3482">    size += end - start;</a>
<a name="ln3483">  }</a>
<a name="ln3484">  return size;</a>
<a name="ln3485">}</a>
<a name="ln3486"> </a>
<a name="ln3487">uint64_t VersionSet::ApproximateSize(Version* v, const FdWithBoundaries&amp; f, const Slice&amp; key) {</a>
<a name="ln3488">  // pre-condition</a>
<a name="ln3489">  assert(v);</a>
<a name="ln3490"> </a>
<a name="ln3491">  uint64_t result = 0;</a>
<a name="ln3492">  if (v-&gt;cfd_-&gt;internal_comparator()-&gt;Compare(f.largest.key, key) &lt;= 0) {</a>
<a name="ln3493">    // Entire file is before &quot;key&quot;, so just add the file size</a>
<a name="ln3494">    result = f.fd.GetTotalFileSize();</a>
<a name="ln3495">  } else if (v-&gt;cfd_-&gt;internal_comparator()-&gt;Compare(f.smallest.key, key) &gt; 0) {</a>
<a name="ln3496">    // Entire file is after &quot;key&quot;, so ignore</a>
<a name="ln3497">    result = 0;</a>
<a name="ln3498">  } else {</a>
<a name="ln3499">    // &quot;key&quot; falls in the range for this table.  Add the</a>
<a name="ln3500">    // approximate offset of &quot;key&quot; within the table.</a>
<a name="ln3501">    TableReader* table_reader_ptr;</a>
<a name="ln3502">    InternalIterator* iter = v-&gt;cfd_-&gt;table_cache()-&gt;NewIterator(</a>
<a name="ln3503">        ReadOptions(), env_options_, v-&gt;cfd_-&gt;internal_comparator(), f.fd, Slice() /* filter */,</a>
<a name="ln3504">        &amp;table_reader_ptr);</a>
<a name="ln3505">    if (table_reader_ptr != nullptr) {</a>
<a name="ln3506">      result = table_reader_ptr-&gt;ApproximateOffsetOf(key);</a>
<a name="ln3507">    }</a>
<a name="ln3508">    delete iter;</a>
<a name="ln3509">  }</a>
<a name="ln3510">  return result;</a>
<a name="ln3511">}</a>
<a name="ln3512"> </a>
<a name="ln3513">void VersionSet::AddLiveFiles(std::vector&lt;FileDescriptor&gt;* live_list) {</a>
<a name="ln3514">  // pre-calculate space requirement</a>
<a name="ln3515">  int64_t total_files = 0;</a>
<a name="ln3516">  for (auto cfd : *column_family_set_) {</a>
<a name="ln3517">    Version* dummy_versions = cfd-&gt;dummy_versions();</a>
<a name="ln3518">    for (Version* v = dummy_versions-&gt;next_; v != dummy_versions;</a>
<a name="ln3519">         v = v-&gt;next_) {</a>
<a name="ln3520">      const auto* vstorage = v-&gt;storage_info();</a>
<a name="ln3521">      for (int level = 0; level &lt; vstorage-&gt;num_levels(); level++) {</a>
<a name="ln3522">        total_files += vstorage-&gt;LevelFiles(level).size();</a>
<a name="ln3523">      }</a>
<a name="ln3524">    }</a>
<a name="ln3525">  }</a>
<a name="ln3526"> </a>
<a name="ln3527">  // just one time extension to the right size</a>
<a name="ln3528">  live_list-&gt;reserve(live_list-&gt;size() + static_cast&lt;size_t&gt;(total_files));</a>
<a name="ln3529"> </a>
<a name="ln3530">  for (auto cfd : *column_family_set_) {</a>
<a name="ln3531">    auto* current = cfd-&gt;current();</a>
<a name="ln3532">    bool found_current = false;</a>
<a name="ln3533">    Version* dummy_versions = cfd-&gt;dummy_versions();</a>
<a name="ln3534">    for (Version* v = dummy_versions-&gt;next_; v != dummy_versions;</a>
<a name="ln3535">         v = v-&gt;next_) {</a>
<a name="ln3536">      v-&gt;AddLiveFiles(live_list);</a>
<a name="ln3537">      if (v == current) {</a>
<a name="ln3538">        found_current = true;</a>
<a name="ln3539">      }</a>
<a name="ln3540">    }</a>
<a name="ln3541">    if (!found_current &amp;&amp; current != nullptr) {</a>
<a name="ln3542">      // Should never happen unless it is a bug.</a>
<a name="ln3543">      assert(false);</a>
<a name="ln3544">      current-&gt;AddLiveFiles(live_list);</a>
<a name="ln3545">    }</a>
<a name="ln3546">  }</a>
<a name="ln3547">}</a>
<a name="ln3548"> </a>
<a name="ln3549">InternalIterator* VersionSet::MakeInputIterator(Compaction* c) {</a>
<a name="ln3550">  auto cfd = c-&gt;column_family_data();</a>
<a name="ln3551">  ReadOptions read_options;</a>
<a name="ln3552">  read_options.verify_checksums =</a>
<a name="ln3553">    c-&gt;mutable_cf_options()-&gt;verify_checksums_in_compaction;</a>
<a name="ln3554">  read_options.fill_cache = false;</a>
<a name="ln3555">  if (c-&gt;ShouldFormSubcompactions()) {</a>
<a name="ln3556">    read_options.total_order_seek = true;</a>
<a name="ln3557">  }</a>
<a name="ln3558"> </a>
<a name="ln3559">  // Level-0 files have to be merged together.  For other levels,</a>
<a name="ln3560">  // we will make a concatenating iterator per level.</a>
<a name="ln3561">  // TODO(opt): use concatenating iterator for level-0 if there is no overlap</a>
<a name="ln3562">  const size_t space = (c-&gt;level() == 0 ? c-&gt;input_levels(0)-&gt;num_files +</a>
<a name="ln3563">                                              c-&gt;num_input_levels() - 1</a>
<a name="ln3564">                                        : c-&gt;num_input_levels());</a>
<a name="ln3565">  InternalIterator** list = new InternalIterator* [space];</a>
<a name="ln3566">  size_t num = 0;</a>
<a name="ln3567">  for (size_t which = 0; which &lt; c-&gt;num_input_levels(); which++) {</a>
<a name="ln3568">    if (c-&gt;input_levels(which)-&gt;num_files != 0) {</a>
<a name="ln3569">      if (c-&gt;level(which) == 0) {</a>
<a name="ln3570">        const LevelFilesBrief* flevel = c-&gt;input_levels(which);</a>
<a name="ln3571">        for (size_t i = 0; i &lt; flevel-&gt;num_files; i++) {</a>
<a name="ln3572">          list[num++] = cfd-&gt;table_cache()-&gt;NewIterator(</a>
<a name="ln3573">              read_options, env_options_compactions_,</a>
<a name="ln3574">              cfd-&gt;internal_comparator(), flevel-&gt;files[i].fd, flevel-&gt;files[i].user_filter_data,</a>
<a name="ln3575">              nullptr, nullptr /* no per level latency histogram*/,</a>
<a name="ln3576">              true /* for compaction */);</a>
<a name="ln3577">        }</a>
<a name="ln3578">      } else {</a>
<a name="ln3579">        // Create concatenating iterator for the files from this level</a>
<a name="ln3580">        list[num++] = NewTwoLevelIterator(</a>
<a name="ln3581">            new LevelFileIteratorState(</a>
<a name="ln3582">                cfd-&gt;table_cache(), read_options, env_options_,</a>
<a name="ln3583">                cfd-&gt;internal_comparator(),</a>
<a name="ln3584">                nullptr /* no per level latency histogram */,</a>
<a name="ln3585">                true /* for_compaction */, false /* prefix enabled */,</a>
<a name="ln3586">                false /* skip_filters */),</a>
<a name="ln3587">            new LevelFileNumIterator(*cfd-&gt;internal_comparator(),</a>
<a name="ln3588">                                     c-&gt;input_levels(which)));</a>
<a name="ln3589">      }</a>
<a name="ln3590">    }</a>
<a name="ln3591">  }</a>
<a name="ln3592">  assert(num &lt;= space);</a>
<a name="ln3593">  InternalIterator* result =</a>
<a name="ln3594">      NewMergingIterator(c-&gt;column_family_data()-&gt;internal_comparator().get(), list,</a>
<a name="ln3595">                         static_cast&lt;int&gt;(num));</a>
<a name="ln3596">  delete[] list;</a>
<a name="ln3597">  return result;</a>
<a name="ln3598">}</a>
<a name="ln3599"> </a>
<a name="ln3600">// verify that the files listed in this compaction are present</a>
<a name="ln3601">// in the current version</a>
<a name="ln3602">bool VersionSet::VerifyCompactionFileConsistency(Compaction* c) {</a>
<a name="ln3603">#ifndef NDEBUG</a>
<a name="ln3604">  Version* version = c-&gt;column_family_data()-&gt;current();</a>
<a name="ln3605">  const VersionStorageInfo* vstorage = version-&gt;storage_info();</a>
<a name="ln3606">  if (c-&gt;input_version_number() != version-&gt;GetVersionNumber()) {</a>
<a name="ln3607">    RLOG(InfoLogLevel::INFO_LEVEL, db_options_-&gt;info_log,</a>
<a name="ln3608">        &quot;[%s] compaction output being applied to a different base version from&quot;</a>
<a name="ln3609">        &quot; input version&quot;,</a>
<a name="ln3610">        c-&gt;column_family_data()-&gt;GetName().c_str());</a>
<a name="ln3611"> </a>
<a name="ln3612">    if (vstorage-&gt;compaction_style_ == kCompactionStyleLevel &amp;&amp;</a>
<a name="ln3613">        c-&gt;start_level() == 0 &amp;&amp; c-&gt;num_input_levels() &gt; 2U) {</a>
<a name="ln3614">      // We are doing a L0-&gt;base_level compaction. The assumption is if</a>
<a name="ln3615">      // base level is not L1, levels from L1 to base_level - 1 is empty.</a>
<a name="ln3616">      // This is ensured by having one compaction from L0 going on at the</a>
<a name="ln3617">      // same time in level-based compaction. So that during the time, no</a>
<a name="ln3618">      // compaction/flush can put files to those levels.</a>
<a name="ln3619">      for (int l = c-&gt;start_level() + 1; l &lt; c-&gt;output_level(); l++) {</a>
<a name="ln3620">        if (vstorage-&gt;NumLevelFiles(l) != 0) {</a>
<a name="ln3621">          return false;</a>
<a name="ln3622">        }</a>
<a name="ln3623">      }</a>
<a name="ln3624">    }</a>
<a name="ln3625">  }</a>
<a name="ln3626"> </a>
<a name="ln3627">  for (size_t input = 0; input &lt; c-&gt;num_input_levels(); ++input) {</a>
<a name="ln3628">    int level = c-&gt;level(input);</a>
<a name="ln3629">    for (size_t i = 0; i &lt; c-&gt;num_input_files(input); ++i) {</a>
<a name="ln3630">      uint64_t number = c-&gt;input(input, i)-&gt;fd.GetNumber();</a>
<a name="ln3631">      bool found = false;</a>
<a name="ln3632">      for (size_t j = 0; j &lt; vstorage-&gt;files_[level].size(); j++) {</a>
<a name="ln3633">        FileMetaData* f = vstorage-&gt;files_[level][j];</a>
<a name="ln3634">        if (f-&gt;fd.GetNumber() == number) {</a>
<a name="ln3635">          found = true;</a>
<a name="ln3636">          break;</a>
<a name="ln3637">        }</a>
<a name="ln3638">      }</a>
<a name="ln3639">      if (!found) {</a>
<a name="ln3640">        return false;  // input files non existent in current version</a>
<a name="ln3641">      }</a>
<a name="ln3642">    }</a>
<a name="ln3643">  }</a>
<a name="ln3644">#endif</a>
<a name="ln3645">  return true;     // everything good</a>
<a name="ln3646">}</a>
<a name="ln3647"> </a>
<a name="ln3648">Status VersionSet::GetMetadataForFile(uint64_t number, int* filelevel,</a>
<a name="ln3649">                                      FileMetaData** meta,</a>
<a name="ln3650">                                      ColumnFamilyData** cfd) {</a>
<a name="ln3651">  for (auto cfd_iter : *column_family_set_) {</a>
<a name="ln3652">    Version* version = cfd_iter-&gt;current();</a>
<a name="ln3653">    const auto* vstorage = version-&gt;storage_info();</a>
<a name="ln3654">    for (int level = 0; level &lt; vstorage-&gt;num_levels(); level++) {</a>
<a name="ln3655">      for (const auto&amp; file : vstorage-&gt;LevelFiles(level)) {</a>
<a name="ln3656">        if (file-&gt;fd.GetNumber() == number) {</a>
<a name="ln3657">          *meta = file;</a>
<a name="ln3658">          *filelevel = level;</a>
<a name="ln3659">          *cfd = cfd_iter;</a>
<a name="ln3660">          return Status::OK();</a>
<a name="ln3661">        }</a>
<a name="ln3662">      }</a>
<a name="ln3663">    }</a>
<a name="ln3664">  }</a>
<a name="ln3665">  return STATUS(NotFound, &quot;File not present in any level&quot;);</a>
<a name="ln3666">}</a>
<a name="ln3667"> </a>
<a name="ln3668">void VersionSet::GetLiveFilesMetaData(std::vector&lt;LiveFileMetaData&gt;* metadata) {</a>
<a name="ln3669">  for (auto cfd : *column_family_set_) {</a>
<a name="ln3670">    if (cfd-&gt;IsDropped()) {</a>
<a name="ln3671">      continue;</a>
<a name="ln3672">    }</a>
<a name="ln3673">    for (int level = 0; level &lt; cfd-&gt;NumberLevels(); level++) {</a>
<a name="ln3674">      for (const auto&amp; file :</a>
<a name="ln3675">           cfd-&gt;current()-&gt;storage_info()-&gt;LevelFiles(level)) {</a>
<a name="ln3676">        LiveFileMetaData filemetadata;</a>
<a name="ln3677">        filemetadata.column_family_name = cfd-&gt;GetName();</a>
<a name="ln3678">        uint32_t path_id = file-&gt;fd.GetPathId();</a>
<a name="ln3679">        if (path_id &lt; db_options_-&gt;db_paths.size()) {</a>
<a name="ln3680">          filemetadata.db_path = db_options_-&gt;db_paths[path_id].path;</a>
<a name="ln3681">        } else {</a>
<a name="ln3682">          assert(!db_options_-&gt;db_paths.empty());</a>
<a name="ln3683">          filemetadata.db_path = db_options_-&gt;db_paths.back().path;</a>
<a name="ln3684">        }</a>
<a name="ln3685">        filemetadata.name = MakeTableFileName(&quot;&quot;, file-&gt;fd.GetNumber());</a>
<a name="ln3686">        filemetadata.level = level;</a>
<a name="ln3687">        filemetadata.total_size = file-&gt;fd.GetTotalFileSize();</a>
<a name="ln3688">        filemetadata.base_size = file-&gt;fd.GetBaseFileSize();</a>
<a name="ln3689">        // TODO: replace base_size with an accurate metadata size for</a>
<a name="ln3690">        // uncompressed data. Look into: BlockBasedTableBuilder</a>
<a name="ln3691">        filemetadata.uncompressed_size = filemetadata.base_size +</a>
<a name="ln3692">            file-&gt;raw_key_size + file-&gt;raw_value_size;</a>
<a name="ln3693">        filemetadata.smallest = ConvertBoundaryValues(file-&gt;smallest);</a>
<a name="ln3694">        filemetadata.largest = ConvertBoundaryValues(file-&gt;largest);</a>
<a name="ln3695">        filemetadata.imported = file-&gt;imported;</a>
<a name="ln3696">        metadata-&gt;push_back(filemetadata);</a>
<a name="ln3697">      }</a>
<a name="ln3698">    }</a>
<a name="ln3699">  }</a>
<a name="ln3700">}</a>
<a name="ln3701"> </a>
<a name="ln3702">void VersionSet::GetObsoleteFiles(const FileNumbersProvider&amp; pending_outputs,</a>
<a name="ln3703">                                  std::vector&lt;FileMetaData*&gt;* files,</a>
<a name="ln3704">                                  std::vector&lt;std::string&gt;* manifest_filenames) {</a>
<a name="ln3705">  assert(manifest_filenames-&gt;empty());</a>
<a name="ln3706">  obsolete_manifests_.swap(*manifest_filenames);</a>
<a name="ln3707">  std::vector&lt;FileMetaData*&gt; pending_files;</a>
<a name="ln3708">  for (auto f : obsolete_files_) {</a>
<a name="ln3709">    if (!pending_outputs.HasFileNumber(f-&gt;fd.GetNumber())) {</a>
<a name="ln3710">      files-&gt;push_back(f);</a>
<a name="ln3711">    } else {</a>
<a name="ln3712">      pending_files.push_back(f);</a>
<a name="ln3713">    }</a>
<a name="ln3714">  }</a>
<a name="ln3715">  obsolete_files_.swap(pending_files);</a>
<a name="ln3716">}</a>
<a name="ln3717"> </a>
<a name="ln3718">ColumnFamilyData* VersionSet::CreateColumnFamily(</a>
<a name="ln3719">    const ColumnFamilyOptions&amp; cf_options, VersionEdit* edit) {</a>
<a name="ln3720">  assert(edit-&gt;column_family_name_);</a>
<a name="ln3721"> </a>
<a name="ln3722">  Version* dummy_versions = new Version(nullptr, this);</a>
<a name="ln3723">  // Ref() dummy version once so that later we can call Unref() to delete it</a>
<a name="ln3724">  // by avoiding calling &quot;delete&quot; explicitly (~Version is private)</a>
<a name="ln3725">  dummy_versions-&gt;Ref();</a>
<a name="ln3726">  auto new_cfd = column_family_set_-&gt;CreateColumnFamily(</a>
<a name="ln3727">      *edit-&gt;column_family_name_,</a>
<a name="ln3728">      edit-&gt;column_family_,</a>
<a name="ln3729">      dummy_versions,</a>
<a name="ln3730">      cf_options);</a>
<a name="ln3731"> </a>
<a name="ln3732">  Version* v = new Version(new_cfd, this, current_version_number_++);</a>
<a name="ln3733"> </a>
<a name="ln3734">  // Fill level target base information.</a>
<a name="ln3735">  v-&gt;storage_info()-&gt;CalculateBaseBytes(*new_cfd-&gt;ioptions(),</a>
<a name="ln3736">                                        *new_cfd-&gt;GetLatestMutableCFOptions());</a>
<a name="ln3737">  AppendVersion(new_cfd, v);</a>
<a name="ln3738">  // GetLatestMutableCFOptions() is safe here without mutex since the</a>
<a name="ln3739">  // cfd is not available to client</a>
<a name="ln3740">  new_cfd-&gt;CreateNewMemtable(*new_cfd-&gt;GetLatestMutableCFOptions(),</a>
<a name="ln3741">                             LastSequence());</a>
<a name="ln3742">  new_cfd-&gt;SetLogNumber(edit-&gt;log_number_.get_value_or(0));</a>
<a name="ln3743">  return new_cfd;</a>
<a name="ln3744">}</a>
<a name="ln3745"> </a>
<a name="ln3746">void VersionSet::UnrefFile(ColumnFamilyData* cfd, FileMetaData* f) {</a>
<a name="ln3747">  if (f-&gt;Unref(cfd-&gt;table_cache())) {</a>
<a name="ln3748">    obsolete_files_.push_back(f);</a>
<a name="ln3749">  }</a>
<a name="ln3750">}</a>
<a name="ln3751"> </a>
<a name="ln3752">uint64_t VersionSet::GetNumLiveVersions(Version* dummy_versions) {</a>
<a name="ln3753">  uint64_t count = 0;</a>
<a name="ln3754">  for (Version* v = dummy_versions-&gt;next_; v != dummy_versions; v = v-&gt;next_) {</a>
<a name="ln3755">    count++;</a>
<a name="ln3756">  }</a>
<a name="ln3757">  return count;</a>
<a name="ln3758">}</a>
<a name="ln3759"> </a>
<a name="ln3760">uint64_t VersionSet::GetTotalSstFilesSize(Version* dummy_versions) {</a>
<a name="ln3761">  std::unordered_set&lt;uint64_t&gt; unique_files;</a>
<a name="ln3762">  uint64_t total_files_size = 0;</a>
<a name="ln3763">  for (Version* v = dummy_versions-&gt;next_; v != dummy_versions; v = v-&gt;next_) {</a>
<a name="ln3764">    VersionStorageInfo* storage_info = v-&gt;storage_info();</a>
<a name="ln3765">    for (int level = 0; level &lt; storage_info-&gt;num_levels_; level++) {</a>
<a name="ln3766">      for (const auto&amp; file_meta : storage_info-&gt;LevelFiles(level)) {</a>
<a name="ln3767">        if (unique_files.find(file_meta-&gt;fd.packed_number_and_path_id) ==</a>
<a name="ln3768">            unique_files.end()) {</a>
<a name="ln3769">          unique_files.insert(file_meta-&gt;fd.packed_number_and_path_id);</a>
<a name="ln3770">          total_files_size += file_meta-&gt;fd.GetTotalFileSize();</a>
<a name="ln3771">        }</a>
<a name="ln3772">      }</a>
<a name="ln3773">    }</a>
<a name="ln3774">  }</a>
<a name="ln3775">  return total_files_size;</a>
<a name="ln3776">}</a>
<a name="ln3777"> </a>
<a name="ln3778">void VersionSet::EnsureNonDecreasingLastSequence(</a>
<a name="ln3779">    SequenceNumber prev_last_seq,</a>
<a name="ln3780">    SequenceNumber new_last_seq) {</a>
<a name="ln3781">  if (new_last_seq &lt; prev_last_seq) {</a>
<a name="ln3782">    LOG(DFATAL) &lt;&lt; &quot;New last sequence id &quot; &lt;&lt; new_last_seq &lt;&lt; &quot; is lower than &quot;</a>
<a name="ln3783">                &lt;&lt; &quot;the previous last sequence &quot; &lt;&lt; prev_last_seq;</a>
<a name="ln3784">  }</a>
<a name="ln3785">}</a>
<a name="ln3786"> </a>
<a name="ln3787">void VersionSet::EnsureNonDecreasingFlushedFrontier(</a>
<a name="ln3788">    const UserFrontier* prev_value,</a>
<a name="ln3789">    const UserFrontier&amp; new_value) {</a>
<a name="ln3790">  if (!prev_value) {</a>
<a name="ln3791">    return;</a>
<a name="ln3792">  }</a>
<a name="ln3793">  if (!prev_value-&gt;IsUpdateValid(new_value, UpdateUserValueType::kLargest)) {</a>
<a name="ln3794">    LOG(DFATAL) &lt;&lt; &quot;Attempt to decrease flushed frontier &quot; &lt;&lt; prev_value-&gt;ToString() &lt;&lt; &quot; to &quot;</a>
<a name="ln3795">                &lt;&lt; new_value.ToString();</a>
<a name="ln3796">  }</a>
<a name="ln3797">}</a>
<a name="ln3798"> </a>
<a name="ln3799">void VersionSet::UpdateFlushedFrontierNoSanityChecking(UserFrontierPtr value) {</a>
<a name="ln3800">  UpdateUserFrontier(&amp;flushed_frontier_, std::move(value), UpdateUserValueType::kLargest);</a>
<a name="ln3801">}</a>
<a name="ln3802"> </a>
<a name="ln3803">}  // namespace rocksdb</a>

</code></pre>
<div class="balloon" rel="2752"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2756"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="3727"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v1007/" target="_blank">V1007</a> The value from the potentially uninitialized optional 'edit->column_family_name_' is used. Probably it is a mistake.</p></div>
<div class="balloon" rel="2486"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v730/" target="_blank">V730</a> Not all members of a class are initialized inside the constructor. Consider inspecting: reporter_.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
