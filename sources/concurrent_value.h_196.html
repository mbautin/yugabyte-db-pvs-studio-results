
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
  <title>concurrent_value.h</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">//</a>
<a name="ln2">// Copyright (c) YugaByte, Inc.</a>
<a name="ln3">//</a>
<a name="ln4"> </a>
<a name="ln5">#ifndef YB_UTIL_CONCURRENT_VALUE_H</a>
<a name="ln6">#define YB_UTIL_CONCURRENT_VALUE_H</a>
<a name="ln7"> </a>
<a name="ln8">#include &lt;atomic&gt;</a>
<a name="ln9">#include &lt;mutex&gt;</a>
<a name="ln10">#include &lt;thread&gt;</a>
<a name="ln11"> </a>
<a name="ln12">#if defined(__APPLE__) &amp;&amp; __clang_major__ &lt; 8 || YB_ZAPCC</a>
<a name="ln13">#define YB_CONCURRENT_VALUE_USE_BOOST_THREAD_SPECIFIC_PTR 1</a>
<a name="ln14">#else</a>
<a name="ln15">#define YB_CONCURRENT_VALUE_USE_BOOST_THREAD_SPECIFIC_PTR 0</a>
<a name="ln16">#endif</a>
<a name="ln17"> </a>
<a name="ln18">#if YB_CONCURRENT_VALUE_USE_BOOST_THREAD_SPECIFIC_PTR</a>
<a name="ln19">#include &lt;boost/thread/tss.hpp&gt;</a>
<a name="ln20">#endif</a>
<a name="ln21"> </a>
<a name="ln22">#include &quot;yb/util/logging.h&quot;</a>
<a name="ln23"> </a>
<a name="ln24">namespace yb {</a>
<a name="ln25"> </a>
<a name="ln26">namespace internal {</a>
<a name="ln27">typedef decltype(std::this_thread::get_id()) ThreadId;</a>
<a name="ln28"> </a>
<a name="ln29">// Tracks list of threads that is using URCU.</a>
<a name="ln30">template&lt;class T&gt;</a>
<a name="ln31">class ThreadList {</a>
<a name="ln32"> public:</a>
<a name="ln33">  typedef T Data;</a>
<a name="ln34"> </a>
<a name="ln35">  ~ThreadList() {</a>
<a name="ln36">    while (allocated_.load(std::memory_order_acquire) != 0) {</a>
<a name="ln37">      std::this_thread::sleep_for(std::chrono::milliseconds(10));</a>
<a name="ln38">    }</a>
<a name="ln39"> </a>
<a name="ln40">    for (auto* p = head_.exchange(nullptr, std::memory_order_acquire); p;) {</a>
<a name="ln41">      auto* n = p-&gt;next.load(std::memory_order_relaxed);</a>
<a name="ln42"> </a>
<a name="ln43">      delete p;</a>
<a name="ln44">      p = n;</a>
<a name="ln45">    }</a>
<a name="ln46">  }</a>
<a name="ln47"> </a>
<a name="ln48">  Data* Alloc() {</a>
<a name="ln49">    allocated_.fetch_add(1, std::memory_order_relaxed);</a>
<a name="ln50">    Data* data;</a>
<a name="ln51">    const auto current_thread_id = std::this_thread::get_id();</a>
<a name="ln52">    const auto null_thread_id = ThreadId();</a>
<a name="ln53"> </a>
<a name="ln54">    // First, try to reuse a retired (non-active) HP record.</a>
<a name="ln55">    for (data = head_.load(std::memory_order_acquire); data;</a>
<a name="ln56">         data = data-&gt;next.load(std::memory_order_relaxed)) {</a>
<a name="ln57">      auto old_value = null_thread_id;</a>
<a name="ln58">      if (data-&gt;owner.compare_exchange_strong(old_value,</a>
<a name="ln59">                                              current_thread_id,</a>
<a name="ln60">                                              std::memory_order_seq_cst,</a>
<a name="ln61">                                              std::memory_order_relaxed)) {</a>
<a name="ln62">        return data;</a>
<a name="ln63">      }</a>
<a name="ln64">    }</a>
<a name="ln65"> </a>
<a name="ln66">    data = new Data(current_thread_id);</a>
<a name="ln67"> </a>
<a name="ln68">    auto old_head = head_.load(std::memory_order_acquire);</a>
<a name="ln69">    do {</a>
<a name="ln70">      data-&gt;next.store(old_head, std::memory_order_relaxed);</a>
<a name="ln71">    } while (!head_.compare_exchange_weak(old_head,</a>
<a name="ln72">                                          data,</a>
<a name="ln73">                                          std::memory_order_acq_rel,</a>
<a name="ln74">                                          std::memory_order_acquire));</a>
<a name="ln75"> </a>
<a name="ln76">    return data;</a>
<a name="ln77">  }</a>
<a name="ln78"> </a>
<a name="ln79">  void Retire(Data* data) {</a>
<a name="ln80">    DCHECK_ONLY_NOTNULL(data);</a>
<a name="ln81">    const auto null_thread_id = decltype(std::this_thread::get_id())();</a>
<a name="ln82">    data-&gt;owner.store(null_thread_id, std::memory_order_release);</a>
<a name="ln83">    allocated_.fetch_sub(1, std::memory_order_release);</a>
<a name="ln84">  }</a>
<a name="ln85"> </a>
<a name="ln86">  Data* Head(std::memory_order mo) const {</a>
<a name="ln87">    return head_.load(mo);</a>
<a name="ln88">  }</a>
<a name="ln89"> </a>
<a name="ln90">  static ThreadList&lt;T&gt;&amp; Instance() {</a>
<a name="ln91">    static ThreadList&lt;T&gt; result;</a>
<a name="ln92">    return result;</a>
<a name="ln93">  }</a>
<a name="ln94"> private:</a>
<a name="ln95">  ThreadList() {}</a>
<a name="ln96"> </a>
<a name="ln97">  std::atomic&lt;Data*&gt; head_{nullptr};</a>
<a name="ln98">  std::atomic&lt;size_t&gt; allocated_{0};</a>
<a name="ln99">};</a>
<a name="ln100"> </a>
<a name="ln101">// URCU data associated with thread.</a>
<a name="ln102">struct URCUThreadData {</a>
<a name="ln103">  std::atomic&lt;uint32_t&gt; access_control{0};</a>
<a name="ln104">  std::atomic&lt;URCUThreadData*&gt; next{nullptr};</a>
<a name="ln105">  std::atomic&lt;ThreadId&gt; owner;</a>
<a name="ln106"> </a>
<a name="ln107">  explicit URCUThreadData(ThreadId owner_) : owner(owner_) {}</a>
<a name="ln108">};</a>
<a name="ln109"> </a>
<a name="ln110">constexpr uint32_t kControlBit = 0x80000000;</a>
<a name="ln111">constexpr uint32_t kNestMask = kControlBit - 1;</a>
<a name="ln112"> </a>
<a name="ln113">// Userspace Read-copy-update.</a>
<a name="ln114">// Full description https://en.wikipedia.org/wiki/Read-copy-update</a>
<a name="ln115">// In computer science, read-copy-update (RCU) is a synchronization mechanism based on mutual</a>
<a name="ln116">// exclusion. It is used when performance of reads is crucial and is an example of space-time</a>
<a name="ln117">// tradeoff, enabling fast operations at the cost of more space.</a>
<a name="ln118">//</a>
<a name="ln119">// Read-copy-update allows multiple threads to efficiently read from shared memory by deferring</a>
<a name="ln120">// updates after pre-existing reads to a later time while simultaneously marking the data,</a>
<a name="ln121">// ensuring new readers will read the updated data. This makes all readers proceed as if there</a>
<a name="ln122">// were no synchronization involved, hence they will be fast, but also making updates more</a>
<a name="ln123">// difficult.</a>
<a name="ln124">class URCU {</a>
<a name="ln125"> public:</a>
<a name="ln126">  URCU() {}</a>
<a name="ln127"> </a>
<a name="ln128">  URCU(const URCU&amp;) = delete;</a>
<a name="ln129">  void operator=(const URCU&amp;) = delete;</a>
<a name="ln130"> </a>
<a name="ln131">  void AccessLock() {</a>
<a name="ln132">    auto* data = DCHECK_NOTNULL(ThreadData());</a>
<a name="ln133"> </a>
<a name="ln134">    uint32_t tmp = data-&gt;access_control.load(std::memory_order_relaxed);</a>
<a name="ln135">    if ((tmp &amp; kNestMask) == 0) {</a>
<a name="ln136">      data-&gt;access_control.store(global_control_word_.load(std::memory_order_relaxed),</a>
<a name="ln137">          std::memory_order_relaxed);</a>
<a name="ln138"> </a>
<a name="ln139">      std::atomic_thread_fence(std::memory_order_seq_cst);</a>
<a name="ln140">    } else {</a>
<a name="ln141">      // nested lock</a>
<a name="ln142">      data-&gt;access_control.store(tmp + 1, std::memory_order_relaxed);</a>
<a name="ln143">    }</a>
<a name="ln144">  }</a>
<a name="ln145"> </a>
<a name="ln146">  void AccessUnlock() {</a>
<a name="ln147">    auto* data = DCHECK_NOTNULL(ThreadData());</a>
<a name="ln148"> </a>
<a name="ln149">    uint32_t tmp = data-&gt;access_control.load(std::memory_order_relaxed);</a>
<a name="ln150">    CHECK_GT(tmp &amp; kNestMask, 0);</a>
<a name="ln151"> </a>
<a name="ln152">    data-&gt;access_control.store(tmp - 1, std::memory_order_release);</a>
<a name="ln153">  }</a>
<a name="ln154"> </a>
<a name="ln155">  void Synchronize() {</a>
<a name="ln156">    std::lock_guard&lt;std::mutex&gt; lock(mutex_);</a>
<a name="ln157">    FlipAndWait();</a>
<a name="ln158">    FlipAndWait();</a>
<a name="ln159">  }</a>
<a name="ln160"> </a>
<a name="ln161"> private:</a>
<a name="ln162">  URCUThreadData* ThreadData() {</a>
<a name="ln163">    auto result = data_.get();</a>
<a name="ln164">    if (!result) {</a>
<a name="ln165">      data_.reset(result = ThreadList&lt;URCUThreadData&gt;::Instance().Alloc());</a>
<a name="ln166">    }</a>
<a name="ln167">    return result;</a>
<a name="ln168">  }</a>
<a name="ln169"> </a>
<a name="ln170">  void FlipAndWait() {</a>
<a name="ln171">    const auto null_thread_id = ThreadId();</a>
<a name="ln172">    global_control_word_.fetch_xor(kControlBit, std::memory_order_seq_cst);</a>
<a name="ln173"> </a>
<a name="ln174">    for (auto* data = ThreadList&lt;URCUThreadData&gt;::Instance().Head(std::memory_order_acquire);</a>
<a name="ln175">         data;</a>
<a name="ln176">         data = data-&gt;next.load(std::memory_order_acquire)) {</a>
<a name="ln177">      while (data-&gt;owner.load(std::memory_order_acquire) != null_thread_id &amp;&amp;</a>
<a name="ln178">             CheckGracePeriod(data)) {</a>
<a name="ln179">        std::this_thread::sleep_for(std::chrono::milliseconds(10));</a>
<a name="ln180">        std::atomic_thread_fence(std::memory_order_seq_cst);</a>
<a name="ln181">      }</a>
<a name="ln182">    }</a>
<a name="ln183">  }</a>
<a name="ln184"> </a>
<a name="ln185">  bool CheckGracePeriod(URCUThreadData* data) {</a>
<a name="ln186">    const uint32_t v = data-&gt;access_control.load(std::memory_order_acquire);</a>
<a name="ln187">    return (v &amp; kNestMask) &amp;&amp;</a>
<a name="ln188">           ((v ^ global_control_word_.load(std::memory_order_relaxed)) &amp; ~kNestMask);</a>
<a name="ln189">  }</a>
<a name="ln190"> </a>
<a name="ln191">  std::atomic &lt;uint32_t&gt; global_control_word_{1};</a>
<a name="ln192">  std::mutex mutex_;</a>
<a name="ln193">#if YB_CONCURRENT_VALUE_USE_BOOST_THREAD_SPECIFIC_PTR</a>
<a name="ln194">  static void CleanupThreadData(URCUThreadData* data) {</a>
<a name="ln195">    ThreadList&lt;URCUThreadData&gt;::Instance().Retire(data);</a>
<a name="ln196">  }</a>
<a name="ln197"> </a>
<a name="ln198">  static boost::thread_specific_ptr&lt;URCUThreadData&gt; data_;</a>
<a name="ln199">#else</a>
<a name="ln200">  struct CleanupThreadData {</a>
<a name="ln201">    void operator()(URCUThreadData* data) {</a>
<a name="ln202">      ThreadList&lt;URCUThreadData&gt;::Instance().Retire(data);</a>
<a name="ln203">    }</a>
<a name="ln204">  };</a>
<a name="ln205"> </a>
<a name="ln206">  static thread_local std::unique_ptr&lt;URCUThreadData, CleanupThreadData&gt; data_;</a>
<a name="ln207">#endif</a>
<a name="ln208">};</a>
<a name="ln209"> </a>
<a name="ln210">// Reference to concurrent value. Provides read access to concurrent value.</a>
<a name="ln211">// Should have short life time period.</a>
<a name="ln212">template&lt;class T&gt;</a>
<a name="ln213">class ConcurrentValueReference {</a>
<a name="ln214"> public:</a>
<a name="ln215">  explicit ConcurrentValueReference(std::atomic&lt;T*&gt;* value, URCU* urcu)</a>
<a name="ln216">      : urcu_(urcu) {</a>
<a name="ln217">    urcu_-&gt;AccessLock();</a>
<a name="ln218">    value_ = value-&gt;load(std::memory_order_acquire);</a>
<a name="ln219">  }</a>
<a name="ln220"> </a>
<a name="ln221">  ~ConcurrentValueReference() {</a>
<a name="ln222">    if (urcu_) {</a>
<a name="ln223">      urcu_-&gt;AccessUnlock();</a>
<a name="ln224">    }</a>
<a name="ln225">  }</a>
<a name="ln226"> </a>
<a name="ln227">  ConcurrentValueReference(const ConcurrentValueReference&amp;) = delete;</a>
<a name="ln228">  void operator=(const ConcurrentValueReference&amp;) = delete;</a>
<a name="ln229"> </a>
<a name="ln230">  ConcurrentValueReference(ConcurrentValueReference&amp;&amp; rhs)</a>
<a name="ln231">      : value_(rhs.value_), urcu_(rhs.urcu_) {</a>
<a name="ln232">    rhs.urcu_ = nullptr;</a>
<a name="ln233">  }</a>
<a name="ln234"> </a>
<a name="ln235">  const T&amp; operator*() const {</a>
<a name="ln236">    return get();</a>
<a name="ln237">  }</a>
<a name="ln238"> </a>
<a name="ln239">  const T* operator-&gt;() const {</a>
<a name="ln240">    return &amp;get();</a>
<a name="ln241">  }</a>
<a name="ln242"> </a>
<a name="ln243">  const T&amp; get() const {</a>
<a name="ln244">    DCHECK_ONLY_NOTNULL(urcu_);</a>
<a name="ln245">    return *value_;</a>
<a name="ln246">  }</a>
<a name="ln247"> private:</a>
<a name="ln248">  const T* value_;</a>
<a name="ln249">  URCU* urcu_;</a>
<a name="ln250">};</a>
<a name="ln251"> </a>
<a name="ln252">// Concurrent value is used for cases when some object has a lot of reads with small amount of</a>
<a name="ln253">// writes.</a>
<a name="ln254">template&lt;class T&gt;</a>
<a name="ln255">class ConcurrentValue {</a>
<a name="ln256"> public:</a>
<a name="ln257">  template&lt;class... Args&gt;</a>
<a name="ln258">  explicit ConcurrentValue(Args&amp;&amp;... args) : value_(new T(std::forward&lt;Args&gt;(args)...)) {}</a>
<a name="ln259"> </a>
<a name="ln260">  ~ConcurrentValue() {</a>
<a name="ln261">    delete value_.load(std::memory_order_relaxed);</a>
<a name="ln262">  }</a>
<a name="ln263"> </a>
<a name="ln264">  ConcurrentValueReference&lt;T&gt; get() {</a>
<a name="ln265">    return ConcurrentValueReference&lt;T&gt;(&amp;value_, &amp;urcu_);</a>
<a name="ln266">  }</a>
<a name="ln267"> </a>
<a name="ln268">  template&lt;class... Args&gt;</a>
<a name="ln269">  void Emplace(Args&amp;&amp; ... args) {</a>
<a name="ln270">    DoSet(new T(std::forward&lt;Args&gt;(args)...));</a>
<a name="ln271">  }</a>
<a name="ln272"> </a>
<a name="ln273">  void Set(const T&amp; t) {</a>
<a name="ln274">    DoSet(new T(t));</a>
<a name="ln275">  }</a>
<a name="ln276"> </a>
<a name="ln277">  void Set(T&amp;&amp; t) {</a>
<a name="ln278">    DoSet(new T(std::move(t)));</a>
<a name="ln279">  }</a>
<a name="ln280"> </a>
<a name="ln281"> private:</a>
<a name="ln282">  void DoSet(T* new_value) {</a>
<a name="ln283">    auto* old_value = value_.exchange(new_value, std::memory_order_acq_rel);</a>
<a name="ln284">    urcu_.Synchronize();</a>
<a name="ln285">    delete old_value;</a>
<a name="ln286">  }</a>
<a name="ln287"> </a>
<a name="ln288">  std::atomic&lt;T*&gt; value_ = {nullptr};</a>
<a name="ln289">  URCU urcu_;</a>
<a name="ln290">};</a>
<a name="ln291"> </a>
<a name="ln292">} // namespace internal</a>
<a name="ln293"> </a>
<a name="ln294">using internal::ConcurrentValue;</a>
<a name="ln295"> </a>
<a name="ln296">} // namespace yb</a>
<a name="ln297"> </a>
<a name="ln298">#endif // YB_UTIL_CONCURRENT_VALUE_H</a>

</code></pre>
<div class="balloon" rel="213"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v690/" target="_blank">V690</a> The 'ConcurrentValueReference' class implements a move constructor, but lacks the move assignment operator. It is dangerous to use such a class.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
