
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
  <title>consensus_peers.cc</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">// Licensed to the Apache Software Foundation (ASF) under one</a>
<a name="ln2">// or more contributor license agreements.  See the NOTICE file</a>
<a name="ln3">// distributed with this work for additional information</a>
<a name="ln4">// regarding copyright ownership.  The ASF licenses this file</a>
<a name="ln5">// to you under the Apache License, Version 2.0 (the</a>
<a name="ln6">// &quot;License&quot;); you may not use this file except in compliance</a>
<a name="ln7">// with the License.  You may obtain a copy of the License at</a>
<a name="ln8">//</a>
<a name="ln9">//   http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="ln10">//</a>
<a name="ln11">// Unless required by applicable law or agreed to in writing,</a>
<a name="ln12">// software distributed under the License is distributed on an</a>
<a name="ln13">// &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</a>
<a name="ln14">// KIND, either express or implied.  See the License for the</a>
<a name="ln15">// specific language governing permissions and limitations</a>
<a name="ln16">// under the License.</a>
<a name="ln17">//</a>
<a name="ln18">// The following only applies to changes made to this file as part of YugaByte development.</a>
<a name="ln19">//</a>
<a name="ln20">// Portions Copyright (c) YugaByte, Inc.</a>
<a name="ln21">//</a>
<a name="ln22">// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except</a>
<a name="ln23">// in compliance with the License.  You may obtain a copy of the License at</a>
<a name="ln24">//</a>
<a name="ln25">// http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="ln26">//</a>
<a name="ln27">// Unless required by applicable law or agreed to in writing, software distributed under the License</a>
<a name="ln28">// is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express</a>
<a name="ln29">// or implied.  See the License for the specific language governing permissions and limitations</a>
<a name="ln30">// under the License.</a>
<a name="ln31">//</a>
<a name="ln32"> </a>
<a name="ln33">#include &quot;yb/consensus/consensus_peers.h&quot;</a>
<a name="ln34"> </a>
<a name="ln35">#include &lt;algorithm&gt;</a>
<a name="ln36">#include &lt;mutex&gt;</a>
<a name="ln37">#include &lt;string&gt;</a>
<a name="ln38">#include &lt;utility&gt;</a>
<a name="ln39">#include &lt;vector&gt;</a>
<a name="ln40"> </a>
<a name="ln41">#include &lt;gflags/gflags.h&gt;</a>
<a name="ln42">#include &lt;glog/logging.h&gt;</a>
<a name="ln43">#include &lt;boost/optional.hpp&gt;</a>
<a name="ln44"> </a>
<a name="ln45">#include &quot;yb/common/wire_protocol.h&quot;</a>
<a name="ln46">#include &quot;yb/consensus/consensus.h&quot;</a>
<a name="ln47">#include &quot;yb/consensus/consensus.proxy.h&quot;</a>
<a name="ln48">#include &quot;yb/consensus/consensus_error.h&quot;</a>
<a name="ln49">#include &quot;yb/consensus/consensus_meta.h&quot;</a>
<a name="ln50">#include &quot;yb/consensus/consensus_queue.h&quot;</a>
<a name="ln51">#include &quot;yb/consensus/log.h&quot;</a>
<a name="ln52">#include &quot;yb/consensus/replicate_msgs_holder.h&quot;</a>
<a name="ln53"> </a>
<a name="ln54">#include &quot;yb/gutil/strings/substitute.h&quot;</a>
<a name="ln55">#include &quot;yb/rpc/messenger.h&quot;</a>
<a name="ln56">#include &quot;yb/rpc/periodic.h&quot;</a>
<a name="ln57">#include &quot;yb/tablet/tablet_error.h&quot;</a>
<a name="ln58">#include &quot;yb/tserver/tserver.pb.h&quot;</a>
<a name="ln59">#include &quot;yb/tserver/tserver_error.h&quot;</a>
<a name="ln60"> </a>
<a name="ln61">#include &quot;yb/util/backoff_waiter.h&quot;</a>
<a name="ln62">#include &quot;yb/util/fault_injection.h&quot;</a>
<a name="ln63">#include &quot;yb/util/flag_tags.h&quot;</a>
<a name="ln64">#include &quot;yb/util/logging.h&quot;</a>
<a name="ln65">#include &quot;yb/util/monotime.h&quot;</a>
<a name="ln66">#include &quot;yb/util/net/net_util.h&quot;</a>
<a name="ln67">#include &quot;yb/util/status_callback.h&quot;</a>
<a name="ln68">#include &quot;yb/util/threadpool.h&quot;</a>
<a name="ln69">#include &quot;yb/util/tsan_util.h&quot;</a>
<a name="ln70"> </a>
<a name="ln71">using namespace std::literals;</a>
<a name="ln72">using namespace std::placeholders;</a>
<a name="ln73"> </a>
<a name="ln74">DEFINE_int32(consensus_rpc_timeout_ms, 3000,</a>
<a name="ln75">             &quot;Timeout used for all consensus internal RPC communications.&quot;);</a>
<a name="ln76">TAG_FLAG(consensus_rpc_timeout_ms, advanced);</a>
<a name="ln77"> </a>
<a name="ln78">DEFINE_int32(max_wait_for_processresponse_before_closing_ms,</a>
<a name="ln79">             yb::RegularBuildVsSanitizers(5000, 60000),</a>
<a name="ln80">             &quot;Maximum amount of time we will wait in Peer::Close() for Peer::ProcessResponse() to &quot;</a>
<a name="ln81">             &quot;finish before returning proceding to close the Peer and return&quot;);</a>
<a name="ln82">TAG_FLAG(max_wait_for_processresponse_before_closing_ms, advanced);</a>
<a name="ln83"> </a>
<a name="ln84">DECLARE_int32(raft_heartbeat_interval_ms);</a>
<a name="ln85"> </a>
<a name="ln86">DEFINE_test_flag(double, fault_crash_on_leader_request_fraction, 0.0,</a>
<a name="ln87">                 &quot;Fraction of the time when the leader will crash just before sending an &quot;</a>
<a name="ln88">                 &quot;UpdateConsensus RPC.&quot;);</a>
<a name="ln89"> </a>
<a name="ln90">DEFINE_test_flag(int32, delay_removing_peer_with_failed_tablet_secs, 0,</a>
<a name="ln91">                 &quot;If greater than 0, Peer::ProcessResponse will sleep after receiving a response &quot;</a>
<a name="ln92">                 &quot;indicating that a tablet is in the FAILED state, and before marking this peer &quot;</a>
<a name="ln93">                 &quot;as failed.&quot;);</a>
<a name="ln94"> </a>
<a name="ln95">// Allow for disabling remote bootstrap in unit tests where we want to test</a>
<a name="ln96">// certain scenarios without triggering bootstrap of a remote peer.</a>
<a name="ln97">DEFINE_test_flag(bool, enable_remote_bootstrap, true,</a>
<a name="ln98">                 &quot;Whether remote bootstrap will be initiated by the leader when it &quot;</a>
<a name="ln99">                 &quot;detects that a follower is out of date or does not have a tablet &quot;</a>
<a name="ln100">                 &quot;replica.&quot;);</a>
<a name="ln101"> </a>
<a name="ln102">DECLARE_int32(TEST_log_change_config_every_n);</a>
<a name="ln103"> </a>
<a name="ln104">namespace yb {</a>
<a name="ln105">namespace consensus {</a>
<a name="ln106"> </a>
<a name="ln107">using log::Log;</a>
<a name="ln108">using log::LogEntryBatch;</a>
<a name="ln109">using std::shared_ptr;</a>
<a name="ln110">using rpc::Messenger;</a>
<a name="ln111">using rpc::PeriodicTimer;</a>
<a name="ln112">using rpc::RpcController;</a>
<a name="ln113">using strings::Substitute;</a>
<a name="ln114"> </a>
<a name="ln115">Peer::Peer(</a>
<a name="ln116">    const RaftPeerPB&amp; peer_pb, string tablet_id, string leader_uuid, PeerProxyPtr proxy,</a>
<a name="ln117">    PeerMessageQueue* queue, ThreadPoolToken* raft_pool_token, Consensus* consensus,</a>
<a name="ln118">    rpc::Messenger* messenger)</a>
<a name="ln119">    : tablet_id_(std::move(tablet_id)),</a>
<a name="ln120">      leader_uuid_(std::move(leader_uuid)),</a>
<a name="ln121">      peer_pb_(peer_pb),</a>
<a name="ln122">      proxy_(std::move(proxy)),</a>
<a name="ln123">      queue_(queue),</a>
<a name="ln124">      raft_pool_token_(raft_pool_token),</a>
<a name="ln125">      consensus_(consensus),</a>
<a name="ln126">      messenger_(messenger) {}</a>
<a name="ln127"> </a>
<a name="ln128">void Peer::SetTermForTest(int term) {</a>
<a name="ln129">  response_.set_responder_term(term);</a>
<a name="ln130">}</a>
<a name="ln131"> </a>
<a name="ln132">Status Peer::Init() {</a>
<a name="ln133">  std::lock_guard&lt;simple_spinlock&gt; lock(peer_lock_);</a>
<a name="ln134">  queue_-&gt;TrackPeer(peer_pb_.permanent_uuid());</a>
<a name="ln135">  // Capture a weak_ptr reference into the functor so it can safely handle</a>
<a name="ln136">  // outliving the peer.</a>
<a name="ln137">  std::weak_ptr&lt;Peer&gt; weak_peer = shared_from_this();</a>
<a name="ln138">  heartbeater_ = PeriodicTimer::Create(</a>
<a name="ln139">      messenger_,</a>
<a name="ln140">      [weak_peer]() {</a>
<a name="ln141">        if (auto p = weak_peer.lock()) {</a>
<a name="ln142">          Status s = p-&gt;SignalRequest(RequestTriggerMode::kAlwaysSend);</a>
<a name="ln143">        }</a>
<a name="ln144">      },</a>
<a name="ln145">      MonoDelta::FromMilliseconds(FLAGS_raft_heartbeat_interval_ms));</a>
<a name="ln146">  heartbeater_-&gt;Start();</a>
<a name="ln147">  state_ = kPeerStarted;</a>
<a name="ln148">  return Status::OK();</a>
<a name="ln149">}</a>
<a name="ln150"> </a>
<a name="ln151">Status Peer::SignalRequest(RequestTriggerMode trigger_mode) {</a>
<a name="ln152">  // If the peer is currently sending, return Status::OK().</a>
<a name="ln153">  // If there are new requests in the queue we'll get them on ProcessResponse().</a>
<a name="ln154">  auto performing_lock = LockPerforming(std::try_to_lock);</a>
<a name="ln155">  if (!performing_lock.owns_lock()) {</a>
<a name="ln156">    return Status::OK();</a>
<a name="ln157">  }</a>
<a name="ln158"> </a>
<a name="ln159">  {</a>
<a name="ln160">    auto processing_lock = StartProcessingUnlocked();</a>
<a name="ln161">    if (!processing_lock.owns_lock()) {</a>
<a name="ln162">      return STATUS(IllegalState, &quot;Peer was closed.&quot;);</a>
<a name="ln163">    }</a>
<a name="ln164"> </a>
<a name="ln165">    // For the first request sent by the peer, we send it even if the queue is empty, which it will</a>
<a name="ln166">    // always appear to be for the first request, since this is the negotiation round.</a>
<a name="ln167">    if (PREDICT_FALSE(state_ == kPeerStarted)) {</a>
<a name="ln168">      trigger_mode = RequestTriggerMode::kAlwaysSend;</a>
<a name="ln169">      state_ = kPeerRunning;</a>
<a name="ln170">    }</a>
<a name="ln171">    DCHECK_EQ(state_, kPeerRunning);</a>
<a name="ln172"> </a>
<a name="ln173">    // If our last request generated an error, and this is not a normal heartbeat request (i.e.</a>
<a name="ln174">    // we're not forcing a request even if the queue is empty, unlike we do during heartbeats),</a>
<a name="ln175">    // then don't send the &quot;per-RPC&quot; request. Instead, we'll wait for the heartbeat.</a>
<a name="ln176">    //</a>
<a name="ln177">    // TODO: we could consider looking at the number of consecutive failed attempts, and instead of</a>
<a name="ln178">    // ignoring the signal, ask the heartbeater to &quot;expedite&quot; the next heartbeat in order to achieve</a>
<a name="ln179">    // something like exponential backoff after an error. As it is implemented today, any transient</a>
<a name="ln180">    // error will result in a latency blip as long as the heartbeat period.</a>
<a name="ln181">    if (failed_attempts_ &gt; 0 &amp;&amp; trigger_mode == RequestTriggerMode::kNonEmptyOnly) {</a>
<a name="ln182">      return Status::OK();</a>
<a name="ln183">    }</a>
<a name="ln184"> </a>
<a name="ln185">    using_thread_pool_.fetch_add(1, std::memory_order_acq_rel);</a>
<a name="ln186">  }</a>
<a name="ln187">  auto status = raft_pool_token_-&gt;SubmitFunc(</a>
<a name="ln188">      std::bind(&amp;Peer::SendNextRequest, shared_from_this(), trigger_mode));</a>
<a name="ln189">  using_thread_pool_.fetch_sub(1, std::memory_order_acq_rel);</a>
<a name="ln190">  if (status.ok()) {</a>
<a name="ln191">    performing_lock.release();</a>
<a name="ln192">  }</a>
<a name="ln193">  return status;</a>
<a name="ln194">}</a>
<a name="ln195"> </a>
<a name="ln196">void Peer::SendNextRequest(RequestTriggerMode trigger_mode) {</a>
<a name="ln197">  auto retain_self = shared_from_this();</a>
<a name="ln198">  DCHECK(performing_mutex_.is_locked()) &lt;&lt; &quot;Cannot send request&quot;;</a>
<a name="ln199"> </a>
<a name="ln200">  auto performing_lock = LockPerforming(std::adopt_lock);</a>
<a name="ln201">  auto processing_lock = StartProcessingUnlocked();</a>
<a name="ln202">  if (!processing_lock.owns_lock()) {</a>
<a name="ln203">    return;</a>
<a name="ln204">  }</a>
<a name="ln205"> </a>
<a name="ln206">  // The peer has no pending request nor is sending: send the request.</a>
<a name="ln207">  bool needs_remote_bootstrap = false;</a>
<a name="ln208">  bool last_exchange_successful = false;</a>
<a name="ln209">  RaftPeerPB::MemberType member_type = RaftPeerPB::UNKNOWN_MEMBER_TYPE;</a>
<a name="ln210">  int64_t commit_index_before = request_.has_committed_op_id() ?</a>
<a name="ln211">      request_.committed_op_id().index() : kMinimumOpIdIndex;</a>
<a name="ln212">  ReplicateMsgsHolder msgs_holder;</a>
<a name="ln213">  Status s = queue_-&gt;RequestForPeer(</a>
<a name="ln214">      peer_pb_.permanent_uuid(), &amp;request_, &amp;msgs_holder, &amp;needs_remote_bootstrap,</a>
<a name="ln215">      &amp;member_type, &amp;last_exchange_successful);</a>
<a name="ln216">  int64_t commit_index_after = request_.has_committed_op_id() ?</a>
<a name="ln217">      request_.committed_op_id().index() : kMinimumOpIdIndex;</a>
<a name="ln218"> </a>
<a name="ln219">  if (PREDICT_FALSE(!s.ok())) {</a>
<a name="ln220">    LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Could not obtain request from queue for peer: &quot; &lt;&lt; s;</a>
<a name="ln221">    return;</a>
<a name="ln222">  }</a>
<a name="ln223"> </a>
<a name="ln224">  if (PREDICT_FALSE(needs_remote_bootstrap)) {</a>
<a name="ln225">    Status status;</a>
<a name="ln226">    if (!FLAGS_TEST_enable_remote_bootstrap) {</a>
<a name="ln227">      failed_attempts_++;</a>
<a name="ln228">      status = STATUS(NotSupported, &quot;remote bootstrap is disabled&quot;);</a>
<a name="ln229">    } else {</a>
<a name="ln230">      status = queue_-&gt;GetRemoteBootstrapRequestForPeer(peer_pb_.permanent_uuid(), &amp;rb_request_);</a>
<a name="ln231">    }</a>
<a name="ln232">    if (!status.ok()) {</a>
<a name="ln233">      LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Unable to generate remote bootstrap request for peer: &quot;</a>
<a name="ln234">                               &lt;&lt; status;</a>
<a name="ln235">      return;</a>
<a name="ln236">    }</a>
<a name="ln237"> </a>
<a name="ln238">    using_thread_pool_.fetch_add(1, std::memory_order_acq_rel);</a>
<a name="ln239">    s = SendRemoteBootstrapRequest();</a>
<a name="ln240">    using_thread_pool_.fetch_sub(1, std::memory_order_acq_rel);</a>
<a name="ln241">    if (s.ok()) {</a>
<a name="ln242">      performing_lock.release();</a>
<a name="ln243">    }</a>
<a name="ln244">    return;</a>
<a name="ln245">  }</a>
<a name="ln246"> </a>
<a name="ln247">  // If the peer doesn't need remote bootstrap, but it is a PRE_VOTER or PRE_OBSERVER in the config,</a>
<a name="ln248">  // we need to promote it.</a>
<a name="ln249">  if (last_exchange_successful &amp;&amp;</a>
<a name="ln250">      (member_type == RaftPeerPB::PRE_VOTER || member_type == RaftPeerPB::PRE_OBSERVER)) {</a>
<a name="ln251">    if (PREDICT_TRUE(consensus_)) {</a>
<a name="ln252">      auto uuid = peer_pb_.permanent_uuid();</a>
<a name="ln253">      processing_lock.unlock();</a>
<a name="ln254">      performing_lock.unlock();</a>
<a name="ln255">      consensus::ChangeConfigRequestPB req;</a>
<a name="ln256">      consensus::ChangeConfigResponsePB resp;</a>
<a name="ln257"> </a>
<a name="ln258">      req.set_tablet_id(tablet_id_);</a>
<a name="ln259">      req.set_type(consensus::CHANGE_ROLE);</a>
<a name="ln260">      RaftPeerPB *peer = req.mutable_server();</a>
<a name="ln261">      peer-&gt;set_permanent_uuid(peer_pb_.permanent_uuid());</a>
<a name="ln262"> </a>
<a name="ln263">      boost::optional&lt;tserver::TabletServerErrorPB::Code&gt; error_code;</a>
<a name="ln264"> </a>
<a name="ln265">      // If another ChangeConfig is being processed, our request will be rejected.</a>
<a name="ln266">      YB_LOG_EVERY_N(INFO, FLAGS_TEST_log_change_config_every_n)</a>
<a name="ln267">          &lt;&lt; &quot;Sending ChangeConfig request to promote peer&quot;;</a>
<a name="ln268">      auto status = consensus_-&gt;ChangeConfig(req, &amp;DoNothingStatusCB, &amp;error_code);</a>
<a name="ln269">      if (PREDICT_FALSE(!status.ok())) {</a>
<a name="ln270">        YB_LOG_EVERY_N(INFO, FLAGS_TEST_log_change_config_every_n)</a>
<a name="ln271">            &lt;&lt; &quot;Unable to change role for peer &quot; &lt;&lt; uuid &lt;&lt; &quot;: &quot; &lt;&lt; status;</a>
<a name="ln272">        // Since we released the semaphore, we need to call SignalRequest again to send a message</a>
<a name="ln273">        status = SignalRequest(RequestTriggerMode::kAlwaysSend);</a>
<a name="ln274">        if (PREDICT_FALSE(!status.ok())) {</a>
<a name="ln275">          LOG(WARNING) &lt;&lt; &quot;Unexpected error when trying to send request: &quot;</a>
<a name="ln276">                       &lt;&lt; status;</a>
<a name="ln277">        }</a>
<a name="ln278">      }</a>
<a name="ln279">      return;</a>
<a name="ln280">    }</a>
<a name="ln281">  }</a>
<a name="ln282"> </a>
<a name="ln283">  if (request_.tablet_id().empty()) {</a>
<a name="ln284">    request_.set_tablet_id(tablet_id_);</a>
<a name="ln285">    request_.set_caller_uuid(leader_uuid_);</a>
<a name="ln286">    request_.set_dest_uuid(peer_pb_.permanent_uuid());</a>
<a name="ln287">  }</a>
<a name="ln288"> </a>
<a name="ln289">  const bool req_has_ops = (request_.ops_size() &gt; 0) || (commit_index_after &gt; commit_index_before);</a>
<a name="ln290"> </a>
<a name="ln291">  // If the queue is empty, check if we were told to send a status-only message (which is what</a>
<a name="ln292">  // happens during heartbeats). If not, just return.</a>
<a name="ln293">  if (PREDICT_FALSE(!req_has_ops &amp;&amp; trigger_mode == RequestTriggerMode::kNonEmptyOnly)) {</a>
<a name="ln294">    return;</a>
<a name="ln295">  }</a>
<a name="ln296"> </a>
<a name="ln297">  // If we're actually sending ops there's no need to heartbeat for a while, reset the heartbeater.</a>
<a name="ln298">  if (req_has_ops) {</a>
<a name="ln299">    heartbeater_-&gt;Snooze();</a>
<a name="ln300">  }</a>
<a name="ln301"> </a>
<a name="ln302">  MAYBE_FAULT(FLAGS_TEST_fault_crash_on_leader_request_fraction);</a>
<a name="ln303"> </a>
<a name="ln304">  processing_lock.unlock();</a>
<a name="ln305">  performing_lock.release();</a>
<a name="ln306"> </a>
<a name="ln307">  // We will cleanup ops from request in ProcessResponse, because otherwise there could be race</a>
<a name="ln308">  // condition. When rest of this function is running in parallel to ProcessResponse.</a>
<a name="ln309">  msgs_holder.ReleaseOps();</a>
<a name="ln310"> </a>
<a name="ln311">  controller_.set_invoke_callback_mode(rpc::InvokeCallbackMode::kThreadPoolHigh);</a>
<a name="ln312">  proxy_-&gt;UpdateAsync(&amp;request_, trigger_mode, &amp;response_, &amp;controller_,</a>
<a name="ln313">                      std::bind(&amp;Peer::ProcessResponse, retain_self));</a>
<a name="ln314">}</a>
<a name="ln315"> </a>
<a name="ln316">std::unique_lock&lt;simple_spinlock&gt; Peer::StartProcessingUnlocked() {</a>
<a name="ln317">  std::unique_lock&lt;simple_spinlock&gt; lock(peer_lock_);</a>
<a name="ln318"> </a>
<a name="ln319">  if (state_ == kPeerClosed) {</a>
<a name="ln320">    lock.unlock();</a>
<a name="ln321">  }</a>
<a name="ln322"> </a>
<a name="ln323">  return lock;</a>
<a name="ln324">}</a>
<a name="ln325"> </a>
<a name="ln326">void Peer::ProcessResponse() {</a>
<a name="ln327">  request_.mutable_ops()-&gt;ExtractSubrange(0, request_.ops().size(), nullptr /* elements */);</a>
<a name="ln328"> </a>
<a name="ln329">  DCHECK(performing_mutex_.is_locked()) &lt;&lt; &quot;Got a response when nothing was pending&quot;;</a>
<a name="ln330">  Status status = controller_.status();</a>
<a name="ln331">  controller_.Reset();</a>
<a name="ln332"> </a>
<a name="ln333">  auto performing_lock = LockPerforming(std::adopt_lock);</a>
<a name="ln334"> </a>
<a name="ln335">  auto processing_lock = StartProcessingUnlocked();</a>
<a name="ln336">  if (!processing_lock.owns_lock()) {</a>
<a name="ln337">    return;</a>
<a name="ln338">  }</a>
<a name="ln339"> </a>
<a name="ln340">  if (!status.ok()) {</a>
<a name="ln341">    if (status.IsRemoteError()) {</a>
<a name="ln342">      // Most controller errors are caused by network issues or corner cases like shutdown and</a>
<a name="ln343">      // failure to serialize a protobuf. Therefore, we generally consider these errors to indicate</a>
<a name="ln344">      // an unreachable peer.  However, a RemoteError wraps some other error propagated from the</a>
<a name="ln345">      // remote peer, so we know the remote is alive. Therefore, we will let the queue know that the</a>
<a name="ln346">      // remote is responsive.</a>
<a name="ln347">      queue_-&gt;NotifyPeerIsResponsiveDespiteError(peer_pb_.permanent_uuid());</a>
<a name="ln348">    }</a>
<a name="ln349">    ProcessResponseError(status);</a>
<a name="ln350">    return;</a>
<a name="ln351">  }</a>
<a name="ln352"> </a>
<a name="ln353">  if (response_.has_propagated_hybrid_time()) {</a>
<a name="ln354">    queue_-&gt;clock()-&gt;Update(HybridTime(response_.propagated_hybrid_time()));</a>
<a name="ln355">  }</a>
<a name="ln356"> </a>
<a name="ln357">  // We should try to evict a follower which returns a WRONG UUID error.</a>
<a name="ln358">  if (response_.has_error() &amp;&amp;</a>
<a name="ln359">      response_.error().code() == tserver::TabletServerErrorPB::WRONG_SERVER_UUID) {</a>
<a name="ln360">    queue_-&gt;NotifyObserversOfFailedFollower(</a>
<a name="ln361">        peer_pb_.permanent_uuid(),</a>
<a name="ln362">        Substitute(&quot;Leader communication with peer $0 received error $1, will try to &quot;</a>
<a name="ln363">                   &quot;evict peer&quot;, peer_pb_.permanent_uuid(),</a>
<a name="ln364">                   response_.error().ShortDebugString()));</a>
<a name="ln365">    ProcessResponseError(StatusFromPB(response_.error().status()));</a>
<a name="ln366">    return;</a>
<a name="ln367">  }</a>
<a name="ln368"> </a>
<a name="ln369">  auto s = StatusFromResponse(response_);</a>
<a name="ln370">  if (!s.ok() &amp;&amp;</a>
<a name="ln371">      tserver::TabletServerError(s) == tserver::TabletServerErrorPB::TABLET_NOT_RUNNING &amp;&amp;</a>
<a name="ln372">      tablet::RaftGroupStateError(s) == tablet::RaftGroupStatePB::FAILED) {</a>
<a name="ln373">    if (PREDICT_FALSE(FLAGS_TEST_delay_removing_peer_with_failed_tablet_secs &gt; 0)) {</a>
<a name="ln374">      LOG(INFO) &lt;&lt; &quot;TEST: Sleeping for &quot; &lt;&lt; FLAGS_TEST_delay_removing_peer_with_failed_tablet_secs</a>
<a name="ln375">                &lt;&lt; &quot; seconds&quot;;</a>
<a name="ln376">      SleepFor(MonoDelta::FromSeconds(FLAGS_TEST_delay_removing_peer_with_failed_tablet_secs));</a>
<a name="ln377">    }</a>
<a name="ln378">    queue_-&gt;NotifyObserversOfFailedFollower(</a>
<a name="ln379">        peer_pb_.permanent_uuid(),</a>
<a name="ln380">        Format(&quot;Tablet in peer $0 is in FAILED state, will try to evict peer&quot;,</a>
<a name="ln381">               peer_pb_.permanent_uuid()));</a>
<a name="ln382">    ProcessResponseError(StatusFromPB(response_.error().status()));</a>
<a name="ln383">  }</a>
<a name="ln384"> </a>
<a name="ln385">  // Response should be either error or status.</a>
<a name="ln386">  LOG_IF(DFATAL, response_.has_error() == response_.has_status())</a>
<a name="ln387">    &lt;&lt; &quot;Invalid response: &quot; &lt;&lt; response_.ShortDebugString();</a>
<a name="ln388"> </a>
<a name="ln389">  // Pass through errors we can respond to, like not found, since in that case</a>
<a name="ln390">  // we will need to remotely bootstrap. TODO: Handle DELETED response once implemented.</a>
<a name="ln391">  if ((response_.has_error() &amp;&amp;</a>
<a name="ln392">      response_.error().code() != tserver::TabletServerErrorPB::TABLET_NOT_FOUND) ||</a>
<a name="ln393">      (response_.status().has_error() &amp;&amp;</a>
<a name="ln394">          response_.status().error().code() == consensus::ConsensusErrorPB::CANNOT_PREPARE)) {</a>
<a name="ln395">    // Again, let the queue know that the remote is still responsive, since we will not be sending</a>
<a name="ln396">    // this error response through to the queue.</a>
<a name="ln397">    queue_-&gt;NotifyPeerIsResponsiveDespiteError(peer_pb_.permanent_uuid());</a>
<a name="ln398">    ProcessResponseError(StatusFromPB(response_.error().status()));</a>
<a name="ln399">    return;</a>
<a name="ln400">  }</a>
<a name="ln401"> </a>
<a name="ln402">  failed_attempts_ = 0;</a>
<a name="ln403">  bool more_pending = queue_-&gt;ResponseFromPeer(peer_pb_.permanent_uuid(), response_);</a>
<a name="ln404"> </a>
<a name="ln405">  if (more_pending) {</a>
<a name="ln406">    processing_lock.unlock();</a>
<a name="ln407">    performing_lock.release();</a>
<a name="ln408">    SendNextRequest(RequestTriggerMode::kAlwaysSend);</a>
<a name="ln409">  }</a>
<a name="ln410">}</a>
<a name="ln411"> </a>
<a name="ln412">Status Peer::SendRemoteBootstrapRequest() {</a>
<a name="ln413">  YB_LOG_WITH_PREFIX_EVERY_N_SECS(INFO, 30) &lt;&lt; &quot;Sending request to remotely bootstrap&quot;;</a>
<a name="ln414">  controller_.set_invoke_callback_mode(rpc::InvokeCallbackMode::kThreadPoolNormal);</a>
<a name="ln415">  return raft_pool_token_-&gt;SubmitFunc([retain_self = shared_from_this()]() {</a>
<a name="ln416">    retain_self-&gt;proxy_-&gt;StartRemoteBootstrap(</a>
<a name="ln417">      &amp;retain_self-&gt;rb_request_, &amp;retain_self-&gt;rb_response_, &amp;retain_self-&gt;controller_,</a>
<a name="ln418">      std::bind(&amp;Peer::ProcessRemoteBootstrapResponse, retain_self));</a>
<a name="ln419">  });</a>
<a name="ln420">}</a>
<a name="ln421"> </a>
<a name="ln422">void Peer::ProcessRemoteBootstrapResponse() {</a>
<a name="ln423">  Status status = controller_.status();</a>
<a name="ln424">  controller_.Reset();</a>
<a name="ln425"> </a>
<a name="ln426">  auto performing_lock = LockPerforming(std::adopt_lock);</a>
<a name="ln427">  auto processing_lock = StartProcessingUnlocked();</a>
<a name="ln428">  if (!processing_lock.owns_lock()) {</a>
<a name="ln429">    return;</a>
<a name="ln430">  }</a>
<a name="ln431"> </a>
<a name="ln432">  if (!status.ok()) {</a>
<a name="ln433">    LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Unable to begin remote bootstrap on peer: &quot; &lt;&lt; status;</a>
<a name="ln434">    return;</a>
<a name="ln435">  }</a>
<a name="ln436"> </a>
<a name="ln437">  if (rb_response_.has_error()) {</a>
<a name="ln438">    if (rb_response_.error().code() == tserver::TabletServerErrorPB::ALREADY_IN_PROGRESS) {</a>
<a name="ln439">      queue_-&gt;NotifyPeerIsResponsiveDespiteError(peer_pb_.permanent_uuid());</a>
<a name="ln440">      YB_LOG_WITH_PREFIX_EVERY_N_SECS(WARNING, 30)</a>
<a name="ln441">        &lt;&lt; &quot;:::Unable to begin remote bootstrap on peer: &quot; &lt;&lt; rb_response_.ShortDebugString();</a>
<a name="ln442">    } else {</a>
<a name="ln443">      LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Unable to begin remote bootstrap on peer: &quot;</a>
<a name="ln444">                               &lt;&lt; rb_response_.ShortDebugString();</a>
<a name="ln445">    }</a>
<a name="ln446">  }</a>
<a name="ln447">}</a>
<a name="ln448"> </a>
<a name="ln449">void Peer::ProcessResponseError(const Status&amp; status) {</a>
<a name="ln450">  DCHECK(performing_mutex_.is_locked());</a>
<a name="ln451">  failed_attempts_++;</a>
<a name="ln452">  YB_LOG_WITH_PREFIX_EVERY_N_SECS(WARNING, 5) &lt;&lt; &quot;Couldn't send request. &quot;</a>
<a name="ln453">      &lt;&lt; &quot; Status: &quot; &lt;&lt; status.ToString() &lt;&lt; &quot;. Retrying in the next heartbeat period.&quot;</a>
<a name="ln454">      &lt;&lt; &quot; Already tried &quot; &lt;&lt; failed_attempts_ &lt;&lt; &quot; times. State: &quot; &lt;&lt; state_;</a>
<a name="ln455">}</a>
<a name="ln456"> </a>
<a name="ln457">string Peer::LogPrefix() const {</a>
<a name="ln458">  return Format(&quot;T $0 P $1 -&gt; Peer $2 ($3, $4): &quot;,</a>
<a name="ln459">                tablet_id_, leader_uuid_, peer_pb_.permanent_uuid(),</a>
<a name="ln460">                peer_pb_.last_known_private_addr(), peer_pb_.last_known_broadcast_addr());</a>
<a name="ln461">}</a>
<a name="ln462"> </a>
<a name="ln463">void Peer::Close() {</a>
<a name="ln464">  if (heartbeater_) {</a>
<a name="ln465">    heartbeater_-&gt;Stop();</a>
<a name="ln466">  }</a>
<a name="ln467"> </a>
<a name="ln468">  // If the peer is already closed return.</a>
<a name="ln469">  {</a>
<a name="ln470">    std::lock_guard&lt;simple_spinlock&gt; processing_lock(peer_lock_);</a>
<a name="ln471">    if (using_thread_pool_.load(std::memory_order_acquire) &gt; 0) {</a>
<a name="ln472">      auto deadline = std::chrono::steady_clock::now() +</a>
<a name="ln473">                      FLAGS_max_wait_for_processresponse_before_closing_ms * 1ms;</a>
<a name="ln474">      BackoffWaiter waiter(deadline, 100ms);</a>
<a name="ln475">      while (using_thread_pool_.load(std::memory_order_acquire) &gt; 0) {</a>
<a name="ln476">        if (!waiter.Wait()) {</a>
<a name="ln477">          LOG_WITH_PREFIX(DFATAL)</a>
<a name="ln478">              &lt;&lt; &quot;Timed out waiting for ThreadPoolToken::SubmitFunc() to finish. &quot;</a>
<a name="ln479">              &lt;&lt; &quot;Number of pending calls: &quot; &lt;&lt; using_thread_pool_.load(std::memory_order_acquire);</a>
<a name="ln480">          break;</a>
<a name="ln481">        }</a>
<a name="ln482">      }</a>
<a name="ln483">    }</a>
<a name="ln484">    if (state_ == kPeerClosed) {</a>
<a name="ln485">      return;</a>
<a name="ln486">    }</a>
<a name="ln487">    DCHECK(state_ == kPeerRunning || state_ == kPeerStarted) &lt;&lt; &quot;Unexpected state: &quot; &lt;&lt; state_;</a>
<a name="ln488">    state_ = kPeerClosed;</a>
<a name="ln489">    LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Closing peer&quot;;</a>
<a name="ln490">  }</a>
<a name="ln491"> </a>
<a name="ln492">  auto retain_self = shared_from_this();</a>
<a name="ln493"> </a>
<a name="ln494">  queue_-&gt;UntrackPeer(peer_pb_.permanent_uuid());</a>
<a name="ln495">}</a>
<a name="ln496"> </a>
<a name="ln497">Peer::~Peer() {</a>
<a name="ln498">  std::lock_guard&lt;simple_spinlock&gt; processing_lock(peer_lock_);</a>
<a name="ln499">  CHECK_EQ(state_, kPeerClosed) &lt;&lt; &quot;Peer cannot be implicitly closed&quot;;</a>
<a name="ln500">}</a>
<a name="ln501"> </a>
<a name="ln502">RpcPeerProxy::RpcPeerProxy(HostPort hostport, ConsensusServiceProxyPtr consensus_proxy)</a>
<a name="ln503">    : hostport_(std::move(hostport)), consensus_proxy_(std::move(consensus_proxy)) {</a>
<a name="ln504">}</a>
<a name="ln505"> </a>
<a name="ln506">void RpcPeerProxy::UpdateAsync(const ConsensusRequestPB* request,</a>
<a name="ln507">                               RequestTriggerMode trigger_mode,</a>
<a name="ln508">                               ConsensusResponsePB* response,</a>
<a name="ln509">                               rpc::RpcController* controller,</a>
<a name="ln510">                               const rpc::ResponseCallback&amp; callback) {</a>
<a name="ln511">  controller-&gt;set_timeout(MonoDelta::FromMilliseconds(FLAGS_consensus_rpc_timeout_ms));</a>
<a name="ln512">  consensus_proxy_-&gt;UpdateConsensusAsync(*request, response, controller, callback);</a>
<a name="ln513">}</a>
<a name="ln514"> </a>
<a name="ln515">void RpcPeerProxy::RequestConsensusVoteAsync(const VoteRequestPB* request,</a>
<a name="ln516">                                             VoteResponsePB* response,</a>
<a name="ln517">                                             rpc::RpcController* controller,</a>
<a name="ln518">                                             const rpc::ResponseCallback&amp; callback) {</a>
<a name="ln519">  consensus_proxy_-&gt;RequestConsensusVoteAsync(*request, response, controller, callback);</a>
<a name="ln520">}</a>
<a name="ln521"> </a>
<a name="ln522">void RpcPeerProxy::RunLeaderElectionAsync(const RunLeaderElectionRequestPB* request,</a>
<a name="ln523">                                          RunLeaderElectionResponsePB* response,</a>
<a name="ln524">                                          rpc::RpcController* controller,</a>
<a name="ln525">                                          const rpc::ResponseCallback&amp; callback) {</a>
<a name="ln526">  controller-&gt;set_timeout(MonoDelta::FromMilliseconds(FLAGS_consensus_rpc_timeout_ms));</a>
<a name="ln527">  consensus_proxy_-&gt;RunLeaderElectionAsync(*request, response, controller, callback);</a>
<a name="ln528">}</a>
<a name="ln529"> </a>
<a name="ln530">void RpcPeerProxy::LeaderElectionLostAsync(const LeaderElectionLostRequestPB* request,</a>
<a name="ln531">                                           LeaderElectionLostResponsePB* response,</a>
<a name="ln532">                                           rpc::RpcController* controller,</a>
<a name="ln533">                                           const rpc::ResponseCallback&amp; callback) {</a>
<a name="ln534">  consensus_proxy_-&gt;LeaderElectionLostAsync(*request, response, controller, callback);</a>
<a name="ln535">}</a>
<a name="ln536"> </a>
<a name="ln537">void RpcPeerProxy::StartRemoteBootstrap(const StartRemoteBootstrapRequestPB* request,</a>
<a name="ln538">                                        StartRemoteBootstrapResponsePB* response,</a>
<a name="ln539">                                        rpc::RpcController* controller,</a>
<a name="ln540">                                        const rpc::ResponseCallback&amp; callback) {</a>
<a name="ln541">  consensus_proxy_-&gt;StartRemoteBootstrapAsync(*request, response, controller, callback);</a>
<a name="ln542">}</a>
<a name="ln543"> </a>
<a name="ln544">RpcPeerProxy::~RpcPeerProxy() {}</a>
<a name="ln545"> </a>
<a name="ln546">RpcPeerProxyFactory::RpcPeerProxyFactory(</a>
<a name="ln547">    Messenger* messenger, rpc::ProxyCache* proxy_cache, CloudInfoPB from)</a>
<a name="ln548">    : messenger_(messenger), proxy_cache_(proxy_cache), from_(std::move(from)) {}</a>
<a name="ln549"> </a>
<a name="ln550">PeerProxyPtr RpcPeerProxyFactory::NewProxy(const RaftPeerPB&amp; peer_pb) {</a>
<a name="ln551">  auto hostport = HostPortFromPB(DesiredHostPort(peer_pb, from_));</a>
<a name="ln552">  auto proxy = std::make_unique&lt;ConsensusServiceProxy&gt;(proxy_cache_, hostport);</a>
<a name="ln553">  return std::make_unique&lt;RpcPeerProxy&gt;(std::move(hostport), std::move(proxy));</a>
<a name="ln554">}</a>
<a name="ln555"> </a>
<a name="ln556">RpcPeerProxyFactory::~RpcPeerProxyFactory() {}</a>
<a name="ln557"> </a>
<a name="ln558">rpc::Messenger* RpcPeerProxyFactory::messenger() const { return messenger_; }</a>
<a name="ln559"> </a>
<a name="ln560">struct GetNodeInstanceRequest {</a>
<a name="ln561">  GetNodeInstanceRequestPB req;</a>
<a name="ln562">  GetNodeInstanceResponsePB resp;</a>
<a name="ln563">  rpc::RpcController controller;</a>
<a name="ln564">  ConsensusServiceProxy proxy;</a>
<a name="ln565"> </a>
<a name="ln566">  GetNodeInstanceRequest(rpc::ProxyCache* proxy_cache, const HostPort&amp; hostport)</a>
<a name="ln567">      : proxy(proxy_cache, hostport) {}</a>
<a name="ln568">};</a>
<a name="ln569"> </a>
<a name="ln570">Status SetPermanentUuidForRemotePeer(</a>
<a name="ln571">    rpc::ProxyCache* proxy_cache,</a>
<a name="ln572">    std::chrono::steady_clock::duration timeout,</a>
<a name="ln573">    const std::vector&lt;HostPort&gt;&amp; endpoints,</a>
<a name="ln574">    RaftPeerPB* remote_peer) {</a>
<a name="ln575"> </a>
<a name="ln576">  DCHECK(!remote_peer-&gt;has_permanent_uuid());</a>
<a name="ln577">  auto deadline = std::chrono::steady_clock::now() + timeout;</a>
<a name="ln578"> </a>
<a name="ln579">  std::vector&lt;GetNodeInstanceRequest&gt; requests;</a>
<a name="ln580">  requests.reserve(endpoints.size());</a>
<a name="ln581">  for (const auto&amp; hp : endpoints) {</a>
<a name="ln582">    requests.emplace_back(proxy_cache, hp);</a>
<a name="ln583">  }</a>
<a name="ln584"> </a>
<a name="ln585">  CountDownLatch latch(requests.size());</a>
<a name="ln586">  const auto kMaxWait = 10s;</a>
<a name="ln587">  BackoffWaiter waiter(deadline, kMaxWait);</a>
<a name="ln588">  for (;;) {</a>
<a name="ln589">    latch.Reset(requests.size());</a>
<a name="ln590">    std::atomic&lt;GetNodeInstanceRequest*&gt; last_reply{nullptr};</a>
<a name="ln591">    for (auto&amp; request : requests) {</a>
<a name="ln592">      request.controller.Reset();</a>
<a name="ln593">      request.controller.set_timeout(kMaxWait);</a>
<a name="ln594">      VLOG(2) &lt;&lt; &quot;Getting uuid from remote peer. Request: &quot; &lt;&lt; request.req.ShortDebugString();</a>
<a name="ln595"> </a>
<a name="ln596">      request.proxy.GetNodeInstanceAsync(</a>
<a name="ln597">          request.req, &amp;request.resp, &amp;request.controller,</a>
<a name="ln598">          [&amp;latch, &amp;request, &amp;last_reply] {</a>
<a name="ln599">        if (!request.controller.status().IsTimedOut()) {</a>
<a name="ln600">          last_reply.store(&amp;request, std::memory_order_release);</a>
<a name="ln601">        }</a>
<a name="ln602">        latch.CountDown();</a>
<a name="ln603">      });</a>
<a name="ln604">    }</a>
<a name="ln605"> </a>
<a name="ln606">    latch.Wait();</a>
<a name="ln607"> </a>
<a name="ln608">    for (auto&amp; request : requests) {</a>
<a name="ln609">      auto status = request.controller.status();</a>
<a name="ln610">      if (status.ok()) {</a>
<a name="ln611">        remote_peer-&gt;set_permanent_uuid(request.resp.node_instance().permanent_uuid());</a>
<a name="ln612">        remote_peer-&gt;set_member_type(RaftPeerPB::VOTER);</a>
<a name="ln613">        if (request.resp.has_registration()) {</a>
<a name="ln614">          CopyRegistration(request.resp.registration(), remote_peer);</a>
<a name="ln615">        } else {</a>
<a name="ln616">          // Required for backward compatibility.</a>
<a name="ln617">          HostPortsToPBs(endpoints, remote_peer-&gt;mutable_last_known_private_addr());</a>
<a name="ln618">        }</a>
<a name="ln619">        return Status::OK();</a>
<a name="ln620">      }</a>
<a name="ln621">    }</a>
<a name="ln622"> </a>
<a name="ln623">    auto* last_reply_value = last_reply.load(std::memory_order_acquire);</a>
<a name="ln624">    if (last_reply_value == nullptr) {</a>
<a name="ln625">      last_reply_value = &amp;requests.front();</a>
<a name="ln626">    }</a>
<a name="ln627"> </a>
<a name="ln628">    LOG(WARNING) &lt;&lt; &quot;Error getting permanent uuid from config peer &quot; &lt;&lt; yb::ToString(endpoints)</a>
<a name="ln629">                 &lt;&lt; &quot;: &quot; &lt;&lt; last_reply_value-&gt;controller.status();</a>
<a name="ln630"> </a>
<a name="ln631">    if (last_reply_value-&gt;controller.status().IsAborted()) {</a>
<a name="ln632">      return last_reply_value-&gt;controller.status();</a>
<a name="ln633">    }</a>
<a name="ln634"> </a>
<a name="ln635">    if (!waiter.Wait()) {</a>
<a name="ln636">      return STATUS_FORMAT(</a>
<a name="ln637">          TimedOut, &quot;Getting permanent uuid from $0 timed out after $1: $2&quot;,</a>
<a name="ln638">          endpoints, timeout, last_reply_value-&gt;controller.status());</a>
<a name="ln639">    }</a>
<a name="ln640"> </a>
<a name="ln641">    LOG(INFO) &lt;&lt; &quot;Retrying to get permanent uuid for remote peer: &quot;</a>
<a name="ln642">              &lt;&lt; yb::ToString(endpoints) &lt;&lt; &quot; attempt: &quot; &lt;&lt; waiter.attempt();</a>
<a name="ln643">  }</a>
<a name="ln644">}</a>
<a name="ln645"> </a>
<a name="ln646">}  // namespace consensus</a>
<a name="ln647">}  // namespace yb</a>

</code></pre>
<div class="balloon" rel="198"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="329"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="386"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="450"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="487"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="576"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="594"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
