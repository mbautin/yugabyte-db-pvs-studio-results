
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
  <title>tablet.cc</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">// Licensed to the Apache Software Foundation (ASF) under one</a>
<a name="ln2">// or more contributor license agreements.  See the NOTICE file</a>
<a name="ln3">// distributed with this work for additional information</a>
<a name="ln4">// regarding copyright ownership.  The ASF licenses this file</a>
<a name="ln5">// to you under the Apache License, Version 2.0 (the</a>
<a name="ln6">// &quot;License&quot;); you may not use this file except in compliance</a>
<a name="ln7">// with the License.  You may obtain a copy of the License at</a>
<a name="ln8">//</a>
<a name="ln9">//   http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="ln10">//</a>
<a name="ln11">// Unless required by applicable law or agreed to in writing,</a>
<a name="ln12">// software distributed under the License is distributed on an</a>
<a name="ln13">// &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</a>
<a name="ln14">// KIND, either express or implied.  See the License for the</a>
<a name="ln15">// specific language governing permissions and limitations</a>
<a name="ln16">// under the License.</a>
<a name="ln17">//</a>
<a name="ln18">// The following only applies to changes made to this file as part of YugaByte development.</a>
<a name="ln19">//</a>
<a name="ln20">// Portions Copyright (c) YugaByte, Inc.</a>
<a name="ln21">//</a>
<a name="ln22">// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except</a>
<a name="ln23">// in compliance with the License.  You may obtain a copy of the License at</a>
<a name="ln24">//</a>
<a name="ln25">// http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="ln26">//</a>
<a name="ln27">// Unless required by applicable law or agreed to in writing, software distributed under the License</a>
<a name="ln28">// is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express</a>
<a name="ln29">// or implied.  See the License for the specific language governing permissions and limitations</a>
<a name="ln30">// under the License.</a>
<a name="ln31">//</a>
<a name="ln32"> </a>
<a name="ln33">#include &quot;yb/tablet/tablet.h&quot;</a>
<a name="ln34"> </a>
<a name="ln35">#include &lt;libpq-fe.h&gt;</a>
<a name="ln36"> </a>
<a name="ln37">#include &lt;algorithm&gt;</a>
<a name="ln38">#include &lt;iterator&gt;</a>
<a name="ln39">#include &lt;limits&gt;</a>
<a name="ln40">#include &lt;memory&gt;</a>
<a name="ln41">#include &lt;mutex&gt;</a>
<a name="ln42">#include &lt;ostream&gt;</a>
<a name="ln43">#include &lt;unordered_set&gt;</a>
<a name="ln44">#include &lt;utility&gt;</a>
<a name="ln45">#include &lt;vector&gt;</a>
<a name="ln46"> </a>
<a name="ln47">#include &lt;boost/container/static_vector.hpp&gt;</a>
<a name="ln48">#include &lt;boost/optional.hpp&gt;</a>
<a name="ln49"> </a>
<a name="ln50">#include &quot;yb/rocksdb/db.h&quot;</a>
<a name="ln51">#include &quot;yb/rocksdb/db/memtable.h&quot;</a>
<a name="ln52">#include &quot;yb/rocksdb/options.h&quot;</a>
<a name="ln53">#include &quot;yb/rocksdb/statistics.h&quot;</a>
<a name="ln54">#include &quot;yb/rocksdb/utilities/checkpoint.h&quot;</a>
<a name="ln55">#include &quot;yb/rocksdb/write_batch.h&quot;</a>
<a name="ln56">#include &quot;yb/rocksdb/util/file_util.h&quot;</a>
<a name="ln57">#include &quot;yb/rocksutil/write_batch_formatter.h&quot;</a>
<a name="ln58"> </a>
<a name="ln59">#include &quot;yb/client/error.h&quot;</a>
<a name="ln60">#include &quot;yb/client/table.h&quot;</a>
<a name="ln61">#include &quot;yb/client/transaction.h&quot;</a>
<a name="ln62">#include &quot;yb/client/session.h&quot;</a>
<a name="ln63">#include &quot;yb/client/yb_op.h&quot;</a>
<a name="ln64"> </a>
<a name="ln65">#include &quot;yb/common/common.pb.h&quot;</a>
<a name="ln66">#include &quot;yb/common/hybrid_time.h&quot;</a>
<a name="ln67">#include &quot;yb/common/ql_protocol.pb.h&quot;</a>
<a name="ln68">#include &quot;yb/common/ql_rowblock.h&quot;</a>
<a name="ln69">#include &quot;yb/common/pgsql_error.h&quot;</a>
<a name="ln70">#include &quot;yb/common/row_mark.h&quot;</a>
<a name="ln71">#include &quot;yb/common/schema.h&quot;</a>
<a name="ln72">#include &quot;yb/common/transaction_error.h&quot;</a>
<a name="ln73"> </a>
<a name="ln74">#include &quot;yb/consensus/consensus.h&quot;</a>
<a name="ln75">#include &quot;yb/consensus/consensus.pb.h&quot;</a>
<a name="ln76">#include &quot;yb/consensus/log_anchor_registry.h&quot;</a>
<a name="ln77">#include &quot;yb/consensus/opid_util.h&quot;</a>
<a name="ln78"> </a>
<a name="ln79">#include &quot;yb/docdb/bounded_rocksdb_iterator.h&quot;</a>
<a name="ln80">#include &quot;yb/docdb/conflict_resolution.h&quot;</a>
<a name="ln81">#include &quot;yb/docdb/consensus_frontier.h&quot;</a>
<a name="ln82">#include &quot;yb/docdb/cql_operation.h&quot;</a>
<a name="ln83">#include &quot;yb/docdb/doc_rowwise_iterator.h&quot;</a>
<a name="ln84">#include &quot;yb/docdb/docdb.h&quot;</a>
<a name="ln85">#include &quot;yb/docdb/docdb.pb.h&quot;</a>
<a name="ln86">#include &quot;yb/docdb/docdb_compaction_filter.h&quot;</a>
<a name="ln87">#include &quot;yb/docdb/docdb_compaction_filter_intents.h&quot;</a>
<a name="ln88">#include &quot;yb/docdb/docdb_debug.h&quot;</a>
<a name="ln89">#include &quot;yb/docdb/docdb_rocksdb_util.h&quot;</a>
<a name="ln90">#include &quot;yb/docdb/intent.h&quot;</a>
<a name="ln91">#include &quot;yb/docdb/key_bytes.h&quot;</a>
<a name="ln92">#include &quot;yb/docdb/lock_batch.h&quot;</a>
<a name="ln93">#include &quot;yb/docdb/pgsql_operation.h&quot;</a>
<a name="ln94">#include &quot;yb/docdb/primitive_value.h&quot;</a>
<a name="ln95">#include &quot;yb/docdb/redis_operation.h&quot;</a>
<a name="ln96"> </a>
<a name="ln97">#include &quot;yb/gutil/atomicops.h&quot;</a>
<a name="ln98">#include &quot;yb/gutil/map-util.h&quot;</a>
<a name="ln99">#include &quot;yb/gutil/stl_util.h&quot;</a>
<a name="ln100">#include &quot;yb/gutil/strings/numbers.h&quot;</a>
<a name="ln101">#include &quot;yb/gutil/strings/substitute.h&quot;</a>
<a name="ln102">#include &quot;yb/rocksutil/yb_rocksdb.h&quot;</a>
<a name="ln103">#include &quot;yb/rocksutil/yb_rocksdb_logger.h&quot;</a>
<a name="ln104">#include &quot;yb/server/hybrid_clock.h&quot;</a>
<a name="ln105"> </a>
<a name="ln106">#include &quot;yb/tablet/tablet_fwd.h&quot;</a>
<a name="ln107">#include &quot;yb/tablet/maintenance_manager.h&quot;</a>
<a name="ln108">#include &quot;yb/tablet/snapshot_coordinator.h&quot;</a>
<a name="ln109">#include &quot;yb/tablet/tablet_snapshots.h&quot;</a>
<a name="ln110">#include &quot;yb/tablet/tablet_metrics.h&quot;</a>
<a name="ln111">#include &quot;yb/tablet/tablet_retention_policy.h&quot;</a>
<a name="ln112">#include &quot;yb/tablet/transaction_coordinator.h&quot;</a>
<a name="ln113">#include &quot;yb/tablet/transaction_participant.h&quot;</a>
<a name="ln114">#include &quot;yb/tablet/operations/change_metadata_operation.h&quot;</a>
<a name="ln115">#include &quot;yb/tablet/operations/truncate_operation.h&quot;</a>
<a name="ln116">#include &quot;yb/tablet/operations/write_operation.h&quot;</a>
<a name="ln117">#include &quot;yb/tablet/operations/snapshot_operation.h&quot;</a>
<a name="ln118">#include &quot;yb/tablet/tablet_options.h&quot;</a>
<a name="ln119"> </a>
<a name="ln120">#include &quot;yb/util/bloom_filter.h&quot;</a>
<a name="ln121">#include &quot;yb/util/debug/trace_event.h&quot;</a>
<a name="ln122">#include &quot;yb/util/enums.h&quot;</a>
<a name="ln123">#include &quot;yb/util/env.h&quot;</a>
<a name="ln124">#include &quot;yb/util/flag_tags.h&quot;</a>
<a name="ln125">#include &quot;yb/util/jsonwriter.h&quot;</a>
<a name="ln126">#include &quot;yb/util/locks.h&quot;</a>
<a name="ln127">#include &quot;yb/util/mem_tracker.h&quot;</a>
<a name="ln128">#include &quot;yb/util/metrics.h&quot;</a>
<a name="ln129">#include &quot;yb/util/net/net_util.h&quot;</a>
<a name="ln130">#include &quot;yb/util/pg_connstr.h&quot;</a>
<a name="ln131">#include &quot;yb/util/scope_exit.h&quot;</a>
<a name="ln132">#include &quot;yb/util/slice.h&quot;</a>
<a name="ln133">#include &quot;yb/util/stopwatch.h&quot;</a>
<a name="ln134">#include &quot;yb/util/trace.h&quot;</a>
<a name="ln135">#include &quot;yb/util/url-coding.h&quot;</a>
<a name="ln136"> </a>
<a name="ln137">DEFINE_bool(tablet_do_dup_key_checks, true,</a>
<a name="ln138">            &quot;Whether to check primary keys for duplicate on insertion. &quot;</a>
<a name="ln139">            &quot;Use at your own risk!&quot;);</a>
<a name="ln140">TAG_FLAG(tablet_do_dup_key_checks, unsafe);</a>
<a name="ln141"> </a>
<a name="ln142">DEFINE_bool(tablet_do_compaction_cleanup_for_intents, true,</a>
<a name="ln143">            &quot;Whether to clean up intents for aborted transactions in compaction.&quot;);</a>
<a name="ln144"> </a>
<a name="ln145">DEFINE_int32(tablet_bloom_block_size, 4096,</a>
<a name="ln146">             &quot;Block size of the bloom filters used for tablet keys.&quot;);</a>
<a name="ln147">TAG_FLAG(tablet_bloom_block_size, advanced);</a>
<a name="ln148"> </a>
<a name="ln149">DEFINE_double(tablet_bloom_target_fp_rate, 0.01f,</a>
<a name="ln150">              &quot;Target false-positive rate (between 0 and 1) to size tablet key bloom filters. &quot;</a>
<a name="ln151">              &quot;A lower false positive rate may reduce the number of disk seeks required &quot;</a>
<a name="ln152">              &quot;in heavy insert workloads, at the expense of more space and RAM &quot;</a>
<a name="ln153">              &quot;required for bloom filters.&quot;);</a>
<a name="ln154">TAG_FLAG(tablet_bloom_target_fp_rate, advanced);</a>
<a name="ln155"> </a>
<a name="ln156">METRIC_DEFINE_entity(tablet);</a>
<a name="ln157"> </a>
<a name="ln158">// TODO: use a lower default for truncate / snapshot restore Raft operations. The one-minute timeout</a>
<a name="ln159">// is probably OK for shutdown.</a>
<a name="ln160">DEFINE_int32(tablet_rocksdb_ops_quiet_down_timeout_ms, 60000,</a>
<a name="ln161">             &quot;Max amount of time we can wait for read/write operations on RocksDB to finish &quot;</a>
<a name="ln162">             &quot;so that we can perform exclusive-ownership operations on RocksDB, such as removing &quot;</a>
<a name="ln163">             &quot;all data in the tablet by replacing the RocksDB instance with an empty one.&quot;);</a>
<a name="ln164"> </a>
<a name="ln165">DEFINE_int32(intents_flush_max_delay_ms, 2000,</a>
<a name="ln166">             &quot;Max time to wait for regular db to flush during flush of intents. &quot;</a>
<a name="ln167">             &quot;After this time flush of regular db will be forced.&quot;);</a>
<a name="ln168"> </a>
<a name="ln169">DEFINE_int32(num_raft_ops_to_force_idle_intents_db_to_flush, 1000,</a>
<a name="ln170">             &quot;When writes to intents RocksDB are stopped and the number of Raft operations after &quot;</a>
<a name="ln171">             &quot;the last write to the intents RocksDB &quot;</a>
<a name="ln172">             &quot;is greater than this value, the intents RocksDB would be requested to flush.&quot;);</a>
<a name="ln173"> </a>
<a name="ln174">DEFINE_bool(delete_intents_sst_files, true,</a>
<a name="ln175">            &quot;Delete whole intents .SST files when possible.&quot;);</a>
<a name="ln176"> </a>
<a name="ln177">DEFINE_int32(backfill_index_write_batch_size, 128, &quot;The batch size for backfilling the index.&quot;);</a>
<a name="ln178">TAG_FLAG(backfill_index_write_batch_size, advanced);</a>
<a name="ln179">TAG_FLAG(backfill_index_write_batch_size, runtime);</a>
<a name="ln180"> </a>
<a name="ln181">DEFINE_int32(backfill_index_rate_rows_per_sec, 0, &quot;Rate of at which the &quot;</a>
<a name="ln182">             &quot;indexed table's entries are populated into the index table during index &quot;</a>
<a name="ln183">             &quot;backfill. This is a per-tablet flag, i.e. a tserver responsible for &quot;</a>
<a name="ln184">             &quot;multiple tablets could be processing more than this.&quot;);</a>
<a name="ln185">TAG_FLAG(backfill_index_rate_rows_per_sec, advanced);</a>
<a name="ln186">TAG_FLAG(backfill_index_rate_rows_per_sec, runtime);</a>
<a name="ln187"> </a>
<a name="ln188">DEFINE_int32(backfill_index_timeout_grace_margin_ms, 50,</a>
<a name="ln189">             &quot;The time we give the backfill process to wrap up the current set &quot;</a>
<a name="ln190">             &quot;of writes and return successfully the RPC with the information about &quot;</a>
<a name="ln191">             &quot;how far we have processed the rows.&quot;);</a>
<a name="ln192">TAG_FLAG(backfill_index_timeout_grace_margin_ms, advanced);</a>
<a name="ln193">TAG_FLAG(backfill_index_timeout_grace_margin_ms, runtime);</a>
<a name="ln194"> </a>
<a name="ln195">DEFINE_bool(disable_alter_vs_write_mutual_exclusion, false,</a>
<a name="ln196">             &quot;A safety switch to disable the changes from D8710 which makes a schema &quot;</a>
<a name="ln197">             &quot;operation take an exclusive lock making all write operations wait for it.&quot;);</a>
<a name="ln198">TAG_FLAG(disable_alter_vs_write_mutual_exclusion, advanced);</a>
<a name="ln199">TAG_FLAG(disable_alter_vs_write_mutual_exclusion, runtime);</a>
<a name="ln200"> </a>
<a name="ln201">DEFINE_bool(cleanup_intents_sst_files, true,</a>
<a name="ln202">            &quot;Cleanup intents files that are no more relevant to any running transaction.&quot;);</a>
<a name="ln203"> </a>
<a name="ln204">DEFINE_test_flag(int32, slowdown_backfill_by_ms, 0,</a>
<a name="ln205">                 &quot;If set &gt; 0, slows down the backfill process by this amount.&quot;);</a>
<a name="ln206"> </a>
<a name="ln207">DEFINE_test_flag(int32, backfill_paging_size, 0,</a>
<a name="ln208">                 &quot;If set &gt; 0, returns early after processing this number of rows.&quot;);</a>
<a name="ln209"> </a>
<a name="ln210">DEFINE_test_flag(bool, tablet_verify_flushed_frontier_after_modifying, false,</a>
<a name="ln211">                 &quot;After modifying the flushed frontier in RocksDB, verify that the restored value &quot;</a>
<a name="ln212">                 &quot;of it is as expected. Used for testing.&quot;);</a>
<a name="ln213"> </a>
<a name="ln214">DEFINE_test_flag(bool, docdb_log_write_batches, false,</a>
<a name="ln215">                 &quot;Dump write batches being written to RocksDB&quot;);</a>
<a name="ln216"> </a>
<a name="ln217">DECLARE_int32(rocksdb_level0_slowdown_writes_trigger);</a>
<a name="ln218">DECLARE_int32(rocksdb_level0_stop_writes_trigger);</a>
<a name="ln219">DECLARE_int64(apply_intents_task_injected_delay_ms);</a>
<a name="ln220"> </a>
<a name="ln221">using namespace std::placeholders;</a>
<a name="ln222"> </a>
<a name="ln223">using std::shared_ptr;</a>
<a name="ln224">using std::make_shared;</a>
<a name="ln225">using std::string;</a>
<a name="ln226">using std::unordered_set;</a>
<a name="ln227">using std::vector;</a>
<a name="ln228">using std::unique_ptr;</a>
<a name="ln229">using namespace std::literals;  // NOLINT</a>
<a name="ln230"> </a>
<a name="ln231">using rocksdb::WriteBatch;</a>
<a name="ln232">using rocksdb::SequenceNumber;</a>
<a name="ln233">using yb::tserver::WriteRequestPB;</a>
<a name="ln234">using yb::tserver::WriteResponsePB;</a>
<a name="ln235">using yb::docdb::KeyValueWriteBatchPB;</a>
<a name="ln236">using yb::tserver::ReadRequestPB;</a>
<a name="ln237">using yb::docdb::DocOperation;</a>
<a name="ln238">using yb::docdb::RedisWriteOperation;</a>
<a name="ln239">using yb::docdb::QLWriteOperation;</a>
<a name="ln240">using yb::docdb::PgsqlWriteOperation;</a>
<a name="ln241">using yb::docdb::DocDBCompactionFilterFactory;</a>
<a name="ln242">using yb::docdb::InitMarkerBehavior;</a>
<a name="ln243"> </a>
<a name="ln244">namespace yb {</a>
<a name="ln245">namespace tablet {</a>
<a name="ln246"> </a>
<a name="ln247">using yb::MaintenanceManager;</a>
<a name="ln248">using consensus::MaximumOpId;</a>
<a name="ln249">using log::LogAnchorRegistry;</a>
<a name="ln250">using strings::Substitute;</a>
<a name="ln251">using base::subtle::Barrier_AtomicIncrement;</a>
<a name="ln252"> </a>
<a name="ln253">using client::ChildTransactionData;</a>
<a name="ln254">using client::TransactionManager;</a>
<a name="ln255">using client::YBSession;</a>
<a name="ln256">using client::YBTransaction;</a>
<a name="ln257">using client::YBTablePtr;</a>
<a name="ln258"> </a>
<a name="ln259">using docdb::DocKey;</a>
<a name="ln260">using docdb::DocPath;</a>
<a name="ln261">using docdb::DocRowwiseIterator;</a>
<a name="ln262">using docdb::DocWriteBatch;</a>
<a name="ln263">using docdb::SubDocKey;</a>
<a name="ln264">using docdb::PrimitiveValue;</a>
<a name="ln265">using docdb::StorageDbType;</a>
<a name="ln266"> </a>
<a name="ln267">////////////////////////////////////////////////////////////</a>
<a name="ln268">// Tablet</a>
<a name="ln269">////////////////////////////////////////////////////////////</a>
<a name="ln270"> </a>
<a name="ln271">namespace {</a>
<a name="ln272"> </a>
<a name="ln273">void EmitRocksDbMetricsAsJson(</a>
<a name="ln274">    std::shared_ptr&lt;rocksdb::Statistics&gt; rocksdb_statistics,</a>
<a name="ln275">    JsonWriter* writer,</a>
<a name="ln276">    const MetricJsonOptions&amp; opts) {</a>
<a name="ln277">  // Make sure the class member 'rocksdb_statistics_' exists, as this is the stats object</a>
<a name="ln278">  // maintained by RocksDB for this tablet.</a>
<a name="ln279">  if (rocksdb_statistics == nullptr) {</a>
<a name="ln280">    return;</a>
<a name="ln281">  }</a>
<a name="ln282">  // Emit all the ticker (gauge) metrics.</a>
<a name="ln283">  for (std::pair&lt;rocksdb::Tickers, std::string&gt; entry : rocksdb::TickersNameMap) {</a>
<a name="ln284">    // Start the metric object.</a>
<a name="ln285">    writer-&gt;StartObject();</a>
<a name="ln286">    // Write the name.</a>
<a name="ln287">    writer-&gt;String(&quot;name&quot;);</a>
<a name="ln288">    writer-&gt;String(entry.second);</a>
<a name="ln289">    // Write the value.</a>
<a name="ln290">    uint64_t value = rocksdb_statistics-&gt;getTickerCount(entry.first);</a>
<a name="ln291">    writer-&gt;String(&quot;value&quot;);</a>
<a name="ln292">    writer-&gt;Uint64(value);</a>
<a name="ln293">    // Finish the metric object.</a>
<a name="ln294">    writer-&gt;EndObject();</a>
<a name="ln295">  }</a>
<a name="ln296">  // Emit all the histogram metrics.</a>
<a name="ln297">  rocksdb::HistogramData histogram_data;</a>
<a name="ln298">  for (std::pair&lt;rocksdb::Histograms, std::string&gt; entry : rocksdb::HistogramsNameMap) {</a>
<a name="ln299">    // Start the metric object.</a>
<a name="ln300">    writer-&gt;StartObject();</a>
<a name="ln301">    // Write the name.</a>
<a name="ln302">    writer-&gt;String(&quot;name&quot;);</a>
<a name="ln303">    writer-&gt;String(entry.second);</a>
<a name="ln304">    // Write the value.</a>
<a name="ln305">    rocksdb_statistics-&gt;histogramData(entry.first, &amp;histogram_data);</a>
<a name="ln306">    writer-&gt;String(&quot;total_count&quot;);</a>
<a name="ln307">    writer-&gt;Double(histogram_data.count);</a>
<a name="ln308">    writer-&gt;String(&quot;min&quot;);</a>
<a name="ln309">    writer-&gt;Double(histogram_data.min);</a>
<a name="ln310">    writer-&gt;String(&quot;mean&quot;);</a>
<a name="ln311">    writer-&gt;Double(histogram_data.average);</a>
<a name="ln312">    writer-&gt;String(&quot;median&quot;);</a>
<a name="ln313">    writer-&gt;Double(histogram_data.median);</a>
<a name="ln314">    writer-&gt;String(&quot;std_dev&quot;);</a>
<a name="ln315">    writer-&gt;Double(histogram_data.standard_deviation);</a>
<a name="ln316">    writer-&gt;String(&quot;percentile_95&quot;);</a>
<a name="ln317">    writer-&gt;Double(histogram_data.percentile95);</a>
<a name="ln318">    writer-&gt;String(&quot;percentile_99&quot;);</a>
<a name="ln319">    writer-&gt;Double(histogram_data.percentile99);</a>
<a name="ln320">    writer-&gt;String(&quot;max&quot;);</a>
<a name="ln321">    writer-&gt;Double(histogram_data.max);</a>
<a name="ln322">    writer-&gt;String(&quot;total_sum&quot;);</a>
<a name="ln323">    writer-&gt;Double(histogram_data.sum);</a>
<a name="ln324">    // Finish the metric object.</a>
<a name="ln325">    writer-&gt;EndObject();</a>
<a name="ln326">  }</a>
<a name="ln327">}</a>
<a name="ln328"> </a>
<a name="ln329">CHECKED_STATUS EmitRocksDbMetricsAsPrometheus(</a>
<a name="ln330">    std::shared_ptr&lt;rocksdb::Statistics&gt; rocksdb_statistics,</a>
<a name="ln331">    PrometheusWriter* writer,</a>
<a name="ln332">    const MetricEntity::AttributeMap&amp; attrs) {</a>
<a name="ln333">  // Make sure the class member 'rocksdb_statistics_' exists, as this is the stats object</a>
<a name="ln334">  // maintained by RocksDB for this tablet.</a>
<a name="ln335">  if (rocksdb_statistics == nullptr) {</a>
<a name="ln336">    return Status::OK();</a>
<a name="ln337">  }</a>
<a name="ln338">  // Emit all the ticker (gauge) metrics.</a>
<a name="ln339">  for (std::pair&lt;rocksdb::Tickers, std::string&gt; entry : rocksdb::TickersNameMap) {</a>
<a name="ln340">    RETURN_NOT_OK(writer-&gt;WriteSingleEntry(</a>
<a name="ln341">        attrs, entry.second, rocksdb_statistics-&gt;getTickerCount(entry.first)));</a>
<a name="ln342">  }</a>
<a name="ln343">  // Emit all the histogram metrics.</a>
<a name="ln344">  rocksdb::HistogramData histogram_data;</a>
<a name="ln345">  for (std::pair&lt;rocksdb::Histograms, std::string&gt; entry : rocksdb::HistogramsNameMap) {</a>
<a name="ln346">    rocksdb_statistics-&gt;histogramData(entry.first, &amp;histogram_data);</a>
<a name="ln347"> </a>
<a name="ln348">    auto copy_of_attr = attrs;</a>
<a name="ln349">    const std::string hist_name = entry.second;</a>
<a name="ln350">    RETURN_NOT_OK(writer-&gt;WriteSingleEntry(</a>
<a name="ln351">        copy_of_attr, hist_name + &quot;_sum&quot;, histogram_data.sum));</a>
<a name="ln352">    RETURN_NOT_OK(writer-&gt;WriteSingleEntry(</a>
<a name="ln353">        copy_of_attr, hist_name + &quot;_count&quot;, histogram_data.count));</a>
<a name="ln354">  }</a>
<a name="ln355">  return Status::OK();</a>
<a name="ln356">}</a>
<a name="ln357"> </a>
<a name="ln358">docdb::PartialRangeKeyIntents UsePartialRangeKeyIntents(const RaftGroupMetadata&amp; metadata) {</a>
<a name="ln359">  return docdb::PartialRangeKeyIntents(metadata.table_type() == TableType::PGSQL_TABLE_TYPE);</a>
<a name="ln360">}</a>
<a name="ln361"> </a>
<a name="ln362">std::string MakeTabletLogPrefix(</a>
<a name="ln363">    const TabletId&amp; tablet_id, const std::string&amp; log_prefix_suffix) {</a>
<a name="ln364">  return Format(&quot;T $0$1: &quot;, tablet_id, log_prefix_suffix);</a>
<a name="ln365">}</a>
<a name="ln366"> </a>
<a name="ln367">} // namespace</a>
<a name="ln368"> </a>
<a name="ln369">class Tablet::RegularRocksDbListener : public rocksdb::EventListener {</a>
<a name="ln370"> public:</a>
<a name="ln371">  RegularRocksDbListener(Tablet* tablet, const std::string&amp; log_prefix)</a>
<a name="ln372">      : tablet_(*CHECK_NOTNULL(tablet)),</a>
<a name="ln373">        log_prefix_(log_prefix) {}</a>
<a name="ln374"> </a>
<a name="ln375">  void OnCompactionCompleted(rocksdb::DB* db, const rocksdb::CompactionJobInfo&amp; ci) override {</a>
<a name="ln376">    if (ci.is_full_compaction) {</a>
<a name="ln377">      auto&amp; metadata = *CHECK_NOTNULL(tablet_.metadata());</a>
<a name="ln378">      if (!metadata.has_been_fully_compacted()) {</a>
<a name="ln379">        metadata.set_has_been_fully_compacted(true);</a>
<a name="ln380">        ERROR_NOT_OK(metadata.Flush(), log_prefix_);</a>
<a name="ln381">      }</a>
<a name="ln382">    }</a>
<a name="ln383">  }</a>
<a name="ln384"> </a>
<a name="ln385"> private:</a>
<a name="ln386">  Tablet&amp; tablet_;</a>
<a name="ln387">  const std::string log_prefix_;</a>
<a name="ln388">};</a>
<a name="ln389"> </a>
<a name="ln390">Tablet::Tablet(const TabletInitData&amp; data)</a>
<a name="ln391">    : key_schema_(data.metadata-&gt;schema()-&gt;CreateKeyProjection()),</a>
<a name="ln392">      metadata_(data.metadata),</a>
<a name="ln393">      table_type_(data.metadata-&gt;table_type()),</a>
<a name="ln394">      log_anchor_registry_(data.log_anchor_registry),</a>
<a name="ln395">      mem_tracker_(MemTracker::CreateTracker(</a>
<a name="ln396">          Format(&quot;tablet-$0&quot;, tablet_id()), data.parent_mem_tracker, AddToParent::kTrue,</a>
<a name="ln397">          CreateMetrics::kFalse)),</a>
<a name="ln398">      block_based_table_mem_tracker_(data.block_based_table_mem_tracker),</a>
<a name="ln399">      clock_(data.clock),</a>
<a name="ln400">      mvcc_(</a>
<a name="ln401">          MakeTabletLogPrefix(data.metadata-&gt;raft_group_id(), data.log_prefix_suffix), data.clock),</a>
<a name="ln402">      tablet_options_(data.tablet_options),</a>
<a name="ln403">      pending_op_counter_(&quot;RocksDB&quot;),</a>
<a name="ln404">      write_ops_being_submitted_counter_(&quot;Tablet schema&quot;),</a>
<a name="ln405">      client_future_(data.client_future),</a>
<a name="ln406">      local_tablet_filter_(data.local_tablet_filter),</a>
<a name="ln407">      log_prefix_suffix_(data.log_prefix_suffix),</a>
<a name="ln408">      is_sys_catalog_(data.is_sys_catalog),</a>
<a name="ln409">      txns_enabled_(data.txns_enabled),</a>
<a name="ln410">      retention_policy_(std::make_shared&lt;TabletRetentionPolicy&gt;(clock_, metadata_.get())) {</a>
<a name="ln411">  CHECK(schema()-&gt;has_column_ids());</a>
<a name="ln412">  LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Schema version for &quot; &lt;&lt; metadata_-&gt;table_name() &lt;&lt; &quot; is &quot;</a>
<a name="ln413">                        &lt;&lt; metadata_-&gt;schema_version();</a>
<a name="ln414"> </a>
<a name="ln415">  if (data.metric_registry) {</a>
<a name="ln416">    MetricEntity::AttributeMap attrs;</a>
<a name="ln417">    // TODO(KUDU-745): table_id is apparently not set in the metadata.</a>
<a name="ln418">    attrs[&quot;table_id&quot;] = metadata_-&gt;table_id();</a>
<a name="ln419">    attrs[&quot;table_name&quot;] = metadata_-&gt;table_name();</a>
<a name="ln420">    attrs[&quot;namespace_name&quot;] = metadata_-&gt;namespace_name();</a>
<a name="ln421">    attrs[&quot;partition&quot;] = metadata_-&gt;partition_schema()-&gt;PartitionDebugString(</a>
<a name="ln422">        *metadata_-&gt;partition(), *schema());</a>
<a name="ln423">    metric_entity_ = METRIC_ENTITY_tablet.Instantiate(data.metric_registry, tablet_id(), attrs);</a>
<a name="ln424">    // If we are creating a KV table create the metrics callback.</a>
<a name="ln425">    rocksdb_statistics_ = rocksdb::CreateDBStatistics();</a>
<a name="ln426">    auto rocksdb_statistics = rocksdb_statistics_;</a>
<a name="ln427">    metric_entity_-&gt;AddExternalJsonMetricsCb(</a>
<a name="ln428">        [rocksdb_statistics](JsonWriter* jw, const MetricJsonOptions&amp; opts) {</a>
<a name="ln429">      // Assume all rocksdb statistics are at &quot;info&quot; level.</a>
<a name="ln430">      if (MetricLevel::kInfo &lt; opts.level) {</a>
<a name="ln431">        return;</a>
<a name="ln432">      }</a>
<a name="ln433"> </a>
<a name="ln434">      EmitRocksDbMetricsAsJson(rocksdb_statistics, jw, opts);</a>
<a name="ln435">    });</a>
<a name="ln436"> </a>
<a name="ln437">    metric_entity_-&gt;AddExternalPrometheusMetricsCb(</a>
<a name="ln438">        [rocksdb_statistics, attrs](PrometheusWriter* pw, const MetricPrometheusOptions&amp; opts) {</a>
<a name="ln439">      // Assume all rocksdb statistics are at &quot;info&quot; level.</a>
<a name="ln440">      if (MetricLevel::kInfo &lt; opts.level) {</a>
<a name="ln441">        return;</a>
<a name="ln442">      }</a>
<a name="ln443"> </a>
<a name="ln444">      auto s = EmitRocksDbMetricsAsPrometheus(rocksdb_statistics, pw, attrs);</a>
<a name="ln445">      if (!s.ok()) {</a>
<a name="ln446">        YB_LOG_EVERY_N(WARNING, 100) &lt;&lt; &quot;Failed to get Prometheus metrics: &quot; &lt;&lt; s.ToString();</a>
<a name="ln447">      }</a>
<a name="ln448">    });</a>
<a name="ln449"> </a>
<a name="ln450">    metrics_.reset(new TabletMetrics(metric_entity_));</a>
<a name="ln451"> </a>
<a name="ln452">    mem_tracker_-&gt;SetMetricEntity(metric_entity_);</a>
<a name="ln453">  }</a>
<a name="ln454"> </a>
<a name="ln455">  auto table_info = metadata_-&gt;primary_table_info();</a>
<a name="ln456">  bool has_index = !table_info-&gt;index_map.empty();</a>
<a name="ln457">  if (txns_enabled_ &amp;&amp;</a>
<a name="ln458">      data.transaction_participant_context &amp;&amp;</a>
<a name="ln459">      (is_sys_catalog_ || data.metadata-&gt;schema()-&gt;table_properties().is_transactional())) {</a>
<a name="ln460">    transaction_participant_ = std::make_unique&lt;TransactionParticipant&gt;(</a>
<a name="ln461">        data.transaction_participant_context, this, metric_entity_);</a>
<a name="ln462">    // Create transaction manager for secondary index update.</a>
<a name="ln463">    if (has_index) {</a>
<a name="ln464">      transaction_manager_.emplace(client_future_.get(),</a>
<a name="ln465">                                   scoped_refptr&lt;server::Clock&gt;(clock_),</a>
<a name="ln466">                                   local_tablet_filter_);</a>
<a name="ln467">    }</a>
<a name="ln468">  }</a>
<a name="ln469"> </a>
<a name="ln470">  // Create index table metadata cache for secondary index update.</a>
<a name="ln471">  if (has_index) {</a>
<a name="ln472">    CreateNewYBMetaDataCache();</a>
<a name="ln473">  }</a>
<a name="ln474"> </a>
<a name="ln475">  // If this is a unique index tablet, set up the index primary key schema.</a>
<a name="ln476">  if (table_info-&gt;index_info &amp;&amp; table_info-&gt;index_info-&gt;is_unique()) {</a>
<a name="ln477">    unique_index_key_schema_.emplace();</a>
<a name="ln478">    const auto ids = table_info-&gt;index_info-&gt;index_key_column_ids();</a>
<a name="ln479">    CHECK_OK(table_info-&gt;schema.CreateProjectionByIdsIgnoreMissing(ids,</a>
<a name="ln480">                                                                   &amp;*unique_index_key_schema_));</a>
<a name="ln481">  }</a>
<a name="ln482"> </a>
<a name="ln483">  if (data.transaction_coordinator_context &amp;&amp;</a>
<a name="ln484">      table_info-&gt;table_type == TableType::TRANSACTION_STATUS_TABLE_TYPE) {</a>
<a name="ln485">    transaction_coordinator_ = std::make_unique&lt;TransactionCoordinator&gt;(</a>
<a name="ln486">        metadata_-&gt;fs_manager()-&gt;uuid(),</a>
<a name="ln487">        data.transaction_coordinator_context,</a>
<a name="ln488">        metrics_-&gt;expired_transactions.get());</a>
<a name="ln489">  }</a>
<a name="ln490"> </a>
<a name="ln491">  snapshots_ = std::make_unique&lt;TabletSnapshots&gt;(this);</a>
<a name="ln492"> </a>
<a name="ln493">  snapshot_coordinator_ = data.snapshot_coordinator;</a>
<a name="ln494">}</a>
<a name="ln495"> </a>
<a name="ln496">Tablet::~Tablet() {</a>
<a name="ln497">  if (StartShutdown()) {</a>
<a name="ln498">    CompleteShutdown();</a>
<a name="ln499">  } else {</a>
<a name="ln500">    auto state = state_;</a>
<a name="ln501">    LOG_IF_WITH_PREFIX(DFATAL, state != kShutdown)</a>
<a name="ln502">        &lt;&lt; &quot;Destroying Tablet that did not complete shutdown: &quot; &lt;&lt; state;</a>
<a name="ln503">  }</a>
<a name="ln504">  mem_tracker_-&gt;UnregisterFromParent();</a>
<a name="ln505">}</a>
<a name="ln506"> </a>
<a name="ln507">Status Tablet::Open() {</a>
<a name="ln508">  TRACE_EVENT0(&quot;tablet&quot;, &quot;Tablet::Open&quot;);</a>
<a name="ln509">  std::lock_guard&lt;rw_spinlock&gt; lock(component_lock_);</a>
<a name="ln510">  CHECK_EQ(state_, kInitialized) &lt;&lt; &quot;already open&quot;;</a>
<a name="ln511">  CHECK(schema()-&gt;has_column_ids());</a>
<a name="ln512"> </a>
<a name="ln513">  switch (table_type_) {</a>
<a name="ln514">    case TableType::PGSQL_TABLE_TYPE: FALLTHROUGH_INTENDED;</a>
<a name="ln515">    case TableType::YQL_TABLE_TYPE: FALLTHROUGH_INTENDED;</a>
<a name="ln516">    case TableType::REDIS_TABLE_TYPE:</a>
<a name="ln517">      RETURN_NOT_OK(OpenKeyValueTablet());</a>
<a name="ln518">      state_ = kBootstrapping;</a>
<a name="ln519">      return Status::OK();</a>
<a name="ln520">    case TableType::TRANSACTION_STATUS_TABLE_TYPE:</a>
<a name="ln521">      state_ = kBootstrapping;</a>
<a name="ln522">      return Status::OK();</a>
<a name="ln523">  }</a>
<a name="ln524">  FATAL_INVALID_ENUM_VALUE(TableType, table_type_);</a>
<a name="ln525"> </a>
<a name="ln526">  return Status::OK();</a>
<a name="ln527">}</a>
<a name="ln528"> </a>
<a name="ln529">Status Tablet::CreateTabletDirectories(const string&amp; db_dir, FsManager* fs) {</a>
<a name="ln530">  LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Creating RocksDB database in dir &quot; &lt;&lt; db_dir;</a>
<a name="ln531"> </a>
<a name="ln532">  // Create the directory table-uuid first.</a>
<a name="ln533">  RETURN_NOT_OK_PREPEND(fs-&gt;CreateDirIfMissingAndSync(DirName(db_dir)),</a>
<a name="ln534">                        Format(&quot;Failed to create RocksDB table directory $0&quot;, DirName(db_dir)));</a>
<a name="ln535"> </a>
<a name="ln536">  RETURN_NOT_OK_PREPEND(fs-&gt;CreateDirIfMissingAndSync(db_dir),</a>
<a name="ln537">                        Format(&quot;Failed to create RocksDB tablet directory $0&quot;, db_dir));</a>
<a name="ln538"> </a>
<a name="ln539">  RETURN_NOT_OK_PREPEND(fs-&gt;CreateDirIfMissingAndSync(db_dir + kIntentsDBSuffix),</a>
<a name="ln540">                        Format(&quot;Failed to create RocksDB tablet intents directory $0&quot;, db_dir));</a>
<a name="ln541"> </a>
<a name="ln542">  RETURN_NOT_OK(snapshots_-&gt;CreateDirectories(db_dir, fs));</a>
<a name="ln543"> </a>
<a name="ln544">  return Status::OK();</a>
<a name="ln545">}</a>
<a name="ln546"> </a>
<a name="ln547">void Tablet::ResetYBMetaDataCache() {</a>
<a name="ln548">  std::atomic_store_explicit(&amp;metadata_cache_, {}, std::memory_order_release);</a>
<a name="ln549">}</a>
<a name="ln550"> </a>
<a name="ln551">void Tablet::CreateNewYBMetaDataCache() {</a>
<a name="ln552">  std::atomic_store_explicit(&amp;metadata_cache_,</a>
<a name="ln553">      std::make_shared&lt;client::YBMetaDataCache&gt;(client_future_.get(),</a>
<a name="ln554">                                                false /* Update permissions cache */),</a>
<a name="ln555">      std::memory_order_release);</a>
<a name="ln556">}</a>
<a name="ln557"> </a>
<a name="ln558">std::shared_ptr&lt;client::YBMetaDataCache&gt; Tablet::YBMetaDataCache() {</a>
<a name="ln559">  return std::atomic_load_explicit(&amp;metadata_cache_, std::memory_order_acquire);</a>
<a name="ln560">}</a>
<a name="ln561"> </a>
<a name="ln562">template &lt;class F&gt;</a>
<a name="ln563">auto MakeMemTableFlushFilterFactory(const F&amp; f) {</a>
<a name="ln564">  // Trick to get type of mem_table_flush_filter_factory field.</a>
<a name="ln565">  typedef typename decltype(</a>
<a name="ln566">      static_cast&lt;rocksdb::Options*&gt;(nullptr)-&gt;mem_table_flush_filter_factory)::element_type</a>
<a name="ln567">      MemTableFlushFilterFactoryType;</a>
<a name="ln568">  return std::make_shared&lt;MemTableFlushFilterFactoryType&gt;(f);</a>
<a name="ln569">}</a>
<a name="ln570"> </a>
<a name="ln571">Result&lt;bool&gt; Tablet::IntentsDbFlushFilter(const rocksdb::MemTable&amp; memtable) {</a>
<a name="ln572">  VLOG_WITH_PREFIX(4) &lt;&lt; __func__;</a>
<a name="ln573"> </a>
<a name="ln574">  auto frontiers = memtable.Frontiers();</a>
<a name="ln575">  if (frontiers) {</a>
<a name="ln576">    const auto&amp; intents_largest =</a>
<a name="ln577">        down_cast&lt;const docdb::ConsensusFrontier&amp;&gt;(frontiers-&gt;Largest());</a>
<a name="ln578"> </a>
<a name="ln579">    // We allow to flush intents DB only after regular DB.</a>
<a name="ln580">    // Otherwise we could lose applied intents when corresponding regular records were not</a>
<a name="ln581">    // flushed.</a>
<a name="ln582">    auto regular_flushed_frontier = regular_db_-&gt;GetFlushedFrontier();</a>
<a name="ln583">    if (regular_flushed_frontier) {</a>
<a name="ln584">      const auto&amp; regular_flushed_largest =</a>
<a name="ln585">          static_cast&lt;const docdb::ConsensusFrontier&amp;&gt;(*regular_flushed_frontier);</a>
<a name="ln586">      if (regular_flushed_largest.op_id().index &gt;= intents_largest.op_id().index) {</a>
<a name="ln587">        VLOG_WITH_PREFIX(4) &lt;&lt; __func__ &lt;&lt; &quot;, regular already flushed&quot;;</a>
<a name="ln588">        return true;</a>
<a name="ln589">      }</a>
<a name="ln590">    }</a>
<a name="ln591">  } else {</a>
<a name="ln592">    VLOG_WITH_PREFIX(4) &lt;&lt; __func__ &lt;&lt; &quot;, no frontiers&quot;;</a>
<a name="ln593">  }</a>
<a name="ln594"> </a>
<a name="ln595">  // If regular db does not have anything to flush, it means that we have just added intents,</a>
<a name="ln596">  // without apply, so it is OK to flush the intents RocksDB.</a>
<a name="ln597">  auto flush_intention = regular_db_-&gt;GetFlushAbility();</a>
<a name="ln598">  if (flush_intention == rocksdb::FlushAbility::kNoNewData) {</a>
<a name="ln599">    VLOG_WITH_PREFIX(4) &lt;&lt; __func__ &lt;&lt; &quot;, no new data&quot;;</a>
<a name="ln600">    return true;</a>
<a name="ln601">  }</a>
<a name="ln602"> </a>
<a name="ln603">  // Force flush of regular DB if we were not able to flush for too long.</a>
<a name="ln604">  auto timeout = std::chrono::milliseconds(FLAGS_intents_flush_max_delay_ms);</a>
<a name="ln605">  if (flush_intention != rocksdb::FlushAbility::kAlreadyFlushing &amp;&amp;</a>
<a name="ln606">      (shutdown_requested_.load(std::memory_order_acquire) ||</a>
<a name="ln607">       std::chrono::steady_clock::now() &gt; memtable.FlushStartTime() + timeout)) {</a>
<a name="ln608">    VLOG_WITH_PREFIX(2) &lt;&lt; __func__ &lt;&lt; &quot;, force flush&quot;;</a>
<a name="ln609"> </a>
<a name="ln610">    rocksdb::FlushOptions options;</a>
<a name="ln611">    options.wait = false;</a>
<a name="ln612">    RETURN_NOT_OK(regular_db_-&gt;Flush(options));</a>
<a name="ln613">  }</a>
<a name="ln614"> </a>
<a name="ln615">  return false;</a>
<a name="ln616">}</a>
<a name="ln617"> </a>
<a name="ln618">std::string Tablet::LogPrefix() const {</a>
<a name="ln619">  return MakeTabletLogPrefix(tablet_id(), log_prefix_suffix_);</a>
<a name="ln620">}</a>
<a name="ln621"> </a>
<a name="ln622">namespace {</a>
<a name="ln623"> </a>
<a name="ln624">std::string LogDbTypePrefix(docdb::StorageDbType db_type) {</a>
<a name="ln625">  switch (db_type) {</a>
<a name="ln626">    case docdb::StorageDbType::kRegular:</a>
<a name="ln627">      return &quot;R&quot;;</a>
<a name="ln628">    case docdb::StorageDbType::kIntents:</a>
<a name="ln629">      return &quot;I&quot;;</a>
<a name="ln630">  }</a>
<a name="ln631">  FATAL_INVALID_ENUM_VALUE(docdb::StorageDbType, db_type);</a>
<a name="ln632">}</a>
<a name="ln633"> </a>
<a name="ln634">std::string MakeTabletLogPrefix(</a>
<a name="ln635">    const TabletId&amp; tablet_id, const std::string&amp; log_prefix_suffix, docdb::StorageDbType db_type) {</a>
<a name="ln636">  return MakeTabletLogPrefix(</a>
<a name="ln637">      tablet_id, Format(&quot;$0 [$1]&quot;, log_prefix_suffix, LogDbTypePrefix(db_type)));</a>
<a name="ln638">}</a>
<a name="ln639"> </a>
<a name="ln640">} // namespace</a>
<a name="ln641"> </a>
<a name="ln642">std::string Tablet::LogPrefix(docdb::StorageDbType db_type) const {</a>
<a name="ln643">  return MakeTabletLogPrefix(tablet_id(), log_prefix_suffix_, db_type);</a>
<a name="ln644">}</a>
<a name="ln645"> </a>
<a name="ln646">Status Tablet::OpenKeyValueTablet() {</a>
<a name="ln647">  static const std::string kRegularDB = &quot;RegularDB&quot;s;</a>
<a name="ln648">  static const std::string kIntentsDB = &quot;IntentsDB&quot;s;</a>
<a name="ln649"> </a>
<a name="ln650">  rocksdb::Options rocksdb_options;</a>
<a name="ln651">  InitRocksDBOptions(&amp;rocksdb_options, LogPrefix(docdb::StorageDbType::kRegular));</a>
<a name="ln652">  rocksdb_options.mem_tracker = MemTracker::FindOrCreateTracker(kRegularDB, mem_tracker_);</a>
<a name="ln653">  rocksdb_options.block_based_table_mem_tracker =</a>
<a name="ln654">      MemTracker::FindOrCreateTracker(</a>
<a name="ln655">          Format(&quot;$0-$1&quot;, kRegularDB, tablet_id()), block_based_table_mem_tracker_,</a>
<a name="ln656">          AddToParent::kTrue, CreateMetrics::kFalse);</a>
<a name="ln657">  // We may not have a metrics_entity_ instantiated in tests.</a>
<a name="ln658">  if (metric_entity_) {</a>
<a name="ln659">    rocksdb_options.block_based_table_mem_tracker-&gt;SetMetricEntity(metric_entity_,</a>
<a name="ln660">        Format(&quot;$0_$1&quot;, &quot;BlockBasedTable&quot;, kRegularDB));</a>
<a name="ln661">  }</a>
<a name="ln662"> </a>
<a name="ln663">  key_bounds_ = docdb::KeyBounds(metadata()-&gt;lower_bound_key(), metadata()-&gt;upper_bound_key());</a>
<a name="ln664"> </a>
<a name="ln665">  // Install the history cleanup handler. Note that TabletRetentionPolicy is going to hold a raw ptr</a>
<a name="ln666">  // to this tablet. So, we ensure that rocksdb_ is reset before this tablet gets destroyed.</a>
<a name="ln667">  rocksdb_options.compaction_filter_factory = make_shared&lt;DocDBCompactionFilterFactory&gt;(</a>
<a name="ln668">      retention_policy_, &amp;key_bounds_);</a>
<a name="ln669"> </a>
<a name="ln670">  rocksdb_options.mem_table_flush_filter_factory = MakeMemTableFlushFilterFactory([this] {</a>
<a name="ln671">    if (mem_table_flush_filter_factory_) {</a>
<a name="ln672">      return mem_table_flush_filter_factory_();</a>
<a name="ln673">    }</a>
<a name="ln674">    return rocksdb::MemTableFilter();</a>
<a name="ln675">  });</a>
<a name="ln676"> </a>
<a name="ln677">  rocksdb_options.disable_auto_compactions = true;</a>
<a name="ln678">  rocksdb_options.level0_slowdown_writes_trigger = std::numeric_limits&lt;int&gt;::max();</a>
<a name="ln679">  rocksdb_options.level0_stop_writes_trigger = std::numeric_limits&lt;int&gt;::max();</a>
<a name="ln680"> </a>
<a name="ln681">  rocksdb::Options regular_rocksdb_options(rocksdb_options);</a>
<a name="ln682">  regular_rocksdb_options.listeners.push_back(</a>
<a name="ln683">      std::make_shared&lt;RegularRocksDbListener&gt;(this, regular_rocksdb_options.log_prefix));</a>
<a name="ln684"> </a>
<a name="ln685">  const string db_dir = metadata()-&gt;rocksdb_dir();</a>
<a name="ln686">  RETURN_NOT_OK(CreateTabletDirectories(db_dir, metadata()-&gt;fs_manager()));</a>
<a name="ln687"> </a>
<a name="ln688">  LOG(INFO) &lt;&lt; &quot;Opening RocksDB at: &quot; &lt;&lt; db_dir;</a>
<a name="ln689">  rocksdb::DB* db = nullptr;</a>
<a name="ln690">  rocksdb::Status rocksdb_open_status = rocksdb::DB::Open(regular_rocksdb_options, db_dir, &amp;db);</a>
<a name="ln691">  if (!rocksdb_open_status.ok()) {</a>
<a name="ln692">    LOG_WITH_PREFIX(ERROR) &lt;&lt; &quot;Failed to open a RocksDB database in directory &quot; &lt;&lt; db_dir &lt;&lt; &quot;: &quot;</a>
<a name="ln693">                           &lt;&lt; rocksdb_open_status;</a>
<a name="ln694">    if (db != nullptr) {</a>
<a name="ln695">      delete db;</a>
<a name="ln696">    }</a>
<a name="ln697">    return STATUS(IllegalState, rocksdb_open_status.ToString());</a>
<a name="ln698">  }</a>
<a name="ln699">  regular_db_.reset(db);</a>
<a name="ln700">  regular_db_-&gt;ListenFilesChanged(std::bind(&amp;Tablet::RegularDbFilesChanged, this));</a>
<a name="ln701"> </a>
<a name="ln702">  if (transaction_participant_) {</a>
<a name="ln703">    LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Opening intents DB at: &quot; &lt;&lt; db_dir + kIntentsDBSuffix;</a>
<a name="ln704">    docdb::SetLogPrefix(&amp;rocksdb_options, LogPrefix(docdb::StorageDbType::kIntents));</a>
<a name="ln705"> </a>
<a name="ln706">    rocksdb_options.mem_table_flush_filter_factory = MakeMemTableFlushFilterFactory([this] {</a>
<a name="ln707">      return std::bind(&amp;Tablet::IntentsDbFlushFilter, this, _1);</a>
<a name="ln708">    });</a>
<a name="ln709"> </a>
<a name="ln710">    rocksdb_options.compaction_filter_factory =</a>
<a name="ln711">        FLAGS_tablet_do_compaction_cleanup_for_intents ?</a>
<a name="ln712">        std::make_shared&lt;docdb::DocDBIntentsCompactionFilterFactory&gt;(this, &amp;key_bounds_) : nullptr;</a>
<a name="ln713"> </a>
<a name="ln714">    rocksdb_options.mem_tracker = MemTracker::FindOrCreateTracker(kIntentsDB, mem_tracker_);</a>
<a name="ln715">    rocksdb_options.block_based_table_mem_tracker =</a>
<a name="ln716">        MemTracker::FindOrCreateTracker(</a>
<a name="ln717">            Format(&quot;$0-$1&quot;, kIntentsDB, tablet_id()), block_based_table_mem_tracker_,</a>
<a name="ln718">            AddToParent::kTrue, CreateMetrics::kFalse);</a>
<a name="ln719">    // We may not have a metrics_entity_ instantiated in tests.</a>
<a name="ln720">    if (metric_entity_) {</a>
<a name="ln721">      rocksdb_options.block_based_table_mem_tracker-&gt;SetMetricEntity(metric_entity_,</a>
<a name="ln722">        Format(&quot;$0_$1&quot;, &quot;BlockBasedTable&quot;, kIntentsDB));</a>
<a name="ln723">    }</a>
<a name="ln724"> </a>
<a name="ln725">    rocksdb::DB* intents_db = nullptr;</a>
<a name="ln726">    RETURN_NOT_OK(rocksdb::DB::Open(rocksdb_options, db_dir + kIntentsDBSuffix, &amp;intents_db));</a>
<a name="ln727">    intents_db_.reset(intents_db);</a>
<a name="ln728">    intents_db_-&gt;ListenFilesChanged(std::bind(&amp;Tablet::CleanupIntentFiles, this));</a>
<a name="ln729">  }</a>
<a name="ln730"> </a>
<a name="ln731">  ql_storage_.reset(new docdb::QLRocksDBStorage(doc_db()));</a>
<a name="ln732">  if (transaction_participant_) {</a>
<a name="ln733">    transaction_participant_-&gt;SetDB(doc_db(), &amp;key_bounds_, &amp;pending_op_counter_);</a>
<a name="ln734">  }</a>
<a name="ln735"> </a>
<a name="ln736">  // Don't allow reads at timestamps lower than the highest history cutoff of a past compaction.</a>
<a name="ln737">  auto regular_flushed_frontier = regular_db_-&gt;GetFlushedFrontier();</a>
<a name="ln738">  if (regular_flushed_frontier) {</a>
<a name="ln739">    retention_policy_-&gt;UpdateCommittedHistoryCutoff(</a>
<a name="ln740">        static_cast&lt;const docdb::ConsensusFrontier&amp;&gt;(*regular_flushed_frontier).history_cutoff());</a>
<a name="ln741">  }</a>
<a name="ln742"> </a>
<a name="ln743">  LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Successfully opened a RocksDB database at &quot; &lt;&lt; db_dir</a>
<a name="ln744">                        &lt;&lt; &quot;, obj: &quot; &lt;&lt; db;</a>
<a name="ln745"> </a>
<a name="ln746">  return Status::OK();</a>
<a name="ln747">}</a>
<a name="ln748"> </a>
<a name="ln749">void Tablet::RegularDbFilesChanged() {</a>
<a name="ln750">  std::lock_guard&lt;std::mutex&gt; lock(num_sst_files_changed_listener_mutex_);</a>
<a name="ln751">  if (num_sst_files_changed_listener_) {</a>
<a name="ln752">    num_sst_files_changed_listener_();</a>
<a name="ln753">  }</a>
<a name="ln754">}</a>
<a name="ln755"> </a>
<a name="ln756">void Tablet::SetCleanupPool(ThreadPool* thread_pool) {</a>
<a name="ln757">  cleanup_intent_files_token_ = thread_pool-&gt;NewToken(ThreadPool::ExecutionMode::SERIAL);</a>
<a name="ln758">}</a>
<a name="ln759"> </a>
<a name="ln760">void Tablet::CleanupIntentFiles() {</a>
<a name="ln761">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln762">  if (!scoped_read_operation.ok() || state_ != State::kOpen || !FLAGS_delete_intents_sst_files ||</a>
<a name="ln763">      !cleanup_intent_files_token_) {</a>
<a name="ln764">    return;</a>
<a name="ln765">  }</a>
<a name="ln766"> </a>
<a name="ln767">  WARN_NOT_OK(</a>
<a name="ln768">      cleanup_intent_files_token_-&gt;SubmitFunc(std::bind(&amp;Tablet::DoCleanupIntentFiles, this)),</a>
<a name="ln769">      &quot;Submit cleanup intent files failed&quot;);</a>
<a name="ln770">}</a>
<a name="ln771"> </a>
<a name="ln772">void Tablet::DoCleanupIntentFiles() {</a>
<a name="ln773">  HybridTime best_file_max_ht = HybridTime::kMax;</a>
<a name="ln774">  std::vector&lt;rocksdb::LiveFileMetaData&gt; files;</a>
<a name="ln775">  // Stops when there are no more files to delete.</a>
<a name="ln776">  std::string previous_name;</a>
<a name="ln777">  while (GetAtomicFlag(&amp;FLAGS_cleanup_intents_sst_files)) {</a>
<a name="ln778">    ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln779">    if (!scoped_read_operation.ok()) {</a>
<a name="ln780">      break;</a>
<a name="ln781">    }</a>
<a name="ln782"> </a>
<a name="ln783">    best_file_max_ht = HybridTime::kMax;</a>
<a name="ln784">    const rocksdb::LiveFileMetaData* best_file = nullptr;</a>
<a name="ln785">    files.clear();</a>
<a name="ln786">    intents_db_-&gt;GetLiveFilesMetaData(&amp;files);</a>
<a name="ln787">    auto min_largest_seq_no = std::numeric_limits&lt;rocksdb::SequenceNumber&gt;::max();</a>
<a name="ln788">    for (const auto&amp; file : files) {</a>
<a name="ln789">      if (file.largest.seqno &lt; min_largest_seq_no) {</a>
<a name="ln790">        min_largest_seq_no = file.largest.seqno;</a>
<a name="ln791">        auto&amp; frontier = down_cast&lt;docdb::ConsensusFrontier&amp;&gt;(*file.largest.user_frontier);</a>
<a name="ln792">        best_file_max_ht = frontier.hybrid_time();</a>
<a name="ln793">        best_file = &amp;file;</a>
<a name="ln794">      }</a>
<a name="ln795">    }</a>
<a name="ln796"> </a>
<a name="ln797">    auto min_running_start_ht = transaction_participant_-&gt;MinRunningHybridTime();</a>
<a name="ln798">    if (!min_running_start_ht.is_valid() || min_running_start_ht &lt;= best_file_max_ht) {</a>
<a name="ln799">      break;</a>
<a name="ln800">    }</a>
<a name="ln801">    if (best_file-&gt;name == previous_name) {</a>
<a name="ln802">      LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Attempt to delete same file: &quot; &lt;&lt; previous_name</a>
<a name="ln803">                            &lt;&lt; &quot;, stopping cleanup&quot;;</a>
<a name="ln804">      break;</a>
<a name="ln805">    }</a>
<a name="ln806">    previous_name = best_file-&gt;name;</a>
<a name="ln807"> </a>
<a name="ln808">    LOG_WITH_PREFIX(INFO)</a>
<a name="ln809">        &lt;&lt; &quot;Intents SST file will be deleted: &quot; &lt;&lt; best_file-&gt;ToString()</a>
<a name="ln810">        &lt;&lt; &quot;, max ht: &quot; &lt;&lt; best_file_max_ht &lt;&lt; &quot;, min running transaction start ht: &quot;</a>
<a name="ln811">        &lt;&lt; min_running_start_ht;</a>
<a name="ln812">    auto flush_status = regular_db_-&gt;Flush(rocksdb::FlushOptions());</a>
<a name="ln813">    if (!flush_status.ok()) {</a>
<a name="ln814">      LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Failed to flush regular db: &quot; &lt;&lt; flush_status;</a>
<a name="ln815">      break;</a>
<a name="ln816">    }</a>
<a name="ln817">    auto delete_status = intents_db_-&gt;DeleteFile(best_file-&gt;name);</a>
<a name="ln818">    if (!delete_status.ok()) {</a>
<a name="ln819">      LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Failed to delete &quot; &lt;&lt; best_file-&gt;ToString()</a>
<a name="ln820">                               &lt;&lt; &quot;, all files &quot; &lt;&lt; AsString(files) &lt;&lt; &quot;: &quot; &lt;&lt; delete_status;</a>
<a name="ln821">      break;</a>
<a name="ln822">    }</a>
<a name="ln823">  }</a>
<a name="ln824"> </a>
<a name="ln825">  if (best_file_max_ht != HybridTime::kMax) {</a>
<a name="ln826">    transaction_participant_-&gt;WaitMinRunningHybridTime(best_file_max_ht);</a>
<a name="ln827">  }</a>
<a name="ln828">}</a>
<a name="ln829"> </a>
<a name="ln830">Status Tablet::EnableCompactions(ScopedRWOperationPause* pause_operation) {</a>
<a name="ln831">  if (!pause_operation) {</a>
<a name="ln832">    ScopedRWOperation operation(&amp;pending_op_counter_);</a>
<a name="ln833">    RETURN_NOT_OK(operation);</a>
<a name="ln834">    return DoEnableCompactions();</a>
<a name="ln835">  }</a>
<a name="ln836"> </a>
<a name="ln837">  return DoEnableCompactions();</a>
<a name="ln838">}</a>
<a name="ln839"> </a>
<a name="ln840">Status Tablet::DoEnableCompactions() {</a>
<a name="ln841">  Status regular_db_status;</a>
<a name="ln842">  std::unordered_map&lt;std::string, std::string&gt; new_options = {</a>
<a name="ln843">      { &quot;level0_slowdown_writes_trigger&quot;s,</a>
<a name="ln844">        std::to_string(max_if_negative(FLAGS_rocksdb_level0_slowdown_writes_trigger))},</a>
<a name="ln845">      { &quot;level0_stop_writes_trigger&quot;s,</a>
<a name="ln846">        std::to_string(max_if_negative(FLAGS_rocksdb_level0_stop_writes_trigger))},</a>
<a name="ln847">  };</a>
<a name="ln848">  if (regular_db_) {</a>
<a name="ln849">    WARN_WITH_PREFIX_NOT_OK(</a>
<a name="ln850">        regular_db_-&gt;SetOptions(new_options),</a>
<a name="ln851">        &quot;Failed to set options on regular DB&quot;);</a>
<a name="ln852">    regular_db_status =</a>
<a name="ln853">        regular_db_-&gt;EnableAutoCompaction({regular_db_-&gt;DefaultColumnFamily()});</a>
<a name="ln854">    if (!regular_db_status.ok()) {</a>
<a name="ln855">      LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Failed to enable compactions on regular DB: &quot;</a>
<a name="ln856">                               &lt;&lt; regular_db_status;</a>
<a name="ln857">    }</a>
<a name="ln858">  }</a>
<a name="ln859">  if (intents_db_) {</a>
<a name="ln860">    WARN_WITH_PREFIX_NOT_OK(</a>
<a name="ln861">        intents_db_-&gt;SetOptions(new_options),</a>
<a name="ln862">        &quot;Failed to set options on provisional records DB&quot;);</a>
<a name="ln863">    Status intents_db_status =</a>
<a name="ln864">        intents_db_-&gt;EnableAutoCompaction({intents_db_-&gt;DefaultColumnFamily()});</a>
<a name="ln865">    if (!intents_db_status.ok()) {</a>
<a name="ln866">      LOG_WITH_PREFIX(WARNING)</a>
<a name="ln867">          &lt;&lt; &quot;Failed to enable compactions on provisional records DB: &quot; &lt;&lt; intents_db_status;</a>
<a name="ln868">      return intents_db_status;</a>
<a name="ln869">    }</a>
<a name="ln870">  }</a>
<a name="ln871">  return regular_db_status;</a>
<a name="ln872">}</a>
<a name="ln873"> </a>
<a name="ln874">void Tablet::MarkFinishedBootstrapping() {</a>
<a name="ln875">  CHECK_EQ(state_, kBootstrapping);</a>
<a name="ln876">  state_ = kOpen;</a>
<a name="ln877">}</a>
<a name="ln878"> </a>
<a name="ln879">bool Tablet::StartShutdown() {</a>
<a name="ln880">  LOG_WITH_PREFIX(INFO) &lt;&lt; __func__;</a>
<a name="ln881"> </a>
<a name="ln882">  bool expected = false;</a>
<a name="ln883">  if (!shutdown_requested_.compare_exchange_strong(expected, true)) {</a>
<a name="ln884">    return false;</a>
<a name="ln885">  }</a>
<a name="ln886"> </a>
<a name="ln887">  if (transaction_participant_) {</a>
<a name="ln888">    transaction_participant_-&gt;StartShutdown();</a>
<a name="ln889">  }</a>
<a name="ln890"> </a>
<a name="ln891">  return true;</a>
<a name="ln892">}</a>
<a name="ln893"> </a>
<a name="ln894">void Tablet::PreventCallbacksFromRocksDBs(DisableFlushOnShutdown disable_flush_on_shutdown) {</a>
<a name="ln895">  if (intents_db_) {</a>
<a name="ln896">    intents_db_-&gt;ListenFilesChanged(nullptr);</a>
<a name="ln897">    intents_db_-&gt;SetDisableFlushOnShutdown(disable_flush_on_shutdown);</a>
<a name="ln898">  }</a>
<a name="ln899"> </a>
<a name="ln900">  if (regular_db_) {</a>
<a name="ln901">    regular_db_-&gt;SetDisableFlushOnShutdown(disable_flush_on_shutdown);</a>
<a name="ln902">  }</a>
<a name="ln903">}</a>
<a name="ln904"> </a>
<a name="ln905">void Tablet::CompleteShutdown(IsDropTable is_drop_table) {</a>
<a name="ln906">  LOG_WITH_PREFIX(INFO) &lt;&lt; __func__ &lt;&lt; &quot;(&quot; &lt;&lt; is_drop_table &lt;&lt; &quot;)&quot;;</a>
<a name="ln907"> </a>
<a name="ln908">  StartShutdown();</a>
<a name="ln909"> </a>
<a name="ln910">  auto op_pause = PauseReadWriteOperations(Stop::kTrue);</a>
<a name="ln911">  if (!op_pause.ok()) {</a>
<a name="ln912">    LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Failed to shut down: &quot; &lt;&lt; op_pause.status();</a>
<a name="ln913">    return;</a>
<a name="ln914">  }</a>
<a name="ln915"> </a>
<a name="ln916">  cleanup_intent_files_token_.reset();</a>
<a name="ln917"> </a>
<a name="ln918">  if (transaction_coordinator_) {</a>
<a name="ln919">    transaction_coordinator_-&gt;Shutdown();</a>
<a name="ln920">  }</a>
<a name="ln921"> </a>
<a name="ln922">  if (transaction_participant_) {</a>
<a name="ln923">    transaction_participant_-&gt;CompleteShutdown();</a>
<a name="ln924">  }</a>
<a name="ln925"> </a>
<a name="ln926">  std::lock_guard&lt;rw_spinlock&gt; lock(component_lock_);</a>
<a name="ln927"> </a>
<a name="ln928">  // Shutdown the RocksDB instance for this table, if present.</a>
<a name="ln929">  // Destroy intents and regular DBs in reverse order to their creation.</a>
<a name="ln930">  // Also it makes sure that regular DB is alive during flush filter of intents db.</a>
<a name="ln931">  WARN_NOT_OK(ResetRocksDBs(Destroy::kFalse, DisableFlushOnShutdown(is_drop_table)),</a>
<a name="ln932">              &quot;Failed to reset rocksdb during shutdown&quot;);</a>
<a name="ln933">  state_ = kShutdown;</a>
<a name="ln934"> </a>
<a name="ln935">  // Release the mutex that prevents snapshot restore / truncate operations from running. Such</a>
<a name="ln936">  // operations are no longer possible because the tablet has shut down. When we start the</a>
<a name="ln937">  // &quot;read/write operation pause&quot;, we incremented the &quot;exclusive operation&quot; counter. This will</a>
<a name="ln938">  // prevent us from decrementing that counter back, disabling read/write operations permanently.</a>
<a name="ln939">  op_pause.ReleaseMutexButKeepDisabled();</a>
<a name="ln940">  DCHECK(op_pause.status().ok());  // Ensure that op_pause stays in scope throughout this function.</a>
<a name="ln941">}</a>
<a name="ln942"> </a>
<a name="ln943">CHECKED_STATUS ResetRocksDB(</a>
<a name="ln944">    bool destroy, const rocksdb::Options&amp; options, std::unique_ptr&lt;rocksdb::DB&gt;* db) {</a>
<a name="ln945">  if (!*db) {</a>
<a name="ln946">    return Status::OK();</a>
<a name="ln947">  }</a>
<a name="ln948"> </a>
<a name="ln949">  auto dir = (**db).GetName();</a>
<a name="ln950">  db-&gt;reset();</a>
<a name="ln951">  if (!destroy) {</a>
<a name="ln952">    return Status::OK();</a>
<a name="ln953">  }</a>
<a name="ln954"> </a>
<a name="ln955">  return rocksdb::DestroyDB(dir, options);</a>
<a name="ln956">}</a>
<a name="ln957"> </a>
<a name="ln958">Status Tablet::ResetRocksDBs(Destroy destroy, DisableFlushOnShutdown disable_flush_on_shutdown) {</a>
<a name="ln959">  PreventCallbacksFromRocksDBs(disable_flush_on_shutdown);</a>
<a name="ln960"> </a>
<a name="ln961">  rocksdb::Options rocksdb_options;</a>
<a name="ln962">  if (destroy) {</a>
<a name="ln963">    InitRocksDBOptions(&amp;rocksdb_options, LogPrefix());</a>
<a name="ln964">  }</a>
<a name="ln965"> </a>
<a name="ln966">  Status intents_status = ResetRocksDB(destroy, rocksdb_options, &amp;intents_db_);</a>
<a name="ln967">  Status regular_status = ResetRocksDB(destroy, rocksdb_options, &amp;regular_db_);</a>
<a name="ln968">  key_bounds_ = docdb::KeyBounds();</a>
<a name="ln969"> </a>
<a name="ln970">  return regular_status.ok() ? intents_status : regular_status;</a>
<a name="ln971">}</a>
<a name="ln972"> </a>
<a name="ln973">Result&lt;std::unique_ptr&lt;common::YQLRowwiseIteratorIf&gt;&gt; Tablet::NewRowIterator(</a>
<a name="ln974">    const Schema &amp;projection,</a>
<a name="ln975">    const boost::optional&lt;TransactionId&gt;&amp; transaction_id,</a>
<a name="ln976">    const ReadHybridTime read_hybrid_time,</a>
<a name="ln977">    const TableId&amp; table_id,</a>
<a name="ln978">    CoarseTimePoint deadline,</a>
<a name="ln979">    AllowBootstrappingState allow_bootstrapping_state) const {</a>
<a name="ln980">  if (state_ != kOpen &amp;&amp; (!allow_bootstrapping_state || state_ != kBootstrapping)) {</a>
<a name="ln981">    return STATUS_FORMAT(IllegalState, &quot;Tablet in wrong state: $0&quot;, state_);</a>
<a name="ln982">  }</a>
<a name="ln983"> </a>
<a name="ln984">  if (table_type_ != TableType::YQL_TABLE_TYPE &amp;&amp; table_type_ != TableType::PGSQL_TABLE_TYPE) {</a>
<a name="ln985">    return STATUS_FORMAT(NotSupported, &quot;Invalid table type: $0&quot;, table_type_);</a>
<a name="ln986">  }</a>
<a name="ln987"> </a>
<a name="ln988">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln989">  RETURN_NOT_OK(scoped_read_operation);</a>
<a name="ln990"> </a>
<a name="ln991">  VLOG_WITH_PREFIX(2) &lt;&lt; &quot;Created new Iterator reading at &quot; &lt;&lt; read_hybrid_time.ToString();</a>
<a name="ln992"> </a>
<a name="ln993">  const std::shared_ptr&lt;tablet::TableInfo&gt; table_info =</a>
<a name="ln994">      VERIFY_RESULT(metadata_-&gt;GetTableInfo(table_id));</a>
<a name="ln995">  const Schema&amp; schema = table_info-&gt;schema;</a>
<a name="ln996">  auto mapped_projection = std::make_unique&lt;Schema&gt;();</a>
<a name="ln997">  RETURN_NOT_OK(schema.GetMappedReadProjection(projection, mapped_projection.get()));</a>
<a name="ln998"> </a>
<a name="ln999">  auto txn_op_ctx = CreateTransactionOperationContext(</a>
<a name="ln1000">      transaction_id, schema.table_properties().is_ysql_catalog_table());</a>
<a name="ln1001">  const auto read_time =</a>
<a name="ln1002">      (read_hybrid_time ? read_hybrid_time</a>
<a name="ln1003">                        : ReadHybridTime::SingleTime(SafeTime(RequireLease::kFalse)));</a>
<a name="ln1004">  auto result = std::make_unique&lt;DocRowwiseIterator&gt;(</a>
<a name="ln1005">      std::move(mapped_projection), schema, txn_op_ctx, doc_db(),</a>
<a name="ln1006">      deadline, read_time, &amp;pending_op_counter_);</a>
<a name="ln1007">  RETURN_NOT_OK(result-&gt;Init());</a>
<a name="ln1008">  return std::move(result);</a>
<a name="ln1009">}</a>
<a name="ln1010"> </a>
<a name="ln1011">Result&lt;std::unique_ptr&lt;common::YQLRowwiseIteratorIf&gt;&gt; Tablet::NewRowIterator(</a>
<a name="ln1012">    const TableId&amp; table_id) const {</a>
<a name="ln1013">  const std::shared_ptr&lt;tablet::TableInfo&gt; table_info =</a>
<a name="ln1014">      VERIFY_RESULT(metadata_-&gt;GetTableInfo(table_id));</a>
<a name="ln1015">  return NewRowIterator(table_info-&gt;schema, boost::none, {}, table_id);</a>
<a name="ln1016">}</a>
<a name="ln1017"> </a>
<a name="ln1018">void Tablet::StartOperation(WriteOperationState* operation_state) {</a>
<a name="ln1019">  // If the state already has a hybrid_time then we're replaying a transaction that occurred</a>
<a name="ln1020">  // before a crash or at another node.</a>
<a name="ln1021">  DVLOG(4) &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; &quot; for &quot; &lt;&lt; yb::ToString(operation_state-&gt;request());</a>
<a name="ln1022">  HybridTime ht = operation_state-&gt;hybrid_time_even_if_unset();</a>
<a name="ln1023">  bool was_valid = ht.is_valid();</a>
<a name="ln1024">  if (!was_valid) {</a>
<a name="ln1025">    // Add only leader operation here, since follower operations already registered in MVCC,</a>
<a name="ln1026">    // as soon as they received.</a>
<a name="ln1027">    mvcc_.AddPending(&amp;ht);</a>
<a name="ln1028">    operation_state-&gt;set_hybrid_time(ht);</a>
<a name="ln1029">  }</a>
<a name="ln1030">}</a>
<a name="ln1031"> </a>
<a name="ln1032">Status Tablet::ApplyRowOperations(WriteOperationState* operation_state) {</a>
<a name="ln1033">  const auto&amp; write_request =</a>
<a name="ln1034">      operation_state-&gt;consensus_round() &amp;&amp; operation_state-&gt;consensus_round()-&gt;replicate_msg()</a>
<a name="ln1035">          // Online case.</a>
<a name="ln1036">          ? operation_state-&gt;consensus_round()-&gt;replicate_msg()-&gt;write_request()</a>
<a name="ln1037">          // Bootstrap case.</a>
<a name="ln1038">          : *operation_state-&gt;request();</a>
<a name="ln1039">  const KeyValueWriteBatchPB&amp; put_batch = write_request.write_batch();</a>
<a name="ln1040">  if (metrics_) {</a>
<a name="ln1041">    metrics_-&gt;rows_inserted-&gt;IncrementBy(write_request.write_batch().write_pairs().size());</a>
<a name="ln1042">  }</a>
<a name="ln1043"> </a>
<a name="ln1044">  return ApplyOperationState(*operation_state, write_request.batch_idx(), put_batch);</a>
<a name="ln1045">}</a>
<a name="ln1046"> </a>
<a name="ln1047">Status Tablet::ApplyOperationState(</a>
<a name="ln1048">    const OperationState&amp; operation_state, int64_t batch_idx,</a>
<a name="ln1049">    const docdb::KeyValueWriteBatchPB&amp; write_batch) {</a>
<a name="ln1050">  docdb::ConsensusFrontiers frontiers;</a>
<a name="ln1051">  set_op_id(yb::OpId::FromPB(operation_state.op_id()), &amp;frontiers);</a>
<a name="ln1052"> </a>
<a name="ln1053">  auto hybrid_time = operation_state.WriteHybridTime();</a>
<a name="ln1054"> </a>
<a name="ln1055">  // Even if we have an external hybrid time, use the local commit hybrid time in the consensus</a>
<a name="ln1056">  // frontier.</a>
<a name="ln1057">  set_hybrid_time(operation_state.hybrid_time(), &amp;frontiers);</a>
<a name="ln1058">  return ApplyKeyValueRowOperations(</a>
<a name="ln1059">      batch_idx, write_batch, &amp;frontiers, hybrid_time);</a>
<a name="ln1060">}</a>
<a name="ln1061"> </a>
<a name="ln1062">Status Tablet::PrepareTransactionWriteBatch(</a>
<a name="ln1063">    int64_t batch_idx,</a>
<a name="ln1064">    const KeyValueWriteBatchPB&amp; put_batch,</a>
<a name="ln1065">    HybridTime hybrid_time,</a>
<a name="ln1066">    rocksdb::WriteBatch* rocksdb_write_batch) {</a>
<a name="ln1067">  auto transaction_id = CHECK_RESULT(</a>
<a name="ln1068">      FullyDecodeTransactionId(put_batch.transaction().transaction_id()));</a>
<a name="ln1069">  if (put_batch.transaction().has_isolation()) {</a>
<a name="ln1070">    // Store transaction metadata (status tablet, isolation level etc.)</a>
<a name="ln1071">    if (!transaction_participant()-&gt;Add(put_batch.transaction(), rocksdb_write_batch)) {</a>
<a name="ln1072">      return STATUS(TryAgain,</a>
<a name="ln1073">                    Format(&quot;Transaction was recently aborted: $0&quot;, transaction_id), Slice(),</a>
<a name="ln1074">                    PgsqlError(YBPgErrorCode::YB_PG_T_R_SERIALIZATION_FAILURE));</a>
<a name="ln1075">    }</a>
<a name="ln1076">  }</a>
<a name="ln1077">  boost::container::small_vector&lt;uint8_t, 16&gt; encoded_replicated_batch_idx_set;</a>
<a name="ln1078">  auto prepare_batch_data = transaction_participant()-&gt;PrepareBatchData(</a>
<a name="ln1079">      transaction_id, batch_idx, &amp;encoded_replicated_batch_idx_set);</a>
<a name="ln1080">  if (!prepare_batch_data) {</a>
<a name="ln1081">    // If metadata is missing it could be caused by aborted and removed transaction.</a>
<a name="ln1082">    // In this case we should not add new intents for it.</a>
<a name="ln1083">    return STATUS(TryAgain,</a>
<a name="ln1084">                  Format(&quot;Transaction metadata missing: $0, looks like it was just aborted&quot;,</a>
<a name="ln1085">                         transaction_id), Slice(),</a>
<a name="ln1086">                         PgsqlError(YBPgErrorCode::YB_PG_T_R_SERIALIZATION_FAILURE));</a>
<a name="ln1087">  }</a>
<a name="ln1088"> </a>
<a name="ln1089">  auto isolation_level = prepare_batch_data-&gt;first;</a>
<a name="ln1090">  auto&amp; last_batch_data = prepare_batch_data-&gt;second;</a>
<a name="ln1091">  yb::docdb::PrepareTransactionWriteBatch(</a>
<a name="ln1092">      put_batch, hybrid_time, rocksdb_write_batch, transaction_id, isolation_level,</a>
<a name="ln1093">      UsePartialRangeKeyIntents(*metadata_),</a>
<a name="ln1094">      Slice(encoded_replicated_batch_idx_set.data(), encoded_replicated_batch_idx_set.size()),</a>
<a name="ln1095">      &amp;last_batch_data.write_id);</a>
<a name="ln1096">  last_batch_data.hybrid_time = hybrid_time;</a>
<a name="ln1097">  transaction_participant()-&gt;BatchReplicated(transaction_id, last_batch_data);</a>
<a name="ln1098"> </a>
<a name="ln1099">  return Status::OK();</a>
<a name="ln1100">}</a>
<a name="ln1101"> </a>
<a name="ln1102">Status Tablet::ApplyKeyValueRowOperations(int64_t batch_idx,</a>
<a name="ln1103">                                          const KeyValueWriteBatchPB&amp; put_batch,</a>
<a name="ln1104">                                          const rocksdb::UserFrontiers* frontiers,</a>
<a name="ln1105">                                          const HybridTime hybrid_time) {</a>
<a name="ln1106">  if (put_batch.write_pairs().empty() &amp;&amp; put_batch.read_pairs().empty()) {</a>
<a name="ln1107">    return Status::OK();</a>
<a name="ln1108">  }</a>
<a name="ln1109"> </a>
<a name="ln1110">  // Could return failure only for cases where it is safe to skip applying operations to DB.</a>
<a name="ln1111">  // For instance where aborted transaction intents are written.</a>
<a name="ln1112">  // In all other cases we should crash instead of skipping apply.</a>
<a name="ln1113"> </a>
<a name="ln1114">  rocksdb::WriteBatch write_batch;</a>
<a name="ln1115">  if (put_batch.has_transaction()) {</a>
<a name="ln1116">    RequestScope request_scope(transaction_participant_.get());</a>
<a name="ln1117">    RETURN_NOT_OK(PrepareTransactionWriteBatch(batch_idx, put_batch, hybrid_time, &amp;write_batch));</a>
<a name="ln1118">    WriteToRocksDB(frontiers, &amp;write_batch, StorageDbType::kIntents);</a>
<a name="ln1119">  } else {</a>
<a name="ln1120">    PrepareNonTransactionWriteBatch(put_batch, hybrid_time, &amp;write_batch);</a>
<a name="ln1121">    WriteToRocksDB(frontiers, &amp;write_batch, StorageDbType::kRegular);</a>
<a name="ln1122">    if (snapshot_coordinator_) {</a>
<a name="ln1123">      for (const auto&amp; pair : put_batch.write_pairs()) {</a>
<a name="ln1124">        WARN_NOT_OK(snapshot_coordinator_-&gt;ApplyWritePair(pair.key(), pair.value()),</a>
<a name="ln1125">                    &quot;ApplyWritePair failed&quot;);</a>
<a name="ln1126">      }</a>
<a name="ln1127">    }</a>
<a name="ln1128">  }</a>
<a name="ln1129"> </a>
<a name="ln1130">  return Status::OK();</a>
<a name="ln1131">}</a>
<a name="ln1132"> </a>
<a name="ln1133">void Tablet::WriteToRocksDB(</a>
<a name="ln1134">    const rocksdb::UserFrontiers* frontiers,</a>
<a name="ln1135">    rocksdb::WriteBatch* write_batch,</a>
<a name="ln1136">    docdb::StorageDbType storage_db_type) {</a>
<a name="ln1137">  if (write_batch-&gt;Count() == 0) {</a>
<a name="ln1138">    return;</a>
<a name="ln1139">  }</a>
<a name="ln1140">  rocksdb::DB* dest_db = nullptr;</a>
<a name="ln1141">  switch (storage_db_type) {</a>
<a name="ln1142">    case StorageDbType::kRegular: dest_db = regular_db_.get(); break;</a>
<a name="ln1143">    case StorageDbType::kIntents: dest_db = intents_db_.get(); break;</a>
<a name="ln1144">  }</a>
<a name="ln1145"> </a>
<a name="ln1146">  // Frontiers can be null for deferred apply operations.</a>
<a name="ln1147">  if (frontiers) {</a>
<a name="ln1148">    write_batch-&gt;SetFrontiers(frontiers);</a>
<a name="ln1149">  }</a>
<a name="ln1150"> </a>
<a name="ln1151">  // We are using Raft replication index for the RocksDB sequence number for</a>
<a name="ln1152">  // all members of this write batch.</a>
<a name="ln1153">  rocksdb::WriteOptions write_options;</a>
<a name="ln1154">  InitRocksDBWriteOptions(&amp;write_options);</a>
<a name="ln1155"> </a>
<a name="ln1156">  auto rocksdb_write_status = dest_db-&gt;Write(write_options, write_batch);</a>
<a name="ln1157">  if (!rocksdb_write_status.ok()) {</a>
<a name="ln1158">    LOG_WITH_PREFIX(FATAL) &lt;&lt; &quot;Failed to write a batch with &quot; &lt;&lt; write_batch-&gt;Count()</a>
<a name="ln1159">                           &lt;&lt; &quot; operations into RocksDB: &quot; &lt;&lt; rocksdb_write_status;</a>
<a name="ln1160">  }</a>
<a name="ln1161"> </a>
<a name="ln1162">  if (FLAGS_TEST_docdb_log_write_batches) {</a>
<a name="ln1163">    LOG_WITH_PREFIX(INFO)</a>
<a name="ln1164">        &lt;&lt; &quot;Wrote &quot; &lt;&lt; write_batch-&gt;Count() &lt;&lt; &quot; key/value pairs to &quot; &lt;&lt; storage_db_type</a>
<a name="ln1165">        &lt;&lt; &quot; RocksDB:\n&quot; &lt;&lt; docdb::WriteBatchToString(</a>
<a name="ln1166">            *write_batch, storage_db_type, BinaryOutputFormat::kEscapedAndHex);</a>
<a name="ln1167">  }</a>
<a name="ln1168">}</a>
<a name="ln1169"> </a>
<a name="ln1170">namespace {</a>
<a name="ln1171"> </a>
<a name="ln1172">// Separate Redis / QL / row operations write batches from write_request in preparation for the</a>
<a name="ln1173">// write transaction. Leave just the tablet id behind. Return Redis / QL / row operations, etc.</a>
<a name="ln1174">// in batch_request.</a>
<a name="ln1175">void SetupKeyValueBatch(WriteRequestPB* write_request, WriteRequestPB* batch_request) {</a>
<a name="ln1176">  batch_request-&gt;Swap(write_request);</a>
<a name="ln1177">  write_request-&gt;set_allocated_tablet_id(batch_request-&gt;release_tablet_id());</a>
<a name="ln1178">  if (batch_request-&gt;has_read_time()) {</a>
<a name="ln1179">    write_request-&gt;set_allocated_read_time(batch_request-&gt;release_read_time());</a>
<a name="ln1180">  }</a>
<a name="ln1181">  if (batch_request-&gt;write_batch().has_transaction()) {</a>
<a name="ln1182">    write_request-&gt;mutable_write_batch()-&gt;mutable_transaction()-&gt;Swap(</a>
<a name="ln1183">        batch_request-&gt;mutable_write_batch()-&gt;mutable_transaction());</a>
<a name="ln1184">  }</a>
<a name="ln1185">  write_request-&gt;mutable_write_batch()-&gt;set_deprecated_may_have_metadata(true);</a>
<a name="ln1186">  if (batch_request-&gt;has_request_id()) {</a>
<a name="ln1187">    write_request-&gt;set_client_id1(batch_request-&gt;client_id1());</a>
<a name="ln1188">    write_request-&gt;set_client_id2(batch_request-&gt;client_id2());</a>
<a name="ln1189">    write_request-&gt;set_request_id(batch_request-&gt;request_id());</a>
<a name="ln1190">    write_request-&gt;set_min_running_request_id(batch_request-&gt;min_running_request_id());</a>
<a name="ln1191">  }</a>
<a name="ln1192">  if (batch_request-&gt;has_external_hybrid_time()) {</a>
<a name="ln1193">    write_request-&gt;set_external_hybrid_time(batch_request-&gt;external_hybrid_time());</a>
<a name="ln1194">  }</a>
<a name="ln1195">  write_request-&gt;set_batch_idx(batch_request-&gt;batch_idx());</a>
<a name="ln1196">}</a>
<a name="ln1197"> </a>
<a name="ln1198">} // namespace</a>
<a name="ln1199"> </a>
<a name="ln1200">//--------------------------------------------------------------------------------------------------</a>
<a name="ln1201">// Redis Request Processing.</a>
<a name="ln1202">void Tablet::KeyValueBatchFromRedisWriteBatch(std::unique_ptr&lt;WriteOperation&gt; operation) {</a>
<a name="ln1203">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln1204">  if (!scoped_read_operation.ok()) {</a>
<a name="ln1205">    WriteOperation::StartSynchronization(std::move(operation), MoveStatus(scoped_read_operation));</a>
<a name="ln1206">  }</a>
<a name="ln1207"> </a>
<a name="ln1208">  docdb::DocOperations&amp; doc_ops = operation-&gt;doc_ops();</a>
<a name="ln1209">  // Since we take exclusive locks, it's okay to use Now as the read TS for writes.</a>
<a name="ln1210">  WriteRequestPB batch_request;</a>
<a name="ln1211">  SetupKeyValueBatch(operation-&gt;request(), &amp;batch_request);</a>
<a name="ln1212">  auto* redis_write_batch = batch_request.mutable_redis_write_batch();</a>
<a name="ln1213"> </a>
<a name="ln1214">  doc_ops.reserve(redis_write_batch-&gt;size());</a>
<a name="ln1215">  for (size_t i = 0; i &lt; redis_write_batch-&gt;size(); i++) {</a>
<a name="ln1216">    doc_ops.emplace_back(new RedisWriteOperation(redis_write_batch-&gt;Mutable(i)));</a>
<a name="ln1217">  }</a>
<a name="ln1218"> </a>
<a name="ln1219">  StartDocWriteOperation(std::move(operation), std::move(scoped_read_operation),</a>
<a name="ln1220">                         [](auto operation, const Status&amp; status) {</a>
<a name="ln1221">    if (!status.ok() || operation-&gt;restart_read_ht().is_valid()) {</a>
<a name="ln1222">      WriteOperation::StartSynchronization(std::move(operation), status);</a>
<a name="ln1223">      return;</a>
<a name="ln1224">    }</a>
<a name="ln1225">    auto* response = operation-&gt;response();</a>
<a name="ln1226">    docdb::DocOperations&amp; doc_ops = operation-&gt;doc_ops();</a>
<a name="ln1227">    for (size_t i = 0; i &lt; doc_ops.size(); i++) {</a>
<a name="ln1228">      auto* redis_write_operation = down_cast&lt;RedisWriteOperation*&gt;(doc_ops[i].get());</a>
<a name="ln1229">      response-&gt;add_redis_response_batch()-&gt;Swap(&amp;redis_write_operation-&gt;response());</a>
<a name="ln1230">    }</a>
<a name="ln1231"> </a>
<a name="ln1232">    WriteOperation::StartSynchronization(std::move(operation), Status::OK());</a>
<a name="ln1233">  });</a>
<a name="ln1234">}</a>
<a name="ln1235"> </a>
<a name="ln1236">Status Tablet::HandleRedisReadRequest(CoarseTimePoint deadline,</a>
<a name="ln1237">                                      const ReadHybridTime&amp; read_time,</a>
<a name="ln1238">                                      const RedisReadRequestPB&amp; redis_read_request,</a>
<a name="ln1239">                                      RedisResponsePB* response) {</a>
<a name="ln1240">  // TODO: move this locking to the top-level read request handler in TabletService.</a>
<a name="ln1241">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_, deadline);</a>
<a name="ln1242">  RETURN_NOT_OK(scoped_read_operation);</a>
<a name="ln1243"> </a>
<a name="ln1244">  ScopedTabletMetricsTracker metrics_tracker(metrics_-&gt;redis_read_latency);</a>
<a name="ln1245"> </a>
<a name="ln1246">  docdb::RedisReadOperation doc_op(redis_read_request, doc_db(), deadline, read_time);</a>
<a name="ln1247">  RETURN_NOT_OK(doc_op.Execute());</a>
<a name="ln1248">  *response = std::move(doc_op.response());</a>
<a name="ln1249">  return Status::OK();</a>
<a name="ln1250">}</a>
<a name="ln1251"> </a>
<a name="ln1252">//--------------------------------------------------------------------------------------------------</a>
<a name="ln1253">// CQL Request Processing.</a>
<a name="ln1254">Status Tablet::HandleQLReadRequest(</a>
<a name="ln1255">    CoarseTimePoint deadline,</a>
<a name="ln1256">    const ReadHybridTime&amp; read_time,</a>
<a name="ln1257">    const QLReadRequestPB&amp; ql_read_request,</a>
<a name="ln1258">    const TransactionMetadataPB&amp; transaction_metadata,</a>
<a name="ln1259">    QLReadRequestResult* result) {</a>
<a name="ln1260">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_, deadline);</a>
<a name="ln1261">  RETURN_NOT_OK(scoped_read_operation);</a>
<a name="ln1262">  ScopedTabletMetricsTracker metrics_tracker(metrics_-&gt;ql_read_latency);</a>
<a name="ln1263"> </a>
<a name="ln1264">  if (metadata()-&gt;schema_version() != ql_read_request.schema_version()) {</a>
<a name="ln1265">    DVLOG(1) &lt;&lt; &quot;Setting status for read as YQL_STATUS_SCHEMA_VERSION_MISMATCH&quot;;</a>
<a name="ln1266">    result-&gt;response.set_status(QLResponsePB::YQL_STATUS_SCHEMA_VERSION_MISMATCH);</a>
<a name="ln1267">    result-&gt;response.set_error_message(</a>
<a name="ln1268">        Format(&quot;schema version mismatch for table $0: expected $1, got $2&quot;,</a>
<a name="ln1269">               metadata()-&gt;table_id(),</a>
<a name="ln1270">               metadata()-&gt;schema_version(),</a>
<a name="ln1271">               ql_read_request.schema_version()));</a>
<a name="ln1272">    return Status::OK();</a>
<a name="ln1273">  }</a>
<a name="ln1274"> </a>
<a name="ln1275">  Result&lt;TransactionOperationContextOpt&gt; txn_op_ctx =</a>
<a name="ln1276">      CreateTransactionOperationContext(transaction_metadata, /* is_ysql_catalog_table */ false);</a>
<a name="ln1277">  RETURN_NOT_OK(txn_op_ctx);</a>
<a name="ln1278">  return AbstractTablet::HandleQLReadRequest(</a>
<a name="ln1279">      deadline, read_time, ql_read_request, *txn_op_ctx, result);</a>
<a name="ln1280">}</a>
<a name="ln1281"> </a>
<a name="ln1282">CHECKED_STATUS Tablet::CreatePagingStateForRead(const QLReadRequestPB&amp; ql_read_request,</a>
<a name="ln1283">                                                const size_t row_count,</a>
<a name="ln1284">                                                QLResponsePB* response) const {</a>
<a name="ln1285"> </a>
<a name="ln1286">  // If the response does not have a next partition key, it means we are done reading the current</a>
<a name="ln1287">  // tablet. But, if the request does not have the hash columns set, this must be a table-scan,</a>
<a name="ln1288">  // so we need to decide if we are done or if we need to move to the next tablet.</a>
<a name="ln1289">  // If we did not reach the:</a>
<a name="ln1290">  //   1. max number of results (LIMIT clause -- if set)</a>
<a name="ln1291">  //   2. end of the table (this was the last tablet)</a>
<a name="ln1292">  //   3. max partition key (upper bound condition using 'token' -- if set)</a>
<a name="ln1293">  // we set the paging state to point to the exclusive end partition key of this tablet, which is</a>
<a name="ln1294">  // the start key of the next tablet).</a>
<a name="ln1295">  if (ql_read_request.hashed_column_values().empty() &amp;&amp;</a>
<a name="ln1296">      !response-&gt;paging_state().has_next_partition_key()) {</a>
<a name="ln1297">    // Check we did not reach the results limit.</a>
<a name="ln1298">    // If return_paging_state is set, it means the request limit is actually just the page size.</a>
<a name="ln1299">    if (!ql_read_request.has_limit() ||</a>
<a name="ln1300">        row_count &lt; ql_read_request.limit() ||</a>
<a name="ln1301">        ql_read_request.return_paging_state()) {</a>
<a name="ln1302"> </a>
<a name="ln1303">      // Check we did not reach the last tablet.</a>
<a name="ln1304">      const string&amp; next_partition_key = metadata_-&gt;partition()-&gt;partition_key_end();</a>
<a name="ln1305">      if (!next_partition_key.empty()) {</a>
<a name="ln1306">        uint16_t next_hash_code = PartitionSchema::DecodeMultiColumnHashValue(next_partition_key);</a>
<a name="ln1307"> </a>
<a name="ln1308">        // Check we did not reach the max partition key.</a>
<a name="ln1309">        if (!ql_read_request.has_max_hash_code() ||</a>
<a name="ln1310">            next_hash_code &lt;= ql_read_request.max_hash_code()) {</a>
<a name="ln1311">          response-&gt;mutable_paging_state()-&gt;set_next_partition_key(next_partition_key);</a>
<a name="ln1312">        }</a>
<a name="ln1313">      }</a>
<a name="ln1314">    }</a>
<a name="ln1315">  }</a>
<a name="ln1316"> </a>
<a name="ln1317">  // If there is a paging state, update the total number of rows read so far.</a>
<a name="ln1318">  if (response-&gt;has_paging_state()) {</a>
<a name="ln1319">    response-&gt;mutable_paging_state()-&gt;set_total_num_rows_read(</a>
<a name="ln1320">        ql_read_request.paging_state().total_num_rows_read() + row_count);</a>
<a name="ln1321">  }</a>
<a name="ln1322">  return Status::OK();</a>
<a name="ln1323">}</a>
<a name="ln1324"> </a>
<a name="ln1325">void Tablet::KeyValueBatchFromQLWriteBatch(std::unique_ptr&lt;WriteOperation&gt; operation) {</a>
<a name="ln1326">  DVLOG(2) &lt;&lt; &quot; Schema version for  &quot; &lt;&lt; metadata_-&gt;table_name() &lt;&lt; &quot; is &quot;</a>
<a name="ln1327">           &lt;&lt; metadata_-&gt;schema_version();</a>
<a name="ln1328">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln1329">  if (!scoped_read_operation.ok()) {</a>
<a name="ln1330">    WriteOperation::StartSynchronization(std::move(operation), MoveStatus(scoped_read_operation));</a>
<a name="ln1331">    return;</a>
<a name="ln1332">  }</a>
<a name="ln1333"> </a>
<a name="ln1334">  docdb::DocOperations&amp; doc_ops = operation-&gt;doc_ops();</a>
<a name="ln1335">  WriteRequestPB batch_request;</a>
<a name="ln1336">  SetupKeyValueBatch(operation-&gt;request(), &amp;batch_request);</a>
<a name="ln1337">  auto* ql_write_batch = batch_request.mutable_ql_write_batch();</a>
<a name="ln1338"> </a>
<a name="ln1339">  doc_ops.reserve(ql_write_batch-&gt;size());</a>
<a name="ln1340"> </a>
<a name="ln1341">  Result&lt;TransactionOperationContextOpt&gt; txn_op_ctx =</a>
<a name="ln1342">      CreateTransactionOperationContext(</a>
<a name="ln1343">          operation-&gt;request()-&gt;write_batch().transaction(),</a>
<a name="ln1344">          /* is_ysql_catalog_table */ false);</a>
<a name="ln1345">  if (!txn_op_ctx.ok()) {</a>
<a name="ln1346">    WriteOperation::StartSynchronization(std::move(operation), txn_op_ctx.status());</a>
<a name="ln1347">    return;</a>
<a name="ln1348">  }</a>
<a name="ln1349">  auto table_info = metadata_-&gt;primary_table_info();</a>
<a name="ln1350">  for (size_t i = 0; i &lt; ql_write_batch-&gt;size(); i++) {</a>
<a name="ln1351">    QLWriteRequestPB* req = ql_write_batch-&gt;Mutable(i);</a>
<a name="ln1352">    QLResponsePB* resp = operation-&gt;response()-&gt;add_ql_response_batch();</a>
<a name="ln1353">    if (table_info-&gt;schema_version != req-&gt;schema_version()) {</a>
<a name="ln1354">      DVLOG(3) &lt;&lt; &quot; On &quot; &lt;&lt; table_info-&gt;table_name</a>
<a name="ln1355">               &lt;&lt; &quot; Setting status for write as YQL_STATUS_SCHEMA_VERSION_MISMATCH tserver's: &quot;</a>
<a name="ln1356">               &lt;&lt; table_info-&gt;schema_version &lt;&lt; &quot; vs req's : &quot; &lt;&lt; req-&gt;schema_version()</a>
<a name="ln1357">               &lt;&lt; &quot; for &quot; &lt;&lt; yb::ToString(req);</a>
<a name="ln1358">      resp-&gt;set_status(QLResponsePB::YQL_STATUS_SCHEMA_VERSION_MISMATCH);</a>
<a name="ln1359">      resp-&gt;set_error_message(</a>
<a name="ln1360">          Format(&quot;schema version mismatch for table $0: expected $1, got $2&quot;,</a>
<a name="ln1361">                 table_info-&gt;table_id,</a>
<a name="ln1362">                 table_info-&gt;schema_version,</a>
<a name="ln1363">                 req-&gt;schema_version()));</a>
<a name="ln1364">    } else {</a>
<a name="ln1365">      DVLOG(3) &lt;&lt; &quot;Version matches : &quot; &lt;&lt; table_info-&gt;schema_version &lt;&lt; &quot; for &quot;</a>
<a name="ln1366">               &lt;&lt; yb::ToString(req);</a>
<a name="ln1367">      auto write_op = std::make_unique&lt;QLWriteOperation&gt;(</a>
<a name="ln1368">          std::shared_ptr&lt;Schema&gt;(table_info, &amp;table_info-&gt;schema),</a>
<a name="ln1369">          table_info-&gt;index_map, unique_index_key_schema_.get_ptr(),</a>
<a name="ln1370">          *txn_op_ctx);</a>
<a name="ln1371">      auto status = write_op-&gt;Init(req, resp);</a>
<a name="ln1372">      if (!status.ok()) {</a>
<a name="ln1373">        WriteOperation::StartSynchronization(std::move(operation), status);</a>
<a name="ln1374">        return;</a>
<a name="ln1375">      }</a>
<a name="ln1376">      doc_ops.emplace_back(std::move(write_op));</a>
<a name="ln1377">    }</a>
<a name="ln1378">  }</a>
<a name="ln1379"> </a>
<a name="ln1380">  // All operations has wrong schema version</a>
<a name="ln1381">  if (doc_ops.empty()) {</a>
<a name="ln1382">    WriteOperation::StartSynchronization(std::move(operation), Status::OK());</a>
<a name="ln1383">    return;</a>
<a name="ln1384">  }</a>
<a name="ln1385"> </a>
<a name="ln1386">  StartDocWriteOperation(std::move(operation), std::move(scoped_read_operation),</a>
<a name="ln1387">                         [this](auto operation, const Status&amp; status) {</a>
<a name="ln1388">    if (operation-&gt;restart_read_ht().is_valid()) {</a>
<a name="ln1389">      WriteOperation::StartSynchronization(std::move(operation), Status::OK());</a>
<a name="ln1390">      return;</a>
<a name="ln1391">    }</a>
<a name="ln1392"> </a>
<a name="ln1393">    if (status.ok()) {</a>
<a name="ln1394">      this-&gt;UpdateQLIndexes(std::move(operation));</a>
<a name="ln1395">    } else {</a>
<a name="ln1396">      this-&gt;CompleteQLWriteBatch(std::move(operation), status);</a>
<a name="ln1397">    }</a>
<a name="ln1398">  });</a>
<a name="ln1399">}</a>
<a name="ln1400"> </a>
<a name="ln1401">void Tablet::CompleteQLWriteBatch(std::unique_ptr&lt;WriteOperation&gt; operation, const Status&amp; status) {</a>
<a name="ln1402">  if (!status.ok()) {</a>
<a name="ln1403">    WriteOperation::StartSynchronization(std::move(operation), status);</a>
<a name="ln1404">    return;</a>
<a name="ln1405">  }</a>
<a name="ln1406">  auto&amp; doc_ops = operation-&gt;doc_ops();</a>
<a name="ln1407"> </a>
<a name="ln1408">  for (size_t i = 0; i &lt; doc_ops.size(); i++) {</a>
<a name="ln1409">    QLWriteOperation* ql_write_op = down_cast&lt;QLWriteOperation*&gt;(doc_ops[i].get());</a>
<a name="ln1410">    if (metadata_-&gt;is_unique_index() &amp;&amp;</a>
<a name="ln1411">        ql_write_op-&gt;request().type() == QLWriteRequestPB::QL_STMT_INSERT &amp;&amp;</a>
<a name="ln1412">        ql_write_op-&gt;response()-&gt;has_applied() &amp;&amp; !ql_write_op-&gt;response()-&gt;applied()) {</a>
<a name="ln1413">      // If this is an insert into a unique index and it fails to apply, report duplicate value err.</a>
<a name="ln1414">      ql_write_op-&gt;response()-&gt;set_status(QLResponsePB::YQL_STATUS_USAGE_ERROR);</a>
<a name="ln1415">      ql_write_op-&gt;response()-&gt;set_error_message(</a>
<a name="ln1416">          Format(&quot;Duplicate value disallowed by unique index $0&quot;, metadata_-&gt;table_name()));</a>
<a name="ln1417">      DVLOG(1) &lt;&lt; &quot;Could not apply the given operation &quot; &lt;&lt; yb::ToString(ql_write_op-&gt;request())</a>
<a name="ln1418">               &lt;&lt; &quot; due to &quot; &lt;&lt; yb::ToString(ql_write_op-&gt;response());</a>
<a name="ln1419">    } else if (ql_write_op-&gt;rowblock() != nullptr) {</a>
<a name="ln1420">      // If the QL write op returns a rowblock, move the op to the transaction state to return the</a>
<a name="ln1421">      // rows data as a sidecar after the transaction completes.</a>
<a name="ln1422">      doc_ops[i].release();</a>
<a name="ln1423">      operation-&gt;state()-&gt;ql_write_ops()-&gt;emplace_back(unique_ptr&lt;QLWriteOperation&gt;(ql_write_op));</a>
<a name="ln1424">    }</a>
<a name="ln1425">  }</a>
<a name="ln1426"> </a>
<a name="ln1427">  WriteOperation::StartSynchronization(std::move(operation), Status::OK());</a>
<a name="ln1428">}</a>
<a name="ln1429"> </a>
<a name="ln1430">void Tablet::UpdateQLIndexes(std::unique_ptr&lt;WriteOperation&gt; operation) {</a>
<a name="ln1431">  client::YBClient* client = nullptr;</a>
<a name="ln1432">  client::YBSessionPtr session;</a>
<a name="ln1433">  client::YBTransactionPtr txn;</a>
<a name="ln1434">  IndexOps index_ops;</a>
<a name="ln1435">  const ChildTransactionDataPB* child_transaction_data = nullptr;</a>
<a name="ln1436">  for (auto&amp; doc_op : operation-&gt;doc_ops()) {</a>
<a name="ln1437">    auto* write_op = static_cast&lt;QLWriteOperation*&gt;(doc_op.get());</a>
<a name="ln1438">    if (write_op-&gt;index_requests()-&gt;empty()) {</a>
<a name="ln1439">      continue;</a>
<a name="ln1440">    }</a>
<a name="ln1441">    if (!client) {</a>
<a name="ln1442">      client = client_future_.get();</a>
<a name="ln1443">      session = std::make_shared&lt;YBSession&gt;(client);</a>
<a name="ln1444">      if (write_op-&gt;request().has_child_transaction_data()) {</a>
<a name="ln1445">        child_transaction_data = &amp;write_op-&gt;request().child_transaction_data();</a>
<a name="ln1446">        if (!transaction_manager_) {</a>
<a name="ln1447">          WriteOperation::StartSynchronization(</a>
<a name="ln1448">              std::move(operation),</a>
<a name="ln1449">              STATUS(Corruption, &quot;Transaction manager is not present for index update&quot;));</a>
<a name="ln1450">          return;</a>
<a name="ln1451">        }</a>
<a name="ln1452">        auto child_data = ChildTransactionData::FromPB(</a>
<a name="ln1453">            write_op-&gt;request().child_transaction_data());</a>
<a name="ln1454">        if (!child_data.ok()) {</a>
<a name="ln1455">          WriteOperation::StartSynchronization(std::move(operation), child_data.status());</a>
<a name="ln1456">          return;</a>
<a name="ln1457">        }</a>
<a name="ln1458">        txn = std::make_shared&lt;YBTransaction&gt;(&amp;transaction_manager_.get(), *child_data);</a>
<a name="ln1459">        session-&gt;SetTransaction(txn);</a>
<a name="ln1460">      } else {</a>
<a name="ln1461">        child_transaction_data = nullptr;</a>
<a name="ln1462">      }</a>
<a name="ln1463">    } else if (write_op-&gt;request().has_child_transaction_data()) {</a>
<a name="ln1464">      DCHECK_ONLY_NOTNULL(child_transaction_data);</a>
<a name="ln1465">      DCHECK_EQ(child_transaction_data-&gt;ShortDebugString(),</a>
<a name="ln1466">                write_op-&gt;request().child_transaction_data().ShortDebugString());</a>
<a name="ln1467">    } else {</a>
<a name="ln1468">      DCHECK(child_transaction_data == nullptr) &lt;&lt;</a>
<a name="ln1469">          &quot;Value: &quot; &lt;&lt; child_transaction_data-&gt;ShortDebugString();</a>
<a name="ln1470">    }</a>
<a name="ln1471"> </a>
<a name="ln1472">    // Apply the write ops to update the index</a>
<a name="ln1473">    for (auto&amp; pair : *write_op-&gt;index_requests()) {</a>
<a name="ln1474">      client::YBTablePtr index_table;</a>
<a name="ln1475">      bool cache_used_ignored = false;</a>
<a name="ln1476">      auto metadata_cache = YBMetaDataCache();</a>
<a name="ln1477">      if (!metadata_cache) {</a>
<a name="ln1478">        WriteOperation::StartSynchronization(</a>
<a name="ln1479">            std::move(operation),</a>
<a name="ln1480">            STATUS(Corruption, &quot;Table metadata cache is not present for index update&quot;));</a>
<a name="ln1481">        return;</a>
<a name="ln1482">      }</a>
<a name="ln1483">      // TODO create async version of GetTable.</a>
<a name="ln1484">      // It is ok to have sync call here, because we use cache and it should not take too long.</a>
<a name="ln1485">      auto status = metadata_cache-&gt;GetTable(pair.first-&gt;table_id(), &amp;index_table,</a>
<a name="ln1486">                                             &amp;cache_used_ignored);</a>
<a name="ln1487">      if (!status.ok()) {</a>
<a name="ln1488">        WriteOperation::StartSynchronization(std::move(operation), status);</a>
<a name="ln1489">        return;</a>
<a name="ln1490">      }</a>
<a name="ln1491">      shared_ptr&lt;client::YBqlWriteOp&gt; index_op(index_table-&gt;NewQLWrite());</a>
<a name="ln1492">      index_op-&gt;mutable_request()-&gt;Swap(&amp;pair.second);</a>
<a name="ln1493">      index_op-&gt;mutable_request()-&gt;MergeFrom(pair.second);</a>
<a name="ln1494">      status = session-&gt;Apply(index_op);</a>
<a name="ln1495">      if (!status.ok()) {</a>
<a name="ln1496">        WriteOperation::StartSynchronization(std::move(operation), status);</a>
<a name="ln1497">        return;</a>
<a name="ln1498">      }</a>
<a name="ln1499">      index_ops.emplace_back(std::move(index_op), write_op);</a>
<a name="ln1500">    }</a>
<a name="ln1501">  }</a>
<a name="ln1502"> </a>
<a name="ln1503">  if (!session) {</a>
<a name="ln1504">    CompleteQLWriteBatch(std::move(operation), Status::OK());</a>
<a name="ln1505">    return;</a>
<a name="ln1506">  }</a>
<a name="ln1507"> </a>
<a name="ln1508">  session-&gt;FlushAsync(std::bind(</a>
<a name="ln1509">      &amp;Tablet::UpdateQLIndexesFlushed, this, operation.release(), session, txn,</a>
<a name="ln1510">      std::move(index_ops), _1));</a>
<a name="ln1511">}</a>
<a name="ln1512"> </a>
<a name="ln1513">void Tablet::UpdateQLIndexesFlushed(</a>
<a name="ln1514">    WriteOperation* op, const client::YBSessionPtr&amp; session, const client::YBTransactionPtr&amp; txn,</a>
<a name="ln1515">    const IndexOps&amp; index_ops, const Status&amp; status) {</a>
<a name="ln1516">  std::unique_ptr&lt;WriteOperation&gt; operation(op);</a>
<a name="ln1517"> </a>
<a name="ln1518">  if (PREDICT_FALSE(!status.ok())) {</a>
<a name="ln1519">    // When any error occurs during the dispatching of YBOperation, YBSession saves the error and</a>
<a name="ln1520">    // returns IOError. When it happens, retrieves the errors and discard the IOError.</a>
<a name="ln1521">    if (status.IsIOError()) {</a>
<a name="ln1522">      for (const auto&amp; error : session-&gt;GetPendingErrors()) {</a>
<a name="ln1523">        // return just the first error seen.</a>
<a name="ln1524">        operation-&gt;state()-&gt;CompleteWithStatus(error-&gt;status());</a>
<a name="ln1525">        return;</a>
<a name="ln1526">      }</a>
<a name="ln1527">    }</a>
<a name="ln1528">    operation-&gt;state()-&gt;CompleteWithStatus(status);</a>
<a name="ln1529">    return;</a>
<a name="ln1530">  }</a>
<a name="ln1531"> </a>
<a name="ln1532">  ChildTransactionResultPB child_result;</a>
<a name="ln1533">  if (txn) {</a>
<a name="ln1534">    auto finish_result = txn-&gt;FinishChild();</a>
<a name="ln1535">    if (!finish_result.ok()) {</a>
<a name="ln1536">      operation-&gt;state()-&gt;CompleteWithStatus(finish_result.status());</a>
<a name="ln1537">      return;</a>
<a name="ln1538">    }</a>
<a name="ln1539">    child_result = std::move(*finish_result);</a>
<a name="ln1540">  }</a>
<a name="ln1541"> </a>
<a name="ln1542">  // Check the responses of the index write ops.</a>
<a name="ln1543">  for (const auto&amp; pair : index_ops) {</a>
<a name="ln1544">    shared_ptr&lt;client::YBqlWriteOp&gt; index_op = pair.first;</a>
<a name="ln1545">    auto* response = pair.second-&gt;response();</a>
<a name="ln1546">    DCHECK_ONLY_NOTNULL(response);</a>
<a name="ln1547">    auto* index_response = index_op-&gt;mutable_response();</a>
<a name="ln1548"> </a>
<a name="ln1549">    if (index_response-&gt;status() != QLResponsePB::YQL_STATUS_OK) {</a>
<a name="ln1550">      DVLOG(1) &lt;&lt; &quot;Got status &quot; &lt;&lt; index_response-&gt;status() &lt;&lt; &quot; for &quot; &lt;&lt; yb::ToString(index_op);</a>
<a name="ln1551">      response-&gt;set_status(index_response-&gt;status());</a>
<a name="ln1552">      response-&gt;set_error_message(std::move(*index_response-&gt;mutable_error_message()));</a>
<a name="ln1553">    }</a>
<a name="ln1554">    if (txn) {</a>
<a name="ln1555">      *response-&gt;mutable_child_transaction_result() = child_result;</a>
<a name="ln1556">    }</a>
<a name="ln1557">  }</a>
<a name="ln1558"> </a>
<a name="ln1559">  CompleteQLWriteBatch(std::move(operation), Status::OK());</a>
<a name="ln1560">}</a>
<a name="ln1561"> </a>
<a name="ln1562">//--------------------------------------------------------------------------------------------------</a>
<a name="ln1563">// PGSQL Request Processing.</a>
<a name="ln1564">//--------------------------------------------------------------------------------------------------</a>
<a name="ln1565">Status Tablet::HandlePgsqlReadRequest(</a>
<a name="ln1566">    CoarseTimePoint deadline,</a>
<a name="ln1567">    const ReadHybridTime&amp; read_time,</a>
<a name="ln1568">    const PgsqlReadRequestPB&amp; pgsql_read_request,</a>
<a name="ln1569">    const TransactionMetadataPB&amp; transaction_metadata,</a>
<a name="ln1570">    PgsqlReadRequestResult* result) {</a>
<a name="ln1571">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_, deadline);</a>
<a name="ln1572">  RETURN_NOT_OK(scoped_read_operation);</a>
<a name="ln1573">  // TODO(neil) Work on metrics for PGSQL.</a>
<a name="ln1574">  // ScopedTabletMetricsTracker metrics_tracker(metrics_-&gt;pgsql_read_latency);</a>
<a name="ln1575"> </a>
<a name="ln1576">  const shared_ptr&lt;tablet::TableInfo&gt; table_info =</a>
<a name="ln1577">      VERIFY_RESULT(metadata_-&gt;GetTableInfo(pgsql_read_request.table_id()));</a>
<a name="ln1578">  // Assert the table is a Postgres table.</a>
<a name="ln1579">  DCHECK_EQ(table_info-&gt;table_type, TableType::PGSQL_TABLE_TYPE);</a>
<a name="ln1580">  if (table_info-&gt;schema_version != pgsql_read_request.schema_version()) {</a>
<a name="ln1581">    result-&gt;response.set_status(PgsqlResponsePB::PGSQL_STATUS_SCHEMA_VERSION_MISMATCH);</a>
<a name="ln1582">    result-&gt;response.set_error_message(</a>
<a name="ln1583">        Format(&quot;schema version mismatch for table $0: expected $1, got $2&quot;,</a>
<a name="ln1584">               table_info-&gt;table_id,</a>
<a name="ln1585">               table_info-&gt;schema_version,</a>
<a name="ln1586">               pgsql_read_request.schema_version()));</a>
<a name="ln1587">    return Status::OK();</a>
<a name="ln1588">  }</a>
<a name="ln1589"> </a>
<a name="ln1590">  Result&lt;TransactionOperationContextOpt&gt; txn_op_ctx =</a>
<a name="ln1591">      CreateTransactionOperationContext(</a>
<a name="ln1592">          transaction_metadata,</a>
<a name="ln1593">          table_info-&gt;schema.table_properties().is_ysql_catalog_table());</a>
<a name="ln1594">  RETURN_NOT_OK(txn_op_ctx);</a>
<a name="ln1595">  return AbstractTablet::HandlePgsqlReadRequest(</a>
<a name="ln1596">      deadline, read_time, pgsql_read_request, *txn_op_ctx, result);</a>
<a name="ln1597">}</a>
<a name="ln1598"> </a>
<a name="ln1599">// Returns true if the query can be satisfied by rows present in current tablet.</a>
<a name="ln1600">// Returns false if query requires other tablets to also be scanned. Examples of this include:</a>
<a name="ln1601">//   (1) full table scan queries</a>
<a name="ln1602">//   (2) queries that whose key conditions are such that the query will require a multi tablet</a>
<a name="ln1603">//       scan.</a>
<a name="ln1604">Result&lt;bool&gt; Tablet::IsQueryOnlyForTablet(const PgsqlReadRequestPB&amp; pgsql_read_request) const {</a>
<a name="ln1605">  if (!pgsql_read_request.ybctid_column_value().value().binary_value().empty() ||</a>
<a name="ln1606">      !pgsql_read_request.partition_column_values().empty()) {</a>
<a name="ln1607">    return true;</a>
<a name="ln1608">  }</a>
<a name="ln1609"> </a>
<a name="ln1610">  std::shared_ptr&lt;const Schema&gt; schema = metadata_-&gt;schema();</a>
<a name="ln1611">  if (schema-&gt;has_pgtable_id() || schema-&gt;has_cotable_id())  {</a>
<a name="ln1612">    // This is a colocated table.</a>
<a name="ln1613">    return true;</a>
<a name="ln1614">  }</a>
<a name="ln1615"> </a>
<a name="ln1616">  if (schema-&gt;num_hash_key_columns() == 0 &amp;&amp;</a>
<a name="ln1617">      schema-&gt;num_range_key_columns() == pgsql_read_request.range_column_values_size()) {</a>
<a name="ln1618">    // PK is contained within this tablet.</a>
<a name="ln1619">    return true;</a>
<a name="ln1620">  }</a>
<a name="ln1621">  return false;</a>
<a name="ln1622">}</a>
<a name="ln1623"> </a>
<a name="ln1624">Result&lt;bool&gt; Tablet::HasScanReachedMaxPartitionKey(</a>
<a name="ln1625">    const PgsqlReadRequestPB&amp; pgsql_read_request, const string&amp; partition_key) const {</a>
<a name="ln1626">  if (metadata_-&gt;schema()-&gt;num_hash_key_columns() &gt; 0) {</a>
<a name="ln1627">    uint16_t next_hash_code = PartitionSchema::DecodeMultiColumnHashValue(partition_key);</a>
<a name="ln1628">    if (pgsql_read_request.has_max_hash_code() &amp;&amp;</a>
<a name="ln1629">        next_hash_code &gt; pgsql_read_request.max_hash_code()) {</a>
<a name="ln1630">      return true;</a>
<a name="ln1631">    }</a>
<a name="ln1632">  } else if (pgsql_read_request.has_max_partition_key() &amp;&amp;</a>
<a name="ln1633">             !pgsql_read_request.max_partition_key().empty()) {</a>
<a name="ln1634">    docdb::DocKey partition_doc_key(*metadata_-&gt;schema());</a>
<a name="ln1635">    VERIFY_RESULT(partition_doc_key.DecodeFrom(</a>
<a name="ln1636">        partition_key, docdb::DocKeyPart::kWholeDocKey, docdb::AllowSpecial::kTrue));</a>
<a name="ln1637">    docdb::DocKey max_partition_doc_key(*metadata_-&gt;schema());</a>
<a name="ln1638">    VERIFY_RESULT(max_partition_doc_key.DecodeFrom(</a>
<a name="ln1639">        pgsql_read_request.max_partition_key(), docdb::DocKeyPart::kWholeDocKey,</a>
<a name="ln1640">        docdb::AllowSpecial::kTrue));</a>
<a name="ln1641"> </a>
<a name="ln1642">    if (partition_doc_key.CompareTo(max_partition_doc_key) &gt;= 0) {</a>
<a name="ln1643">      return true;</a>
<a name="ln1644">    }</a>
<a name="ln1645">  }</a>
<a name="ln1646">  return false;</a>
<a name="ln1647">}</a>
<a name="ln1648"> </a>
<a name="ln1649">CHECKED_STATUS Tablet::CreatePagingStateForRead(const PgsqlReadRequestPB&amp; pgsql_read_request,</a>
<a name="ln1650">                                                const size_t row_count,</a>
<a name="ln1651">                                                PgsqlResponsePB* response) const {</a>
<a name="ln1652">  // If there is no hash column in the read request, this is a full-table query. And if there is no</a>
<a name="ln1653">  // paging state in the response, we are done reading from the current tablet. In this case, we</a>
<a name="ln1654">  // should return the exclusive end partition key of this tablet if not empty which is the start</a>
<a name="ln1655">  // key of the next tablet. Do so only if the request has no row count limit, or there is and we</a>
<a name="ln1656">  // haven't hit it, or we are asked to return paging state even when we have hit the limit.</a>
<a name="ln1657">  // Otherwise, leave the paging state empty which means we are completely done reading for the</a>
<a name="ln1658">  // whole SELECT statement.</a>
<a name="ln1659">  const bool single_tablet_query = VERIFY_RESULT(IsQueryOnlyForTablet(pgsql_read_request));</a>
<a name="ln1660">  if (!single_tablet_query &amp;&amp;</a>
<a name="ln1661">      !response-&gt;has_paging_state() &amp;&amp;</a>
<a name="ln1662">      (!pgsql_read_request.has_limit() || row_count &lt; pgsql_read_request.limit() ||</a>
<a name="ln1663">       pgsql_read_request.return_paging_state())) {</a>
<a name="ln1664">    // For backward scans partition_key_start must be used as next_partition_key.</a>
<a name="ln1665">    // Client level logic will check it and route next request to the preceding tablet.</a>
<a name="ln1666">    const auto&amp; next_partition_key =</a>
<a name="ln1667">        pgsql_read_request.has_hash_code() ||</a>
<a name="ln1668">        pgsql_read_request.is_forward_scan()</a>
<a name="ln1669">            ? metadata_-&gt;partition()-&gt;partition_key_end()</a>
<a name="ln1670">            : metadata_-&gt;partition()-&gt;partition_key_start();</a>
<a name="ln1671">    // Check we did not reach the last tablet.</a>
<a name="ln1672">    const bool end_scan = next_partition_key.empty() ||</a>
<a name="ln1673">        VERIFY_RESULT(HasScanReachedMaxPartitionKey(pgsql_read_request, next_partition_key));</a>
<a name="ln1674">    if (!end_scan) {</a>
<a name="ln1675">      response-&gt;mutable_paging_state()-&gt;set_next_partition_key(next_partition_key);</a>
<a name="ln1676">    }</a>
<a name="ln1677">  }</a>
<a name="ln1678"> </a>
<a name="ln1679">  // If there is a paging state, update the total number of rows read so far.</a>
<a name="ln1680">  if (response-&gt;has_paging_state()) {</a>
<a name="ln1681">    response-&gt;mutable_paging_state()-&gt;set_total_num_rows_read(</a>
<a name="ln1682">        pgsql_read_request.paging_state().total_num_rows_read() + row_count);</a>
<a name="ln1683">  }</a>
<a name="ln1684">  return Status::OK();</a>
<a name="ln1685">}</a>
<a name="ln1686"> </a>
<a name="ln1687">CHECKED_STATUS Tablet::PreparePgsqlWriteOperations(WriteOperation* operation) {</a>
<a name="ln1688">  docdb::DocOperations&amp; doc_ops = operation-&gt;doc_ops();</a>
<a name="ln1689">  WriteRequestPB batch_request;</a>
<a name="ln1690"> </a>
<a name="ln1691">  SetupKeyValueBatch(operation-&gt;request(), &amp;batch_request);</a>
<a name="ln1692">  auto* pgsql_write_batch = batch_request.mutable_pgsql_write_batch();</a>
<a name="ln1693"> </a>
<a name="ln1694">  doc_ops.reserve(pgsql_write_batch-&gt;size());</a>
<a name="ln1695"> </a>
<a name="ln1696">  Result&lt;TransactionOperationContextOpt&gt; txn_op_ctx(boost::none);</a>
<a name="ln1697"> </a>
<a name="ln1698">  for (size_t i = 0; i &lt; pgsql_write_batch-&gt;size(); i++) {</a>
<a name="ln1699">    PgsqlWriteRequestPB* req = pgsql_write_batch-&gt;Mutable(i);</a>
<a name="ln1700">    PgsqlResponsePB* resp = operation-&gt;response()-&gt;add_pgsql_response_batch();</a>
<a name="ln1701">    // Table-level tombstones should not be requested for non-colocated tables.</a>
<a name="ln1702">    if ((req-&gt;stmt_type() == PgsqlWriteRequestPB::PGSQL_TRUNCATE_COLOCATED) &amp;&amp;</a>
<a name="ln1703">        !metadata_-&gt;colocated()) {</a>
<a name="ln1704">      LOG(WARNING) &lt;&lt; &quot;cannot create table-level tombstone for a non-colocated table&quot;;</a>
<a name="ln1705">      resp-&gt;set_skipped(true);</a>
<a name="ln1706">      continue;</a>
<a name="ln1707">    }</a>
<a name="ln1708">    const std::shared_ptr&lt;tablet::TableInfo&gt; table_info =</a>
<a name="ln1709">        VERIFY_RESULT(metadata_-&gt;GetTableInfo(req-&gt;table_id()));</a>
<a name="ln1710">    if (table_info-&gt;schema_version != req-&gt;schema_version()) {</a>
<a name="ln1711">      resp-&gt;set_status(PgsqlResponsePB::PGSQL_STATUS_SCHEMA_VERSION_MISMATCH);</a>
<a name="ln1712">      resp-&gt;set_error_message(</a>
<a name="ln1713">          Format(&quot;schema version mismatch for table $0: expected $1, got $2&quot;,</a>
<a name="ln1714">                 table_info-&gt;table_id,</a>
<a name="ln1715">                 table_info-&gt;schema_version,</a>
<a name="ln1716">                 req-&gt;schema_version()));</a>
<a name="ln1717">    } else {</a>
<a name="ln1718">      if (doc_ops.empty()) {</a>
<a name="ln1719">        // Use the value of is_ysql_catalog_table from the first operation in the batch.</a>
<a name="ln1720">        txn_op_ctx = CreateTransactionOperationContext(</a>
<a name="ln1721">            operation-&gt;request()-&gt;write_batch().transaction(),</a>
<a name="ln1722">            table_info-&gt;schema.table_properties().is_ysql_catalog_table());</a>
<a name="ln1723">        RETURN_NOT_OK(txn_op_ctx);</a>
<a name="ln1724">      }</a>
<a name="ln1725">      auto write_op = std::make_unique&lt;PgsqlWriteOperation&gt;(table_info-&gt;schema, *txn_op_ctx);</a>
<a name="ln1726">      RETURN_NOT_OK(write_op-&gt;Init(req, resp));</a>
<a name="ln1727">      doc_ops.emplace_back(std::move(write_op));</a>
<a name="ln1728">    }</a>
<a name="ln1729">  }</a>
<a name="ln1730"> </a>
<a name="ln1731">  return Status::OK();</a>
<a name="ln1732">}</a>
<a name="ln1733"> </a>
<a name="ln1734">void Tablet::KeyValueBatchFromPgsqlWriteBatch(std::unique_ptr&lt;WriteOperation&gt; operation) {</a>
<a name="ln1735">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln1736">  if (!scoped_read_operation.ok()) {</a>
<a name="ln1737">    WriteOperation::StartSynchronization(std::move(operation), MoveStatus(scoped_read_operation));</a>
<a name="ln1738">    return;</a>
<a name="ln1739">  }</a>
<a name="ln1740"> </a>
<a name="ln1741">  auto status = PreparePgsqlWriteOperations(operation.get());</a>
<a name="ln1742">  if (!status.ok()) {</a>
<a name="ln1743">    WriteOperation::StartSynchronization(std::move(operation), status);</a>
<a name="ln1744">    return;</a>
<a name="ln1745">  }</a>
<a name="ln1746"> </a>
<a name="ln1747">  // All operations have wrong schema version.</a>
<a name="ln1748">  if (operation-&gt;doc_ops().empty()) {</a>
<a name="ln1749">    WriteOperation::StartSynchronization(std::move(operation), Status::OK());</a>
<a name="ln1750">    return;</a>
<a name="ln1751">  }</a>
<a name="ln1752"> </a>
<a name="ln1753">  StartDocWriteOperation(std::move(operation), std::move(scoped_read_operation),</a>
<a name="ln1754">                         [](auto operation, const Status&amp; status) {</a>
<a name="ln1755">    if (!status.ok() || operation-&gt;restart_read_ht().is_valid()) {</a>
<a name="ln1756">      WriteOperation::StartSynchronization(std::move(operation), status);</a>
<a name="ln1757">      return;</a>
<a name="ln1758">    }</a>
<a name="ln1759">    auto&amp; doc_ops = operation-&gt;doc_ops();</a>
<a name="ln1760"> </a>
<a name="ln1761">    for (size_t i = 0; i &lt; doc_ops.size(); i++) {</a>
<a name="ln1762">      PgsqlWriteOperation* pgsql_write_op = down_cast&lt;PgsqlWriteOperation*&gt;(doc_ops[i].get());</a>
<a name="ln1763">      // We'll need to return the number of rows inserted, updated, or deleted by each operation.</a>
<a name="ln1764">      doc_ops[i].release();</a>
<a name="ln1765">      operation-&gt;state()-&gt;pgsql_write_ops()</a>
<a name="ln1766">                        -&gt;emplace_back(unique_ptr&lt;PgsqlWriteOperation&gt;(pgsql_write_op));</a>
<a name="ln1767">    }</a>
<a name="ln1768"> </a>
<a name="ln1769">    WriteOperation::StartSynchronization(std::move(operation), Status::OK());</a>
<a name="ln1770">  });</a>
<a name="ln1771">}</a>
<a name="ln1772"> </a>
<a name="ln1773">//--------------------------------------------------------------------------------------------------</a>
<a name="ln1774"> </a>
<a name="ln1775">void Tablet::AcquireLocksAndPerformDocOperations(std::unique_ptr&lt;WriteOperation&gt; operation) {</a>
<a name="ln1776">  if (table_type_ == TableType::TRANSACTION_STATUS_TABLE_TYPE) {</a>
<a name="ln1777">    operation-&gt;state()-&gt;CompleteWithStatus(</a>
<a name="ln1778">        STATUS(NotSupported, &quot;Transaction status table does not support write&quot;));</a>
<a name="ln1779">    return;</a>
<a name="ln1780">  }</a>
<a name="ln1781"> </a>
<a name="ln1782">  const WriteRequestPB* key_value_write_request = operation-&gt;state()-&gt;request();</a>
<a name="ln1783">  if (!GetAtomicFlag(&amp;FLAGS_disable_alter_vs_write_mutual_exclusion)) {</a>
<a name="ln1784">    auto write_permit = GetPermitToWrite(operation-&gt;deadline());</a>
<a name="ln1785">    if (!write_permit.ok()) {</a>
<a name="ln1786">      TRACE(&quot;Could not get the write permit.&quot;);</a>
<a name="ln1787">      WriteOperation::StartSynchronization(std::move(operation), MoveStatus(write_permit));</a>
<a name="ln1788">      return;</a>
<a name="ln1789">    }</a>
<a name="ln1790">    // Save the write permit to be released after the operation is submitted</a>
<a name="ln1791">    // to Raft queue.</a>
<a name="ln1792">    operation-&gt;UseSubmitToken(std::move(write_permit));</a>
<a name="ln1793">  }</a>
<a name="ln1794"> </a>
<a name="ln1795">  if (!key_value_write_request-&gt;redis_write_batch().empty()) {</a>
<a name="ln1796">    KeyValueBatchFromRedisWriteBatch(std::move(operation));</a>
<a name="ln1797">    return;</a>
<a name="ln1798">  }</a>
<a name="ln1799"> </a>
<a name="ln1800">  if (!key_value_write_request-&gt;ql_write_batch().empty()) {</a>
<a name="ln1801">    KeyValueBatchFromQLWriteBatch(std::move(operation));</a>
<a name="ln1802">    return;</a>
<a name="ln1803">  }</a>
<a name="ln1804"> </a>
<a name="ln1805">  if (!key_value_write_request-&gt;pgsql_write_batch().empty()) {</a>
<a name="ln1806">    KeyValueBatchFromPgsqlWriteBatch(std::move(operation));</a>
<a name="ln1807">    return;</a>
<a name="ln1808">  }</a>
<a name="ln1809"> </a>
<a name="ln1810">  if (key_value_write_request-&gt;has_write_batch()) {</a>
<a name="ln1811">    if (!key_value_write_request-&gt;write_batch().read_pairs().empty()) {</a>
<a name="ln1812">      ScopedRWOperation scoped_operation(&amp;pending_op_counter_);</a>
<a name="ln1813">      if (!scoped_operation.ok()) {</a>
<a name="ln1814">        operation-&gt;state()-&gt;CompleteWithStatus(MoveStatus(scoped_operation));</a>
<a name="ln1815">        return;</a>
<a name="ln1816">      }</a>
<a name="ln1817"> </a>
<a name="ln1818">      StartDocWriteOperation(std::move(operation), std::move(scoped_operation),</a>
<a name="ln1819">                             [](auto operation, const Status&amp; status) {</a>
<a name="ln1820">        WriteOperation::StartSynchronization(std::move(operation), status);</a>
<a name="ln1821">      });</a>
<a name="ln1822">    } else {</a>
<a name="ln1823">      DCHECK(key_value_write_request-&gt;has_external_hybrid_time());</a>
<a name="ln1824">      WriteOperation::StartSynchronization(std::move(operation), Status::OK());</a>
<a name="ln1825">    }</a>
<a name="ln1826">    return;</a>
<a name="ln1827">  }</a>
<a name="ln1828"> </a>
<a name="ln1829">  // Empty write should not happen, but we could handle it.</a>
<a name="ln1830">  // Just report it as error in release mode.</a>
<a name="ln1831">  LOG(DFATAL) &lt;&lt; &quot;Empty write&quot;;</a>
<a name="ln1832"> </a>
<a name="ln1833">  operation-&gt;state()-&gt;CompleteWithStatus(Status::OK());</a>
<a name="ln1834">}</a>
<a name="ln1835"> </a>
<a name="ln1836">Status Tablet::Flush(FlushMode mode, FlushFlags flags, int64_t ignore_if_flushed_after_tick) {</a>
<a name="ln1837">  TRACE_EVENT0(&quot;tablet&quot;, &quot;Tablet::Flush&quot;);</a>
<a name="ln1838"> </a>
<a name="ln1839">  rocksdb::FlushOptions options;</a>
<a name="ln1840">  options.ignore_if_flushed_after_tick = ignore_if_flushed_after_tick;</a>
<a name="ln1841">  bool flush_intents = intents_db_ &amp;&amp; HasFlags(flags, FlushFlags::kIntents);</a>
<a name="ln1842">  if (flush_intents) {</a>
<a name="ln1843">    options.wait = false;</a>
<a name="ln1844">    WARN_NOT_OK(intents_db_-&gt;Flush(options), &quot;Flush intents DB&quot;);</a>
<a name="ln1845">  }</a>
<a name="ln1846"> </a>
<a name="ln1847">  if (HasFlags(flags, FlushFlags::kRegular) &amp;&amp; regular_db_) {</a>
<a name="ln1848">    options.wait = mode == FlushMode::kSync;</a>
<a name="ln1849">    WARN_NOT_OK(regular_db_-&gt;Flush(options), &quot;Flush regular DB&quot;);</a>
<a name="ln1850">  }</a>
<a name="ln1851"> </a>
<a name="ln1852">  if (flush_intents &amp;&amp; mode == FlushMode::kSync) {</a>
<a name="ln1853">    RETURN_NOT_OK(intents_db_-&gt;WaitForFlush());</a>
<a name="ln1854">  }</a>
<a name="ln1855"> </a>
<a name="ln1856">  return Status::OK();</a>
<a name="ln1857">}</a>
<a name="ln1858"> </a>
<a name="ln1859">Status Tablet::WaitForFlush() {</a>
<a name="ln1860">  TRACE_EVENT0(&quot;tablet&quot;, &quot;Tablet::WaitForFlush&quot;);</a>
<a name="ln1861"> </a>
<a name="ln1862">  if (regular_db_) {</a>
<a name="ln1863">    RETURN_NOT_OK(regular_db_-&gt;WaitForFlush());</a>
<a name="ln1864">  }</a>
<a name="ln1865">  if (intents_db_) {</a>
<a name="ln1866">    RETURN_NOT_OK(intents_db_-&gt;WaitForFlush());</a>
<a name="ln1867">  }</a>
<a name="ln1868"> </a>
<a name="ln1869">  return Status::OK();</a>
<a name="ln1870">}</a>
<a name="ln1871"> </a>
<a name="ln1872">Status Tablet::ImportData(const std::string&amp; source_dir) {</a>
<a name="ln1873">  // We import only regular records, so don't have to deal with intents here.</a>
<a name="ln1874">  return regular_db_-&gt;Import(source_dir);</a>
<a name="ln1875">}</a>
<a name="ln1876"> </a>
<a name="ln1877">template &lt;class Data&gt;</a>
<a name="ln1878">void InitFrontiers(const Data&amp; data, docdb::ConsensusFrontiers* frontiers) {</a>
<a name="ln1879">  set_op_id({data.op_id.term(), data.op_id.index()}, frontiers);</a>
<a name="ln1880">  set_hybrid_time(data.log_ht, frontiers);</a>
<a name="ln1881">}</a>
<a name="ln1882"> </a>
<a name="ln1883">// We apply intents by iterating over whole transaction reverse index.</a>
<a name="ln1884">// Using value of reverse index record we find original intent record and apply it.</a>
<a name="ln1885">// After that we delete both intent record and reverse index record.</a>
<a name="ln1886">Result&lt;docdb::ApplyTransactionState&gt; Tablet::ApplyIntents(const TransactionApplyData&amp; data) {</a>
<a name="ln1887">  rocksdb::WriteBatch regular_write_batch;</a>
<a name="ln1888">  auto new_apply_state = VERIFY_RESULT(docdb::PrepareApplyIntentsBatch(</a>
<a name="ln1889">      data.transaction_id, data.commit_ht, &amp;key_bounds_, data.apply_state,</a>
<a name="ln1890">      &amp;regular_write_batch, intents_db_.get(), nullptr /* intents_write_batch */));</a>
<a name="ln1891"> </a>
<a name="ln1892">  // data.hybrid_time contains transaction commit time.</a>
<a name="ln1893">  // We don't set transaction field of put_batch, otherwise we would write another bunch of intents.</a>
<a name="ln1894">  docdb::ConsensusFrontiers frontiers;</a>
<a name="ln1895">  docdb::ConsensusFrontiers* frontiers_ptr = nullptr;</a>
<a name="ln1896">  if (data.op_id.IsInitialized()) {</a>
<a name="ln1897">    InitFrontiers(data, &amp;frontiers);</a>
<a name="ln1898">    frontiers_ptr = &amp;frontiers;</a>
<a name="ln1899">  }</a>
<a name="ln1900">  WriteToRocksDB(frontiers_ptr, &amp;regular_write_batch, StorageDbType::kRegular);</a>
<a name="ln1901">  return new_apply_state;</a>
<a name="ln1902">}</a>
<a name="ln1903"> </a>
<a name="ln1904">template &lt;class Ids&gt;</a>
<a name="ln1905">CHECKED_STATUS Tablet::RemoveIntentsImpl(const RemoveIntentsData&amp; data, const Ids&amp; ids) {</a>
<a name="ln1906">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln1907">  RETURN_NOT_OK(scoped_read_operation);</a>
<a name="ln1908"> </a>
<a name="ln1909">  rocksdb::WriteBatch intents_write_batch;</a>
<a name="ln1910">  for (const auto&amp; id : ids) {</a>
<a name="ln1911">    boost::optional&lt;docdb::ApplyTransactionState&gt; apply_state;</a>
<a name="ln1912">    for (;;) {</a>
<a name="ln1913">      auto new_apply_state = VERIFY_RESULT(docdb::PrepareApplyIntentsBatch(</a>
<a name="ln1914">          id, HybridTime() /* commit_ht */, &amp;key_bounds_, apply_state.get_ptr(),</a>
<a name="ln1915">          nullptr /* regular_write_batch */, intents_db_.get(), &amp;intents_write_batch));</a>
<a name="ln1916">      if (new_apply_state.key.empty()) {</a>
<a name="ln1917">        break;</a>
<a name="ln1918">      }</a>
<a name="ln1919"> </a>
<a name="ln1920">      docdb::ConsensusFrontiers frontiers;</a>
<a name="ln1921">      InitFrontiers(data, &amp;frontiers);</a>
<a name="ln1922">      WriteToRocksDB(&amp;frontiers, &amp;intents_write_batch, StorageDbType::kIntents);</a>
<a name="ln1923"> </a>
<a name="ln1924">      apply_state = std::move(new_apply_state);</a>
<a name="ln1925">      intents_write_batch.Clear();</a>
<a name="ln1926"> </a>
<a name="ln1927">      AtomicFlagSleepMs(&amp;FLAGS_apply_intents_task_injected_delay_ms);</a>
<a name="ln1928">    }</a>
<a name="ln1929">  }</a>
<a name="ln1930"> </a>
<a name="ln1931">  docdb::ConsensusFrontiers frontiers;</a>
<a name="ln1932">  InitFrontiers(data, &amp;frontiers);</a>
<a name="ln1933">  WriteToRocksDB(&amp;frontiers, &amp;intents_write_batch, StorageDbType::kIntents);</a>
<a name="ln1934">  return Status::OK();</a>
<a name="ln1935">}</a>
<a name="ln1936"> </a>
<a name="ln1937"> </a>
<a name="ln1938">Status Tablet::RemoveIntents(const RemoveIntentsData&amp; data, const TransactionId&amp; id) {</a>
<a name="ln1939">  return RemoveIntentsImpl(data, std::initializer_list&lt;TransactionId&gt;{id});</a>
<a name="ln1940">}</a>
<a name="ln1941"> </a>
<a name="ln1942">Status Tablet::RemoveIntents(const RemoveIntentsData&amp; data, const TransactionIdSet&amp; transactions) {</a>
<a name="ln1943">  return RemoveIntentsImpl(data, transactions);</a>
<a name="ln1944">}</a>
<a name="ln1945"> </a>
<a name="ln1946">HybridTime Tablet::ApplierSafeTime(HybridTime min_allowed, CoarseTimePoint deadline) {</a>
<a name="ln1947">  // We could not use mvcc_ directly, because correct lease should be passed to it.</a>
<a name="ln1948">  return SafeTime(RequireLease::kFalse, min_allowed, deadline);</a>
<a name="ln1949">}</a>
<a name="ln1950"> </a>
<a name="ln1951">Status Tablet::CreatePreparedChangeMetadata(ChangeMetadataOperationState *operation_state,</a>
<a name="ln1952">                                            const Schema* schema) {</a>
<a name="ln1953">  if (schema) {</a>
<a name="ln1954">    auto key_schema = GetKeySchema(</a>
<a name="ln1955">        operation_state-&gt;has_table_id() ? operation_state-&gt;table_id() : &quot;&quot;);</a>
<a name="ln1956">    if (!key_schema.KeyEquals(*schema)) {</a>
<a name="ln1957">      return STATUS_FORMAT(</a>
<a name="ln1958">          InvalidArgument,</a>
<a name="ln1959">          &quot;Schema keys cannot be altered. New schema key: $0. Existing schema key: $1&quot;,</a>
<a name="ln1960">          schema-&gt;CreateKeyProjection(),</a>
<a name="ln1961">          key_schema);</a>
<a name="ln1962">    }</a>
<a name="ln1963"> </a>
<a name="ln1964">    if (!schema-&gt;has_column_ids()) {</a>
<a name="ln1965">      // this probably means that the request is not from the Master</a>
<a name="ln1966">      return STATUS(InvalidArgument, &quot;Missing Column IDs&quot;);</a>
<a name="ln1967">    }</a>
<a name="ln1968">  }</a>
<a name="ln1969"> </a>
<a name="ln1970">  operation_state-&gt;set_schema(schema);</a>
<a name="ln1971">  return Status::OK();</a>
<a name="ln1972">}</a>
<a name="ln1973"> </a>
<a name="ln1974">Status Tablet::AddTable(const TableInfoPB&amp; table_info) {</a>
<a name="ln1975">  Schema schema;</a>
<a name="ln1976">  RETURN_NOT_OK(SchemaFromPB(table_info.schema(), &amp;schema));</a>
<a name="ln1977"> </a>
<a name="ln1978">  PartitionSchema partition_schema;</a>
<a name="ln1979">  RETURN_NOT_OK(PartitionSchema::FromPB(table_info.partition_schema(), schema, &amp;partition_schema));</a>
<a name="ln1980"> </a>
<a name="ln1981">  metadata_-&gt;AddTable(</a>
<a name="ln1982">      table_info.table_id(), table_info.namespace_name(), table_info.table_name(),</a>
<a name="ln1983">      table_info.table_type(), schema, IndexMap(), partition_schema, boost::none,</a>
<a name="ln1984">      table_info.schema_version());</a>
<a name="ln1985"> </a>
<a name="ln1986">  RETURN_NOT_OK(metadata_-&gt;Flush());</a>
<a name="ln1987"> </a>
<a name="ln1988">  return Status::OK();</a>
<a name="ln1989">}</a>
<a name="ln1990"> </a>
<a name="ln1991">Status Tablet::RemoveTable(const std::string&amp; table_id) {</a>
<a name="ln1992">  metadata_-&gt;RemoveTable(table_id);</a>
<a name="ln1993">  RETURN_NOT_OK(metadata_-&gt;Flush());</a>
<a name="ln1994">  return Status::OK();</a>
<a name="ln1995">}</a>
<a name="ln1996"> </a>
<a name="ln1997">Status Tablet::MarkBackfillDone() {</a>
<a name="ln1998">  auto table_info = metadata_-&gt;primary_table_info();</a>
<a name="ln1999">  LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Setting backfill as done. Current schema  &quot;</a>
<a name="ln2000">                        &lt;&lt; table_info-&gt;schema.ToString();</a>
<a name="ln2001">  const vector&lt;DeletedColumn&gt; empty_deleted_cols;</a>
<a name="ln2002">  Schema new_schema = Schema(table_info-&gt;schema);</a>
<a name="ln2003">  new_schema.SetIsBackfilling(false);</a>
<a name="ln2004">  metadata_-&gt;SetSchema(</a>
<a name="ln2005">      new_schema, table_info-&gt;index_map, empty_deleted_cols, table_info-&gt;schema_version);</a>
<a name="ln2006">  return metadata_-&gt;Flush();</a>
<a name="ln2007">}</a>
<a name="ln2008"> </a>
<a name="ln2009">Status Tablet::AlterSchema(ChangeMetadataOperationState *operation_state) {</a>
<a name="ln2010">  auto current_table_info = VERIFY_RESULT(metadata_-&gt;GetTableInfo(</a>
<a name="ln2011">        operation_state-&gt;request()-&gt;has_alter_table_id() ?</a>
<a name="ln2012">        operation_state-&gt;request()-&gt;alter_table_id() : &quot;&quot;));</a>
<a name="ln2013">  auto key_schema = current_table_info-&gt;schema.CreateKeyProjection();</a>
<a name="ln2014"> </a>
<a name="ln2015">  DSCHECK(key_schema.KeyEquals(*DCHECK_NOTNULL(operation_state-&gt;schema())), IllegalState,</a>
<a name="ln2016">      &quot;Schema keys cannot be altered&quot;);</a>
<a name="ln2017"> </a>
<a name="ln2018">  auto op_pause = PauseReadWriteOperations();</a>
<a name="ln2019">  RETURN_NOT_OK(op_pause);</a>
<a name="ln2020"> </a>
<a name="ln2021">  // If the current version &gt;= new version, there is nothing to do.</a>
<a name="ln2022">  if (current_table_info-&gt;schema_version &gt;= operation_state-&gt;schema_version()) {</a>
<a name="ln2023">    LOG_WITH_PREFIX(INFO)</a>
<a name="ln2024">        &lt;&lt; &quot;Already running schema version &quot; &lt;&lt; current_table_info-&gt;schema_version</a>
<a name="ln2025">        &lt;&lt; &quot; got alter request for version &quot; &lt;&lt; operation_state-&gt;schema_version();</a>
<a name="ln2026">    return Status::OK();</a>
<a name="ln2027">  }</a>
<a name="ln2028"> </a>
<a name="ln2029">  LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Alter schema from &quot; &lt;&lt; current_table_info-&gt;schema.ToString()</a>
<a name="ln2030">                        &lt;&lt; &quot; version &quot; &lt;&lt; current_table_info-&gt;schema_version</a>
<a name="ln2031">                        &lt;&lt; &quot; to &quot; &lt;&lt; operation_state-&gt;schema()-&gt;ToString()</a>
<a name="ln2032">                        &lt;&lt; &quot; version &quot; &lt;&lt; operation_state-&gt;schema_version();</a>
<a name="ln2033"> </a>
<a name="ln2034">  // Find out which columns have been deleted in this schema change, and add them to metadata.</a>
<a name="ln2035">  vector&lt;DeletedColumn&gt; deleted_cols;</a>
<a name="ln2036">  for (const auto&amp; col : current_table_info-&gt;schema.column_ids()) {</a>
<a name="ln2037">    if (operation_state-&gt;schema()-&gt;find_column_by_id(col) == Schema::kColumnNotFound) {</a>
<a name="ln2038">      deleted_cols.emplace_back(col, clock_-&gt;Now());</a>
<a name="ln2039">      LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Column &quot; &lt;&lt; col &lt;&lt; &quot; recorded as deleted.&quot;;</a>
<a name="ln2040">    }</a>
<a name="ln2041">  }</a>
<a name="ln2042"> </a>
<a name="ln2043">  metadata_-&gt;SetSchema(*operation_state-&gt;schema(), operation_state-&gt;index_map(), deleted_cols,</a>
<a name="ln2044">                       operation_state-&gt;schema_version(), current_table_info-&gt;table_id);</a>
<a name="ln2045">  if (operation_state-&gt;has_new_table_name()) {</a>
<a name="ln2046">    metadata_-&gt;SetTableName(current_table_info-&gt;namespace_name, operation_state-&gt;new_table_name());</a>
<a name="ln2047">    if (metric_entity_) {</a>
<a name="ln2048">      metric_entity_-&gt;SetAttribute(&quot;table_name&quot;, operation_state-&gt;new_table_name());</a>
<a name="ln2049">      metric_entity_-&gt;SetAttribute(&quot;namespace_name&quot;, current_table_info-&gt;namespace_name);</a>
<a name="ln2050">    }</a>
<a name="ln2051">  }</a>
<a name="ln2052"> </a>
<a name="ln2053">  // Clear old index table metadata cache.</a>
<a name="ln2054">  ResetYBMetaDataCache();</a>
<a name="ln2055"> </a>
<a name="ln2056">  // Create transaction manager and index table metadata cache for secondary index update.</a>
<a name="ln2057">  if (!operation_state-&gt;index_map().empty()) {</a>
<a name="ln2058">    if (current_table_info-&gt;schema.table_properties().is_transactional() &amp;&amp; !transaction_manager_) {</a>
<a name="ln2059">      transaction_manager_.emplace(client_future_.get(),</a>
<a name="ln2060">                                   scoped_refptr&lt;server::Clock&gt;(clock_),</a>
<a name="ln2061">                                   local_tablet_filter_);</a>
<a name="ln2062">    }</a>
<a name="ln2063">    CreateNewYBMetaDataCache();</a>
<a name="ln2064">  }</a>
<a name="ln2065"> </a>
<a name="ln2066">  // Flush the updated schema metadata to disk.</a>
<a name="ln2067">  return metadata_-&gt;Flush();</a>
<a name="ln2068">}</a>
<a name="ln2069"> </a>
<a name="ln2070">Status Tablet::AlterWalRetentionSecs(ChangeMetadataOperationState* operation_state) {</a>
<a name="ln2071">  if (operation_state-&gt;has_wal_retention_secs()) {</a>
<a name="ln2072">    LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Altering metadata wal_retention_secs from &quot;</a>
<a name="ln2073">                          &lt;&lt; metadata_-&gt;wal_retention_secs()</a>
<a name="ln2074">                          &lt;&lt; &quot; to &quot; &lt;&lt; operation_state-&gt;wal_retention_secs();</a>
<a name="ln2075">    metadata_-&gt;set_wal_retention_secs(operation_state-&gt;wal_retention_secs());</a>
<a name="ln2076">    // Flush the updated schema metadata to disk.</a>
<a name="ln2077">    return metadata_-&gt;Flush();</a>
<a name="ln2078">  }</a>
<a name="ln2079">  return STATUS_SUBSTITUTE(InvalidArgument, &quot;Invalid ChangeMetadataOperationState: $0&quot;,</a>
<a name="ln2080">      operation_state-&gt;ToString());</a>
<a name="ln2081">}</a>
<a name="ln2082"> </a>
<a name="ln2083">// Assume that we are already in the Backfilling mode.</a>
<a name="ln2084">Result&lt;std::string&gt; Tablet::BackfillIndexesForYsql(</a>
<a name="ln2085">    const std::vector&lt;IndexInfo&gt;&amp; indexes,</a>
<a name="ln2086">    const std::string&amp; backfill_from,</a>
<a name="ln2087">    const CoarseTimePoint deadline,</a>
<a name="ln2088">    const HybridTime read_time,</a>
<a name="ln2089">    const HostPort&amp; pgsql_proxy_bind_address,</a>
<a name="ln2090">    const std::string&amp; database_name) {</a>
<a name="ln2091">  if (PREDICT_FALSE(FLAGS_TEST_slowdown_backfill_by_ms &gt; 0)) {</a>
<a name="ln2092">    TRACE(&quot;Sleeping for $0 ms&quot;, FLAGS_TEST_slowdown_backfill_by_ms);</a>
<a name="ln2093">    SleepFor(MonoDelta::FromMilliseconds(FLAGS_TEST_slowdown_backfill_by_ms));</a>
<a name="ln2094">  }</a>
<a name="ln2095">  LOG(INFO) &lt;&lt; &quot;Begin &quot; &lt;&lt; __func__</a>
<a name="ln2096">            &lt;&lt; &quot; at &quot; &lt;&lt; read_time</a>
<a name="ln2097">            &lt;&lt; &quot; for &quot; &lt;&lt; yb::ToString(indexes);</a>
<a name="ln2098"> </a>
<a name="ln2099">  if (!backfill_from.empty()) {</a>
<a name="ln2100">    return STATUS(</a>
<a name="ln2101">        InvalidArgument,</a>
<a name="ln2102">        &quot;YSQL index backfill does not support backfill_from, yet&quot;);</a>
<a name="ln2103">  }</a>
<a name="ln2104"> </a>
<a name="ln2105">  // Construct connection string.</a>
<a name="ln2106">  // TODO(jason): handle &quot;yugabyte&quot; role being password protected</a>
<a name="ln2107">  std::string conn_str = Format(</a>
<a name="ln2108">      &quot;dbname='$0' host=$1 port=$2 user=$3&quot;,</a>
<a name="ln2109">      EscapePgConnStrValue(database_name),</a>
<a name="ln2110">      pgsql_proxy_bind_address.host(),</a>
<a name="ln2111">      pgsql_proxy_bind_address.port(),</a>
<a name="ln2112">      &quot;yugabyte&quot;);</a>
<a name="ln2113">  VLOG(1) &lt;&lt; __func__ &lt;&lt; &quot;: libpq connection string: &quot; &lt;&lt; conn_str;</a>
<a name="ln2114"> </a>
<a name="ln2115">  // Construct query string.</a>
<a name="ln2116">  std::string index_oids;</a>
<a name="ln2117">  {</a>
<a name="ln2118">    std::stringstream ss;</a>
<a name="ln2119">    for (auto&amp; index : indexes) {</a>
<a name="ln2120">      Oid index_oid = VERIFY_RESULT(GetPgsqlTableOid(index.table_id()));</a>
<a name="ln2121">      ss &lt;&lt; index_oid &lt;&lt; &quot;,&quot;;</a>
<a name="ln2122">    }</a>
<a name="ln2123">    index_oids = ss.str();</a>
<a name="ln2124">    index_oids.pop_back();</a>
<a name="ln2125">  }</a>
<a name="ln2126">  std::string partition_key = metadata_-&gt;partition()-&gt;partition_key_start();</a>
<a name="ln2127">  // Ignoring the current situation where users can run BACKFILL INDEX queries themselves, this</a>
<a name="ln2128">  // should be safe from injection attacks because the parameters only consist of characters</a>
<a name="ln2129">  // [,0-9a-f].</a>
<a name="ln2130">  // TODO(jason): pass deadline</a>
<a name="ln2131">  std::string query_str = Format(</a>
<a name="ln2132">      &quot;BACKFILL INDEX $0 READ TIME $1 PARTITION x'$2';&quot;,</a>
<a name="ln2133">      index_oids,</a>
<a name="ln2134">      read_time.ToUint64(),</a>
<a name="ln2135">      b2a_hex(partition_key));</a>
<a name="ln2136">  VLOG(1) &lt;&lt; __func__ &lt;&lt; &quot;: libpq query string: &quot; &lt;&lt; query_str;</a>
<a name="ln2137"> </a>
<a name="ln2138">  // Connect and execute.</a>
<a name="ln2139">  auto conn = PQconnectdb(conn_str.c_str());</a>
<a name="ln2140">  auto res = PQexec(conn, query_str.c_str());</a>
<a name="ln2141">  auto status = PQresultStatus(res);</a>
<a name="ln2142">  PQclear(res);</a>
<a name="ln2143">  PQfinish(conn);</a>
<a name="ln2144"> </a>
<a name="ln2145">  // TODO(jason): more properly handle bad statuses</a>
<a name="ln2146">  if (status == PGRES_FATAL_ERROR) {</a>
<a name="ln2147">    return STATUS_FORMAT(</a>
<a name="ln2148">        QLError,</a>
<a name="ln2149">        &quot;Got PQ status $0 with message \&quot;$1\&quot; when running \&quot;$2\&quot;&quot;,</a>
<a name="ln2150">        status,</a>
<a name="ln2151">        PQresultErrorMessage(res),</a>
<a name="ln2152">        query_str);</a>
<a name="ln2153">  }</a>
<a name="ln2154">  // TODO(jason): handle partially finished backfills.  How am I going to get that info?  From</a>
<a name="ln2155">  // response message by libpq or manual DocDB inspection?</a>
<a name="ln2156">  return &quot;&quot;;</a>
<a name="ln2157">}</a>
<a name="ln2158"> </a>
<a name="ln2159">// Should backfill the index with the information contained in this tablet.</a>
<a name="ln2160">// Assume that we are already in the Backfilling mode.</a>
<a name="ln2161">Result&lt;std::string&gt; Tablet::BackfillIndexes(const std::vector&lt;IndexInfo&gt; &amp;indexes,</a>
<a name="ln2162">                                            const std::string&amp; backfill_from,</a>
<a name="ln2163">                                            const CoarseTimePoint deadline,</a>
<a name="ln2164">                                            const HybridTime read_time) {</a>
<a name="ln2165">  if (PREDICT_FALSE(FLAGS_TEST_slowdown_backfill_by_ms &gt; 0)) {</a>
<a name="ln2166">    TRACE(&quot;Sleeping for $0 ms&quot;, FLAGS_TEST_slowdown_backfill_by_ms);</a>
<a name="ln2167">    SleepFor(MonoDelta::FromMilliseconds(FLAGS_TEST_slowdown_backfill_by_ms));</a>
<a name="ln2168">  }</a>
<a name="ln2169">  LOG(INFO) &lt;&lt; &quot;Begin BackfillIndexes at &quot; &lt;&lt; read_time &lt;&lt; &quot; for &quot;</a>
<a name="ln2170">            &lt;&lt; yb::ToString(indexes);</a>
<a name="ln2171"> </a>
<a name="ln2172">  // For the specific index that we are interested in, set up a scan job to scan all the</a>
<a name="ln2173">  // rows in this tablet and update the index accordingly.</a>
<a name="ln2174">  std::unordered_set&lt;yb::ColumnId&gt; col_ids_set;</a>
<a name="ln2175">  std::vector&lt;yb::ColumnSchema&gt; columns;</a>
<a name="ln2176"> </a>
<a name="ln2177">  for (auto idx : schema()-&gt;column_ids()) {</a>
<a name="ln2178">    if (schema()-&gt;is_key_column(idx)) {</a>
<a name="ln2179">      col_ids_set.insert(idx);</a>
<a name="ln2180">      auto res = schema()-&gt;column_by_id(idx);</a>
<a name="ln2181">      if (res) {</a>
<a name="ln2182">        columns.push_back(*res);</a>
<a name="ln2183">      } else {</a>
<a name="ln2184">        LOG(DFATAL) &lt;&lt; &quot;Unexpected : Cannot find the column in the main table for &quot;</a>
<a name="ln2185">            &lt;&lt; idx;</a>
<a name="ln2186">      }</a>
<a name="ln2187">    }</a>
<a name="ln2188">  }</a>
<a name="ln2189">  std::vector&lt;std::string&gt; index_ids;</a>
<a name="ln2190">  for (const IndexInfo&amp; idx : indexes) {</a>
<a name="ln2191">    index_ids.push_back(idx.table_id());</a>
<a name="ln2192">    for (const auto&amp; idx_col : idx.columns()) {</a>
<a name="ln2193">      if (col_ids_set.find(idx_col.indexed_column_id) == col_ids_set.end()) {</a>
<a name="ln2194">        col_ids_set.insert(idx_col.indexed_column_id);</a>
<a name="ln2195">        auto res = schema()-&gt;column_by_id(idx_col.indexed_column_id);</a>
<a name="ln2196">        if (res) {</a>
<a name="ln2197">          columns.push_back(*res);</a>
<a name="ln2198">        } else {</a>
<a name="ln2199">          LOG(DFATAL) &lt;&lt; &quot;Unexpected : Cannot find the column in the main table for &quot;</a>
<a name="ln2200">              &lt;&lt; idx_col.indexed_column_id;</a>
<a name="ln2201">        }</a>
<a name="ln2202">      }</a>
<a name="ln2203">    }</a>
<a name="ln2204">  }</a>
<a name="ln2205">  Schema projection(columns, {}, schema()-&gt;num_key_columns());</a>
<a name="ln2206">  auto iter =</a>
<a name="ln2207">      VERIFY_RESULT(NewRowIterator(projection, boost::none, ReadHybridTime::SingleTime(read_time)));</a>
<a name="ln2208"> </a>
<a name="ln2209">  if (!backfill_from.empty()) {</a>
<a name="ln2210">    VLOG(1) &lt;&lt; &quot;Resuming backfill from  &quot; &lt;&lt; b2a_hex(backfill_from);</a>
<a name="ln2211">    RETURN_NOT_OK(iter-&gt;SeekTuple(Slice(backfill_from)));</a>
<a name="ln2212">  }</a>
<a name="ln2213"> </a>
<a name="ln2214">  QLTableRow row;</a>
<a name="ln2215">  std::vector&lt;std::pair&lt;const IndexInfo*, QLWriteRequestPB&gt;&gt; index_requests;</a>
<a name="ln2216">  const yb::CoarseDuration kMargin = FLAGS_backfill_index_timeout_grace_margin_ms * 1ms;</a>
<a name="ln2217">  constexpr auto kProgressInterval = 1000;</a>
<a name="ln2218">  int num_rows_processed = 0;</a>
<a name="ln2219">  string resume_from;</a>
<a name="ln2220">  CoarseTimePoint last_flushed_at;</a>
<a name="ln2221">  while (VERIFY_RESULT(iter-&gt;HasNext())) {</a>
<a name="ln2222">    RETURN_NOT_OK(iter-&gt;NextRow(&amp;row));</a>
<a name="ln2223"> </a>
<a name="ln2224">    if (CoarseMonoClock::Now() + kMargin &gt; deadline ||</a>
<a name="ln2225">        (FLAGS_TEST_backfill_paging_size &gt; 0 &amp;&amp;</a>
<a name="ln2226">         num_rows_processed == FLAGS_TEST_backfill_paging_size)) {</a>
<a name="ln2227">      resume_from = VERIFY_RESULT(iter-&gt;GetTupleId()).ToBuffer();</a>
<a name="ln2228">      break;</a>
<a name="ln2229">    }</a>
<a name="ln2230"> </a>
<a name="ln2231">    DVLOG(2) &lt;&lt; &quot;Building index for fetched row: &quot; &lt;&lt; row.ToString();</a>
<a name="ln2232">    RETURN_NOT_OK(UpdateIndexInBatches(row, indexes, &amp;index_requests, &amp;last_flushed_at));</a>
<a name="ln2233">    if (++num_rows_processed % kProgressInterval == 0) {</a>
<a name="ln2234">      VLOG(1) &lt;&lt; &quot;Processed &quot; &lt;&lt; num_rows_processed &lt;&lt; &quot; rows&quot;;</a>
<a name="ln2235">    }</a>
<a name="ln2236">  }</a>
<a name="ln2237"> </a>
<a name="ln2238">  VLOG(1) &lt;&lt; &quot;Processed &quot; &lt;&lt; num_rows_processed &lt;&lt; &quot; rows&quot;;</a>
<a name="ln2239">  RETURN_NOT_OK(FlushIndexBatchIfRequired(&amp;index_requests, /* forced */ true, &amp;last_flushed_at));</a>
<a name="ln2240">  LOG(INFO) &lt;&lt; &quot;Done BackfillIndexes at &quot; &lt;&lt; read_time &lt;&lt; &quot; for &quot;</a>
<a name="ln2241">            &lt;&lt; yb::ToString(index_ids) &lt;&lt; &quot; until &quot;</a>
<a name="ln2242">            &lt;&lt; (resume_from.empty() ? &quot;&lt;end of the tablet&gt;&quot;</a>
<a name="ln2243">                                    : b2a_hex(resume_from));</a>
<a name="ln2244">  return resume_from;</a>
<a name="ln2245">}</a>
<a name="ln2246"> </a>
<a name="ln2247">Status Tablet::UpdateIndexInBatches(</a>
<a name="ln2248">    const QLTableRow&amp; row, const std::vector&lt;IndexInfo&gt;&amp; indexes,</a>
<a name="ln2249">    std::vector&lt;std::pair&lt;const IndexInfo*, QLWriteRequestPB&gt;&gt;* index_requests,</a>
<a name="ln2250">    CoarseTimePoint* last_flushed_at) {</a>
<a name="ln2251">  const QLTableRow&amp; kEmptyRow = QLTableRow::empty_row();</a>
<a name="ln2252">  QLExprExecutor expr_executor;</a>
<a name="ln2253"> </a>
<a name="ln2254">  for (const IndexInfo&amp; index : indexes) {</a>
<a name="ln2255">    bool ignored_key_changed;</a>
<a name="ln2256">    index_requests-&gt;emplace_back(&amp;index, QLWriteRequestPB());</a>
<a name="ln2257">    QLWriteRequestPB* index_request = &amp;index_requests-&gt;back().second;</a>
<a name="ln2258">    index_request-&gt;set_type(QLWriteRequestPB::QL_STMT_INSERT);</a>
<a name="ln2259">    RETURN_NOT_OK(docdb::PrepareIndexWriteAndCheckIfIndexKeyChanged(</a>
<a name="ln2260">        &amp;expr_executor, kEmptyRow, row, &amp;index, index_request, &amp;ignored_key_changed));</a>
<a name="ln2261">    index_request-&gt;set_is_backfilling(true);</a>
<a name="ln2262">  }</a>
<a name="ln2263"> </a>
<a name="ln2264">  // Update the index write op.</a>
<a name="ln2265">  return FlushIndexBatchIfRequired(index_requests, false, last_flushed_at);</a>
<a name="ln2266">}</a>
<a name="ln2267"> </a>
<a name="ln2268">Status Tablet::FlushIndexBatchIfRequired(</a>
<a name="ln2269">    std::vector&lt;std::pair&lt;const IndexInfo*, QLWriteRequestPB&gt;&gt;* index_requests, bool force_flush,</a>
<a name="ln2270">    CoarseTimePoint* last_flushed_at) {</a>
<a name="ln2271">  if (!force_flush &amp;&amp; index_requests-&gt;size() &lt; FLAGS_backfill_index_write_batch_size) {</a>
<a name="ln2272">    return Status::OK();</a>
<a name="ln2273">  }</a>
<a name="ln2274"> </a>
<a name="ln2275">  if (!client_future_.valid()) {</a>
<a name="ln2276">    return STATUS_FORMAT(IllegalState, &quot;Client future is not set up for $0&quot;, tablet_id());</a>
<a name="ln2277">  } else if (!YBMetaDataCache()) {</a>
<a name="ln2278">    return STATUS(IllegalState, &quot;Table metadata cache is not present for index update&quot;);</a>
<a name="ln2279">  }</a>
<a name="ln2280"> </a>
<a name="ln2281">  auto client = client_future_.get();</a>
<a name="ln2282">  auto session = std::make_shared&lt;YBSession&gt;(client);</a>
<a name="ln2283">  const HybridTime kBackfillAt(50);</a>
<a name="ln2284">  session-&gt;SetHybridTimeForWrite(kBackfillAt);</a>
<a name="ln2285"> </a>
<a name="ln2286">  std::unordered_set&lt;</a>
<a name="ln2287">      client::YBqlWriteOpPtr, client::YBqlWriteOp::PrimaryKeyComparator,</a>
<a name="ln2288">      client::YBqlWriteOp::PrimaryKeyComparator&gt;</a>
<a name="ln2289">      ops_by_primary_key;</a>
<a name="ln2290">  std::vector&lt;shared_ptr&lt;client::YBqlWriteOp&gt;&gt; write_ops;</a>
<a name="ln2291">  for (auto&amp; pair : *index_requests) {</a>
<a name="ln2292">    // TODO create async version of GetTable.</a>
<a name="ln2293">    // It is ok to have sync call here, because we use cache and it should not take too long.</a>
<a name="ln2294">    client::YBTablePtr index_table;</a>
<a name="ln2295">    bool cache_used_ignored = false;</a>
<a name="ln2296">    auto metadata_cache = YBMetaDataCache();</a>
<a name="ln2297">    RETURN_NOT_OK(</a>
<a name="ln2298">        metadata_cache-&gt;GetTable(pair.first-&gt;table_id(), &amp;index_table, &amp;cache_used_ignored));</a>
<a name="ln2299"> </a>
<a name="ln2300">    shared_ptr&lt;client::YBqlWriteOp&gt; index_op(index_table-&gt;NewQLWrite());</a>
<a name="ln2301">    index_op-&gt;mutable_request()-&gt;Swap(&amp;pair.second);</a>
<a name="ln2302">    if (index_table-&gt;IsUniqueIndex()) {</a>
<a name="ln2303">      if (ops_by_primary_key.count(index_op) &gt; 0) {</a>
<a name="ln2304">        VLOG(2) &lt;&lt; &quot;Splitting the batch of writes because &quot; &lt;&lt; index_op-&gt;ToString()</a>
<a name="ln2305">                &lt;&lt; &quot; collides with an existing update in this batch.&quot;;</a>
<a name="ln2306">        VLOG(1) &lt;&lt; &quot;Flushing &quot; &lt;&lt; ops_by_primary_key.size() &lt;&lt; &quot; ops to the index&quot;;</a>
<a name="ln2307">        RETURN_NOT_OK_PREPEND(session-&gt;Flush(), &quot;Flush failed.&quot;);</a>
<a name="ln2308">        VLOG(3) &lt;&lt; &quot;Done flushing ops to the index&quot;;</a>
<a name="ln2309">        ops_by_primary_key.clear();</a>
<a name="ln2310">      }</a>
<a name="ln2311">      ops_by_primary_key.insert(index_op);</a>
<a name="ln2312">    }</a>
<a name="ln2313">    RETURN_NOT_OK_PREPEND(session-&gt;Apply(index_op), &quot;Could not Apply.&quot;);</a>
<a name="ln2314">    write_ops.push_back(index_op);</a>
<a name="ln2315">  }</a>
<a name="ln2316"> </a>
<a name="ln2317">  VLOG(1) &lt;&lt; Format(&quot;Flushing $0 ops to the index&quot;,</a>
<a name="ln2318">                    (!ops_by_primary_key.empty() ? ops_by_primary_key.size()</a>
<a name="ln2319">                                                 : write_ops.size()));</a>
<a name="ln2320">  constexpr int kMaxNumRetries = 10;</a>
<a name="ln2321">  RETURN_NOT_OK(FlushWithRetries(session, write_ops, kMaxNumRetries));</a>
<a name="ln2322"> </a>
<a name="ln2323">  auto now = CoarseMonoClock::Now();</a>
<a name="ln2324">  if (FLAGS_backfill_index_rate_rows_per_sec &gt; 0) {</a>
<a name="ln2325">    auto duration_since_last_batch = MonoDelta(now - *last_flushed_at);</a>
<a name="ln2326">    auto expected_duration_ms = MonoDelta::FromMilliseconds(</a>
<a name="ln2327">        index_requests-&gt;size() * 1000 / FLAGS_backfill_index_rate_rows_per_sec);</a>
<a name="ln2328">    DVLOG(3) &lt;&lt; &quot;Duration since last batch &quot; &lt;&lt; duration_since_last_batch</a>
<a name="ln2329">             &lt;&lt; &quot; expected duration &quot; &lt;&lt; expected_duration_ms</a>
<a name="ln2330">             &lt;&lt; &quot; extra time so sleep: &quot; &lt;&lt; expected_duration_ms - duration_since_last_batch;</a>
<a name="ln2331">    if (duration_since_last_batch &lt; expected_duration_ms) {</a>
<a name="ln2332">      SleepFor(expected_duration_ms - duration_since_last_batch);</a>
<a name="ln2333">    }</a>
<a name="ln2334">  }</a>
<a name="ln2335">  *last_flushed_at = now;</a>
<a name="ln2336"> </a>
<a name="ln2337">  index_requests-&gt;clear();</a>
<a name="ln2338">  return Status::OK();</a>
<a name="ln2339">}</a>
<a name="ln2340"> </a>
<a name="ln2341">Status Tablet::FlushWithRetries(</a>
<a name="ln2342">    shared_ptr&lt;YBSession&gt; session,</a>
<a name="ln2343">    const std::vector&lt;shared_ptr&lt;client::YBqlWriteOp&gt;&gt; &amp;write_ops,</a>
<a name="ln2344">    int num_retries) {</a>
<a name="ln2345">  auto retries_left = num_retries;</a>
<a name="ln2346">  std::vector&lt;shared_ptr&lt;client::YBqlWriteOp&gt;&gt; failed_ops;</a>
<a name="ln2347">  std::vector&lt;shared_ptr&lt;client::YBqlWriteOp&gt;&gt; pending_ops = write_ops;</a>
<a name="ln2348">  do {</a>
<a name="ln2349">    RETURN_NOT_OK_PREPEND(session-&gt;Flush(), &quot;Flush failed.&quot;);</a>
<a name="ln2350">    VLOG(3) &lt;&lt; &quot;Done flushing ops to the index&quot;;</a>
<a name="ln2351">    failed_ops.clear();</a>
<a name="ln2352">    for (auto write_op : pending_ops) {</a>
<a name="ln2353">      if (write_op-&gt;response().status() == QLResponsePB::YQL_STATUS_OK) {</a>
<a name="ln2354">        continue;</a>
<a name="ln2355">      }</a>
<a name="ln2356"> </a>
<a name="ln2357">      VLOG(2) &lt;&lt; &quot;Got response &quot; &lt;&lt; yb::ToString(write_op-&gt;response())</a>
<a name="ln2358">              &lt;&lt; &quot; for &quot; &lt;&lt; yb::ToString(write_op-&gt;request());</a>
<a name="ln2359">      if (write_op-&gt;response().status() !=</a>
<a name="ln2360">          QLResponsePB::YQL_STATUS_RESTART_REQUIRED_ERROR) {</a>
<a name="ln2361">        return STATUS_SUBSTITUTE(</a>
<a name="ln2362">            IllegalState, &quot;Backfilling op failed: request : $0 response : $1&quot;,</a>
<a name="ln2363">            yb::ToString(write_op-&gt;request()),</a>
<a name="ln2364">            yb::ToString(write_op-&gt;response()));</a>
<a name="ln2365">      }</a>
<a name="ln2366"> </a>
<a name="ln2367">      failed_ops.push_back(write_op);</a>
<a name="ln2368">      RETURN_NOT_OK_PREPEND(session-&gt;Apply(write_op), &quot;Could not Apply.&quot;);</a>
<a name="ln2369">    }</a>
<a name="ln2370"> </a>
<a name="ln2371">    if (failed_ops.empty()) {</a>
<a name="ln2372">      return Status::OK();</a>
<a name="ln2373">    }</a>
<a name="ln2374">    VLOG(1) &lt;&lt; Format(&quot;Flushing $0 failed ops again to the index&quot;,</a>
<a name="ln2375">                      failed_ops.size());</a>
<a name="ln2376">    pending_ops = failed_ops;</a>
<a name="ln2377">  } while (--retries_left &gt; 0);</a>
<a name="ln2378"> </a>
<a name="ln2379">  // TODO(Amit) Add failure details of form:</a>
<a name="ln2380">  // yb::ToString(write_op-&gt;request()), yb::ToString(write_op-&gt;response()));</a>
<a name="ln2381">  return STATUS_SUBSTITUTE(</a>
<a name="ln2382">      IllegalState, &quot;Backfilling op failed for $0 requests after $1 retries.&quot;,</a>
<a name="ln2383">      failed_ops.size(), num_retries);</a>
<a name="ln2384">}</a>
<a name="ln2385"> </a>
<a name="ln2386">ScopedRWOperationPause Tablet::PauseReadWriteOperations(Stop stop) {</a>
<a name="ln2387">  LOG_SLOW_EXECUTION(WARNING, 1000,</a>
<a name="ln2388">                     Substitute(&quot;Tablet $0: Waiting for pending ops to complete&quot;, tablet_id())) {</a>
<a name="ln2389">    return ScopedRWOperationPause(</a>
<a name="ln2390">        &amp;pending_op_counter_,</a>
<a name="ln2391">        CoarseMonoClock::Now() +</a>
<a name="ln2392">            MonoDelta::FromMilliseconds(FLAGS_tablet_rocksdb_ops_quiet_down_timeout_ms),</a>
<a name="ln2393">        stop);</a>
<a name="ln2394">  }</a>
<a name="ln2395">  FATAL_ERROR(&quot;Unreachable code -- the previous block must always return&quot;);</a>
<a name="ln2396">}</a>
<a name="ln2397"> </a>
<a name="ln2398">Status Tablet::ModifyFlushedFrontier(</a>
<a name="ln2399">    const docdb::ConsensusFrontier&amp; frontier,</a>
<a name="ln2400">    rocksdb::FrontierModificationMode mode) {</a>
<a name="ln2401">  const Status s = regular_db_-&gt;ModifyFlushedFrontier(frontier.Clone(), mode);</a>
<a name="ln2402">  if (PREDICT_FALSE(!s.ok())) {</a>
<a name="ln2403">    auto status = STATUS(IllegalState, &quot;Failed to set flushed frontier&quot;, s.ToString());</a>
<a name="ln2404">    LOG_WITH_PREFIX(WARNING) &lt;&lt; status;</a>
<a name="ln2405">    return status;</a>
<a name="ln2406">  }</a>
<a name="ln2407">  {</a>
<a name="ln2408">    auto flushed_frontier = regular_db_-&gt;GetFlushedFrontier();</a>
<a name="ln2409">    const auto&amp; consensus_flushed_frontier = *down_cast&lt;docdb::ConsensusFrontier*&gt;(</a>
<a name="ln2410">        flushed_frontier.get());</a>
<a name="ln2411">    DCHECK_EQ(frontier.op_id(), consensus_flushed_frontier.op_id());</a>
<a name="ln2412">    DCHECK_EQ(frontier.hybrid_time(), consensus_flushed_frontier.hybrid_time());</a>
<a name="ln2413">  }</a>
<a name="ln2414"> </a>
<a name="ln2415">  if (FLAGS_TEST_tablet_verify_flushed_frontier_after_modifying &amp;&amp;</a>
<a name="ln2416">      mode == rocksdb::FrontierModificationMode::kForce) {</a>
<a name="ln2417">    LOG(INFO) &lt;&lt; &quot;Verifying that flushed frontier was force-set successfully&quot;;</a>
<a name="ln2418">    string test_data_dir = VERIFY_RESULT(Env::Default()-&gt;GetTestDirectory());</a>
<a name="ln2419">    const string checkpoint_dir_for_test = Format(</a>
<a name="ln2420">        &quot;$0/test_checkpoint_$1_$2&quot;, test_data_dir, tablet_id(), MonoTime::Now().ToUint64());</a>
<a name="ln2421">    RETURN_NOT_OK(</a>
<a name="ln2422">        rocksdb::checkpoint::CreateCheckpoint(regular_db_.get(), checkpoint_dir_for_test));</a>
<a name="ln2423">    auto se = ScopeExit([checkpoint_dir_for_test] {</a>
<a name="ln2424">      CHECK_OK(Env::Default()-&gt;DeleteRecursively(checkpoint_dir_for_test));</a>
<a name="ln2425">    });</a>
<a name="ln2426">    rocksdb::Options rocksdb_options;</a>
<a name="ln2427">    docdb::InitRocksDBOptions(</a>
<a name="ln2428">        &amp;rocksdb_options, LogPrefix(), /* statistics */ nullptr, tablet_options_);</a>
<a name="ln2429">    rocksdb_options.create_if_missing = false;</a>
<a name="ln2430">    LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Opening the test RocksDB at &quot; &lt;&lt; checkpoint_dir_for_test</a>
<a name="ln2431">        &lt;&lt; &quot;, expecting to see flushed frontier of &quot; &lt;&lt; frontier.ToString();</a>
<a name="ln2432">    std::unique_ptr&lt;rocksdb::DB&gt; test_db = VERIFY_RESULT(</a>
<a name="ln2433">        rocksdb::DB::Open(rocksdb_options, checkpoint_dir_for_test));</a>
<a name="ln2434">    LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Getting flushed frontier from test RocksDB at &quot;</a>
<a name="ln2435">                          &lt;&lt; checkpoint_dir_for_test;</a>
<a name="ln2436">    auto restored_flushed_frontier = test_db-&gt;GetFlushedFrontier();</a>
<a name="ln2437">    if (!restored_flushed_frontier) {</a>
<a name="ln2438">      LOG_WITH_PREFIX(FATAL) &lt;&lt; LogPrefix() &lt;&lt; &quot;Restored flushed frontier not present&quot;;</a>
<a name="ln2439">    }</a>
<a name="ln2440">    CHECK_EQ(</a>
<a name="ln2441">        frontier,</a>
<a name="ln2442">        down_cast&lt;docdb::ConsensusFrontier&amp;&gt;(*restored_flushed_frontier));</a>
<a name="ln2443">    LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Successfully verified persistently stored flushed frontier: &quot;</a>
<a name="ln2444">        &lt;&lt; frontier.ToString();</a>
<a name="ln2445">  }</a>
<a name="ln2446"> </a>
<a name="ln2447">  if (intents_db_) {</a>
<a name="ln2448">    // It is OK to flush intents even if the regular DB is not yet flushed,</a>
<a name="ln2449">    // because it would wait for flush of regular DB if we have unflushed intents.</a>
<a name="ln2450">    // Otherwise it does not matter which flushed op id is stored.</a>
<a name="ln2451">    RETURN_NOT_OK(intents_db_-&gt;ModifyFlushedFrontier(frontier.Clone(), mode));</a>
<a name="ln2452">  }</a>
<a name="ln2453"> </a>
<a name="ln2454">  return Flush(FlushMode::kAsync);</a>
<a name="ln2455">}</a>
<a name="ln2456"> </a>
<a name="ln2457">Status Tablet::Truncate(TruncateOperationState *state) {</a>
<a name="ln2458">  if (metadata_-&gt;table_type() == TableType::TRANSACTION_STATUS_TABLE_TYPE) {</a>
<a name="ln2459">    // We use only Raft log for transaction status table.</a>
<a name="ln2460">    return Status::OK();</a>
<a name="ln2461">  }</a>
<a name="ln2462"> </a>
<a name="ln2463">  auto op_pause = PauseReadWriteOperations();</a>
<a name="ln2464">  RETURN_NOT_OK(op_pause);</a>
<a name="ln2465"> </a>
<a name="ln2466">  // Check if tablet is in shutdown mode.</a>
<a name="ln2467">  if (IsShutdownRequested()) {</a>
<a name="ln2468">    return STATUS(IllegalState, &quot;Tablet was shut down&quot;);</a>
<a name="ln2469">  }</a>
<a name="ln2470"> </a>
<a name="ln2471">  const rocksdb::SequenceNumber sequence_number = regular_db_-&gt;GetLatestSequenceNumber();</a>
<a name="ln2472">  const string db_dir = regular_db_-&gt;GetName();</a>
<a name="ln2473"> </a>
<a name="ln2474">  auto s = ResetRocksDBs(Destroy::kTrue, DisableFlushOnShutdown::kTrue);</a>
<a name="ln2475">  if (PREDICT_FALSE(!s.ok())) {</a>
<a name="ln2476">    LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Failed to clean up db dir &quot; &lt;&lt; db_dir &lt;&lt; &quot;: &quot; &lt;&lt; s;</a>
<a name="ln2477">    return STATUS(IllegalState, &quot;Failed to clean up db dir&quot;, s.ToString());</a>
<a name="ln2478">  }</a>
<a name="ln2479"> </a>
<a name="ln2480">  // Create a new database.</a>
<a name="ln2481">  // Note: db_dir == metadata()-&gt;rocksdb_dir() is still valid db dir.</a>
<a name="ln2482">  s = OpenKeyValueTablet();</a>
<a name="ln2483">  if (PREDICT_FALSE(!s.ok())) {</a>
<a name="ln2484">    LOG_WITH_PREFIX(WARNING) &lt;&lt; &quot;Failed to create a new db: &quot; &lt;&lt; s;</a>
<a name="ln2485">    return s;</a>
<a name="ln2486">  }</a>
<a name="ln2487"> </a>
<a name="ln2488">  docdb::ConsensusFrontier frontier;</a>
<a name="ln2489">  frontier.set_op_id({state-&gt;op_id().term(), state-&gt;op_id().index()});</a>
<a name="ln2490">  frontier.set_hybrid_time(state-&gt;hybrid_time());</a>
<a name="ln2491">  // We use the kUpdate mode here, because unlike the case of restoring a snapshot to a completely</a>
<a name="ln2492">  // different tablet in an arbitrary Raft group, here there is no possibility of the flushed</a>
<a name="ln2493">  // frontier needing to go backwards.</a>
<a name="ln2494">  RETURN_NOT_OK(ModifyFlushedFrontier(frontier, rocksdb::FrontierModificationMode::kUpdate));</a>
<a name="ln2495"> </a>
<a name="ln2496">  LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Created new db for truncated tablet&quot;;</a>
<a name="ln2497">  LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Sequence numbers: old=&quot; &lt;&lt; sequence_number</a>
<a name="ln2498">                        &lt;&lt; &quot;, new=&quot; &lt;&lt; regular_db_-&gt;GetLatestSequenceNumber();</a>
<a name="ln2499">  DCHECK(op_pause.status().ok());  // Ensure that op_pause stays in scope throughout this function.</a>
<a name="ln2500">  return DoEnableCompactions();</a>
<a name="ln2501">}</a>
<a name="ln2502"> </a>
<a name="ln2503">void Tablet::UpdateMonotonicCounter(int64_t value) {</a>
<a name="ln2504">  int64_t counter = monotonic_counter_;</a>
<a name="ln2505">  while (true) {</a>
<a name="ln2506">    if (counter &gt;= value) {</a>
<a name="ln2507">      break;</a>
<a name="ln2508">    }</a>
<a name="ln2509">    if (monotonic_counter_.compare_exchange_weak(counter, value)) {</a>
<a name="ln2510">      break;</a>
<a name="ln2511">    }</a>
<a name="ln2512">  }</a>
<a name="ln2513">}</a>
<a name="ln2514"> </a>
<a name="ln2515">////////////////////////////////////////////////////////////</a>
<a name="ln2516">// Tablet</a>
<a name="ln2517">////////////////////////////////////////////////////////////</a>
<a name="ln2518"> </a>
<a name="ln2519">Result&lt;bool&gt; Tablet::HasSSTables() const {</a>
<a name="ln2520">  if (!regular_db_) {</a>
<a name="ln2521">    return false;</a>
<a name="ln2522">  }</a>
<a name="ln2523"> </a>
<a name="ln2524">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln2525">  RETURN_NOT_OK(scoped_read_operation);</a>
<a name="ln2526"> </a>
<a name="ln2527">  std::vector&lt;rocksdb::LiveFileMetaData&gt; live_files_metadata;</a>
<a name="ln2528">  regular_db_-&gt;GetLiveFilesMetaData(&amp;live_files_metadata);</a>
<a name="ln2529">  return !live_files_metadata.empty();</a>
<a name="ln2530">}</a>
<a name="ln2531"> </a>
<a name="ln2532">yb::OpId MaxPersistentOpIdForDb(rocksdb::DB* db, bool invalid_if_no_new_data) {</a>
<a name="ln2533">  // A possible race condition could happen, when data is written between this query and</a>
<a name="ln2534">  // actual log gc. But it is not a problem as long as we are reading committed op id</a>
<a name="ln2535">  // before MaxPersistentOpId, since we always keep last committed entry in the log during garbage</a>
<a name="ln2536">  // collection.</a>
<a name="ln2537">  // See TabletPeer::GetEarliestNeededLogIndex</a>
<a name="ln2538">  if (db == nullptr ||</a>
<a name="ln2539">      (invalid_if_no_new_data &amp;&amp;</a>
<a name="ln2540">       db-&gt;GetFlushAbility() == rocksdb::FlushAbility::kNoNewData)) {</a>
<a name="ln2541">    return yb::OpId::Invalid();</a>
<a name="ln2542">  }</a>
<a name="ln2543"> </a>
<a name="ln2544">  rocksdb::UserFrontierPtr frontier = db-&gt;GetFlushedFrontier();</a>
<a name="ln2545">  if (!frontier) {</a>
<a name="ln2546">    return yb::OpId();</a>
<a name="ln2547">  }</a>
<a name="ln2548"> </a>
<a name="ln2549">  return down_cast&lt;docdb::ConsensusFrontier*&gt;(frontier.get())-&gt;op_id();</a>
<a name="ln2550">}</a>
<a name="ln2551"> </a>
<a name="ln2552">Result&lt;DocDbOpIds&gt; Tablet::MaxPersistentOpId(bool invalid_if_no_new_data) const {</a>
<a name="ln2553">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln2554">  RETURN_NOT_OK(scoped_read_operation);</a>
<a name="ln2555"> </a>
<a name="ln2556">  return DocDbOpIds{</a>
<a name="ln2557">      MaxPersistentOpIdForDb(regular_db_.get(), invalid_if_no_new_data),</a>
<a name="ln2558">      MaxPersistentOpIdForDb(intents_db_.get(), invalid_if_no_new_data)</a>
<a name="ln2559">  };</a>
<a name="ln2560">}</a>
<a name="ln2561"> </a>
<a name="ln2562">void Tablet::FlushIntentsDbIfNecessary(const yb::OpId&amp; lastest_log_entry_op_id) {</a>
<a name="ln2563">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln2564">  if (!scoped_read_operation.ok()) {</a>
<a name="ln2565">    return;</a>
<a name="ln2566">  }</a>
<a name="ln2567"> </a>
<a name="ln2568">  auto intents_frontier = intents_db_</a>
<a name="ln2569">      ? intents_db_-&gt;GetMutableMemTableFrontier(rocksdb::UpdateUserValueType::kLargest) : nullptr;</a>
<a name="ln2570">  if (intents_frontier) {</a>
<a name="ln2571">    auto index_delta =</a>
<a name="ln2572">        lastest_log_entry_op_id.index -</a>
<a name="ln2573">        down_cast&lt;docdb::ConsensusFrontier*&gt;(intents_frontier.get())-&gt;op_id().index;</a>
<a name="ln2574">    if (index_delta &gt; FLAGS_num_raft_ops_to_force_idle_intents_db_to_flush) {</a>
<a name="ln2575">      auto intents_flush_ability = intents_db_-&gt;GetFlushAbility();</a>
<a name="ln2576">      if (intents_flush_ability == rocksdb::FlushAbility::kHasNewData) {</a>
<a name="ln2577">        LOG_WITH_PREFIX(INFO)</a>
<a name="ln2578">            &lt;&lt; &quot;Force flushing intents DB since it was not flushed for &quot; &lt;&lt; index_delta</a>
<a name="ln2579">            &lt;&lt; &quot; operations, while only &quot;</a>
<a name="ln2580">            &lt;&lt; FLAGS_num_raft_ops_to_force_idle_intents_db_to_flush &lt;&lt; &quot; is allowed&quot;;</a>
<a name="ln2581">        rocksdb::FlushOptions options;</a>
<a name="ln2582">        options.wait = false;</a>
<a name="ln2583">        WARN_NOT_OK(intents_db_-&gt;Flush(options), &quot;Flush intents db failed&quot;);</a>
<a name="ln2584">      }</a>
<a name="ln2585">    }</a>
<a name="ln2586">  }</a>
<a name="ln2587">}</a>
<a name="ln2588"> </a>
<a name="ln2589">bool Tablet::IsTransactionalRequest(bool is_ysql_request) const {</a>
<a name="ln2590">  // We consider all YSQL tables within the sys catalog transactional.</a>
<a name="ln2591">  return txns_enabled_ &amp;&amp; (</a>
<a name="ln2592">      schema()-&gt;table_properties().is_transactional() ||</a>
<a name="ln2593">          (is_sys_catalog_ &amp;&amp; is_ysql_request));</a>
<a name="ln2594">}</a>
<a name="ln2595"> </a>
<a name="ln2596">Result&lt;HybridTime&gt; Tablet::MaxPersistentHybridTime() const {</a>
<a name="ln2597">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln2598">  RETURN_NOT_OK(scoped_read_operation);</a>
<a name="ln2599"> </a>
<a name="ln2600">  if (!regular_db_) {</a>
<a name="ln2601">    return HybridTime::kMin;</a>
<a name="ln2602">  }</a>
<a name="ln2603"> </a>
<a name="ln2604">  HybridTime result = HybridTime::kMin;</a>
<a name="ln2605">  auto temp = regular_db_-&gt;GetFlushedFrontier();</a>
<a name="ln2606">  if (temp) {</a>
<a name="ln2607">    result.MakeAtLeast(down_cast&lt;docdb::ConsensusFrontier*&gt;(temp.get())-&gt;hybrid_time());</a>
<a name="ln2608">  }</a>
<a name="ln2609">  if (intents_db_) {</a>
<a name="ln2610">    temp = intents_db_-&gt;GetFlushedFrontier();</a>
<a name="ln2611">    if (temp) {</a>
<a name="ln2612">      result.MakeAtLeast(down_cast&lt;docdb::ConsensusFrontier*&gt;(temp.get())-&gt;hybrid_time());</a>
<a name="ln2613">    }</a>
<a name="ln2614">  }</a>
<a name="ln2615">  return result;</a>
<a name="ln2616">}</a>
<a name="ln2617"> </a>
<a name="ln2618">Result&lt;HybridTime&gt; Tablet::OldestMutableMemtableWriteHybridTime() const {</a>
<a name="ln2619">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln2620">  RETURN_NOT_OK(scoped_read_operation);</a>
<a name="ln2621"> </a>
<a name="ln2622">  HybridTime result = HybridTime::kMax;</a>
<a name="ln2623">  for (auto* db : { regular_db_.get(), intents_db_.get() }) {</a>
<a name="ln2624">    if (db) {</a>
<a name="ln2625">      auto mem_frontier = db-&gt;GetMutableMemTableFrontier(rocksdb::UpdateUserValueType::kSmallest);</a>
<a name="ln2626">      if (mem_frontier) {</a>
<a name="ln2627">        const auto hybrid_time =</a>
<a name="ln2628">            static_cast&lt;const docdb::ConsensusFrontier&amp;&gt;(*mem_frontier).hybrid_time();</a>
<a name="ln2629">        result = std::min(result, hybrid_time);</a>
<a name="ln2630">      }</a>
<a name="ln2631">    }</a>
<a name="ln2632">  }</a>
<a name="ln2633">  return result;</a>
<a name="ln2634">}</a>
<a name="ln2635"> </a>
<a name="ln2636">Status Tablet::DebugDump(vector&lt;string&gt; *lines) {</a>
<a name="ln2637">  switch (table_type_) {</a>
<a name="ln2638">    case TableType::PGSQL_TABLE_TYPE: FALLTHROUGH_INTENDED;</a>
<a name="ln2639">    case TableType::YQL_TABLE_TYPE: FALLTHROUGH_INTENDED;</a>
<a name="ln2640">    case TableType::REDIS_TABLE_TYPE:</a>
<a name="ln2641">      DocDBDebugDump(lines);</a>
<a name="ln2642">      return Status::OK();</a>
<a name="ln2643">    case TableType::TRANSACTION_STATUS_TABLE_TYPE:</a>
<a name="ln2644">      return Status::OK();</a>
<a name="ln2645">  }</a>
<a name="ln2646">  FATAL_INVALID_ENUM_VALUE(TableType, table_type_);</a>
<a name="ln2647">}</a>
<a name="ln2648"> </a>
<a name="ln2649">void Tablet::DocDBDebugDump(vector&lt;string&gt; *lines) {</a>
<a name="ln2650">  LOG_STRING(INFO, lines) &lt;&lt; &quot;Dumping tablet:&quot;;</a>
<a name="ln2651">  LOG_STRING(INFO, lines) &lt;&lt; &quot;---------------------------&quot;;</a>
<a name="ln2652">  docdb::DocDBDebugDump(regular_db_.get(), LOG_STRING(INFO, lines), docdb::StorageDbType::kRegular);</a>
<a name="ln2653">}</a>
<a name="ln2654"> </a>
<a name="ln2655">Status Tablet::TEST_SwitchMemtable() {</a>
<a name="ln2656">  ScopedRWOperation scoped_operation(&amp;pending_op_counter_);</a>
<a name="ln2657">  RETURN_NOT_OK(scoped_operation);</a>
<a name="ln2658"> </a>
<a name="ln2659">  if (regular_db_) {</a>
<a name="ln2660">    regular_db_-&gt;TEST_SwitchMemtable();</a>
<a name="ln2661">  } else {</a>
<a name="ln2662">    LOG_WITH_PREFIX(INFO) &lt;&lt; &quot;Ignoring TEST_SwitchMemtable: no regular RocksDB&quot;;</a>
<a name="ln2663">  }</a>
<a name="ln2664">  return Status::OK();</a>
<a name="ln2665">}</a>
<a name="ln2666"> </a>
<a name="ln2667">class DocWriteOperation : public std::enable_shared_from_this&lt;DocWriteOperation&gt; {</a>
<a name="ln2668"> public:</a>
<a name="ln2669">  explicit DocWriteOperation(</a>
<a name="ln2670">      Tablet* tablet, bool txns_enabled, std::unique_ptr&lt;WriteOperation&gt; operation,</a>
<a name="ln2671">      ScopedRWOperation scoped_read_operation, DocWriteOperationCallback callback)</a>
<a name="ln2672">      : tablet_(*tablet), txns_enabled_(txns_enabled), operation_(std::move(operation)),</a>
<a name="ln2673">        scoped_read_operation_(std::move(scoped_read_operation)), callback_(std::move(callback)) {</a>
<a name="ln2674">  }</a>
<a name="ln2675"> </a>
<a name="ln2676">  ~DocWriteOperation() {</a>
<a name="ln2677">    if (operation_) {</a>
<a name="ln2678">      auto status = STATUS(RuntimeError, &quot;DocWriteOperation did not invoke callback&quot;);</a>
<a name="ln2679">      LOG(DFATAL) &lt;&lt; this &lt;&lt; &quot; &quot; &lt;&lt; status;</a>
<a name="ln2680">      InvokeCallback(status);</a>
<a name="ln2681">    }</a>
<a name="ln2682">  }</a>
<a name="ln2683"> </a>
<a name="ln2684">  void Start() {</a>
<a name="ln2685">    auto status = DoStart();</a>
<a name="ln2686">    if (!status.ok()) {</a>
<a name="ln2687">      InvokeCallback(status);</a>
<a name="ln2688">    }</a>
<a name="ln2689">  }</a>
<a name="ln2690"> </a>
<a name="ln2691"> private:</a>
<a name="ln2692">  void InvokeCallback(const Status&amp; status) {</a>
<a name="ln2693">    scoped_read_operation_.Reset();</a>
<a name="ln2694">    callback_(std::move(operation_), status);</a>
<a name="ln2695">  }</a>
<a name="ln2696"> </a>
<a name="ln2697">  CHECKED_STATUS DoStart() {</a>
<a name="ln2698">    auto write_batch = operation_-&gt;request()-&gt;mutable_write_batch();</a>
<a name="ln2699">    isolation_level_ = VERIFY_RESULT(tablet_.GetIsolationLevelFromPB(*write_batch));</a>
<a name="ln2700">    const RowMarkType row_mark_type = GetRowMarkTypeFromPB(*write_batch);</a>
<a name="ln2701">    const auto&amp; metadata = *tablet_.metadata();</a>
<a name="ln2702"> </a>
<a name="ln2703">    const bool transactional_table = metadata.schema()-&gt;table_properties().is_transactional() ||</a>
<a name="ln2704">                                     operation_-&gt;force_txn_path();</a>
<a name="ln2705"> </a>
<a name="ln2706">    if (!transactional_table &amp;&amp; isolation_level_ != IsolationLevel::NON_TRANSACTIONAL) {</a>
<a name="ln2707">      YB_LOG_EVERY_N_SECS(DFATAL, 30)</a>
<a name="ln2708">          &lt;&lt; &quot;An attempt to perform a transactional operation on a non-transactional table: &quot;</a>
<a name="ln2709">          &lt;&lt; operation_-&gt;ToString();</a>
<a name="ln2710">    }</a>
<a name="ln2711"> </a>
<a name="ln2712">    const auto partial_range_key_intents = UsePartialRangeKeyIntents(metadata);</a>
<a name="ln2713">    prepare_result_ = VERIFY_RESULT(docdb::PrepareDocWriteOperation(</a>
<a name="ln2714">        operation_-&gt;doc_ops(), write_batch-&gt;read_pairs(), tablet_.metrics()-&gt;write_lock_latency,</a>
<a name="ln2715">        isolation_level_, operation_-&gt;state()-&gt;kind(), row_mark_type, transactional_table,</a>
<a name="ln2716">        operation_-&gt;deadline(), partial_range_key_intents, tablet_.shared_lock_manager()));</a>
<a name="ln2717"> </a>
<a name="ln2718">    auto* transaction_participant = tablet_.transaction_participant();</a>
<a name="ln2719">    if (transaction_participant) {</a>
<a name="ln2720">      request_scope_ = RequestScope(transaction_participant);</a>
<a name="ln2721">    }</a>
<a name="ln2722"> </a>
<a name="ln2723">    read_time_ = operation_-&gt;read_time();</a>
<a name="ln2724"> </a>
<a name="ln2725">    if (!txns_enabled_ || !transactional_table) {</a>
<a name="ln2726">      Complete();</a>
<a name="ln2727">      return Status::OK();</a>
<a name="ln2728">    }</a>
<a name="ln2729"> </a>
<a name="ln2730">    if (isolation_level_ == IsolationLevel::NON_TRANSACTIONAL) {</a>
<a name="ln2731">      auto now = tablet_.clock()-&gt;Now();</a>
<a name="ln2732">      docdb::ResolveOperationConflicts(</a>
<a name="ln2733">          operation_-&gt;doc_ops(), now, tablet_.doc_db(), partial_range_key_intents,</a>
<a name="ln2734">          transaction_participant, tablet_.metrics()-&gt;transaction_conflicts.get(),</a>
<a name="ln2735">          [self = shared_from_this(), now](const Result&lt;HybridTime&gt;&amp; result) {</a>
<a name="ln2736">            if (!result.ok()) {</a>
<a name="ln2737">              self-&gt;InvokeCallback(result.status());</a>
<a name="ln2738">              return;</a>
<a name="ln2739">            }</a>
<a name="ln2740">            self-&gt;NonTransactionalConflictsResolved(now, *result);</a>
<a name="ln2741">          });</a>
<a name="ln2742">      return Status::OK();</a>
<a name="ln2743">    }</a>
<a name="ln2744"> </a>
<a name="ln2745">    if (isolation_level_ == IsolationLevel::SERIALIZABLE_ISOLATION &amp;&amp;</a>
<a name="ln2746">        prepare_result_.need_read_snapshot) {</a>
<a name="ln2747">      boost::container::small_vector&lt;RefCntPrefix, 16&gt; paths;</a>
<a name="ln2748">      for (const auto&amp; doc_op : operation_-&gt;doc_ops()) {</a>
<a name="ln2749">        paths.clear();</a>
<a name="ln2750">        IsolationLevel ignored_isolation_level;</a>
<a name="ln2751">        RETURN_NOT_OK(doc_op-&gt;GetDocPaths(</a>
<a name="ln2752">            docdb::GetDocPathsMode::kLock, &amp;paths, &amp;ignored_isolation_level));</a>
<a name="ln2753">        for (const auto&amp; path : paths) {</a>
<a name="ln2754">          auto key = path.as_slice();</a>
<a name="ln2755">          auto* pair = write_batch-&gt;mutable_read_pairs()-&gt;Add();</a>
<a name="ln2756">          pair-&gt;set_key(key.data(), key.size());</a>
<a name="ln2757">          // Empty values are disallowed by docdb.</a>
<a name="ln2758">          // https://github.com/YugaByte/yugabyte-db/issues/736</a>
<a name="ln2759">          pair-&gt;set_value(std::string(1, docdb::ValueTypeAsChar::kNullLow));</a>
<a name="ln2760">        }</a>
<a name="ln2761">      }</a>
<a name="ln2762">    }</a>
<a name="ln2763"> </a>
<a name="ln2764">    docdb::ResolveTransactionConflicts(</a>
<a name="ln2765">        operation_-&gt;doc_ops(), *write_batch, tablet_.clock()-&gt;Now(),</a>
<a name="ln2766">        read_time_ ? read_time_.read : HybridTime::kMax,</a>
<a name="ln2767">        tablet_.doc_db(), partial_range_key_intents,</a>
<a name="ln2768">        transaction_participant, tablet_.metrics()-&gt;transaction_conflicts.get(),</a>
<a name="ln2769">        [self = shared_from_this()](const Result&lt;HybridTime&gt;&amp; result) {</a>
<a name="ln2770">          if (!result.ok()) {</a>
<a name="ln2771">            self-&gt;InvokeCallback(result.status());</a>
<a name="ln2772">            return;</a>
<a name="ln2773">          }</a>
<a name="ln2774">          self-&gt;TransactionalConflictsResolved();</a>
<a name="ln2775">        });</a>
<a name="ln2776"> </a>
<a name="ln2777">    return Status::OK();</a>
<a name="ln2778">  }</a>
<a name="ln2779"> </a>
<a name="ln2780"> private:</a>
<a name="ln2781">  void NonTransactionalConflictsResolved(HybridTime now, HybridTime result) {</a>
<a name="ln2782">    if (now != result) {</a>
<a name="ln2783">      tablet_.clock()-&gt;Update(result);</a>
<a name="ln2784">    }</a>
<a name="ln2785"> </a>
<a name="ln2786">    Complete();</a>
<a name="ln2787">  }</a>
<a name="ln2788"> </a>
<a name="ln2789">  void TransactionalConflictsResolved() {</a>
<a name="ln2790">    if (!read_time_) {</a>
<a name="ln2791">      auto safe_time = tablet_.SafeTime(RequireLease::kTrue);</a>
<a name="ln2792">      read_time_ = ReadHybridTime::FromHybridTimeRange(</a>
<a name="ln2793">          {safe_time, tablet_.clock()-&gt;NowRange().second});</a>
<a name="ln2794">    } else if (prepare_result_.need_read_snapshot &amp;&amp;</a>
<a name="ln2795">               isolation_level_ == IsolationLevel::SERIALIZABLE_ISOLATION) {</a>
<a name="ln2796">      auto status = STATUS_FORMAT(</a>
<a name="ln2797">          InvalidArgument,</a>
<a name="ln2798">          &quot;Read time should NOT be specified for serializable isolation level: $0&quot;,</a>
<a name="ln2799">          read_time_);</a>
<a name="ln2800">      LOG(DFATAL) &lt;&lt; status;</a>
<a name="ln2801">      InvokeCallback(status);</a>
<a name="ln2802">      return;</a>
<a name="ln2803">    }</a>
<a name="ln2804"> </a>
<a name="ln2805">    Complete();</a>
<a name="ln2806">  }</a>
<a name="ln2807"> </a>
<a name="ln2808">  bool allow_immediate_read_restart() const {</a>
<a name="ln2809">    return !operation_-&gt;read_time();</a>
<a name="ln2810">  }</a>
<a name="ln2811"> </a>
<a name="ln2812">  void Complete() {</a>
<a name="ln2813">    InvokeCallback(DoComplete());</a>
<a name="ln2814">  }</a>
<a name="ln2815"> </a>
<a name="ln2816">  CHECKED_STATUS DoComplete() {</a>
<a name="ln2817">    auto read_op = prepare_result_.need_read_snapshot</a>
<a name="ln2818">        ? VERIFY_RESULT(ScopedReadOperation::Create(&amp;tablet_, RequireLease::kTrue, read_time_))</a>
<a name="ln2819">        : ScopedReadOperation();</a>
<a name="ln2820">    // Actual read hybrid time used for read-modify-write operation.</a>
<a name="ln2821">    auto real_read_time = prepare_result_.need_read_snapshot</a>
<a name="ln2822">        ? read_op.read_time()</a>
<a name="ln2823">        // When need_read_snapshot is false, this time is used only to write TTL field of record.</a>
<a name="ln2824">        : ReadHybridTime::SingleTime(tablet_.clock()-&gt;Now());</a>
<a name="ln2825"> </a>
<a name="ln2826">    // We expect all read operations for this transaction to be done in ExecuteDocWriteOperation.</a>
<a name="ln2827">    // Once read_txn goes out of scope, the read point is deregistered.</a>
<a name="ln2828">    HybridTime restart_read_ht;</a>
<a name="ln2829">    bool local_limit_updated = false;</a>
<a name="ln2830"> </a>
<a name="ln2831">    // This loop may be executed multiple times multiple times only for serializable isolation or</a>
<a name="ln2832">    // when read_time was not yet picked for snapshot isolation.</a>
<a name="ln2833">    // In all other cases it is executed only once.</a>
<a name="ln2834">    InitMarkerBehavior init_marker_behavior = tablet_.table_type() == TableType::REDIS_TABLE_TYPE</a>
<a name="ln2835">        ? InitMarkerBehavior::kRequired</a>
<a name="ln2836">        : InitMarkerBehavior::kOptional;</a>
<a name="ln2837">    for (;;) {</a>
<a name="ln2838">      RETURN_NOT_OK(docdb::ExecuteDocWriteOperation(</a>
<a name="ln2839">          operation_-&gt;doc_ops(), operation_-&gt;deadline(), real_read_time, tablet_.doc_db(),</a>
<a name="ln2840">          operation_-&gt;request()-&gt;mutable_write_batch(), init_marker_behavior,</a>
<a name="ln2841">          tablet_.monotonic_counter(), &amp;restart_read_ht,</a>
<a name="ln2842">          tablet_.metadata()-&gt;table_name()));</a>
<a name="ln2843"> </a>
<a name="ln2844">      // For serializable isolation we don't fix read time, so could do read restart locally,</a>
<a name="ln2845">      // instead of failing whole transaction.</a>
<a name="ln2846">      if (!restart_read_ht.is_valid() || !allow_immediate_read_restart()) {</a>
<a name="ln2847">        break;</a>
<a name="ln2848">      }</a>
<a name="ln2849"> </a>
<a name="ln2850">      real_read_time.read = restart_read_ht;</a>
<a name="ln2851">      if (!local_limit_updated) {</a>
<a name="ln2852">        local_limit_updated = true;</a>
<a name="ln2853">        real_read_time.local_limit =</a>
<a name="ln2854">            std::min(real_read_time.local_limit, tablet_.SafeTime(RequireLease::kTrue));</a>
<a name="ln2855">      }</a>
<a name="ln2856"> </a>
<a name="ln2857">      restart_read_ht = HybridTime();</a>
<a name="ln2858"> </a>
<a name="ln2859">      operation_-&gt;request()-&gt;mutable_write_batch()-&gt;clear_write_pairs();</a>
<a name="ln2860"> </a>
<a name="ln2861">      for (auto&amp; doc_op : operation_-&gt;doc_ops()) {</a>
<a name="ln2862">        doc_op-&gt;ClearResponse();</a>
<a name="ln2863">      }</a>
<a name="ln2864">    }</a>
<a name="ln2865"> </a>
<a name="ln2866">    operation_-&gt;SetRestartReadHt(restart_read_ht);</a>
<a name="ln2867"> </a>
<a name="ln2868">    if (allow_immediate_read_restart() &amp;&amp;</a>
<a name="ln2869">        isolation_level_ != IsolationLevel::NON_TRANSACTIONAL &amp;&amp;</a>
<a name="ln2870">        operation_-&gt;response()) {</a>
<a name="ln2871">      real_read_time.ToPB(operation_-&gt;response()-&gt;mutable_used_read_time());</a>
<a name="ln2872">    }</a>
<a name="ln2873"> </a>
<a name="ln2874">    if (operation_-&gt;restart_read_ht().is_valid()) {</a>
<a name="ln2875">      return Status::OK();</a>
<a name="ln2876">    }</a>
<a name="ln2877"> </a>
<a name="ln2878">    operation_-&gt;state()-&gt;ReplaceDocDBLocks(std::move(prepare_result_.lock_batch));</a>
<a name="ln2879"> </a>
<a name="ln2880">    return Status::OK();</a>
<a name="ln2881">  }</a>
<a name="ln2882"> </a>
<a name="ln2883">  Tablet&amp; tablet_;</a>
<a name="ln2884">  const bool txns_enabled_;</a>
<a name="ln2885">  std::unique_ptr&lt;WriteOperation&gt; operation_;</a>
<a name="ln2886">  ScopedRWOperation scoped_read_operation_;</a>
<a name="ln2887">  DocWriteOperationCallback callback_;</a>
<a name="ln2888"> </a>
<a name="ln2889">  IsolationLevel isolation_level_;</a>
<a name="ln2890">  docdb::PrepareDocWriteOperationResult prepare_result_;</a>
<a name="ln2891">  RequestScope request_scope_;</a>
<a name="ln2892">  ReadHybridTime read_time_;</a>
<a name="ln2893">};</a>
<a name="ln2894"> </a>
<a name="ln2895">void Tablet::StartDocWriteOperation(</a>
<a name="ln2896">    std::unique_ptr&lt;WriteOperation&gt; operation,</a>
<a name="ln2897">    ScopedRWOperation scoped_read_operation,</a>
<a name="ln2898">    DocWriteOperationCallback callback) {</a>
<a name="ln2899">  auto doc_write_operation = std::make_shared&lt;DocWriteOperation&gt;(</a>
<a name="ln2900">      this, txns_enabled_, std::move(operation), std::move(scoped_read_operation),</a>
<a name="ln2901">      std::move(callback));</a>
<a name="ln2902">  doc_write_operation-&gt;Start();</a>
<a name="ln2903">}</a>
<a name="ln2904"> </a>
<a name="ln2905">HybridTime Tablet::DoGetSafeTime(</a>
<a name="ln2906">    tablet::RequireLease require_lease, HybridTime min_allowed, CoarseTimePoint deadline) const {</a>
<a name="ln2907">  if (!require_lease) {</a>
<a name="ln2908">    return mvcc_.SafeTimeForFollower(min_allowed, deadline);</a>
<a name="ln2909">  }</a>
<a name="ln2910">  FixedHybridTimeLease ht_lease;</a>
<a name="ln2911">  if (require_lease &amp;&amp; ht_lease_provider_) {</a>
<a name="ln2912">    // min_allowed could contain non zero logical part, so we add one microsecond to be sure that</a>
<a name="ln2913">    // the resulting ht_lease is at least min_allowed.</a>
<a name="ln2914">    auto min_allowed_lease = min_allowed.GetPhysicalValueMicros();</a>
<a name="ln2915">    if (min_allowed.GetLogicalValue()) {</a>
<a name="ln2916">      ++min_allowed_lease;</a>
<a name="ln2917">    }</a>
<a name="ln2918">    // This will block until a leader lease reaches the given value or a timeout occurs.</a>
<a name="ln2919">    ht_lease = ht_lease_provider_(min_allowed_lease, deadline);</a>
<a name="ln2920">    if (!ht_lease.lease.is_valid()) {</a>
<a name="ln2921">      // This could happen in case of timeout.</a>
<a name="ln2922">      return HybridTime::kInvalid;</a>
<a name="ln2923">    }</a>
<a name="ln2924">  }</a>
<a name="ln2925">  if (min_allowed &gt; ht_lease.lease) {</a>
<a name="ln2926">    LOG_WITH_PREFIX(DFATAL)</a>
<a name="ln2927">        &lt;&lt; &quot;Read request hybrid time after leader lease: &quot; &lt;&lt; min_allowed &lt;&lt; &quot;, &quot; &lt;&lt; ht_lease;</a>
<a name="ln2928">    return HybridTime::kInvalid;</a>
<a name="ln2929">  }</a>
<a name="ln2930">  return mvcc_.SafeTime(min_allowed, deadline, ht_lease);</a>
<a name="ln2931">}</a>
<a name="ln2932"> </a>
<a name="ln2933">ScopedRWOperationPause Tablet::PauseWritePermits(CoarseTimePoint deadline) {</a>
<a name="ln2934">  TRACE(&quot;Blocking write permit(s)&quot;);</a>
<a name="ln2935">  auto se = ScopeExit([] { TRACE(&quot;Blocking write permit(s) done&quot;); });</a>
<a name="ln2936">  // Prevent new write ops from being submitted.</a>
<a name="ln2937">  return ScopedRWOperationPause(&amp;write_ops_being_submitted_counter_, deadline, Stop::kFalse);</a>
<a name="ln2938">}</a>
<a name="ln2939"> </a>
<a name="ln2940">ScopedRWOperation Tablet::GetPermitToWrite(CoarseTimePoint deadline) {</a>
<a name="ln2941">  TRACE(&quot;Acquiring write permit&quot;);</a>
<a name="ln2942">  auto se = ScopeExit([] { TRACE(&quot;Acquiring write permit done&quot;); });</a>
<a name="ln2943">  return ScopedRWOperation(&amp;write_ops_being_submitted_counter_);</a>
<a name="ln2944">}</a>
<a name="ln2945"> </a>
<a name="ln2946">void Tablet::ForceRocksDBCompactInTest() {</a>
<a name="ln2947">  if (regular_db_) {</a>
<a name="ln2948">    docdb::ForceRocksDBCompact(regular_db_.get());</a>
<a name="ln2949">  }</a>
<a name="ln2950">  if (intents_db_) {</a>
<a name="ln2951">    CHECK_OK(intents_db_-&gt;Flush(rocksdb::FlushOptions()));</a>
<a name="ln2952">    docdb::ForceRocksDBCompact(intents_db_.get());</a>
<a name="ln2953">  }</a>
<a name="ln2954">}</a>
<a name="ln2955"> </a>
<a name="ln2956">std::string Tablet::TEST_DocDBDumpStr(IncludeIntents include_intents) {</a>
<a name="ln2957">  if (!regular_db_) return &quot;&quot;;</a>
<a name="ln2958"> </a>
<a name="ln2959">  if (!include_intents) {</a>
<a name="ln2960">    return docdb::DocDBDebugDumpToStr(doc_db().WithoutIntents());</a>
<a name="ln2961">  }</a>
<a name="ln2962"> </a>
<a name="ln2963">  return docdb::DocDBDebugDumpToStr(doc_db());</a>
<a name="ln2964">}</a>
<a name="ln2965"> </a>
<a name="ln2966">void Tablet::TEST_DocDBDumpToContainer(</a>
<a name="ln2967">    IncludeIntents include_intents, std::unordered_set&lt;std::string&gt;* out) {</a>
<a name="ln2968">  if (!regular_db_) return;</a>
<a name="ln2969"> </a>
<a name="ln2970">  if (!include_intents) {</a>
<a name="ln2971">    return docdb::DocDBDebugDumpToContainer(doc_db().WithoutIntents(), out);</a>
<a name="ln2972">  }</a>
<a name="ln2973"> </a>
<a name="ln2974">  return docdb::DocDBDebugDumpToContainer(doc_db(), out);</a>
<a name="ln2975">}</a>
<a name="ln2976"> </a>
<a name="ln2977">size_t Tablet::TEST_CountRegularDBRecords() {</a>
<a name="ln2978">  if (!regular_db_) return 0;</a>
<a name="ln2979">  rocksdb::ReadOptions read_opts;</a>
<a name="ln2980">  read_opts.query_id = rocksdb::kDefaultQueryId;</a>
<a name="ln2981">  docdb::BoundedRocksDbIterator iter(regular_db_.get(), read_opts, &amp;key_bounds_);</a>
<a name="ln2982"> </a>
<a name="ln2983">  size_t result = 0;</a>
<a name="ln2984">  for (iter.SeekToFirst(); iter.Valid(); iter.Next()) {</a>
<a name="ln2985">    ++result;</a>
<a name="ln2986">  }</a>
<a name="ln2987">  return result;</a>
<a name="ln2988">}</a>
<a name="ln2989"> </a>
<a name="ln2990">template &lt;class Functor&gt;</a>
<a name="ln2991">uint64_t Tablet::GetRegularDbStat(const Functor&amp; functor) const {</a>
<a name="ln2992">  ScopedRWOperation scoped_operation(&amp;pending_op_counter_);</a>
<a name="ln2993">  std::lock_guard&lt;rw_spinlock&gt; lock(component_lock_);</a>
<a name="ln2994"> </a>
<a name="ln2995">  // In order to get actual stats we would have to wait.</a>
<a name="ln2996">  // This would give us correct stats but would make this request slower.</a>
<a name="ln2997">  if (!scoped_operation.ok() || !regular_db_) {</a>
<a name="ln2998">    return 0;</a>
<a name="ln2999">  }</a>
<a name="ln3000">  return functor();</a>
<a name="ln3001">}</a>
<a name="ln3002"> </a>
<a name="ln3003"> </a>
<a name="ln3004">uint64_t Tablet::GetCurrentVersionSstFilesSize() const {</a>
<a name="ln3005">  return GetRegularDbStat([this] {</a>
<a name="ln3006">    return regular_db_-&gt;GetCurrentVersionSstFilesSize();</a>
<a name="ln3007">  });</a>
<a name="ln3008">}</a>
<a name="ln3009"> </a>
<a name="ln3010">uint64_t Tablet::GetCurrentVersionSstFilesUncompressedSize() const {</a>
<a name="ln3011">  return GetRegularDbStat([this] {</a>
<a name="ln3012">    return regular_db_-&gt;GetCurrentVersionSstFilesUncompressedSize();</a>
<a name="ln3013">  });</a>
<a name="ln3014">}</a>
<a name="ln3015"> </a>
<a name="ln3016">uint64_t Tablet::GetCurrentVersionNumSSTFiles() const {</a>
<a name="ln3017">  return GetRegularDbStat([this] {</a>
<a name="ln3018">    return regular_db_-&gt;GetCurrentVersionNumSSTFiles();</a>
<a name="ln3019">  });</a>
<a name="ln3020">}</a>
<a name="ln3021"> </a>
<a name="ln3022">std::pair&lt;int, int&gt; Tablet::GetNumMemtables() const {</a>
<a name="ln3023">  int intents_num_memtables = 0;</a>
<a name="ln3024">  int regular_num_memtables = 0;</a>
<a name="ln3025"> </a>
<a name="ln3026">  {</a>
<a name="ln3027">    ScopedRWOperation scoped_operation(&amp;pending_op_counter_);</a>
<a name="ln3028">    std::lock_guard&lt;rw_spinlock&gt; lock(component_lock_);</a>
<a name="ln3029">    if (intents_db_) {</a>
<a name="ln3030">      // NOTE: 1 is added on behalf of cfd-&gt;mem().</a>
<a name="ln3031">      intents_num_memtables = 1 + intents_db_-&gt;GetCfdImmNumNotFlushed();</a>
<a name="ln3032">    }</a>
<a name="ln3033">    if (regular_db_) {</a>
<a name="ln3034">      // NOTE: 1 is added on behalf of cfd-&gt;mem().</a>
<a name="ln3035">      regular_num_memtables = 1 + regular_db_-&gt;GetCfdImmNumNotFlushed();</a>
<a name="ln3036">    }</a>
<a name="ln3037">  }</a>
<a name="ln3038"> </a>
<a name="ln3039">  return std::make_pair(intents_num_memtables, regular_num_memtables);</a>
<a name="ln3040">}</a>
<a name="ln3041"> </a>
<a name="ln3042">// ------------------------------------------------------------------------------------------------</a>
<a name="ln3043"> </a>
<a name="ln3044">Result&lt;TransactionOperationContextOpt&gt; Tablet::CreateTransactionOperationContext(</a>
<a name="ln3045">    const TransactionMetadataPB&amp; transaction_metadata,</a>
<a name="ln3046">    bool is_ysql_catalog_table) const {</a>
<a name="ln3047">  if (!txns_enabled_)</a>
<a name="ln3048">    return boost::none;</a>
<a name="ln3049"> </a>
<a name="ln3050">  if (transaction_metadata.has_transaction_id()) {</a>
<a name="ln3051">    Result&lt;TransactionId&gt; txn_id = FullyDecodeTransactionId(</a>
<a name="ln3052">        transaction_metadata.transaction_id());</a>
<a name="ln3053">    RETURN_NOT_OK(txn_id);</a>
<a name="ln3054">    return CreateTransactionOperationContext(boost::make_optional(*txn_id), is_ysql_catalog_table);</a>
<a name="ln3055">  } else {</a>
<a name="ln3056">    return CreateTransactionOperationContext(boost::none, is_ysql_catalog_table);</a>
<a name="ln3057">  }</a>
<a name="ln3058">}</a>
<a name="ln3059"> </a>
<a name="ln3060">TransactionOperationContextOpt Tablet::CreateTransactionOperationContext(</a>
<a name="ln3061">    const boost::optional&lt;TransactionId&gt;&amp; transaction_id,</a>
<a name="ln3062">    bool is_ysql_catalog_table) const {</a>
<a name="ln3063">  if (!txns_enabled_) {</a>
<a name="ln3064">    return boost::none;</a>
<a name="ln3065">  }</a>
<a name="ln3066"> </a>
<a name="ln3067">  const TransactionId* txn_id = nullptr;</a>
<a name="ln3068"> </a>
<a name="ln3069">  if (transaction_id.is_initialized()) {</a>
<a name="ln3070">    txn_id = transaction_id.get_ptr();</a>
<a name="ln3071">  } else if (metadata_-&gt;schema()-&gt;table_properties().is_transactional() || is_ysql_catalog_table) {</a>
<a name="ln3072">    // deadbeef-dead-beef-dead-beef00000075</a>
<a name="ln3073">    static const TransactionId kArbitraryTxnIdForNonTxnReads(</a>
<a name="ln3074">        17275436393656397278ULL, 8430738506459819486ULL);</a>
<a name="ln3075">    // We still need context with transaction participant in order to resolve intents during</a>
<a name="ln3076">    // possible reads.</a>
<a name="ln3077">    txn_id = &amp;kArbitraryTxnIdForNonTxnReads;</a>
<a name="ln3078">  } else {</a>
<a name="ln3079">    return boost::none;</a>
<a name="ln3080">  }</a>
<a name="ln3081"> </a>
<a name="ln3082">  return TransactionOperationContext(*txn_id, transaction_participant());</a>
<a name="ln3083">}</a>
<a name="ln3084"> </a>
<a name="ln3085">Status Tablet::CreateReadIntents(</a>
<a name="ln3086">    const TransactionMetadataPB&amp; transaction_metadata,</a>
<a name="ln3087">    const google::protobuf::RepeatedPtrField&lt;QLReadRequestPB&gt;&amp; ql_batch,</a>
<a name="ln3088">    const google::protobuf::RepeatedPtrField&lt;PgsqlReadRequestPB&gt;&amp; pgsql_batch,</a>
<a name="ln3089">    docdb::KeyValueWriteBatchPB* write_batch) {</a>
<a name="ln3090">  auto txn_op_ctx = VERIFY_RESULT(CreateTransactionOperationContext(</a>
<a name="ln3091">      transaction_metadata,</a>
<a name="ln3092">      /* is_ysql_catalog_table */ pgsql_batch.size() &gt; 0 &amp;&amp; is_sys_catalog_));</a>
<a name="ln3093"> </a>
<a name="ln3094">  for (const auto&amp; ql_read : ql_batch) {</a>
<a name="ln3095">    docdb::QLReadOperation doc_op(ql_read, txn_op_ctx);</a>
<a name="ln3096">    RETURN_NOT_OK(doc_op.GetIntents(*GetSchema(), write_batch));</a>
<a name="ln3097">  }</a>
<a name="ln3098"> </a>
<a name="ln3099">  for (const auto&amp; pgsql_read : pgsql_batch) {</a>
<a name="ln3100">    docdb::PgsqlReadOperation doc_op(pgsql_read, txn_op_ctx);</a>
<a name="ln3101">    RETURN_NOT_OK(doc_op.GetIntents(*GetSchema(pgsql_read.table_id()), write_batch));</a>
<a name="ln3102">  }</a>
<a name="ln3103"> </a>
<a name="ln3104">  return Status::OK();</a>
<a name="ln3105">}</a>
<a name="ln3106"> </a>
<a name="ln3107">bool Tablet::ShouldApplyWrite() {</a>
<a name="ln3108">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln3109">  if (!scoped_read_operation.ok()) {</a>
<a name="ln3110">    return false;</a>
<a name="ln3111">  }</a>
<a name="ln3112"> </a>
<a name="ln3113">  return !regular_db_-&gt;NeedsDelay();</a>
<a name="ln3114">}</a>
<a name="ln3115"> </a>
<a name="ln3116">Result&lt;IsolationLevel&gt; Tablet::GetIsolationLevel(const TransactionMetadataPB&amp; transaction) {</a>
<a name="ln3117">  if (transaction.has_isolation()) {</a>
<a name="ln3118">    return transaction.isolation();</a>
<a name="ln3119">  }</a>
<a name="ln3120">  return VERIFY_RESULT(transaction_participant_-&gt;PrepareMetadata(transaction)).isolation;</a>
<a name="ln3121">}</a>
<a name="ln3122"> </a>
<a name="ln3123">Result&lt;RaftGroupMetadataPtr&gt; Tablet::CreateSubtablet(</a>
<a name="ln3124">    const TabletId&amp; tablet_id, const Partition&amp; partition, const docdb::KeyBounds&amp; key_bounds,</a>
<a name="ln3125">    const yb::OpId&amp; split_op_id, const HybridTime&amp; split_op_hybrid_time) {</a>
<a name="ln3126">  ScopedRWOperation scoped_read_operation(&amp;pending_op_counter_);</a>
<a name="ln3127">  RETURN_NOT_OK(scoped_read_operation);</a>
<a name="ln3128"> </a>
<a name="ln3129">  RETURN_NOT_OK(Flush(FlushMode::kSync));</a>
<a name="ln3130"> </a>
<a name="ln3131">  auto metadata = VERIFY_RESULT(metadata_-&gt;CreateSubtabletMetadata(</a>
<a name="ln3132">      tablet_id, partition, key_bounds.lower.ToStringBuffer(), key_bounds.upper.ToStringBuffer()));</a>
<a name="ln3133"> </a>
<a name="ln3134">  RETURN_NOT_OK(snapshots_-&gt;CreateCheckpoint(</a>
<a name="ln3135">      metadata-&gt;rocksdb_dir(), CreateIntentsCheckpointIn::kSubDir));</a>
<a name="ln3136"> </a>
<a name="ln3137">  // We want flushed frontier to cover split_op_id, so during bootstrap of after-split tablets</a>
<a name="ln3138">  // we don't replay split operation.</a>
<a name="ln3139">  docdb::ConsensusFrontier frontier;</a>
<a name="ln3140">  frontier.set_op_id(split_op_id);</a>
<a name="ln3141">  frontier.set_hybrid_time(split_op_hybrid_time);</a>
<a name="ln3142"> </a>
<a name="ln3143">  struct RocksDbDirWithType {</a>
<a name="ln3144">    std::string db_dir;</a>
<a name="ln3145">    docdb::StorageDbType db_type;</a>
<a name="ln3146">  };</a>
<a name="ln3147">  boost::container::static_vector&lt;RocksDbDirWithType, 2&gt; subtablet_rocksdbs(</a>
<a name="ln3148">      {{ metadata-&gt;rocksdb_dir(), docdb::StorageDbType::kRegular }});</a>
<a name="ln3149">  if (intents_db_) {</a>
<a name="ln3150">    subtablet_rocksdbs.push_back(</a>
<a name="ln3151">        { metadata-&gt;intents_rocksdb_dir(), docdb::StorageDbType::kIntents });</a>
<a name="ln3152">  }</a>
<a name="ln3153">  for (auto rocksdb : subtablet_rocksdbs) {</a>
<a name="ln3154">    rocksdb::Options rocksdb_options;</a>
<a name="ln3155">    docdb::InitRocksDBOptions(</a>
<a name="ln3156">        &amp;rocksdb_options, MakeTabletLogPrefix(tablet_id, log_prefix_suffix_, rocksdb.db_type),</a>
<a name="ln3157">        /* statistics */ nullptr, tablet_options_);</a>
<a name="ln3158">    rocksdb_options.create_if_missing = false;</a>
<a name="ln3159">    std::unique_ptr&lt;rocksdb::DB&gt; db =</a>
<a name="ln3160">        VERIFY_RESULT(rocksdb::DB::Open(rocksdb_options, rocksdb.db_dir));</a>
<a name="ln3161">    RETURN_NOT_OK(</a>
<a name="ln3162">        db-&gt;ModifyFlushedFrontier(frontier.Clone(), rocksdb::FrontierModificationMode::kUpdate));</a>
<a name="ln3163">  }</a>
<a name="ln3164">  return metadata;</a>
<a name="ln3165">}</a>
<a name="ln3166"> </a>
<a name="ln3167">Result&lt;int64_t&gt; Tablet::CountIntents() {</a>
<a name="ln3168">  ScopedRWOperation pending_op(&amp;pending_op_counter_);</a>
<a name="ln3169">  RETURN_NOT_OK(pending_op);</a>
<a name="ln3170"> </a>
<a name="ln3171">  if (!intents_db_) {</a>
<a name="ln3172">    return 0;</a>
<a name="ln3173">  }</a>
<a name="ln3174">  rocksdb::ReadOptions read_options;</a>
<a name="ln3175">  auto intent_iter = std::unique_ptr&lt;rocksdb::Iterator&gt;(</a>
<a name="ln3176">      intents_db_-&gt;NewIterator(read_options));</a>
<a name="ln3177">  int64_t num_intents = 0;</a>
<a name="ln3178">  intent_iter-&gt;SeekToFirst();</a>
<a name="ln3179">  while (intent_iter-&gt;Valid()) {</a>
<a name="ln3180">    num_intents++;</a>
<a name="ln3181">    intent_iter-&gt;Next();</a>
<a name="ln3182">  }</a>
<a name="ln3183">  return num_intents;</a>
<a name="ln3184">}</a>
<a name="ln3185"> </a>
<a name="ln3186">void Tablet::ListenNumSSTFilesChanged(std::function&lt;void()&gt; listener) {</a>
<a name="ln3187">  std::lock_guard&lt;std::mutex&gt; lock(num_sst_files_changed_listener_mutex_);</a>
<a name="ln3188">  bool has_new_listener = listener != nullptr;</a>
<a name="ln3189">  bool has_old_listener = num_sst_files_changed_listener_ != nullptr;</a>
<a name="ln3190">  LOG_IF_WITH_PREFIX(DFATAL, has_new_listener == has_old_listener)</a>
<a name="ln3191">      &lt;&lt; __func__ &lt;&lt; &quot; in wrong state, has_old_listener: &quot; &lt;&lt; has_old_listener;</a>
<a name="ln3192">  num_sst_files_changed_listener_ = std::move(listener);</a>
<a name="ln3193">}</a>
<a name="ln3194"> </a>
<a name="ln3195">void Tablet::InitRocksDBOptions(rocksdb::Options* options, const std::string&amp; log_prefix) {</a>
<a name="ln3196">  docdb::InitRocksDBOptions(options, log_prefix, rocksdb_statistics_, tablet_options_);</a>
<a name="ln3197">}</a>
<a name="ln3198"> </a>
<a name="ln3199">rocksdb::Env&amp; Tablet::rocksdb_env() const {</a>
<a name="ln3200">  return *tablet_options_.rocksdb_env;</a>
<a name="ln3201">}</a>
<a name="ln3202"> </a>
<a name="ln3203">Result&lt;std::string&gt; Tablet::GetEncodedMiddleSplitKey() const {</a>
<a name="ln3204">  // TODO(tsplit): should take key_bounds_ into account.</a>
<a name="ln3205">  auto middle_key = VERIFY_RESULT(regular_db_-&gt;GetMiddleKey());</a>
<a name="ln3206">  const auto key_part = metadata()-&gt;partition_schema()-&gt;IsHashPartitioning()</a>
<a name="ln3207">                            ? docdb::DocKeyPart::kUpToHashCode</a>
<a name="ln3208">                            : docdb::DocKeyPart::kWholeDocKey;</a>
<a name="ln3209">  const auto split_key_size = VERIFY_RESULT(DocKey::EncodedSize(middle_key, key_part));</a>
<a name="ln3210">  middle_key.resize(split_key_size);</a>
<a name="ln3211">  return middle_key;</a>
<a name="ln3212">}</a>
<a name="ln3213"> </a>
<a name="ln3214">// ------------------------------------------------------------------------------------------------</a>
<a name="ln3215"> </a>
<a name="ln3216">Result&lt;ScopedReadOperation&gt; ScopedReadOperation::Create(</a>
<a name="ln3217">    AbstractTablet* tablet,</a>
<a name="ln3218">    RequireLease require_lease,</a>
<a name="ln3219">    ReadHybridTime read_time) {</a>
<a name="ln3220">  if (!read_time) {</a>
<a name="ln3221">    read_time = ReadHybridTime::SingleTime(tablet-&gt;SafeTime(require_lease));</a>
<a name="ln3222">  }</a>
<a name="ln3223">  auto* retention_policy = tablet-&gt;RetentionPolicy();</a>
<a name="ln3224">  if (retention_policy) {</a>
<a name="ln3225">    RETURN_NOT_OK(retention_policy-&gt;RegisterReaderTimestamp(read_time.read));</a>
<a name="ln3226">  }</a>
<a name="ln3227">  return ScopedReadOperation(tablet, read_time);</a>
<a name="ln3228">}</a>
<a name="ln3229"> </a>
<a name="ln3230">ScopedReadOperation::ScopedReadOperation(</a>
<a name="ln3231">    AbstractTablet* tablet, const ReadHybridTime&amp; read_time)</a>
<a name="ln3232">    : tablet_(tablet), read_time_(read_time) {</a>
<a name="ln3233">}</a>
<a name="ln3234"> </a>
<a name="ln3235">ScopedReadOperation::~ScopedReadOperation() {</a>
<a name="ln3236">  Reset();</a>
<a name="ln3237">}</a>
<a name="ln3238"> </a>
<a name="ln3239">void ScopedReadOperation::operator=(ScopedReadOperation&amp;&amp; rhs) {</a>
<a name="ln3240">  Reset();</a>
<a name="ln3241">  tablet_ = rhs.tablet_;</a>
<a name="ln3242">  read_time_ = rhs.read_time_;</a>
<a name="ln3243">  rhs.tablet_ = nullptr;</a>
<a name="ln3244">}</a>
<a name="ln3245"> </a>
<a name="ln3246">void ScopedReadOperation::Reset() {</a>
<a name="ln3247">  if (tablet_) {</a>
<a name="ln3248">    auto* retention_policy = tablet_-&gt;RetentionPolicy();</a>
<a name="ln3249">    if (retention_policy) {</a>
<a name="ln3250">      retention_policy-&gt;UnregisterReaderTimestamp(read_time_.read);</a>
<a name="ln3251">    }</a>
<a name="ln3252">    tablet_ = nullptr;</a>
<a name="ln3253">  }</a>
<a name="ln3254">}</a>
<a name="ln3255"> </a>
<a name="ln3256">}  // namespace tablet</a>
<a name="ln3257">}  // namespace yb</a>

</code></pre>
<div class="balloon" rel="411"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="479"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="501"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="511"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="572"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="587"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="592"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="599"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="608"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="940"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="991"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1021"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1067"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1208"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v614/" target="_blank">V614</a> Potentially null smart pointer 'operation' used.</p></div>
<div class="balloon" rel="1216"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v1023/" target="_blank">V1023</a> A pointer without owner is added to the 'doc_ops' container by the 'emplace_back' method. A memory leak will occur in case of an exception.</p></div>
<div class="balloon" rel="1265"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1326"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1354"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1365"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1417"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1468"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1550"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1823"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2113"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2136"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2210"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2231"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2234"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2238"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2304"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2306"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2308"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2317"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2328"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2350"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2357"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2374"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2389"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v612/" target="_blank">V612</a> An unconditional 'return' within a loop.</p></div>
<div class="balloon" rel="2424"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2499"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2951"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="3190"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="2669"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v730/" target="_blank">V730</a> Not all members of a class are initialized inside the constructor. Consider inspecting: isolation_level_.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
