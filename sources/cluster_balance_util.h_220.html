
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
  <title>cluster_balance_util.h</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">// Copyright (c) YugaByte, Inc.</a>
<a name="ln2">//</a>
<a name="ln3">// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except</a>
<a name="ln4">// in compliance with the License.  You may obtain a copy of the License at</a>
<a name="ln5">//</a>
<a name="ln6">// http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="ln7">//</a>
<a name="ln8">// Unless required by applicable law or agreed to in writing, software distributed under the License</a>
<a name="ln9">// is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express</a>
<a name="ln10">// or implied.  See the License for the specific language governing permissions and limitations</a>
<a name="ln11">// under the License.</a>
<a name="ln12">//</a>
<a name="ln13"> </a>
<a name="ln14">#ifndef YB_MASTER_CLUSTER_BALANCE_UTIL_H</a>
<a name="ln15">#define YB_MASTER_CLUSTER_BALANCE_UTIL_H</a>
<a name="ln16"> </a>
<a name="ln17">#include &lt;unordered_set&gt;</a>
<a name="ln18"> </a>
<a name="ln19">#include &lt;map&gt;</a>
<a name="ln20">#include &lt;memory&gt;</a>
<a name="ln21">#include &lt;set&gt;</a>
<a name="ln22">#include &lt;string&gt;</a>
<a name="ln23">#include &lt;unordered_map&gt;</a>
<a name="ln24">#include &lt;vector&gt;</a>
<a name="ln25">#include &lt;atomic&gt;</a>
<a name="ln26"> </a>
<a name="ln27">#include &quot;yb/master/catalog_manager.h&quot;</a>
<a name="ln28">#include &quot;yb/master/ts_descriptor.h&quot;</a>
<a name="ln29">#include &quot;yb/util/random.h&quot;</a>
<a name="ln30"> </a>
<a name="ln31">DECLARE_int32(min_leader_stepdown_retry_interval_ms);</a>
<a name="ln32"> </a>
<a name="ln33">DECLARE_bool(enable_load_balancing);</a>
<a name="ln34"> </a>
<a name="ln35">DECLARE_bool(transaction_tables_use_preferred_zones);</a>
<a name="ln36"> </a>
<a name="ln37">DECLARE_int32(leader_balance_threshold);</a>
<a name="ln38"> </a>
<a name="ln39">DECLARE_int32(leader_balance_unresponsive_timeout_ms);</a>
<a name="ln40"> </a>
<a name="ln41">DECLARE_int32(replication_factor);</a>
<a name="ln42"> </a>
<a name="ln43">DECLARE_int32(load_balancer_max_concurrent_tablet_remote_bootstraps);</a>
<a name="ln44"> </a>
<a name="ln45">DECLARE_int32(load_balancer_max_concurrent_tablet_remote_bootstraps_per_table);</a>
<a name="ln46"> </a>
<a name="ln47">DECLARE_int32(load_balancer_max_over_replicated_tablets);</a>
<a name="ln48"> </a>
<a name="ln49">DECLARE_int32(load_balancer_max_concurrent_adds);</a>
<a name="ln50"> </a>
<a name="ln51">DECLARE_int32(load_balancer_max_concurrent_removals);</a>
<a name="ln52"> </a>
<a name="ln53">DECLARE_int32(load_balancer_max_concurrent_moves);</a>
<a name="ln54"> </a>
<a name="ln55">DECLARE_int32(load_balancer_max_concurrent_moves_per_table);</a>
<a name="ln56"> </a>
<a name="ln57">namespace yb {</a>
<a name="ln58">namespace master {</a>
<a name="ln59"> </a>
<a name="ln60">struct cloud_equal_to {</a>
<a name="ln61">  bool operator()(const yb::CloudInfoPB&amp; x, const yb::CloudInfoPB&amp; y) const {</a>
<a name="ln62">    return x.placement_cloud() == y.placement_cloud() &amp;&amp;</a>
<a name="ln63">        x.placement_region() == y.placement_region() &amp;&amp;</a>
<a name="ln64">        x.placement_zone() == y.placement_zone();</a>
<a name="ln65">  }</a>
<a name="ln66">};</a>
<a name="ln67"> </a>
<a name="ln68">struct cloud_hash {</a>
<a name="ln69">  std::size_t operator()(const yb::CloudInfoPB&amp; ci) const {</a>
<a name="ln70">    return std::hash&lt;std::string&gt;{} (TSDescriptor::generate_placement_id(ci));</a>
<a name="ln71">  }</a>
<a name="ln72">};</a>
<a name="ln73"> </a>
<a name="ln74">using AffinitizedZonesSet = unordered_set&lt;CloudInfoPB, cloud_hash, cloud_equal_to&gt;;</a>
<a name="ln75"> </a>
<a name="ln76">struct CBTabletMetadata {</a>
<a name="ln77">  bool is_missing_replicas() { return is_under_replicated || !under_replicated_placements.empty(); }</a>
<a name="ln78"> </a>
<a name="ln79">  bool has_wrong_placements() {</a>
<a name="ln80">    return !wrong_placement_tablet_servers.empty() || !blacklisted_tablet_servers.empty();</a>
<a name="ln81">  }</a>
<a name="ln82"> </a>
<a name="ln83">  bool has_blacklisted_leader() {</a>
<a name="ln84">    return !leader_blacklisted_tablet_servers.empty();</a>
<a name="ln85">  }</a>
<a name="ln86"> </a>
<a name="ln87">  // Number of running replicas for this tablet.</a>
<a name="ln88">  int running = 0;</a>
<a name="ln89"> </a>
<a name="ln90">  // TODO(bogdan): actually use this!</a>
<a name="ln91">  //</a>
<a name="ln92">  // Number of starting replicas for this tablet.</a>
<a name="ln93">  int starting = 0;</a>
<a name="ln94"> </a>
<a name="ln95">  // If this tablet has fewer replicas than the configured number in the PlacementInfoPB.</a>
<a name="ln96">  bool is_under_replicated = false;</a>
<a name="ln97"> </a>
<a name="ln98">  // Set of placement ids that have less replicas available than the configured minimums.</a>
<a name="ln99">  std::set&lt;PlacementId&gt; under_replicated_placements;</a>
<a name="ln100"> </a>
<a name="ln101">  // If this tablet has more replicas than the configured number in the PlacementInfoPB.</a>
<a name="ln102">  bool is_over_replicated;</a>
<a name="ln103"> </a>
<a name="ln104">  // Set of tablet server ids that can be candidates for removal, due to tablet being</a>
<a name="ln105">  // over-replicated. For tablets with placement information, this will be all tablet servers</a>
<a name="ln106">  // that are housing replicas of this tablet, in a placement with strictly more replicas than the</a>
<a name="ln107">  // configured minimum (as that means there is at least one of them we can remove, and still</a>
<a name="ln108">  // respect the minimum).</a>
<a name="ln109">  //</a>
<a name="ln110">  // For tablets with no placement information, this will be all the tablet servers currently</a>
<a name="ln111">  // serving this tablet, as we can downsize with no restrictions in this case.</a>
<a name="ln112">  std::set&lt;TabletServerId&gt; over_replicated_tablet_servers;</a>
<a name="ln113"> </a>
<a name="ln114">  // Set of tablet server ids whose placement information does not match that listed in the</a>
<a name="ln115">  // table's PlacementInfoPB. This will happen when we change the configuration for the table or</a>
<a name="ln116">  // the cluster.</a>
<a name="ln117">  std::set&lt;TabletServerId&gt; wrong_placement_tablet_servers;</a>
<a name="ln118"> </a>
<a name="ln119">  // Set of tablet server ids that have been blacklisted and as such, should not get any more load</a>
<a name="ln120">  // assigned to them and should be prioritized for removing load.</a>
<a name="ln121">  std::set&lt;TabletServerId&gt; blacklisted_tablet_servers;</a>
<a name="ln122">  std::set&lt;TabletServerId&gt; leader_blacklisted_tablet_servers;</a>
<a name="ln123"> </a>
<a name="ln124">  // The tablet server id of the leader in this tablet's peer group.</a>
<a name="ln125">  TabletServerId leader_uuid;</a>
<a name="ln126"> </a>
<a name="ln127">  // Leader stepdown failures. We use this to prevent retrying the same leader stepdown too soon.</a>
<a name="ln128">  LeaderStepDownFailureTimes leader_stepdown_failures;</a>
<a name="ln129"> </a>
<a name="ln130">  std::string ToString() const {</a>
<a name="ln131">    return Format(&quot;{ running: $0 starting: $1 is_under_replicated: $2 &quot;</a>
<a name="ln132">                      &quot;under_replicated_placements: $3 is_over_replicated: $4 &quot;</a>
<a name="ln133">                      &quot;over_replicated_tablet_servers: $5 wrong_placement_tablet_servers: $6 &quot;</a>
<a name="ln134">                      &quot;blacklisted_tablet_servers: $7 leader_uuid: $8 &quot;</a>
<a name="ln135">                      &quot;leader_stepdown_failures: $9 leader_blacklisted_tablet_servers: $10}&quot;,</a>
<a name="ln136">                  running, starting, is_under_replicated, under_replicated_placements,</a>
<a name="ln137">                  is_over_replicated, over_replicated_tablet_servers,</a>
<a name="ln138">                  wrong_placement_tablet_servers, blacklisted_tablet_servers,</a>
<a name="ln139">                  leader_uuid, leader_stepdown_failures, leader_blacklisted_tablet_servers);</a>
<a name="ln140">  }</a>
<a name="ln141">};</a>
<a name="ln142"> </a>
<a name="ln143">struct CBTabletServerMetadata {</a>
<a name="ln144">  // The TSDescriptor for this tablet server.</a>
<a name="ln145">  std::shared_ptr&lt;TSDescriptor&gt; descriptor = nullptr;</a>
<a name="ln146"> </a>
<a name="ln147">  // The set of tablet ids that this tablet server is currently running.</a>
<a name="ln148">  std::set&lt;TabletId&gt; running_tablets;</a>
<a name="ln149"> </a>
<a name="ln150">  // The set of tablet ids that this tablet server is currently starting.</a>
<a name="ln151">  std::set&lt;TabletId&gt; starting_tablets;</a>
<a name="ln152"> </a>
<a name="ln153">  // The set of tablet leader ids that this tablet server is currently running.</a>
<a name="ln154">  std::set&lt;TabletId&gt; leaders;</a>
<a name="ln155">};</a>
<a name="ln156"> </a>
<a name="ln157">struct Options {</a>
<a name="ln158">  Options() {}</a>
<a name="ln159">  virtual ~Options() {}</a>
<a name="ln160">  // If variance between load on TS goes past this number, we should try to balance.</a>
<a name="ln161">  double kMinLoadVarianceToBalance = 2.0;</a>
<a name="ln162"> </a>
<a name="ln163">  // If variance between leader load on TS goes past this number, we should try to balance.</a>
<a name="ln164">  double kMinLeaderLoadVarianceToBalance = 2.0;</a>
<a name="ln165"> </a>
<a name="ln166">  // Whether to limit the number of tablets being spun up on the cluster at any given time.</a>
<a name="ln167">  bool kAllowLimitStartingTablets = true;</a>
<a name="ln168"> </a>
<a name="ln169">  // Max number of tablets being remote bootstrapped across the cluster, if we enable limiting</a>
<a name="ln170">  // this.</a>
<a name="ln171">  int kMaxTabletRemoteBootstraps = FLAGS_load_balancer_max_concurrent_tablet_remote_bootstraps;</a>
<a name="ln172"> </a>
<a name="ln173">  // Max number of tablets being remote bootstrapped for a specific table, if we enable limiting</a>
<a name="ln174">  // this.</a>
<a name="ln175">  int kMaxTabletRemoteBootstrapsPerTable =</a>
<a name="ln176">      FLAGS_load_balancer_max_concurrent_tablet_remote_bootstraps_per_table;</a>
<a name="ln177"> </a>
<a name="ln178">  // Whether to limit the number of tablets that have more peers than configured at any given</a>
<a name="ln179">  // time.</a>
<a name="ln180">  bool kAllowLimitOverReplicatedTablets = true;</a>
<a name="ln181"> </a>
<a name="ln182">  // Max number of running tablet replicas that are over the configured limit.</a>
<a name="ln183">  int kMaxOverReplicatedTablets = FLAGS_load_balancer_max_over_replicated_tablets;</a>
<a name="ln184"> </a>
<a name="ln185">  // Max number of over-replicated tablet peer removals to do in any one run of the load balancer.</a>
<a name="ln186">  int kMaxConcurrentRemovals = FLAGS_load_balancer_max_concurrent_removals;</a>
<a name="ln187"> </a>
<a name="ln188">  // Max number of tablet peer replicas to add in any one run of the load balancer.</a>
<a name="ln189">  int kMaxConcurrentAdds = FLAGS_load_balancer_max_concurrent_adds;</a>
<a name="ln190"> </a>
<a name="ln191">  // Max number of tablet leaders on tablet servers (across the cluster) to move in any one run of</a>
<a name="ln192">  // the load balancer.</a>
<a name="ln193">  int kMaxConcurrentLeaderMoves = FLAGS_load_balancer_max_concurrent_moves;</a>
<a name="ln194"> </a>
<a name="ln195">  // Max number of tablet leaders per table to move in any one run of the load balancer.</a>
<a name="ln196">  int kMaxConcurrentLeaderMovesPerTable = FLAGS_load_balancer_max_concurrent_moves_per_table;</a>
<a name="ln197"> </a>
<a name="ln198">  // TODO(bogdan): add state for leaders starting remote bootstraps, to limit on that end too.</a>
<a name="ln199">};</a>
<a name="ln200"> </a>
<a name="ln201">// Cluster-wide state and metrics.</a>
<a name="ln202">// For now it's only used to determine how many tablets are being remote bootstrapped across the</a>
<a name="ln203">// cluster.</a>
<a name="ln204">class GlobalLoadState {</a>
<a name="ln205"> public:</a>
<a name="ln206">  int total_starting_tablets_ = 0;</a>
<a name="ln207">};</a>
<a name="ln208"> </a>
<a name="ln209">class PerTableLoadState {</a>
<a name="ln210"> public:</a>
<a name="ln211">  TableId table_id_;</a>
<a name="ln212">  explicit PerTableLoadState(GlobalLoadState* global_state)</a>
<a name="ln213">      : leader_balance_threshold_(FLAGS_leader_balance_threshold),</a>
<a name="ln214">        current_time_(MonoTime::Now()),</a>
<a name="ln215">        global_state_(global_state) {}</a>
<a name="ln216">  virtual ~PerTableLoadState() {}</a>
<a name="ln217"> </a>
<a name="ln218">  // Comparators used for sorting by load.</a>
<a name="ln219">  bool CompareByUuid(const TabletServerId&amp; a, const TabletServerId&amp; b) {</a>
<a name="ln220">    int load_a = GetLoad(a);</a>
<a name="ln221">    int load_b = GetLoad(b);</a>
<a name="ln222">    if (load_a == load_b) {</a>
<a name="ln223">      return a &lt; b;</a>
<a name="ln224">    } else {</a>
<a name="ln225">      return load_a &lt; load_b;</a>
<a name="ln226">    }</a>
<a name="ln227">  }</a>
<a name="ln228"> </a>
<a name="ln229">  bool CompareByReplica(const TabletReplica&amp; a, const TabletReplica&amp; b) {</a>
<a name="ln230">    return CompareByUuid(a.ts_desc-&gt;permanent_uuid(), b.ts_desc-&gt;permanent_uuid());</a>
<a name="ln231">  }</a>
<a name="ln232"> </a>
<a name="ln233">  // Comparator functor to be able to wrap around the public but non-static compare methods that</a>
<a name="ln234">  // end up using internal state of the class.</a>
<a name="ln235">  struct Comparator {</a>
<a name="ln236">    explicit Comparator(PerTableLoadState* state) : state_(state) {}</a>
<a name="ln237">    bool operator()(const TabletServerId&amp; a, const TabletServerId&amp; b) {</a>
<a name="ln238">      return state_-&gt;CompareByUuid(a, b);</a>
<a name="ln239">    }</a>
<a name="ln240"> </a>
<a name="ln241">    bool operator()(const TabletReplica&amp; a, const TabletReplica&amp; b) {</a>
<a name="ln242">      return state_-&gt;CompareByReplica(a, b);</a>
<a name="ln243">    }</a>
<a name="ln244"> </a>
<a name="ln245">    PerTableLoadState* state_;</a>
<a name="ln246">  };</a>
<a name="ln247"> </a>
<a name="ln248">  // Comparator to sort tablet servers' leader load.</a>
<a name="ln249">  struct LeaderLoadComparator {</a>
<a name="ln250">    explicit LeaderLoadComparator(PerTableLoadState* state) : state_(state) {}</a>
<a name="ln251">    bool operator()(const TabletServerId&amp; a, const TabletServerId&amp; b) {</a>
<a name="ln252">      // Primary criteria: whether tserver is leader blacklisted.</a>
<a name="ln253">      auto a_leader_blacklisted =</a>
<a name="ln254">        state_-&gt;leader_blacklisted_servers_.find(a) != state_-&gt;leader_blacklisted_servers_.end();</a>
<a name="ln255">      auto b_leader_blacklisted =</a>
<a name="ln256">        state_-&gt;leader_blacklisted_servers_.find(b) != state_-&gt;leader_blacklisted_servers_.end();</a>
<a name="ln257">      if (a_leader_blacklisted != b_leader_blacklisted) {</a>
<a name="ln258">        return !a_leader_blacklisted;</a>
<a name="ln259">      }</a>
<a name="ln260"> </a>
<a name="ln261">      // Secondary criteria: tserver leader load.</a>
<a name="ln262">      return state_-&gt;GetLeaderLoad(a) &lt; state_-&gt;GetLeaderLoad(b);</a>
<a name="ln263">    }</a>
<a name="ln264">    PerTableLoadState* state_;</a>
<a name="ln265">  };</a>
<a name="ln266"> </a>
<a name="ln267">  // Get the load for a certain TS.</a>
<a name="ln268">  int GetLoad(const TabletServerId&amp; ts_uuid) const {</a>
<a name="ln269">    const auto&amp; ts_meta = per_ts_meta_.at(ts_uuid);</a>
<a name="ln270">    return ts_meta.starting_tablets.size() + ts_meta.running_tablets.size();</a>
<a name="ln271">  }</a>
<a name="ln272"> </a>
<a name="ln273">  // Get the load for a certain TS.</a>
<a name="ln274">  int GetLeaderLoad(const TabletServerId&amp; ts_uuid) const {</a>
<a name="ln275">    return per_ts_meta_.at(ts_uuid).leaders.size();</a>
<a name="ln276">  }</a>
<a name="ln277"> </a>
<a name="ln278">  void SetBlacklist(const BlacklistPB&amp; blacklist) { blacklist_ = blacklist; }</a>
<a name="ln279">  void SetLeaderBlacklist(const BlacklistPB&amp; leader_blacklist) {</a>
<a name="ln280">    leader_blacklist_ = leader_blacklist;</a>
<a name="ln281">  }</a>
<a name="ln282"> </a>
<a name="ln283">  // Update the per-tablet information for this tablet.</a>
<a name="ln284">  Status UpdateTablet(TabletInfo* tablet) {</a>
<a name="ln285">    const auto&amp; tablet_id = tablet-&gt;id();</a>
<a name="ln286">    // Set the per-tablet entry to empty default and get the reference for filling up information.</a>
<a name="ln287">    auto&amp; tablet_meta = per_tablet_meta_[tablet_id];</a>
<a name="ln288"> </a>
<a name="ln289">    // Get the placement for this tablet.</a>
<a name="ln290">    const auto&amp; placement = placement_by_table_[tablet-&gt;table()-&gt;id()];</a>
<a name="ln291"> </a>
<a name="ln292">    // Get replicas for this tablet.</a>
<a name="ln293">    TabletInfo::ReplicaMap replica_map;</a>
<a name="ln294">    GetReplicaLocations(tablet, &amp;replica_map);</a>
<a name="ln295">    // Set state information for both the tablet and the tablet server replicas.</a>
<a name="ln296">    for (const auto&amp; replica : replica_map) {</a>
<a name="ln297">      const auto&amp; ts_uuid = replica.first;</a>
<a name="ln298">      // If we do not have ts_meta information for this particular replica, then we are in the</a>
<a name="ln299">      // rare case where we just became the master leader and started doing load balancing, but we</a>
<a name="ln300">      // have yet to receive heartbeats from all the tablet servers. We will just return false</a>
<a name="ln301">      // across the stack and stop load balancing and log errors, until we get all the needed info.</a>
<a name="ln302">      //</a>
<a name="ln303">      // Worst case scenario, there is a network partition that is stopping us from actually</a>
<a name="ln304">      // getting the heartbeats from a certain tablet server, but we anticipate that to be a</a>
<a name="ln305">      // temporary matter. We should monitor error logs for this and see that it never actually</a>
<a name="ln306">      // becomes a problem!</a>
<a name="ln307">      auto ts_meta_it = per_ts_meta_.find(ts_uuid);</a>
<a name="ln308">      if (ts_meta_it == per_ts_meta_.end()) {</a>
<a name="ln309">        return STATUS_SUBSTITUTE(LeaderNotReadyToServe, &quot;Master leader has not yet received &quot;</a>
<a name="ln310">            &quot;heartbeat from ts $0, either master just became leader or a network partition.&quot;,</a>
<a name="ln311">                                 ts_uuid);</a>
<a name="ln312">      }</a>
<a name="ln313"> </a>
<a name="ln314">      // Fill leader info.</a>
<a name="ln315">      if (replica.second.role == consensus::RaftPeerPB::LEADER) {</a>
<a name="ln316">        tablet_meta.leader_uuid = ts_uuid;</a>
<a name="ln317">        ts_meta_it-&gt;second.leaders.insert(tablet_id);</a>
<a name="ln318">      }</a>
<a name="ln319"> </a>
<a name="ln320">      const tablet::RaftGroupStatePB&amp; tablet_state = replica.second.state;</a>
<a name="ln321">      const bool replica_is_stale = replica.second.IsStale();</a>
<a name="ln322">      VLOG(2) &lt;&lt; &quot;Tablet &quot; &lt;&lt; tablet_id &lt;&lt; &quot; for table &quot; &lt;&lt; table_id_</a>
<a name="ln323">                &lt;&lt; &quot; is in state &quot; &lt;&lt; RaftGroupStatePB_Name(tablet_state);</a>
<a name="ln324">      if (tablet_state == tablet::RUNNING) {</a>
<a name="ln325">        ts_meta_it-&gt;second.running_tablets.insert(tablet_id);</a>
<a name="ln326">        ++tablet_meta.running;</a>
<a name="ln327">        ++total_running_;</a>
<a name="ln328">      } else if (!replica_is_stale &amp;&amp;</a>
<a name="ln329">                 (tablet_state == tablet::BOOTSTRAPPING || tablet_state == tablet::NOT_STARTED)) {</a>
<a name="ln330">        // Keep track of transitioning state (not running, but not in a stopped or failed state).</a>
<a name="ln331">        ts_meta_it-&gt;second.starting_tablets.insert(tablet_id);</a>
<a name="ln332">        ++tablet_meta.starting;</a>
<a name="ln333">        ++total_starting_;</a>
<a name="ln334">        VLOG(1) &lt;&lt; &quot;Increased total_starting to &quot;</a>
<a name="ln335">                   &lt;&lt; total_starting_ &lt;&lt; &quot; for tablet &quot; &lt;&lt; tablet_id &lt;&lt; &quot; and table &quot; &lt;&lt; table_id_;</a>
<a name="ln336">        ++global_state_-&gt;total_starting_tablets_;</a>
<a name="ln337">      } else if (replica_is_stale) {</a>
<a name="ln338">        VLOG(1) &lt;&lt; &quot;Replica is stale: &quot; &lt;&lt; replica.second.ToString();</a>
<a name="ln339">      }</a>
<a name="ln340"> </a>
<a name="ln341">      // If this replica is blacklisted, we want to keep track of these specially, so we can</a>
<a name="ln342">      // prioritize accordingly.</a>
<a name="ln343">      if (blacklisted_servers_.count(ts_uuid)) {</a>
<a name="ln344">        tablet_meta.blacklisted_tablet_servers.insert(ts_uuid);</a>
<a name="ln345">      }</a>
<a name="ln346"> </a>
<a name="ln347">      // If this replica has blacklisted leader, we want to keep track of these specially, so we can</a>
<a name="ln348">      // prioritize accordingly.</a>
<a name="ln349">      if (leader_blacklisted_servers_.count(ts_uuid)) {</a>
<a name="ln350">        tablet_meta.leader_blacklisted_tablet_servers.insert(ts_uuid);</a>
<a name="ln351">      }</a>
<a name="ln352">    }</a>
<a name="ln353"> </a>
<a name="ln354">    // Only set the over-replication section if we need to.</a>
<a name="ln355">    int placement_num_replicas = placement.num_replicas() &gt; 0 ?</a>
<a name="ln356">        placement.num_replicas() : FLAGS_replication_factor;</a>
<a name="ln357">    tablet_meta.is_over_replicated = placement_num_replicas &lt; replica_map.size();</a>
<a name="ln358">    tablet_meta.is_under_replicated = placement_num_replicas &gt; replica_map.size();</a>
<a name="ln359"> </a>
<a name="ln360">    // If no placement information, we will have already set the over and under replication flags.</a>
<a name="ln361">    // For under-replication, we cannot use any placement_id, so we just leave the set empty and</a>
<a name="ln362">    // use that as a marker that we are in this situation.</a>
<a name="ln363">    //</a>
<a name="ln364">    // For over-replication, we just add all the ts_uuids as candidates.</a>
<a name="ln365">    if (placement.placement_blocks().empty()) {</a>
<a name="ln366">      if (tablet_meta.is_over_replicated) {</a>
<a name="ln367">        for (auto&amp; replica_entry : replica_map) {</a>
<a name="ln368">          tablet_meta.over_replicated_tablet_servers.insert(std::move(replica_entry.first));</a>
<a name="ln369">        }</a>
<a name="ln370">      }</a>
<a name="ln371">    } else {</a>
<a name="ln372">      // If we do have placement information, figure out how the load is distributed based on</a>
<a name="ln373">      // placement blocks, for this tablet.</a>
<a name="ln374">      unordered_map&lt;PlacementId, vector&lt;TabletReplica&gt;&gt; placement_to_replicas;</a>
<a name="ln375">      unordered_map&lt;PlacementId, int&gt; placement_to_min_replicas;</a>
<a name="ln376">      // Preset the min_replicas, so we know if we're missing replicas somewhere as well.</a>
<a name="ln377">      for (const auto&amp; pb : placement.placement_blocks()) {</a>
<a name="ln378">        const auto&amp; placement_id = TSDescriptor::generate_placement_id(pb.cloud_info());</a>
<a name="ln379">        // Default empty vector.</a>
<a name="ln380">        placement_to_replicas[placement_id];</a>
<a name="ln381">        placement_to_min_replicas[placement_id] = pb.min_num_replicas();</a>
<a name="ln382">      }</a>
<a name="ln383">      // Now actually fill the structures with matching TSs.</a>
<a name="ln384">      for (auto&amp; replica_entry : replica_map) {</a>
<a name="ln385">        if (VERIFY_RESULT(HasValidPlacement(replica_entry.first, &amp;placement))) {</a>
<a name="ln386">          const auto&amp; placement_id = per_ts_meta_[replica_entry.first].descriptor-&gt;placement_id();</a>
<a name="ln387">          placement_to_replicas[placement_id].push_back(std::move(replica_entry.second));</a>
<a name="ln388">        } else {</a>
<a name="ln389">          // If placement does not match, we likely changed the config or the schema and this</a>
<a name="ln390">          // tablet should no longer live on this tablet server.</a>
<a name="ln391">          tablet_meta.wrong_placement_tablet_servers.insert(std::move(replica_entry.first));</a>
<a name="ln392">        }</a>
<a name="ln393">      }</a>
<a name="ln394"> </a>
<a name="ln395">      // Loop over the data and populate extra replica as well as missing replica information.</a>
<a name="ln396">      for (const auto&amp; entry : placement_to_replicas) {</a>
<a name="ln397">        const auto&amp; placement_id = entry.first;</a>
<a name="ln398">        const auto&amp; replica_set = entry.second;</a>
<a name="ln399">        const auto min_num_replicas = placement_to_min_replicas[placement_id];</a>
<a name="ln400">        if (min_num_replicas &gt; replica_set.size()) {</a>
<a name="ln401">          // Placements that are under-replicated should be handled ASAP.</a>
<a name="ln402">          tablet_meta.under_replicated_placements.insert(placement_id);</a>
<a name="ln403">        } else if (tablet_meta.is_over_replicated &amp;&amp; min_num_replicas &lt; replica_set.size()) {</a>
<a name="ln404">          // If this tablet is over-replicated, consider all the placements that have more than the</a>
<a name="ln405">          // minimum number of tablets, as candidates for removing a replica.</a>
<a name="ln406">          for (auto&amp; replica : replica_set) {</a>
<a name="ln407">            tablet_meta.over_replicated_tablet_servers.insert(</a>
<a name="ln408">              std::move(replica.ts_desc-&gt;permanent_uuid()));</a>
<a name="ln409">          }</a>
<a name="ln410">        }</a>
<a name="ln411">      }</a>
<a name="ln412">    }</a>
<a name="ln413">    tablet-&gt;GetLeaderStepDownFailureTimes(</a>
<a name="ln414">        current_time_ - MonoDelta::FromMilliseconds(FLAGS_min_leader_stepdown_retry_interval_ms),</a>
<a name="ln415">        &amp;tablet_meta.leader_stepdown_failures);</a>
<a name="ln416"> </a>
<a name="ln417">    // Prepare placement related sets for tablets that have placement info.</a>
<a name="ln418">    if (tablet_meta.is_missing_replicas()) {</a>
<a name="ln419">      tablets_missing_replicas_.insert(tablet_id);</a>
<a name="ln420">    }</a>
<a name="ln421">    if (tablet_meta.is_over_replicated) {</a>
<a name="ln422">      tablets_over_replicated_.insert(tablet_id);</a>
<a name="ln423">    }</a>
<a name="ln424">    if (tablet_meta.has_wrong_placements()) {</a>
<a name="ln425">      tablets_wrong_placement_.insert(tablet_id);</a>
<a name="ln426">    }</a>
<a name="ln427"> </a>
<a name="ln428">    return Status::OK();</a>
<a name="ln429">  }</a>
<a name="ln430"> </a>
<a name="ln431">  virtual void UpdateTabletServer(std::shared_ptr&lt;TSDescriptor&gt; ts_desc) {</a>
<a name="ln432">    const auto&amp; ts_uuid = ts_desc-&gt;permanent_uuid();</a>
<a name="ln433">    // Set and get, so we can use this for both tablet servers we've added data to, as well as</a>
<a name="ln434">    // tablet servers that happen to not be serving any tablets, so were not in the map yet.</a>
<a name="ln435">    auto&amp; ts_meta = per_ts_meta_[ts_uuid];</a>
<a name="ln436">    ts_meta.descriptor = ts_desc;</a>
<a name="ln437"> </a>
<a name="ln438">    sorted_load_.push_back(ts_uuid);</a>
<a name="ln439"> </a>
<a name="ln440">    // Mark as blacklisted if it matches.</a>
<a name="ln441">    bool is_blacklisted = false;</a>
<a name="ln442">    for (const auto&amp; hp : blacklist_.hosts()) {</a>
<a name="ln443">      if (ts_meta.descriptor-&gt;IsRunningOn(hp)) {</a>
<a name="ln444">        blacklisted_servers_.insert(ts_uuid);</a>
<a name="ln445">        is_blacklisted = true;</a>
<a name="ln446">        break;</a>
<a name="ln447">      }</a>
<a name="ln448">    }</a>
<a name="ln449"> </a>
<a name="ln450">    // Mark as blacklisted leader if it matches.</a>
<a name="ln451">    for (const auto&amp; hp : leader_blacklist_.hosts()) {</a>
<a name="ln452">      if (ts_meta.descriptor-&gt;IsRunningOn(hp)) {</a>
<a name="ln453">        leader_blacklisted_servers_.insert(ts_uuid);</a>
<a name="ln454">        break;</a>
<a name="ln455">      }</a>
<a name="ln456">    }</a>
<a name="ln457"> </a>
<a name="ln458">    // Add this tablet server for leader load-balancing only if it is not blacklisted and it has</a>
<a name="ln459">    // heartbeated recently enough to be considered responsive for leader balancing.</a>
<a name="ln460">    if (!is_blacklisted &amp;&amp;</a>
<a name="ln461">        ts_desc-&gt;TimeSinceHeartbeat().ToMilliseconds() &lt;</a>
<a name="ln462">        FLAGS_leader_balance_unresponsive_timeout_ms) {</a>
<a name="ln463">      sorted_leader_load_.push_back(ts_uuid);</a>
<a name="ln464">    }</a>
<a name="ln465"> </a>
<a name="ln466">    if (ts_desc-&gt;HasTabletDeletePending()) {</a>
<a name="ln467">      servers_with_pending_deletes_.insert(ts_uuid);</a>
<a name="ln468">    }</a>
<a name="ln469">  }</a>
<a name="ln470"> </a>
<a name="ln471">  Result&lt;bool&gt; CanAddTabletToTabletServer(</a>
<a name="ln472">    const TabletId&amp; tablet_id, const TabletServerId&amp; to_ts,</a>
<a name="ln473">    const PlacementInfoPB* placement_info = nullptr) {</a>
<a name="ln474">    const auto&amp; ts_meta = per_ts_meta_[to_ts];</a>
<a name="ln475">    // If this tablet has already been added to a new tablet server, don't add it again.</a>
<a name="ln476">    if (tablets_added_.count(tablet_id)) {</a>
<a name="ln477">      return false;</a>
<a name="ln478">    }</a>
<a name="ln479">    // We do not add load to blacklisted servers.</a>
<a name="ln480">    if (blacklisted_servers_.count(to_ts)) {</a>
<a name="ln481">      return false;</a>
<a name="ln482">    }</a>
<a name="ln483">    // We cannot add a tablet to a tablet server if it is already serving it.</a>
<a name="ln484">    if (ts_meta.running_tablets.count(tablet_id) || ts_meta.starting_tablets.count(tablet_id)) {</a>
<a name="ln485">      return false;</a>
<a name="ln486">    }</a>
<a name="ln487">    // If we ask to use placement information, check against it.</a>
<a name="ln488">    if (placement_info &amp;&amp; !VERIFY_RESULT(HasValidPlacement(to_ts, placement_info))) {</a>
<a name="ln489">      LOG(INFO) &lt;&lt; &quot;tablet server &quot; &lt;&lt; to_ts &lt;&lt; &quot; has invalid placement info. &quot;</a>
<a name="ln490">                &lt;&lt; &quot;Not allowing it to take more tablets.&quot;;</a>
<a name="ln491">      return false;</a>
<a name="ln492">    }</a>
<a name="ln493">    // If this server has a pending tablet delete, don't use it.</a>
<a name="ln494">    if (servers_with_pending_deletes_.count(to_ts)) {</a>
<a name="ln495">      LOG(INFO) &lt;&lt; &quot;tablet server &quot; &lt;&lt; to_ts &lt;&lt; &quot; has a pending delete. &quot;</a>
<a name="ln496">                &lt;&lt; &quot;Not allowing it to take more tablets&quot;;</a>
<a name="ln497">      return false;</a>
<a name="ln498">    }</a>
<a name="ln499">    // If all checks pass, return true.</a>
<a name="ln500">    return true;</a>
<a name="ln501">  }</a>
<a name="ln502"> </a>
<a name="ln503">  Result&lt;bool&gt; HasValidPlacement(const TabletServerId&amp; ts_uuid,</a>
<a name="ln504">                                 const PlacementInfoPB* placement_info) {</a>
<a name="ln505">    if (!placement_info-&gt;placement_blocks().empty()) {</a>
<a name="ln506">      for (const auto&amp; pb : placement_info-&gt;placement_blocks()) {</a>
<a name="ln507">        if (per_ts_meta_[ts_uuid].descriptor-&gt;MatchesCloudInfo(pb.cloud_info())) {</a>
<a name="ln508">          return true;</a>
<a name="ln509">        }</a>
<a name="ln510">      }</a>
<a name="ln511">      return false;</a>
<a name="ln512">    }</a>
<a name="ln513">    return true;</a>
<a name="ln514">  }</a>
<a name="ln515"> </a>
<a name="ln516">  Result&lt;bool&gt; CanSelectWrongReplicaToMove(</a>
<a name="ln517">    const TabletId&amp; tablet_id, const PlacementInfoPB&amp; placement_info, TabletServerId* out_from_ts,</a>
<a name="ln518">    TabletServerId* out_to_ts) {</a>
<a name="ln519">    // We consider both invalid placements (potentially due to config or schema changes), as well</a>
<a name="ln520">    // as servers being blacklisted, as wrong placement.</a>
<a name="ln521">    const auto&amp; tablet_meta = per_tablet_meta_[tablet_id];</a>
<a name="ln522">    // Prioritize taking away load from blacklisted servers, then from wrong placements.</a>
<a name="ln523">    bool found_match = false;</a>
<a name="ln524">    // Use these to do a fallback move, if placement id is the only thing that does not match.</a>
<a name="ln525">    TabletServerId fallback_to_uuid;</a>
<a name="ln526">    TabletServerId fallback_from_uuid;</a>
<a name="ln527">    for (const auto&amp; from_uuid : tablet_meta.blacklisted_tablet_servers) {</a>
<a name="ln528">      bool invalid_placement = tablet_meta.wrong_placement_tablet_servers.count(from_uuid);</a>
<a name="ln529">      for (const auto&amp; to_uuid : sorted_load_) {</a>
<a name="ln530">        // TODO(bogdan): this could be made smarter if we kept track of per-placement numbers and</a>
<a name="ln531">        // allowed to remove one from one placement, as long as it is still above the minimum.</a>
<a name="ln532">        //</a>
<a name="ln533">        // If this is a blacklisted server, we should aim to still respect placement and for now,</a>
<a name="ln534">        // just try to move the load to the same placement. However, if the from_uuid was</a>
<a name="ln535">        // previously invalidly placed, then we should ignore its placement.</a>
<a name="ln536">        if (invalid_placement &amp;&amp;</a>
<a name="ln537">            VERIFY_RESULT(CanAddTabletToTabletServer(tablet_id, to_uuid, &amp;placement_info))) {</a>
<a name="ln538">          found_match = true;</a>
<a name="ln539">        } else {</a>
<a name="ln540">          if (VERIFY_RESULT(CanAddTabletToTabletServer(tablet_id, to_uuid))) {</a>
<a name="ln541">            const auto&amp; from_placement_id = per_ts_meta_[from_uuid].descriptor-&gt;placement_id();</a>
<a name="ln542">            const auto&amp; to_placement_id = per_ts_meta_[to_uuid].descriptor-&gt;placement_id();</a>
<a name="ln543">            if (from_placement_id == to_placement_id) {</a>
<a name="ln544">              found_match = true;</a>
<a name="ln545">            } else {</a>
<a name="ln546">              // ENG-500 : Placement does not match, but we can still use this combo as a fallback.</a>
<a name="ln547">              // It uses the last such pair, which should be fine.</a>
<a name="ln548">              fallback_to_uuid = to_uuid;</a>
<a name="ln549">              fallback_from_uuid = from_uuid;</a>
<a name="ln550">            }</a>
<a name="ln551">          }</a>
<a name="ln552">        }</a>
<a name="ln553">        if (found_match) {</a>
<a name="ln554">          *out_from_ts = from_uuid;</a>
<a name="ln555">          *out_to_ts = to_uuid;</a>
<a name="ln556">          return true;</a>
<a name="ln557">        }</a>
<a name="ln558">      }</a>
<a name="ln559">    }</a>
<a name="ln560"> </a>
<a name="ln561">    if (!fallback_to_uuid.empty()) {</a>
<a name="ln562">      *out_from_ts = fallback_from_uuid;</a>
<a name="ln563">      *out_to_ts = fallback_to_uuid;</a>
<a name="ln564">      return true;</a>
<a name="ln565">    }</a>
<a name="ln566"> </a>
<a name="ln567">    // TODO(bogdan): sort and pick the highest load as source.</a>
<a name="ln568">    //</a>
<a name="ln569">    // If we didn't have or find any blacklisted server to move load from, move to the wrong</a>
<a name="ln570">    // placement tablet servers. We can pick any of them as the source for now.</a>
<a name="ln571">    if (!tablet_meta.wrong_placement_tablet_servers.empty()) {</a>
<a name="ln572">      for (const auto&amp; to_uuid : sorted_load_) {</a>
<a name="ln573">        if (VERIFY_RESULT(CanAddTabletToTabletServer(tablet_id, to_uuid, &amp;placement_info))) {</a>
<a name="ln574">          *out_from_ts = *tablet_meta.wrong_placement_tablet_servers.begin();</a>
<a name="ln575">          *out_to_ts = to_uuid;</a>
<a name="ln576">          return true;</a>
<a name="ln577">        }</a>
<a name="ln578">      }</a>
<a name="ln579">    }</a>
<a name="ln580"> </a>
<a name="ln581">    return false;</a>
<a name="ln582">  }</a>
<a name="ln583"> </a>
<a name="ln584">  Status AddReplica(const TabletId&amp; tablet_id, const TabletServerId&amp; to_ts) {</a>
<a name="ln585">    per_ts_meta_[to_ts].starting_tablets.insert(tablet_id);</a>
<a name="ln586">    ++per_tablet_meta_[tablet_id].starting;</a>
<a name="ln587">    ++total_starting_;</a>
<a name="ln588">    ++global_state_-&gt;total_starting_tablets_;</a>
<a name="ln589">    tablets_added_.insert(tablet_id);</a>
<a name="ln590">    SortLoad();</a>
<a name="ln591">    return Status::OK();</a>
<a name="ln592">  }</a>
<a name="ln593"> </a>
<a name="ln594">  Status RemoveReplica(const TabletId&amp; tablet_id, const TabletServerId&amp; from_ts) {</a>
<a name="ln595">    if (per_ts_meta_[from_ts].running_tablets.count(tablet_id)) {</a>
<a name="ln596">      per_ts_meta_[from_ts].running_tablets.erase(tablet_id);</a>
<a name="ln597">      --per_tablet_meta_[tablet_id].running;</a>
<a name="ln598">      --total_running_;</a>
<a name="ln599">    }</a>
<a name="ln600">    if (per_ts_meta_[from_ts].starting_tablets.count(tablet_id)) {</a>
<a name="ln601">      LOG(DFATAL) &lt;&lt; &quot;Invalid request: remove starting tablet &quot; &lt;&lt; tablet_id</a>
<a name="ln602">                  &lt;&lt; &quot; from ts &quot; &lt;&lt; from_ts;</a>
<a name="ln603">    }</a>
<a name="ln604">    if (per_tablet_meta_[tablet_id].leader_uuid == from_ts) {</a>
<a name="ln605">      RETURN_NOT_OK(MoveLeader(tablet_id, from_ts));</a>
<a name="ln606">    }</a>
<a name="ln607">    // This artificially constrains the removes to only handle one over_replication/wrong_placement</a>
<a name="ln608">    // per run.</a>
<a name="ln609">    // Create a copy of tablet_id because tablet_id could be a const reference from</a>
<a name="ln610">    // tablets_wrong_placement_ (if the requests comes from HandleRemoveIfWrongPlacement) or a const</a>
<a name="ln611">    // reference from tablets_over_replicated_ (if the request comes from HandleRemoveReplicas).</a>
<a name="ln612">    TabletId tablet_id_key(tablet_id);</a>
<a name="ln613">    tablets_over_replicated_.erase(tablet_id_key);</a>
<a name="ln614">    tablets_wrong_placement_.erase(tablet_id_key);</a>
<a name="ln615">    SortLoad();</a>
<a name="ln616">    return Status::OK();</a>
<a name="ln617">  }</a>
<a name="ln618"> </a>
<a name="ln619">  void SortLoad() {</a>
<a name="ln620">    auto comparator = Comparator(this);</a>
<a name="ln621">    sort(sorted_load_.begin(), sorted_load_.end(), comparator);</a>
<a name="ln622">  }</a>
<a name="ln623"> </a>
<a name="ln624">  Status MoveLeader(</a>
<a name="ln625">    const TabletId&amp; tablet_id, const TabletServerId&amp; from_ts, const TabletServerId&amp; to_ts = &quot;&quot;) {</a>
<a name="ln626">    if (per_tablet_meta_[tablet_id].leader_uuid != from_ts) {</a>
<a name="ln627">      return STATUS_SUBSTITUTE(IllegalState, &quot;Tablet $0 has leader $1, but $2 expected.&quot;,</a>
<a name="ln628">                               tablet_id, per_tablet_meta_[tablet_id].leader_uuid, from_ts);</a>
<a name="ln629">    }</a>
<a name="ln630">    per_tablet_meta_[tablet_id].leader_uuid = to_ts;</a>
<a name="ln631">    per_ts_meta_[from_ts].leaders.erase(tablet_id);</a>
<a name="ln632">    if (!to_ts.empty()) {</a>
<a name="ln633">      per_ts_meta_[to_ts].leaders.insert(tablet_id);</a>
<a name="ln634">    }</a>
<a name="ln635">    SortLeaderLoad();</a>
<a name="ln636">    return Status::OK();</a>
<a name="ln637">  }</a>
<a name="ln638"> </a>
<a name="ln639">  virtual void SortLeaderLoad() {</a>
<a name="ln640">    auto leader_count_comparator = LeaderLoadComparator(this);</a>
<a name="ln641">    sort(sorted_leader_load_.begin(), sorted_leader_load_.end(), leader_count_comparator);</a>
<a name="ln642">  }</a>
<a name="ln643"> </a>
<a name="ln644">  void LogSortedLeaderLoad() {</a>
<a name="ln645">    // Sample output:</a>
<a name="ln646">    // ts1_uuid[ts1_load] ts2_uuid[ts2_load] ts4_uuid[ts4_load] -- ts3_uuid[ts3_load]</a>
<a name="ln647">    // Note: entries following &quot;--&quot; are leader blacklisted tservers</a>
<a name="ln648"> </a>
<a name="ln649">    bool blacklisted_leader = false;</a>
<a name="ln650">    std::string s;</a>
<a name="ln651">    for (const auto&amp; ts_uuid : sorted_leader_load_) {</a>
<a name="ln652">      if (!blacklisted_leader) {</a>
<a name="ln653">        blacklisted_leader = (leader_blacklisted_servers_.find(ts_uuid) !=</a>
<a name="ln654">            leader_blacklisted_servers_.end());</a>
<a name="ln655">        if (blacklisted_leader) {</a>
<a name="ln656">          s += &quot; --&quot;;</a>
<a name="ln657">        }</a>
<a name="ln658">      }</a>
<a name="ln659"> </a>
<a name="ln660">      s +=  &quot; &quot; + ts_uuid + &quot;[&quot; + strings::Substitute(&quot;$0&quot;, GetLeaderLoad(ts_uuid)) + &quot;]&quot;;</a>
<a name="ln661">    }</a>
<a name="ln662">    if (s.size() &gt; 0) {</a>
<a name="ln663">      LOG(INFO) &lt;&lt; &quot;tservers sorted by whether leader blacklisted and load: &quot; &lt;&lt; s;</a>
<a name="ln664">    }</a>
<a name="ln665">  }</a>
<a name="ln666"> </a>
<a name="ln667">  inline bool IsLeaderLoadBelowThreshold(const TabletServerId&amp; ts_uuid) {</a>
<a name="ln668">    return ((leader_balance_threshold_ &gt; 0) &amp;&amp;</a>
<a name="ln669">            (GetLeaderLoad(ts_uuid) &lt;= leader_balance_threshold_));</a>
<a name="ln670">  }</a>
<a name="ln671"> </a>
<a name="ln672">  void AdjustLeaderBalanceThreshold() {</a>
<a name="ln673">    if (leader_balance_threshold_ != 0) {</a>
<a name="ln674">      int min_threshold = sorted_leader_load_.empty() ? 0 :</a>
<a name="ln675">                          static_cast&lt;int&gt;(std::ceil(</a>
<a name="ln676">                            static_cast&lt;double&gt;(per_tablet_meta_.size()) /</a>
<a name="ln677">                            static_cast&lt;double&gt;(sorted_leader_load_.size())));</a>
<a name="ln678">      if (leader_balance_threshold_ &lt; min_threshold) {</a>
<a name="ln679">        LOG(WARNING) &lt;&lt; strings::Substitute(</a>
<a name="ln680">          &quot;leader_balance_threshold flag is set to $0 but is too low for the current &quot;</a>
<a name="ln681">            &quot;configuration. Adjusting it to $1.&quot;,</a>
<a name="ln682">          leader_balance_threshold_, min_threshold);</a>
<a name="ln683">        leader_balance_threshold_ = min_threshold;</a>
<a name="ln684">      }</a>
<a name="ln685">    }</a>
<a name="ln686">  }</a>
<a name="ln687"> </a>
<a name="ln688">  virtual void GetReplicaLocations(TabletInfo* tablet, TabletInfo::ReplicaMap* replica_locations) {</a>
<a name="ln689">    tablet-&gt;GetReplicaLocations(replica_locations);</a>
<a name="ln690">  }</a>
<a name="ln691"> </a>
<a name="ln692">  // PerTableLoadState member fields</a>
<a name="ln693"> </a>
<a name="ln694">  // Map from tablet ids to the metadata we store for each.</a>
<a name="ln695">  unordered_map&lt;TabletId, CBTabletMetadata&gt; per_tablet_meta_;</a>
<a name="ln696"> </a>
<a name="ln697">  // Map from tablet server ids to the metadata we store for each.</a>
<a name="ln698">  unordered_map&lt;TabletServerId, CBTabletServerMetadata&gt; per_ts_meta_;</a>
<a name="ln699"> </a>
<a name="ln700">  // Map from table id to placement information for this table. This will be used for both</a>
<a name="ln701">  // determining over-replication, by checking num_replicas, but also for az awareness, by keeping</a>
<a name="ln702">  // track of the placement block policies between cluster and table level.</a>
<a name="ln703">  unordered_map&lt;TableId, PlacementInfoPB&gt; placement_by_table_;</a>
<a name="ln704"> </a>
<a name="ln705">  // Total number of running tablets in the clusters (including replicas).</a>
<a name="ln706">  int total_running_ = 0;</a>
<a name="ln707"> </a>
<a name="ln708">  // Total number of tablet replicas being started across the cluster.</a>
<a name="ln709">  int total_starting_ = 0;</a>
<a name="ln710"> </a>
<a name="ln711">  // Set of ts_uuid sorted ascending by load. This is the actual raw data of TS load.</a>
<a name="ln712">  vector&lt;TabletServerId&gt; sorted_load_;</a>
<a name="ln713"> </a>
<a name="ln714">  // Set of tablet ids that have been determined to have missing replicas. This can mean they are</a>
<a name="ln715">  // generically under-replicated (2 replicas active, but 3 configured), or missing replicas in</a>
<a name="ln716">  // certain placements (3 replicas active out of 3 configured, but no replicas in one of the AZs</a>
<a name="ln717">  // listed in the placement blocks).</a>
<a name="ln718">  std::set&lt;TabletId&gt; tablets_missing_replicas_;</a>
<a name="ln719"> </a>
<a name="ln720">  // Set of tablet ids that have been temporarily over-replicated. This is used to pick tablets</a>
<a name="ln721">  // to potentially bring back down to their proper configured size, if there are more running than</a>
<a name="ln722">  // expected.</a>
<a name="ln723">  std::set&lt;TabletId&gt; tablets_over_replicated_;</a>
<a name="ln724"> </a>
<a name="ln725">  // Set of tablet ids that have been determined to have replicas in incorrect placements.</a>
<a name="ln726">  std::set&lt;TabletId&gt; tablets_wrong_placement_;</a>
<a name="ln727"> </a>
<a name="ln728">  // The cached blacklist setting of the cluster. We store this upfront, as we add to the list of</a>
<a name="ln729">  // tablet servers one by one, so we compare against it once per tablet server.</a>
<a name="ln730">  BlacklistPB blacklist_;</a>
<a name="ln731">  BlacklistPB leader_blacklist_;</a>
<a name="ln732"> </a>
<a name="ln733">  // The list of tablet server ids that match the cached blacklist.</a>
<a name="ln734">  std::set&lt;TabletServerId&gt; blacklisted_servers_;</a>
<a name="ln735">  std::set&lt;TabletServerId&gt; leader_blacklisted_servers_;</a>
<a name="ln736"> </a>
<a name="ln737">  // List of tablet server ids that have pending deletes.</a>
<a name="ln738">  std::set&lt;TabletServerId&gt; servers_with_pending_deletes_;</a>
<a name="ln739"> </a>
<a name="ln740">  // List of tablet ids that have been added to a new tablet server.</a>
<a name="ln741">  std::set&lt;TabletId&gt; tablets_added_;</a>
<a name="ln742"> </a>
<a name="ln743">  // Number of leaders per each tablet server to balance below.</a>
<a name="ln744">  int leader_balance_threshold_ = 0;</a>
<a name="ln745"> </a>
<a name="ln746">  // List of table server ids sorted by whether leader blacklisted and their leader load.</a>
<a name="ln747">  // If affinitized leaders is enabled, stores leader load for affinitized nodes.</a>
<a name="ln748">  vector&lt;TabletServerId&gt; sorted_leader_load_;</a>
<a name="ln749"> </a>
<a name="ln750">  unordered_map&lt;TableId, TabletToTabletServerMap&gt; pending_add_replica_tasks_;</a>
<a name="ln751">  unordered_map&lt;TableId, TabletToTabletServerMap&gt; pending_remove_replica_tasks_;</a>
<a name="ln752">  unordered_map&lt;TableId, TabletToTabletServerMap&gt; pending_stepdown_leader_tasks_;</a>
<a name="ln753"> </a>
<a name="ln754">  // Time at which we started the current round of load balancing.</a>
<a name="ln755">  MonoTime current_time_;</a>
<a name="ln756"> </a>
<a name="ln757">  // The knobs we use for tweaking the flow of the algorithm.</a>
<a name="ln758">  Options* options_;</a>
<a name="ln759"> </a>
<a name="ln760">  // Pointer to the cluster global state so that it can be updated when operations like add or</a>
<a name="ln761">  // remove are executed.</a>
<a name="ln762">  GlobalLoadState* global_state_;</a>
<a name="ln763"> </a>
<a name="ln764">  // Boolean whether tablets for this table should respect the affinited zones.</a>
<a name="ln765">  bool use_preferred_zones_ = true;</a>
<a name="ln766"> </a>
<a name="ln767"> private:</a>
<a name="ln768">  DISALLOW_COPY_AND_ASSIGN(PerTableLoadState);</a>
<a name="ln769">}; // PerTableLoadState</a>
<a name="ln770"> </a>
<a name="ln771">} // namespace master</a>
<a name="ln772">} // namespace yb</a>
<a name="ln773"> </a>
<a name="ln774">#endif // YB_MASTER_CLUSTER_BALANCE_UTIL_H</a>

</code></pre>
<div class="balloon" rel="322"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="334"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="338"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="76"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v730/" target="_blank">V730</a> Not all members of a class are initialized inside the compiler generated constructor. Consider inspecting: is_over_replicated.</p></div>
<div class="balloon" rel="212"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v730/" target="_blank">V730</a> Not all members of a class are initialized inside the constructor. Consider inspecting: options_.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
