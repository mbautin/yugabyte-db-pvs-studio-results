
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
  <title>consensus_queue.cc</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">// Licensed to the Apache Software Foundation (ASF) under one</a>
<a name="ln2">// or more contributor license agreements.  See the NOTICE file</a>
<a name="ln3">// distributed with this work for additional information</a>
<a name="ln4">// regarding copyright ownership.  The ASF licenses this file</a>
<a name="ln5">// to you under the Apache License, Version 2.0 (the</a>
<a name="ln6">// &quot;License&quot;); you may not use this file except in compliance</a>
<a name="ln7">// with the License.  You may obtain a copy of the License at</a>
<a name="ln8">//</a>
<a name="ln9">//   http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="ln10">//</a>
<a name="ln11">// Unless required by applicable law or agreed to in writing,</a>
<a name="ln12">// software distributed under the License is distributed on an</a>
<a name="ln13">// &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</a>
<a name="ln14">// KIND, either express or implied.  See the License for the</a>
<a name="ln15">// specific language governing permissions and limitations</a>
<a name="ln16">// under the License.</a>
<a name="ln17">//</a>
<a name="ln18">// The following only applies to changes made to this file as part of YugaByte development.</a>
<a name="ln19">//</a>
<a name="ln20">// Portions Copyright (c) YugaByte, Inc.</a>
<a name="ln21">//</a>
<a name="ln22">// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except</a>
<a name="ln23">// in compliance with the License.  You may obtain a copy of the License at</a>
<a name="ln24">//</a>
<a name="ln25">// http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="ln26">//</a>
<a name="ln27">// Unless required by applicable law or agreed to in writing, software distributed under the License</a>
<a name="ln28">// is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express</a>
<a name="ln29">// or implied.  See the License for the specific language governing permissions and limitations</a>
<a name="ln30">// under the License.</a>
<a name="ln31">//</a>
<a name="ln32"> </a>
<a name="ln33">#include &quot;yb/consensus/consensus_queue.h&quot;</a>
<a name="ln34"> </a>
<a name="ln35">#include &lt;shared_mutex&gt;</a>
<a name="ln36">#include &lt;algorithm&gt;</a>
<a name="ln37">#include &lt;iostream&gt;</a>
<a name="ln38">#include &lt;mutex&gt;</a>
<a name="ln39">#include &lt;string&gt;</a>
<a name="ln40">#include &lt;utility&gt;</a>
<a name="ln41"> </a>
<a name="ln42">#include &lt;boost/container/small_vector.hpp&gt;</a>
<a name="ln43"> </a>
<a name="ln44">#include &lt;gflags/gflags.h&gt;</a>
<a name="ln45"> </a>
<a name="ln46">#include &quot;yb/common/wire_protocol.h&quot;</a>
<a name="ln47"> </a>
<a name="ln48">#include &quot;yb/consensus/consensus_context.h&quot;</a>
<a name="ln49">#include &quot;yb/consensus/log.h&quot;</a>
<a name="ln50">#include &quot;yb/consensus/log_reader.h&quot;</a>
<a name="ln51">#include &quot;yb/consensus/log_util.h&quot;</a>
<a name="ln52">#include &quot;yb/consensus/opid_util.h&quot;</a>
<a name="ln53">#include &quot;yb/consensus/quorum_util.h&quot;</a>
<a name="ln54">#include &quot;yb/consensus/raft_consensus.h&quot;</a>
<a name="ln55">#include &quot;yb/consensus/replicate_msgs_holder.h&quot;</a>
<a name="ln56"> </a>
<a name="ln57">#include &quot;yb/gutil/dynamic_annotations.h&quot;</a>
<a name="ln58">#include &quot;yb/gutil/map-util.h&quot;</a>
<a name="ln59">#include &quot;yb/gutil/stl_util.h&quot;</a>
<a name="ln60">#include &quot;yb/gutil/strings/join.h&quot;</a>
<a name="ln61">#include &quot;yb/gutil/strings/substitute.h&quot;</a>
<a name="ln62">#include &quot;yb/gutil/strings/strcat.h&quot;</a>
<a name="ln63">#include &quot;yb/gutil/strings/human_readable.h&quot;</a>
<a name="ln64">#include &quot;yb/util/fault_injection.h&quot;</a>
<a name="ln65">#include &quot;yb/util/flag_tags.h&quot;</a>
<a name="ln66">#include &quot;yb/util/locks.h&quot;</a>
<a name="ln67">#include &quot;yb/util/logging.h&quot;</a>
<a name="ln68">#include &quot;yb/util/mem_tracker.h&quot;</a>
<a name="ln69">#include &quot;yb/util/metrics.h&quot;</a>
<a name="ln70">#include &quot;yb/util/random_util.h&quot;</a>
<a name="ln71">#include &quot;yb/util/size_literals.h&quot;</a>
<a name="ln72">#include &quot;yb/util/threadpool.h&quot;</a>
<a name="ln73">#include &quot;yb/util/url-coding.h&quot;</a>
<a name="ln74">#include &quot;yb/util/enums.h&quot;</a>
<a name="ln75">#include &quot;yb/util/tostring.h&quot;</a>
<a name="ln76"> </a>
<a name="ln77">using namespace std::literals;</a>
<a name="ln78">using namespace yb::size_literals;</a>
<a name="ln79"> </a>
<a name="ln80">DECLARE_int32(rpc_max_message_size);</a>
<a name="ln81"> </a>
<a name="ln82">// We expect that consensus_max_batch_size_bytes + 1_KB would be less than rpc_max_message_size.</a>
<a name="ln83">// Otherwise such batch would be rejected by RPC layer.</a>
<a name="ln84">DEFINE_int32(consensus_max_batch_size_bytes, 4_MB,</a>
<a name="ln85">             &quot;The maximum per-tablet RPC batch size when updating peers.&quot;);</a>
<a name="ln86">TAG_FLAG(consensus_max_batch_size_bytes, advanced);</a>
<a name="ln87">TAG_FLAG(consensus_max_batch_size_bytes, runtime);</a>
<a name="ln88"> </a>
<a name="ln89">DEFINE_int32(follower_unavailable_considered_failed_sec, 900,</a>
<a name="ln90">             &quot;Seconds that a leader is unable to successfully heartbeat to a &quot;</a>
<a name="ln91">             &quot;follower after which the follower is considered to be failed and &quot;</a>
<a name="ln92">             &quot;evicted from the config.&quot;);</a>
<a name="ln93">TAG_FLAG(follower_unavailable_considered_failed_sec, advanced);</a>
<a name="ln94"> </a>
<a name="ln95">DEFINE_int32(consensus_inject_latency_ms_in_notifications, 0,</a>
<a name="ln96">             &quot;Injects a random sleep between 0 and this many milliseconds into &quot;</a>
<a name="ln97">             &quot;asynchronous notifications from the consensus queue back to the &quot;</a>
<a name="ln98">             &quot;consensus implementation.&quot;);</a>
<a name="ln99">TAG_FLAG(consensus_inject_latency_ms_in_notifications, hidden);</a>
<a name="ln100">TAG_FLAG(consensus_inject_latency_ms_in_notifications, unsafe);</a>
<a name="ln101"> </a>
<a name="ln102">DEFINE_int32(cdc_checkpoint_opid_interval_ms, 60 * 1000,</a>
<a name="ln103">             &quot;Interval up to which CDC consumer's checkpoint is considered for retaining log cache.&quot;</a>
<a name="ln104">             &quot;If we haven't received an updated checkpoint from CDC consumer within the interval &quot;</a>
<a name="ln105">             &quot;specified by cdc_checkpoint_opid_interval, then log cache does not consider that &quot;</a>
<a name="ln106">             &quot;consumer while determining which op IDs to evict.&quot;);</a>
<a name="ln107"> </a>
<a name="ln108">DEFINE_bool(enable_consensus_exponential_backoff, true,</a>
<a name="ln109">            &quot;Whether exponential backoff based on number of retransmissions at tablet leader &quot;</a>
<a name="ln110">            &quot;for number of entries to replicate to lagging follower is enabled.&quot;);</a>
<a name="ln111">TAG_FLAG(enable_consensus_exponential_backoff, advanced);</a>
<a name="ln112">TAG_FLAG(enable_consensus_exponential_backoff, runtime);</a>
<a name="ln113"> </a>
<a name="ln114">DEFINE_int32(consensus_lagging_follower_threshold, 10,</a>
<a name="ln115">             &quot;Number of retransmissions at tablet leader to mark a follower as lagging. &quot;</a>
<a name="ln116">             &quot;-1 disables the feature.&quot;);</a>
<a name="ln117">TAG_FLAG(consensus_lagging_follower_threshold, advanced);</a>
<a name="ln118">TAG_FLAG(consensus_lagging_follower_threshold, runtime);</a>
<a name="ln119"> </a>
<a name="ln120">namespace {</a>
<a name="ln121"> </a>
<a name="ln122">constexpr const auto kMinRpcThrottleThresholdBytes = 16;</a>
<a name="ln123"> </a>
<a name="ln124">static bool RpcThrottleThresholdBytesValidator(const char* flagname, int32_t value) {</a>
<a name="ln125">  if (value &gt; 0) {</a>
<a name="ln126">    if (value &lt; kMinRpcThrottleThresholdBytes) {</a>
<a name="ln127">      LOG(ERROR) &lt;&lt; &quot;Expect &quot; &lt;&lt; flagname &lt;&lt; &quot; to be at least &quot; &lt;&lt; kMinRpcThrottleThresholdBytes;</a>
<a name="ln128">      return false;</a>
<a name="ln129">    } else if (value &gt;= FLAGS_consensus_max_batch_size_bytes) {</a>
<a name="ln130">      LOG(ERROR) &lt;&lt; &quot;Expect &quot; &lt;&lt; flagname &lt;&lt; &quot; to be less than consensus_max_batch_size_bytes &quot;</a>
<a name="ln131">                 &lt;&lt; &quot;value (&quot; &lt;&lt; FLAGS_consensus_max_batch_size_bytes &lt;&lt; &quot;)&quot;;</a>
<a name="ln132">      return false;</a>
<a name="ln133">    }</a>
<a name="ln134">  }</a>
<a name="ln135">  return true;</a>
<a name="ln136">}</a>
<a name="ln137"> </a>
<a name="ln138">} // namespace</a>
<a name="ln139"> </a>
<a name="ln140">DECLARE_int32(rpc_throttle_threshold_bytes);</a>
<a name="ln141">__attribute__((unused))</a>
<a name="ln142">DEFINE_validator(rpc_throttle_threshold_bytes, &amp;RpcThrottleThresholdBytesValidator);</a>
<a name="ln143"> </a>
<a name="ln144">namespace yb {</a>
<a name="ln145">namespace consensus {</a>
<a name="ln146"> </a>
<a name="ln147">using log::AsyncLogReader;</a>
<a name="ln148">using log::Log;</a>
<a name="ln149">using std::unique_ptr;</a>
<a name="ln150">using rpc::Messenger;</a>
<a name="ln151">using strings::Substitute;</a>
<a name="ln152"> </a>
<a name="ln153">METRIC_DEFINE_gauge_int64(tablet, majority_done_ops, &quot;Leader Operations Acked by Majority&quot;,</a>
<a name="ln154">                          MetricUnit::kOperations,</a>
<a name="ln155">                          &quot;Number of operations in the leader queue ack'd by a majority but &quot;</a>
<a name="ln156">                          &quot;not all peers.&quot;);</a>
<a name="ln157">METRIC_DEFINE_gauge_int64(tablet, in_progress_ops, &quot;Leader Operations in Progress&quot;,</a>
<a name="ln158">                          MetricUnit::kOperations,</a>
<a name="ln159">                          &quot;Number of operations in the leader queue ack'd by a minority of &quot;</a>
<a name="ln160">                          &quot;peers.&quot;);</a>
<a name="ln161"> </a>
<a name="ln162">const auto kCDCConsumerCheckpointInterval = FLAGS_cdc_checkpoint_opid_interval_ms * 1ms;</a>
<a name="ln163"> </a>
<a name="ln164">std::string MajorityReplicatedData::ToString() const {</a>
<a name="ln165">  return Format(</a>
<a name="ln166">      &quot;{ op_id: $0 leader_lease_expiration: $1 ht_lease_expiration: $2 num_sst_files: $3 }&quot;,</a>
<a name="ln167">      op_id, leader_lease_expiration, ht_lease_expiration, num_sst_files);</a>
<a name="ln168">}</a>
<a name="ln169"> </a>
<a name="ln170">std::string PeerMessageQueue::TrackedPeer::ToString() const {</a>
<a name="ln171">  return Format(&quot;{ peer: $0 is_new: $1 last_received: $2 next_index: $3 &quot;</a>
<a name="ln172">                    &quot;last_known_committed_idx: $4, is_last_exchange_successful: $5, &quot;</a>
<a name="ln173">                    &quot;needs_remote_bootstrap: $6 member_type: $7 num_sst_files: $8 }&quot;,</a>
<a name="ln174">                uuid, is_new, last_received, next_index, last_known_committed_idx,</a>
<a name="ln175">                is_last_exchange_successful, needs_remote_bootstrap,</a>
<a name="ln176">                RaftPeerPB::MemberType_Name(member_type), num_sst_files);</a>
<a name="ln177">}</a>
<a name="ln178"> </a>
<a name="ln179">void PeerMessageQueue::TrackedPeer::ResetLeaderLeases() {</a>
<a name="ln180">  leader_lease_expiration.Reset();</a>
<a name="ln181">  leader_ht_lease_expiration.Reset();</a>
<a name="ln182">}</a>
<a name="ln183"> </a>
<a name="ln184">#define INSTANTIATE_METRIC(x) \</a>
<a name="ln185">  x.Instantiate(metric_entity, 0)</a>
<a name="ln186">PeerMessageQueue::Metrics::Metrics(const scoped_refptr&lt;MetricEntity&gt;&amp; metric_entity)</a>
<a name="ln187">  : num_majority_done_ops(INSTANTIATE_METRIC(METRIC_majority_done_ops)),</a>
<a name="ln188">    num_in_progress_ops(INSTANTIATE_METRIC(METRIC_in_progress_ops)) {</a>
<a name="ln189">}</a>
<a name="ln190">#undef INSTANTIATE_METRIC</a>
<a name="ln191"> </a>
<a name="ln192">PeerMessageQueue::PeerMessageQueue(const scoped_refptr&lt;MetricEntity&gt;&amp; metric_entity,</a>
<a name="ln193">                                   const scoped_refptr&lt;log::Log&gt;&amp; log,</a>
<a name="ln194">                                   const MemTrackerPtr&amp; server_tracker,</a>
<a name="ln195">                                   const MemTrackerPtr&amp; parent_tracker,</a>
<a name="ln196">                                   const RaftPeerPB&amp; local_peer_pb,</a>
<a name="ln197">                                   const string&amp; tablet_id,</a>
<a name="ln198">                                   const server::ClockPtr&amp; clock,</a>
<a name="ln199">                                   ConsensusContext* context,</a>
<a name="ln200">                                   unique_ptr&lt;ThreadPoolToken&gt; raft_pool_token)</a>
<a name="ln201">    : raft_pool_observers_token_(std::move(raft_pool_token)),</a>
<a name="ln202">      local_peer_pb_(local_peer_pb),</a>
<a name="ln203">      local_peer_uuid_(local_peer_pb_.has_permanent_uuid() ? local_peer_pb_.permanent_uuid()</a>
<a name="ln204">                                                           : string()),</a>
<a name="ln205">      tablet_id_(tablet_id),</a>
<a name="ln206">      log_cache_(metric_entity, log, server_tracker, local_peer_pb.permanent_uuid(), tablet_id),</a>
<a name="ln207">      operations_mem_tracker_(</a>
<a name="ln208">          MemTracker::FindOrCreateTracker(&quot;OperationsFromDisk&quot;, parent_tracker)),</a>
<a name="ln209">      metrics_(metric_entity),</a>
<a name="ln210">      clock_(clock),</a>
<a name="ln211">      context_(context) {</a>
<a name="ln212">  DCHECK(local_peer_pb_.has_permanent_uuid());</a>
<a name="ln213">  DCHECK(!local_peer_pb_.last_known_private_addr().empty());</a>
<a name="ln214">}</a>
<a name="ln215"> </a>
<a name="ln216">void PeerMessageQueue::Init(const OpIdPB&amp; last_locally_replicated) {</a>
<a name="ln217">  LockGuard lock(queue_lock_);</a>
<a name="ln218">  CHECK_EQ(queue_state_.state, State::kQueueConstructed);</a>
<a name="ln219">  log_cache_.Init(last_locally_replicated);</a>
<a name="ln220">  queue_state_.last_appended = last_locally_replicated;</a>
<a name="ln221">  queue_state_.state = State::kQueueOpen;</a>
<a name="ln222">  local_peer_ = TrackPeerUnlocked(local_peer_uuid_);</a>
<a name="ln223"> </a>
<a name="ln224">  if (context_) {</a>
<a name="ln225">    context_-&gt;ListenNumSSTFilesChanged(std::bind(&amp;PeerMessageQueue::NumSSTFilesChanged, this));</a>
<a name="ln226">    installed_num_sst_files_changed_listener_ = true;</a>
<a name="ln227">  }</a>
<a name="ln228">}</a>
<a name="ln229"> </a>
<a name="ln230">void PeerMessageQueue::SetLeaderMode(const OpIdPB&amp; committed_op_id,</a>
<a name="ln231">                                     int64_t current_term,</a>
<a name="ln232">                                     const RaftConfigPB&amp; active_config) {</a>
<a name="ln233">  LockGuard lock(queue_lock_);</a>
<a name="ln234">  CHECK(committed_op_id.IsInitialized());</a>
<a name="ln235">  queue_state_.current_term = current_term;</a>
<a name="ln236">  queue_state_.committed_op_id = committed_op_id;</a>
<a name="ln237">  queue_state_.majority_replicated_op_id = committed_op_id;</a>
<a name="ln238">  queue_state_.active_config.reset(new RaftConfigPB(active_config));</a>
<a name="ln239">  CHECK(IsRaftConfigVoter(local_peer_uuid_, *queue_state_.active_config))</a>
<a name="ln240">      &lt;&lt; local_peer_pb_.ShortDebugString() &lt;&lt; &quot; not a voter in config: &quot;</a>
<a name="ln241">      &lt;&lt; queue_state_.active_config-&gt;ShortDebugString();</a>
<a name="ln242">  queue_state_.majority_size_ = MajoritySize(CountVoters(*queue_state_.active_config));</a>
<a name="ln243">  queue_state_.mode = Mode::LEADER;</a>
<a name="ln244"> </a>
<a name="ln245">  LOG_WITH_PREFIX_UNLOCKED(INFO) &lt;&lt; &quot;Queue going to LEADER mode. State: &quot;</a>
<a name="ln246">      &lt;&lt; queue_state_.ToString();</a>
<a name="ln247">  CheckPeersInActiveConfigIfLeaderUnlocked();</a>
<a name="ln248"> </a>
<a name="ln249">  // Reset last communication time with all peers to reset the clock on the</a>
<a name="ln250">  // failure timeout.</a>
<a name="ln251">  MonoTime now(MonoTime::Now());</a>
<a name="ln252">  for (const PeersMap::value_type&amp; entry : peers_map_) {</a>
<a name="ln253">    entry.second-&gt;ResetLeaderLeases();</a>
<a name="ln254">    entry.second-&gt;last_successful_communication_time = now;</a>
<a name="ln255">  }</a>
<a name="ln256">}</a>
<a name="ln257"> </a>
<a name="ln258">void PeerMessageQueue::SetNonLeaderMode() {</a>
<a name="ln259">  LockGuard lock(queue_lock_);</a>
<a name="ln260">  queue_state_.active_config.reset();</a>
<a name="ln261">  queue_state_.mode = Mode::NON_LEADER;</a>
<a name="ln262">  queue_state_.majority_size_ = -1;</a>
<a name="ln263">  LOG_WITH_PREFIX_UNLOCKED(INFO) &lt;&lt; &quot;Queue going to NON_LEADER mode. State: &quot;</a>
<a name="ln264">      &lt;&lt; queue_state_.ToString();</a>
<a name="ln265">}</a>
<a name="ln266"> </a>
<a name="ln267">void PeerMessageQueue::TrackPeer(const string&amp; uuid) {</a>
<a name="ln268">  LockGuard lock(queue_lock_);</a>
<a name="ln269">  TrackPeerUnlocked(uuid);</a>
<a name="ln270">}</a>
<a name="ln271"> </a>
<a name="ln272">PeerMessageQueue::TrackedPeer* PeerMessageQueue::TrackPeerUnlocked(const string&amp; uuid) {</a>
<a name="ln273">  CHECK(!uuid.empty()) &lt;&lt; &quot;Got request to track peer with empty UUID&quot;;</a>
<a name="ln274">  DCHECK_EQ(queue_state_.state, State::kQueueOpen);</a>
<a name="ln275"> </a>
<a name="ln276">  TrackedPeer* tracked_peer = new TrackedPeer(uuid);</a>
<a name="ln277"> </a>
<a name="ln278">  // We don't know the last operation received by the peer so, following the Raft protocol, we set</a>
<a name="ln279">  // next_index to one past the end of our own log. This way, if calling this method is the result</a>
<a name="ln280">  // of a successful leader election and the logs between the new leader and remote peer match, the</a>
<a name="ln281">  // peer-&gt;next_index will point to the index of the soon-to-be-written NO_OP entry that is used to</a>
<a name="ln282">  // assert leadership. If we guessed wrong, and the peer does not have a log that matches ours, the</a>
<a name="ln283">  // normal queue negotiation process will eventually find the right point to resume from.</a>
<a name="ln284">  tracked_peer-&gt;next_index = queue_state_.last_appended.index() + 1;</a>
<a name="ln285">  InsertOrDie(&amp;peers_map_, uuid, tracked_peer);</a>
<a name="ln286"> </a>
<a name="ln287">  CheckPeersInActiveConfigIfLeaderUnlocked();</a>
<a name="ln288"> </a>
<a name="ln289">  // We don't know how far back this peer is, so set the all replicated watermark to</a>
<a name="ln290">  // MinimumOpId. We'll advance it when we know how far along the peer is.</a>
<a name="ln291">  queue_state_.all_replicated_op_id = MinimumOpId();</a>
<a name="ln292">  return tracked_peer;</a>
<a name="ln293">}</a>
<a name="ln294"> </a>
<a name="ln295">void PeerMessageQueue::UntrackPeer(const string&amp; uuid) {</a>
<a name="ln296">  LockGuard lock(queue_lock_);</a>
<a name="ln297">  TrackedPeer* peer = EraseKeyReturnValuePtr(&amp;peers_map_, uuid);</a>
<a name="ln298">  if (peer != nullptr) {</a>
<a name="ln299">    delete peer;</a>
<a name="ln300">  }</a>
<a name="ln301">}</a>
<a name="ln302"> </a>
<a name="ln303">void PeerMessageQueue::CheckPeersInActiveConfigIfLeaderUnlocked() const {</a>
<a name="ln304">  if (queue_state_.mode != Mode::LEADER) return;</a>
<a name="ln305">  unordered_set&lt;string&gt; config_peer_uuids;</a>
<a name="ln306">  for (const RaftPeerPB&amp; peer_pb : queue_state_.active_config-&gt;peers()) {</a>
<a name="ln307">    InsertOrDie(&amp;config_peer_uuids, peer_pb.permanent_uuid());</a>
<a name="ln308">  }</a>
<a name="ln309">  for (const PeersMap::value_type&amp; entry : peers_map_) {</a>
<a name="ln310">    if (!ContainsKey(config_peer_uuids, entry.first)) {</a>
<a name="ln311">      LOG_WITH_PREFIX_UNLOCKED(FATAL) &lt;&lt; Substitute(&quot;Peer $0 is not in the active config. &quot;</a>
<a name="ln312">                                                    &quot;Queue state: $1&quot;,</a>
<a name="ln313">                                                    entry.first,</a>
<a name="ln314">                                                    queue_state_.ToString());</a>
<a name="ln315">    }</a>
<a name="ln316">  }</a>
<a name="ln317">}</a>
<a name="ln318"> </a>
<a name="ln319">void PeerMessageQueue::NumSSTFilesChanged() {</a>
<a name="ln320">  auto num_sst_files = context_-&gt;NumSSTFiles();</a>
<a name="ln321"> </a>
<a name="ln322">  uint64_t majority_replicated_num_sst_files;</a>
<a name="ln323">  {</a>
<a name="ln324">    LockGuard lock(queue_lock_);</a>
<a name="ln325">    if (queue_state_.mode != Mode::LEADER) {</a>
<a name="ln326">      return;</a>
<a name="ln327">    }</a>
<a name="ln328">    auto it = peers_map_.find(local_peer_uuid_);</a>
<a name="ln329">    if (it == peers_map_.end()) {</a>
<a name="ln330">      return;</a>
<a name="ln331">    }</a>
<a name="ln332">    it-&gt;second-&gt;num_sst_files = num_sst_files;</a>
<a name="ln333">    majority_replicated_num_sst_files = NumSSTFilesWatermark();</a>
<a name="ln334">  }</a>
<a name="ln335"> </a>
<a name="ln336">  NotifyObservers(</a>
<a name="ln337">      &quot;majority replicated num SST files changed&quot;,</a>
<a name="ln338">      [majority_replicated_num_sst_files](PeerMessageQueueObserver* observer) {</a>
<a name="ln339">    observer-&gt;MajorityReplicatedNumSSTFilesChanged(majority_replicated_num_sst_files);</a>
<a name="ln340">  });</a>
<a name="ln341">}</a>
<a name="ln342"> </a>
<a name="ln343">void PeerMessageQueue::LocalPeerAppendFinished(const OpIdPB&amp; id,</a>
<a name="ln344">                                               const Status&amp; status) {</a>
<a name="ln345">  CHECK_OK(status);</a>
<a name="ln346"> </a>
<a name="ln347">  // Fake an RPC response from the local peer.</a>
<a name="ln348">  // TODO: we should probably refactor the ResponseFromPeer function so that we don't need to</a>
<a name="ln349">  // construct this fake response, but this seems to work for now.</a>
<a name="ln350">  ConsensusResponsePB fake_response;</a>
<a name="ln351">  *fake_response.mutable_status()-&gt;mutable_last_received() = id;</a>
<a name="ln352">  *fake_response.mutable_status()-&gt;mutable_last_received_current_leader() = id;</a>
<a name="ln353">  if (context_) {</a>
<a name="ln354">    fake_response.set_num_sst_files(context_-&gt;NumSSTFiles());</a>
<a name="ln355">  }</a>
<a name="ln356">  {</a>
<a name="ln357">    LockGuard lock(queue_lock_);</a>
<a name="ln358"> </a>
<a name="ln359">    // TODO This ugly fix is required because we unlock queue_lock_ while doing AppendOperations.</a>
<a name="ln360">    // So LocalPeerAppendFinished could be invoked before rest of AppendOperations.</a>
<a name="ln361">    if (queue_state_.last_appended.index() &lt; id.index()) {</a>
<a name="ln362">      queue_state_.last_appended = id;</a>
<a name="ln363">    }</a>
<a name="ln364">    fake_response.mutable_status()-&gt;set_last_committed_idx(queue_state_.committed_op_id.index());</a>
<a name="ln365"> </a>
<a name="ln366">    if (queue_state_.mode != Mode::LEADER) {</a>
<a name="ln367">      log_cache_.EvictThroughOp(id.index());</a>
<a name="ln368"> </a>
<a name="ln369">      UpdateMetrics();</a>
<a name="ln370">      return;</a>
<a name="ln371">    }</a>
<a name="ln372">  }</a>
<a name="ln373">  ResponseFromPeer(local_peer_uuid_, fake_response);</a>
<a name="ln374">}</a>
<a name="ln375"> </a>
<a name="ln376">Status PeerMessageQueue::TEST_AppendOperation(const ReplicateMsgPtr&amp; msg) {</a>
<a name="ln377">  return AppendOperations(</a>
<a name="ln378">      { msg }, yb::OpId::FromPB(msg-&gt;committed_op_id()), RestartSafeCoarseMonoClock().Now());</a>
<a name="ln379">}</a>
<a name="ln380"> </a>
<a name="ln381">Status PeerMessageQueue::AppendOperations(const ReplicateMsgs&amp; msgs,</a>
<a name="ln382">                                          const yb::OpId&amp; committed_op_id,</a>
<a name="ln383">                                          RestartSafeCoarseTimePoint batch_mono_time) {</a>
<a name="ln384">  DFAKE_SCOPED_LOCK(append_fake_lock_);</a>
<a name="ln385">  OpIdPB last_id;</a>
<a name="ln386">  if (!msgs.empty()) {</a>
<a name="ln387">    std::unique_lock&lt;simple_spinlock&gt; lock(queue_lock_);</a>
<a name="ln388"> </a>
<a name="ln389">    last_id = msgs.back()-&gt;id();</a>
<a name="ln390"> </a>
<a name="ln391">    if (last_id.term() &gt; queue_state_.current_term) {</a>
<a name="ln392">      queue_state_.current_term = last_id.term();</a>
<a name="ln393">    }</a>
<a name="ln394">  } else {</a>
<a name="ln395">    std::unique_lock&lt;simple_spinlock&gt; lock(queue_lock_);</a>
<a name="ln396">    last_id = queue_state_.last_appended;</a>
<a name="ln397">  }</a>
<a name="ln398"> </a>
<a name="ln399">  // Unlock ourselves during Append to prevent a deadlock: it's possible that the log buffer is</a>
<a name="ln400">  // full, in which case AppendOperations would block. However, for the log buffer to empty, it may</a>
<a name="ln401">  // need to call LocalPeerAppendFinished() which also needs queue_lock_.</a>
<a name="ln402">  //</a>
<a name="ln403">  // Since we are doing AppendOperations only in one thread, no concurrent AppendOperations could</a>
<a name="ln404">  // be executed and queue_state_.last_appended will be updated correctly.</a>
<a name="ln405">  RETURN_NOT_OK(log_cache_.AppendOperations(</a>
<a name="ln406">      msgs, committed_op_id, batch_mono_time,</a>
<a name="ln407">      Bind(&amp;PeerMessageQueue::LocalPeerAppendFinished, Unretained(this), last_id)));</a>
<a name="ln408"> </a>
<a name="ln409">  if (!msgs.empty()) {</a>
<a name="ln410">    std::unique_lock&lt;simple_spinlock&gt; lock(queue_lock_);</a>
<a name="ln411">    queue_state_.last_appended = last_id;</a>
<a name="ln412">    UpdateMetrics();</a>
<a name="ln413">  }</a>
<a name="ln414"> </a>
<a name="ln415">  return Status::OK();</a>
<a name="ln416">}</a>
<a name="ln417"> </a>
<a name="ln418">Status PeerMessageQueue::RequestForPeer(const string&amp; uuid,</a>
<a name="ln419">                                        ConsensusRequestPB* request,</a>
<a name="ln420">                                        ReplicateMsgsHolder* msgs_holder,</a>
<a name="ln421">                                        bool* needs_remote_bootstrap,</a>
<a name="ln422">                                        RaftPeerPB::MemberType* member_type,</a>
<a name="ln423">                                        bool* last_exchange_successful) {</a>
<a name="ln424">  DCHECK(request-&gt;ops().empty());</a>
<a name="ln425"> </a>
<a name="ln426">  OpIdPB preceding_id;</a>
<a name="ln427">  MonoDelta unreachable_time = MonoDelta::kMin;</a>
<a name="ln428">  bool is_voter = false;</a>
<a name="ln429">  bool is_new;</a>
<a name="ln430">  int64_t next_index;</a>
<a name="ln431">  int64_t to_index;</a>
<a name="ln432">  HybridTime propagated_safe_time;</a>
<a name="ln433"> </a>
<a name="ln434">  // Should be before now_ht, i.e. not greater than propagated_hybrid_time.</a>
<a name="ln435">  if (context_) {</a>
<a name="ln436">    propagated_safe_time = context_-&gt;PreparePeerRequest();</a>
<a name="ln437">  }</a>
<a name="ln438"> </a>
<a name="ln439">  {</a>
<a name="ln440">    LockGuard lock(queue_lock_);</a>
<a name="ln441">    DCHECK_EQ(queue_state_.state, State::kQueueOpen);</a>
<a name="ln442">    DCHECK_NE(uuid, local_peer_uuid_);</a>
<a name="ln443"> </a>
<a name="ln444">    auto peer = FindPtrOrNull(peers_map_, uuid);</a>
<a name="ln445">    if (PREDICT_FALSE(peer == nullptr || queue_state_.mode == Mode::NON_LEADER)) {</a>
<a name="ln446">      return STATUS(NotFound, &quot;Peer not tracked or queue not in leader mode.&quot;);</a>
<a name="ln447">    }</a>
<a name="ln448"> </a>
<a name="ln449">    HybridTime now_ht;</a>
<a name="ln450"> </a>
<a name="ln451">    is_new = peer-&gt;is_new;</a>
<a name="ln452">    if (!is_new) {</a>
<a name="ln453">      now_ht = clock_-&gt;Now();</a>
<a name="ln454"> </a>
<a name="ln455">      auto ht_lease_expiration_micros = now_ht.GetPhysicalValueMicros() +</a>
<a name="ln456">                                        FLAGS_ht_lease_duration_ms * 1000;</a>
<a name="ln457">      auto leader_lease_duration_ms = GetAtomicFlag(&amp;FLAGS_leader_lease_duration_ms);</a>
<a name="ln458">      request-&gt;set_leader_lease_duration_ms(leader_lease_duration_ms);</a>
<a name="ln459">      request-&gt;set_ht_lease_expiration(ht_lease_expiration_micros);</a>
<a name="ln460"> </a>
<a name="ln461">      // As noted here:</a>
<a name="ln462">      // https://red.ht/2sCSErb</a>
<a name="ln463">      //</a>
<a name="ln464">      // The _COARSE variants are faster to read and have a precision (also known as resolution) of</a>
<a name="ln465">      // one millisecond (ms).</a>
<a name="ln466">      //</a>
<a name="ln467">      // Coarse clock precision is 1 millisecond.</a>
<a name="ln468">      const auto kCoarseClockPrecision = 1ms;</a>
<a name="ln469"> </a>
<a name="ln470">      // Because of coarse clocks we subtract 2ms, to be sure that our local version of lease</a>
<a name="ln471">      // does not expire after it expires at follower.</a>
<a name="ln472">      peer-&gt;leader_lease_expiration.last_sent =</a>
<a name="ln473">          CoarseMonoClock::Now() + leader_lease_duration_ms * 1ms - kCoarseClockPrecision * 2;</a>
<a name="ln474">      peer-&gt;leader_ht_lease_expiration.last_sent = ht_lease_expiration_micros;</a>
<a name="ln475">    } else {</a>
<a name="ln476">      now_ht = clock_-&gt;Now();</a>
<a name="ln477">      request-&gt;clear_leader_lease_duration_ms();</a>
<a name="ln478">      request-&gt;clear_ht_lease_expiration();</a>
<a name="ln479">      peer-&gt;leader_lease_expiration.Reset();</a>
<a name="ln480">      peer-&gt;leader_ht_lease_expiration.Reset();</a>
<a name="ln481">    }</a>
<a name="ln482"> </a>
<a name="ln483">    request-&gt;set_propagated_hybrid_time(now_ht.ToUint64());</a>
<a name="ln484"> </a>
<a name="ln485">    // This is initialized to the queue's last appended op but gets set to the id of the</a>
<a name="ln486">    // log entry preceding the first one in 'messages' if messages are found for the peer.</a>
<a name="ln487">    preceding_id = queue_state_.last_appended;</a>
<a name="ln488"> </a>
<a name="ln489">    // NOTE: committed_op_id may be overwritten later.</a>
<a name="ln490">    *request-&gt;mutable_committed_op_id() = queue_state_.committed_op_id;</a>
<a name="ln491"> </a>
<a name="ln492">    request-&gt;set_caller_term(queue_state_.current_term);</a>
<a name="ln493">    unreachable_time =</a>
<a name="ln494">        MonoTime::Now().GetDeltaSince(peer-&gt;last_successful_communication_time);</a>
<a name="ln495">    if (member_type) *member_type = peer-&gt;member_type;</a>
<a name="ln496">    if (last_exchange_successful) *last_exchange_successful = peer-&gt;is_last_exchange_successful;</a>
<a name="ln497">    *needs_remote_bootstrap = peer-&gt;needs_remote_bootstrap;</a>
<a name="ln498"> </a>
<a name="ln499">    next_index = peer-&gt;next_index;</a>
<a name="ln500">    if (FLAGS_enable_consensus_exponential_backoff &amp;&amp; peer-&gt;last_num_messages_sent &gt;= 0) {</a>
<a name="ln501">      // Previous request to peer has not been acked. Reduce number of entries to be sent</a>
<a name="ln502">      // in this attempt using exponential backoff. Note that to_index is inclusive.</a>
<a name="ln503">      to_index = next_index + std::max&lt;int64_t&gt;((peer-&gt;last_num_messages_sent &gt;&gt; 1) - 1, 0);</a>
<a name="ln504">    } else {</a>
<a name="ln505">      // Previous request to peer has been acked or a heartbeat response has been received.</a>
<a name="ln506">      // Transmit as many entries as allowed.</a>
<a name="ln507">      to_index = 0;</a>
<a name="ln508">    }</a>
<a name="ln509"> </a>
<a name="ln510">    peer-&gt;current_retransmissions++;</a>
<a name="ln511"> </a>
<a name="ln512">    if (peer-&gt;member_type == RaftPeerPB::VOTER) {</a>
<a name="ln513">      is_voter = true;</a>
<a name="ln514">    }</a>
<a name="ln515">  }</a>
<a name="ln516"> </a>
<a name="ln517">  if (unreachable_time.ToSeconds() &gt; FLAGS_follower_unavailable_considered_failed_sec) {</a>
<a name="ln518">    if (!is_voter || CountVoters(*queue_state_.active_config) &gt; 2) {</a>
<a name="ln519">      // We never drop from 2 voters to 1 voter automatically, at least for now (12/4/18). We may</a>
<a name="ln520">      // want to revisit this later, we're just being cautious with this.</a>
<a name="ln521">      // We remove unconditionally any failed non-voter replica (PRE_VOTER, PRE_OBSERVER, OBSERVER).</a>
<a name="ln522">      string msg = Substitute(&quot;Leader has been unable to successfully communicate &quot;</a>
<a name="ln523">                              &quot;with Peer $0 for more than $1 seconds ($2)&quot;,</a>
<a name="ln524">                              uuid,</a>
<a name="ln525">                              FLAGS_follower_unavailable_considered_failed_sec,</a>
<a name="ln526">                              unreachable_time.ToString());</a>
<a name="ln527">      NotifyObserversOfFailedFollower(uuid, queue_state_.current_term, msg);</a>
<a name="ln528">    }</a>
<a name="ln529">  }</a>
<a name="ln530"> </a>
<a name="ln531">  if (PREDICT_FALSE(*needs_remote_bootstrap)) {</a>
<a name="ln532">      YB_LOG_WITH_PREFIX_UNLOCKED_EVERY_N_SECS(INFO, 30)</a>
<a name="ln533">          &lt;&lt; &quot;Peer needs remote bootstrap: &quot; &lt;&lt; uuid;</a>
<a name="ln534">    return Status::OK();</a>
<a name="ln535">  }</a>
<a name="ln536">  *needs_remote_bootstrap = false;</a>
<a name="ln537"> </a>
<a name="ln538">  // If we've never communicated with the peer, we don't know what messages to send, so we'll send a</a>
<a name="ln539">  // status-only request. Otherwise, we grab requests from the log starting at the last_received</a>
<a name="ln540">  // point.</a>
<a name="ln541">  if (!is_new) {</a>
<a name="ln542">    // The batch of messages to send to the peer.</a>
<a name="ln543">    int max_batch_size = FLAGS_consensus_max_batch_size_bytes - request-&gt;ByteSize();</a>
<a name="ln544">    auto result = ReadFromLogCache(next_index - 1, to_index, max_batch_size, uuid);</a>
<a name="ln545">    if (PREDICT_FALSE(!result.ok())) {</a>
<a name="ln546">      if (PREDICT_TRUE(result.status().IsNotFound())) {</a>
<a name="ln547">        std::string msg = Format(&quot;The logs necessary to catch up peer $0 have been &quot;</a>
<a name="ln548">                                 &quot;garbage collected. The follower will never be able &quot;</a>
<a name="ln549">                                 &quot;to catch up ($1)&quot;, uuid, result.status());</a>
<a name="ln550">        NotifyObserversOfFailedFollower(uuid, queue_state_.current_term, msg);</a>
<a name="ln551">      }</a>
<a name="ln552">      return result.status();</a>
<a name="ln553">    }</a>
<a name="ln554"> </a>
<a name="ln555">    if (!result-&gt;messages.empty()) {</a>
<a name="ln556">      // All entries committed at leader may not be available at lagging follower.</a>
<a name="ln557">      // `commited_op_id` in this request may make a lagging follower aware of the</a>
<a name="ln558">      // highest committed op index at the leader. We have a sanity check during tablet</a>
<a name="ln559">      // bootstrap, in TabletBootstrap::PlaySegments(), that this tablet did not lose a</a>
<a name="ln560">      // committed operation. Hence avoid sending a committed op id that is too large</a>
<a name="ln561">      // to such a lagging follower.</a>
<a name="ln562">      const auto&amp; msg = result-&gt;messages.back();</a>
<a name="ln563">      if (msg-&gt;id().index() &lt; request-&gt;mutable_committed_op_id()-&gt;index()) {</a>
<a name="ln564">        *request-&gt;mutable_committed_op_id() = msg-&gt;id();</a>
<a name="ln565">      }</a>
<a name="ln566">    }</a>
<a name="ln567"> </a>
<a name="ln568">    result-&gt;preceding_op.ToPB(&amp;preceding_id);</a>
<a name="ln569">    // We use AddAllocated rather than copy, because we pin the log cache at the &quot;all replicated&quot;</a>
<a name="ln570">    // point. At some point we may want to allow partially loading (and not pinning) earlier</a>
<a name="ln571">    // messages. At that point we'll need to do something smarter here, like copy or ref-count.</a>
<a name="ln572">    for (const auto&amp; msg : result-&gt;messages) {</a>
<a name="ln573">      request-&gt;mutable_ops()-&gt;AddAllocated(msg.get());</a>
<a name="ln574">    }</a>
<a name="ln575"> </a>
<a name="ln576">    {</a>
<a name="ln577">      LockGuard lock(queue_lock_);</a>
<a name="ln578">      auto peer = FindPtrOrNull(peers_map_, uuid);</a>
<a name="ln579">      if (PREDICT_FALSE(peer == nullptr)) {</a>
<a name="ln580">        return STATUS(NotFound, &quot;Peer not tracked.&quot;);</a>
<a name="ln581">      }</a>
<a name="ln582"> </a>
<a name="ln583">      peer-&gt;last_num_messages_sent = result-&gt;messages.size();</a>
<a name="ln584">    }</a>
<a name="ln585"> </a>
<a name="ln586">    ScopedTrackedConsumption consumption;</a>
<a name="ln587">    if (result-&gt;read_from_disk_size) {</a>
<a name="ln588">      consumption = ScopedTrackedConsumption(operations_mem_tracker_, result-&gt;read_from_disk_size);</a>
<a name="ln589">    }</a>
<a name="ln590">    *msgs_holder = ReplicateMsgsHolder(</a>
<a name="ln591">        request-&gt;mutable_ops(), std::move(result-&gt;messages), std::move(consumption));</a>
<a name="ln592"> </a>
<a name="ln593">    if (propagated_safe_time &amp;&amp; !result-&gt;have_more_messages &amp;&amp; to_index == 0) {</a>
<a name="ln594">      // Get the current local safe time on the leader and propagate it to the follower.</a>
<a name="ln595">      request-&gt;set_propagated_safe_time(propagated_safe_time.ToUint64());</a>
<a name="ln596">    } else {</a>
<a name="ln597">      request-&gt;clear_propagated_safe_time();</a>
<a name="ln598">    }</a>
<a name="ln599">  }</a>
<a name="ln600"> </a>
<a name="ln601">  DCHECK(preceding_id.IsInitialized());</a>
<a name="ln602">  request-&gt;mutable_preceding_id()-&gt;CopyFrom(preceding_id);</a>
<a name="ln603"> </a>
<a name="ln604">  if (PREDICT_FALSE(VLOG_IS_ON(2))) {</a>
<a name="ln605">    if (request-&gt;ops_size() &gt; 0) {</a>
<a name="ln606">      VLOG_WITH_PREFIX_UNLOCKED(2) &lt;&lt; &quot;Sending request with operations to Peer: &quot; &lt;&lt; uuid</a>
<a name="ln607">          &lt;&lt; &quot;. Size: &quot; &lt;&lt; request-&gt;ops_size()</a>
<a name="ln608">          &lt;&lt; &quot;. From: &quot; &lt;&lt; request-&gt;ops(0).id().ShortDebugString() &lt;&lt; &quot;. To: &quot;</a>
<a name="ln609">          &lt;&lt; request-&gt;ops(request-&gt;ops_size() - 1).id().ShortDebugString();</a>
<a name="ln610">      VLOG_WITH_PREFIX_UNLOCKED(3) &lt;&lt; &quot;Operations: &quot; &lt;&lt; yb::ToString(request-&gt;ops());</a>
<a name="ln611">    } else {</a>
<a name="ln612">      VLOG_WITH_PREFIX_UNLOCKED(2)</a>
<a name="ln613">          &lt;&lt; &quot;Sending &quot; &lt;&lt; (is_new ? &quot;new &quot; : &quot;&quot;) &lt;&lt; &quot;status only request to Peer: &quot; &lt;&lt; uuid</a>
<a name="ln614">          &lt;&lt; &quot;: &quot; &lt;&lt; request-&gt;ShortDebugString();</a>
<a name="ln615">    }</a>
<a name="ln616">  }</a>
<a name="ln617"> </a>
<a name="ln618">  return Status::OK();</a>
<a name="ln619">}</a>
<a name="ln620"> </a>
<a name="ln621">Result&lt;ReadOpsResult&gt; PeerMessageQueue::ReadFromLogCache(int64_t from_index,</a>
<a name="ln622">                                                         int64_t to_index,</a>
<a name="ln623">                                                         int max_batch_size,</a>
<a name="ln624">                                                         const std::string&amp; peer_uuid) {</a>
<a name="ln625">  DCHECK_LT(FLAGS_consensus_max_batch_size_bytes + 1_KB, FLAGS_rpc_max_message_size);</a>
<a name="ln626"> </a>
<a name="ln627">  // We try to get the follower's next_index from our log.</a>
<a name="ln628">  // Note this is not using &quot;term&quot; and needs to change</a>
<a name="ln629">  auto result = log_cache_.ReadOps(from_index, to_index, max_batch_size);</a>
<a name="ln630">  if (PREDICT_FALSE(!result.ok())) {</a>
<a name="ln631">    auto s = result.status();</a>
<a name="ln632">    if (PREDICT_TRUE(s.IsNotFound())) {</a>
<a name="ln633">      return s;</a>
<a name="ln634">    } else if (s.IsIncomplete()) {</a>
<a name="ln635">      // IsIncomplete() means that we tried to read beyond the head of the log (in the future).</a>
<a name="ln636">      // KUDU-1078 points to a fix of this log spew issue that we've ported. This should not</a>
<a name="ln637">      // happen under normal circumstances.</a>
<a name="ln638">      LOG_WITH_PREFIX_UNLOCKED(ERROR) &lt;&lt; &quot;Error trying to read ahead of the log &quot;</a>
<a name="ln639">                                      &lt;&lt; &quot;while preparing peer request: &quot;</a>
<a name="ln640">                                      &lt;&lt; s.ToString() &lt;&lt; &quot;. Destination peer: &quot;</a>
<a name="ln641">                                      &lt;&lt; peer_uuid;</a>
<a name="ln642">      return s;</a>
<a name="ln643">    } else {</a>
<a name="ln644">      LOG_WITH_PREFIX_UNLOCKED(FATAL) &lt;&lt; &quot;Error reading the log while preparing peer request: &quot;</a>
<a name="ln645">                                      &lt;&lt; s.ToString() &lt;&lt; &quot;. Destination peer: &quot;</a>
<a name="ln646">                                      &lt;&lt; peer_uuid;</a>
<a name="ln647">      return s;</a>
<a name="ln648">    }</a>
<a name="ln649">  }</a>
<a name="ln650">  return result;</a>
<a name="ln651">}</a>
<a name="ln652"> </a>
<a name="ln653">// Read majority replicated messages from cache for CDC.</a>
<a name="ln654">// CDC producer will use this to get the messages to send in response to cdc::GetChanges RPC.</a>
<a name="ln655">Result&lt;ReadOpsResult&gt; PeerMessageQueue::ReadReplicatedMessagesForCDC(const yb::OpId&amp; last_op_id,</a>
<a name="ln656">                                                                     int64_t* repl_index) {</a>
<a name="ln657">  // The batch of messages read from cache.</a>
<a name="ln658"> </a>
<a name="ln659">  int64_t to_index;</a>
<a name="ln660">  bool pending_messages = false;</a>
<a name="ln661">  {</a>
<a name="ln662">    LockGuard lock(queue_lock_);</a>
<a name="ln663">    // Use committed_op_id because it's already been processed by the Transaction codepath.</a>
<a name="ln664">    to_index = queue_state_.committed_op_id.index();</a>
<a name="ln665">    // Determine if there are pending operations in RAFT but not yet LogCache.</a>
<a name="ln666">    pending_messages = to_index != queue_state_.majority_replicated_op_id.index();</a>
<a name="ln667">  }</a>
<a name="ln668">  if (repl_index) {</a>
<a name="ln669">    *repl_index = to_index;</a>
<a name="ln670">  }</a>
<a name="ln671"> </a>
<a name="ln672">  if (last_op_id.index &gt;= to_index) {</a>
<a name="ln673">    // Nothing to read.</a>
<a name="ln674">    return ReadOpsResult();</a>
<a name="ln675">  }</a>
<a name="ln676"> </a>
<a name="ln677">  // If an empty OpID is only sent on the first read request, start at the earliest known entry.</a>
<a name="ln678">  int64_t after_op_index = last_op_id.empty() ?</a>
<a name="ln679">                             max(log_cache_.earliest_op_index(), last_op_id.index) :</a>
<a name="ln680">                             last_op_id.index;</a>
<a name="ln681"> </a>
<a name="ln682">  auto result = ReadFromLogCache(</a>
<a name="ln683">      after_op_index, to_index, FLAGS_consensus_max_batch_size_bytes, local_peer_uuid_);</a>
<a name="ln684">  if (PREDICT_FALSE(!result.ok()) &amp;&amp; PREDICT_TRUE(result.status().IsNotFound())) {</a>
<a name="ln685">    LOG_WITH_PREFIX_UNLOCKED(INFO) &lt;&lt; Format(</a>
<a name="ln686">        &quot;The logs from index $0 have been garbage collected and cannot be read ($1)&quot;,</a>
<a name="ln687">        after_op_index, result.status());</a>
<a name="ln688">  }</a>
<a name="ln689">  if (result.ok()) {</a>
<a name="ln690">    result-&gt;have_more_messages |= pending_messages;</a>
<a name="ln691">  }</a>
<a name="ln692">  return result;</a>
<a name="ln693">}</a>
<a name="ln694"> </a>
<a name="ln695">Status PeerMessageQueue::GetRemoteBootstrapRequestForPeer(const string&amp; uuid,</a>
<a name="ln696">                                                          StartRemoteBootstrapRequestPB* req) {</a>
<a name="ln697">  TrackedPeer* peer = nullptr;</a>
<a name="ln698">  {</a>
<a name="ln699">    LockGuard lock(queue_lock_);</a>
<a name="ln700">    DCHECK_EQ(queue_state_.state, State::kQueueOpen);</a>
<a name="ln701">    DCHECK_NE(uuid, local_peer_uuid_);</a>
<a name="ln702">    peer = FindPtrOrNull(peers_map_, uuid);</a>
<a name="ln703">    if (PREDICT_FALSE(peer == nullptr || queue_state_.mode == Mode::NON_LEADER)) {</a>
<a name="ln704">      return STATUS(NotFound, &quot;Peer not tracked or queue not in leader mode.&quot;);</a>
<a name="ln705">    }</a>
<a name="ln706">  }</a>
<a name="ln707"> </a>
<a name="ln708">  if (PREDICT_FALSE(!peer-&gt;needs_remote_bootstrap)) {</a>
<a name="ln709">    return STATUS(IllegalState, &quot;Peer does not need to remotely bootstrap&quot;, uuid);</a>
<a name="ln710">  }</a>
<a name="ln711"> </a>
<a name="ln712">  if (peer-&gt;member_type == RaftPeerPB::VOTER || peer-&gt;member_type == RaftPeerPB::OBSERVER) {</a>
<a name="ln713">    LOG(INFO) &lt;&lt; &quot;Remote bootstrapping peer &quot; &lt;&lt; uuid &lt;&lt; &quot; with type &quot;</a>
<a name="ln714">              &lt;&lt; RaftPeerPB::MemberType_Name(peer-&gt;member_type);</a>
<a name="ln715">  }</a>
<a name="ln716"> </a>
<a name="ln717">  req-&gt;Clear();</a>
<a name="ln718">  req-&gt;set_dest_uuid(uuid);</a>
<a name="ln719">  req-&gt;set_tablet_id(tablet_id_);</a>
<a name="ln720">  req-&gt;set_bootstrap_peer_uuid(local_peer_uuid_);</a>
<a name="ln721">  *req-&gt;mutable_source_private_addr() = local_peer_pb_.last_known_private_addr();</a>
<a name="ln722">  *req-&gt;mutable_source_broadcast_addr() = local_peer_pb_.last_known_broadcast_addr();</a>
<a name="ln723">  *req-&gt;mutable_source_cloud_info() = local_peer_pb_.cloud_info();</a>
<a name="ln724">  req-&gt;set_caller_term(queue_state_.current_term);</a>
<a name="ln725">  peer-&gt;needs_remote_bootstrap = false; // Now reset the flag.</a>
<a name="ln726">  return Status::OK();</a>
<a name="ln727">}</a>
<a name="ln728"> </a>
<a name="ln729">void PeerMessageQueue::UpdateCDCConsumerOpId(const yb::OpId&amp; op_id) {</a>
<a name="ln730">  std::lock_guard&lt;rw_spinlock&gt; l(cdc_consumer_lock_);</a>
<a name="ln731">  cdc_consumer_op_id_ = op_id;</a>
<a name="ln732">  cdc_consumer_op_id_last_updated_ = CoarseMonoClock::Now();</a>
<a name="ln733">}</a>
<a name="ln734"> </a>
<a name="ln735">yb::OpId PeerMessageQueue::GetCDCConsumerOpIdToEvict() {</a>
<a name="ln736">  std::shared_lock&lt;rw_spinlock&gt; l(cdc_consumer_lock_);</a>
<a name="ln737">  // For log cache eviction, we only want to include CDC consumers that are actively polling.</a>
<a name="ln738">  // If CDC consumer checkpoint has not been updated recently, we exclude it.</a>
<a name="ln739">  if (CoarseMonoClock::Now() - cdc_consumer_op_id_last_updated_ &lt;= kCDCConsumerCheckpointInterval) {</a>
<a name="ln740">    return cdc_consumer_op_id_;</a>
<a name="ln741">  } else {</a>
<a name="ln742">    return yb::OpId::Max();</a>
<a name="ln743">  }</a>
<a name="ln744">}</a>
<a name="ln745"> </a>
<a name="ln746">void PeerMessageQueue::UpdateAllReplicatedOpId(OpIdPB* result) {</a>
<a name="ln747">  OpIdPB new_op_id = MaximumOpId();</a>
<a name="ln748"> </a>
<a name="ln749">  for (const auto&amp; peer : peers_map_) {</a>
<a name="ln750">    if (!peer.second-&gt;is_last_exchange_successful) {</a>
<a name="ln751">      return;</a>
<a name="ln752">    }</a>
<a name="ln753">    if (peer.second-&gt;last_received.index() &lt; new_op_id.index()) {</a>
<a name="ln754">      new_op_id = peer.second-&gt;last_received;</a>
<a name="ln755">    }</a>
<a name="ln756">  }</a>
<a name="ln757"> </a>
<a name="ln758">  CHECK_NE(MaximumOpId().index(), new_op_id.index());</a>
<a name="ln759">  *result = new_op_id;</a>
<a name="ln760">}</a>
<a name="ln761"> </a>
<a name="ln762">void PeerMessageQueue::UpdateAllNonLaggingReplicatedOpId(int32_t threshold) {</a>
<a name="ln763">  OpIdPB new_op_id = MaximumOpId();</a>
<a name="ln764"> </a>
<a name="ln765">  for (const auto&amp; peer : peers_map_) {</a>
<a name="ln766">    // Ignore lagging follower.</a>
<a name="ln767">    if (peer.second-&gt;current_retransmissions &gt;= threshold) {</a>
<a name="ln768">      continue;</a>
<a name="ln769">    }</a>
<a name="ln770">    if (peer.second-&gt;last_received.index() &lt; new_op_id.index()) {</a>
<a name="ln771">      new_op_id = peer.second-&gt;last_received;</a>
<a name="ln772">    }</a>
<a name="ln773">  }</a>
<a name="ln774"> </a>
<a name="ln775">  if (new_op_id.index() == MaximumOpId().index()) {</a>
<a name="ln776">    LOG_WITH_PREFIX_UNLOCKED(INFO) &lt;&lt; &quot;Non lagging peer(s) not found.&quot;;</a>
<a name="ln777">    new_op_id = queue_state_.all_replicated_op_id;</a>
<a name="ln778">  }</a>
<a name="ln779"> </a>
<a name="ln780">  if (queue_state_.all_nonlagging_replicated_op_id.index() &lt; new_op_id.index()) {</a>
<a name="ln781">    queue_state_.all_nonlagging_replicated_op_id = new_op_id;</a>
<a name="ln782">  }</a>
<a name="ln783">}</a>
<a name="ln784"> </a>
<a name="ln785">HAS_MEMBER_FUNCTION(InfiniteWatermarkForLocalPeer);</a>
<a name="ln786"> </a>
<a name="ln787">template &lt;class Policy, bool HasMemberFunction_InfiniteWatermarkForLocalPeer&gt;</a>
<a name="ln788">struct GetInfiniteWatermarkForLocalPeer;</a>
<a name="ln789"> </a>
<a name="ln790">template &lt;class Policy&gt;</a>
<a name="ln791">struct GetInfiniteWatermarkForLocalPeer&lt;Policy, true&gt; {</a>
<a name="ln792">  static auto Apply() {</a>
<a name="ln793">    return Policy::InfiniteWatermarkForLocalPeer();</a>
<a name="ln794">  }</a>
<a name="ln795">};</a>
<a name="ln796"> </a>
<a name="ln797">template &lt;class Policy&gt;</a>
<a name="ln798">struct GetInfiniteWatermarkForLocalPeer&lt;Policy, false&gt; {</a>
<a name="ln799">  // Should not be invoked, but have to define to make compiler happy.</a>
<a name="ln800">  static typename Policy::result_type Apply() {</a>
<a name="ln801">    LOG(DFATAL) &lt;&lt; &quot;Invoked Apply when InfiniteWatermarkForLocalPeer is not defined&quot;;</a>
<a name="ln802">    return typename Policy::result_type();</a>
<a name="ln803">  }</a>
<a name="ln804">};</a>
<a name="ln805"> </a>
<a name="ln806">template &lt;class Policy&gt;</a>
<a name="ln807">typename Policy::result_type PeerMessageQueue::GetWatermark() {</a>
<a name="ln808">  DCHECK(queue_lock_.is_locked());</a>
<a name="ln809">  const int num_peers_required = queue_state_.majority_size_;</a>
<a name="ln810">  if (num_peers_required == kUninitializedMajoritySize) {</a>
<a name="ln811">    // We don't even know the quorum majority size yet.</a>
<a name="ln812">    return Policy::NotEnoughPeersValue();</a>
<a name="ln813">  }</a>
<a name="ln814">  CHECK_GE(num_peers_required, 0);</a>
<a name="ln815"> </a>
<a name="ln816">  const size_t num_peers = peers_map_.size();</a>
<a name="ln817">  if (num_peers &lt; num_peers_required) {</a>
<a name="ln818">    return Policy::NotEnoughPeersValue();</a>
<a name="ln819">  }</a>
<a name="ln820"> </a>
<a name="ln821">  // This flag indicates whether to implicitly assume that the local peer has an &quot;infinite&quot;</a>
<a name="ln822">  // replicated value of the dimension that we are computing a watermark for. There is a difference</a>
<a name="ln823">  // in logic between handling of OpIds vs. leader leases:</a>
<a name="ln824">  // - For OpIds, the local peer might actually be less up-to-date than followers.</a>
<a name="ln825">  // - For leader leases, we always assume that we've replicated an &quot;infinite&quot; lease to ourselves.</a>
<a name="ln826">  const bool local_peer_infinite_watermark =</a>
<a name="ln827">      HasMemberFunction_InfiniteWatermarkForLocalPeer&lt;Policy&gt;::value;</a>
<a name="ln828"> </a>
<a name="ln829">  if (num_peers_required == 1 &amp;&amp; local_peer_infinite_watermark) {</a>
<a name="ln830">    // We give &quot;infinite lease&quot; to ourselves.</a>
<a name="ln831">    return GetInfiniteWatermarkForLocalPeer&lt;</a>
<a name="ln832">        Policy, HasMemberFunction_InfiniteWatermarkForLocalPeer&lt;Policy&gt;::value&gt;::Apply();</a>
<a name="ln833">  }</a>
<a name="ln834"> </a>
<a name="ln835">  constexpr size_t kMaxPracticalReplicationFactor = 5;</a>
<a name="ln836">  boost::container::small_vector&lt;</a>
<a name="ln837">      typename Policy::result_type, kMaxPracticalReplicationFactor&gt; watermarks;</a>
<a name="ln838">  watermarks.reserve(num_peers - 1 + !local_peer_infinite_watermark);</a>
<a name="ln839"> </a>
<a name="ln840">  for (const PeersMap::value_type &amp;peer_map_entry : peers_map_) {</a>
<a name="ln841">    const TrackedPeer &amp;peer = *peer_map_entry.second;</a>
<a name="ln842">    if (local_peer_infinite_watermark &amp;&amp; peer.uuid == local_peer_uuid_) {</a>
<a name="ln843">      // Don't even include the local peer in the watermarks array. Assume it has an &quot;infinite&quot;</a>
<a name="ln844">      // value of the watermark.</a>
<a name="ln845">      continue;</a>
<a name="ln846">    }</a>
<a name="ln847">    if (!IsRaftConfigVoter(peer.uuid, *queue_state_.active_config)) {</a>
<a name="ln848">      // Only votes from VOTERs in the active config should be taken into consideration</a>
<a name="ln849">      continue;</a>
<a name="ln850">    }</a>
<a name="ln851">    if (peer.is_last_exchange_successful) {</a>
<a name="ln852">      watermarks.push_back(Policy::ExtractValue(peer));</a>
<a name="ln853">    }</a>
<a name="ln854">  }</a>
<a name="ln855"> </a>
<a name="ln856">  // We always assume that local peer has most recent information.</a>
<a name="ln857">  const size_t num_responsive_peers = watermarks.size() + local_peer_infinite_watermark;</a>
<a name="ln858"> </a>
<a name="ln859">  if (num_responsive_peers &lt; num_peers_required) {</a>
<a name="ln860">    VLOG_WITH_PREFIX_UNLOCKED(2)</a>
<a name="ln861">        &lt;&lt; Policy::Name() &lt;&lt; &quot; watermarks by peer: &quot; &lt;&lt; ::yb::ToString(watermarks)</a>
<a name="ln862">        &lt;&lt; &quot;, num_peers_required=&quot; &lt;&lt; num_peers_required</a>
<a name="ln863">        &lt;&lt; &quot;, num_responsive_peers=&quot; &lt;&lt; num_responsive_peers</a>
<a name="ln864">        &lt;&lt; &quot;, not enough responsive peers&quot;;</a>
<a name="ln865">    // There are not enough peers with which the last message exchange was successful.</a>
<a name="ln866">    return Policy::NotEnoughPeersValue();</a>
<a name="ln867">  }</a>
<a name="ln868"> </a>
<a name="ln869">  // If there are 5 peers (and num_peers_required is 3), and we have successfully replicated</a>
<a name="ln870">  // something to 3 of them and 4th is our local peer, there are two possibilities:</a>
<a name="ln871">  // - If local_peer_infinite_watermark is false (for OpId): watermarks.size() is 4,</a>
<a name="ln872">  //   and we want an OpId value such that 3 or more peers have replicated that or greater value.</a>
<a name="ln873">  //   Then index_of_interest = 1, computed as watermarks.size() - num_peers_required, or</a>
<a name="ln874">  //   num_responsive_peers - num_peers_required.</a>
<a name="ln875">  //</a>
<a name="ln876">  // - If local_peer_infinite_watermark is true (for leader leases): watermarks.size() is 3, and we</a>
<a name="ln877">  //   are assuming that the local peer (leader) has replicated an infinitely high watermark to</a>
<a name="ln878">  //   itself. Then watermark.size() is 3 (because we skip the local peer when populating</a>
<a name="ln879">  //   watermarks), but num_responsive_peers is still 4, and the expression stays the same.</a>
<a name="ln880"> </a>
<a name="ln881">  const size_t index_of_interest = num_responsive_peers - num_peers_required;</a>
<a name="ln882">  DCHECK_LT(index_of_interest, watermarks.size());</a>
<a name="ln883"> </a>
<a name="ln884">  auto nth = watermarks.begin() + index_of_interest;</a>
<a name="ln885">  std::nth_element(watermarks.begin(), nth, watermarks.end(), typename Policy::Comparator());</a>
<a name="ln886">  VLOG_WITH_PREFIX_UNLOCKED(2)</a>
<a name="ln887">      &lt;&lt; Policy::Name() &lt;&lt; &quot; watermarks by peer: &quot; &lt;&lt; ::yb::ToString(watermarks)</a>
<a name="ln888">      &lt;&lt; &quot;, num_peers_required=&quot; &lt;&lt; num_peers_required</a>
<a name="ln889">      &lt;&lt; &quot;, local_peer_infinite_watermark=&quot; &lt;&lt; local_peer_infinite_watermark</a>
<a name="ln890">      &lt;&lt; &quot;, watermark: &quot; &lt;&lt; yb::ToString(*nth);</a>
<a name="ln891"> </a>
<a name="ln892">  return *nth;</a>
<a name="ln893">}</a>
<a name="ln894"> </a>
<a name="ln895">CoarseTimePoint PeerMessageQueue::LeaderLeaseExpirationWatermark() {</a>
<a name="ln896">  struct Policy {</a>
<a name="ln897">    typedef CoarseTimePoint result_type;</a>
<a name="ln898">    // Workaround for a gcc bug. That does not understand that Comparator is actually being used.</a>
<a name="ln899">    __attribute__((unused)) typedef std::less&lt;result_type&gt; Comparator;</a>
<a name="ln900"> </a>
<a name="ln901">    static result_type NotEnoughPeersValue() {</a>
<a name="ln902">      return result_type::min();</a>
<a name="ln903">    }</a>
<a name="ln904"> </a>
<a name="ln905">    static result_type InfiniteWatermarkForLocalPeer() {</a>
<a name="ln906">      return result_type::max();</a>
<a name="ln907">    }</a>
<a name="ln908"> </a>
<a name="ln909">    static result_type ExtractValue(const TrackedPeer&amp; peer) {</a>
<a name="ln910">      auto lease_exp = peer.leader_lease_expiration.last_received;</a>
<a name="ln911">      return lease_exp != CoarseTimePoint() ? lease_exp : CoarseTimePoint::min();</a>
<a name="ln912">    }</a>
<a name="ln913"> </a>
<a name="ln914">    static const char* Name() {</a>
<a name="ln915">      return &quot;Leader lease expiration&quot;;</a>
<a name="ln916">    }</a>
<a name="ln917">  };</a>
<a name="ln918"> </a>
<a name="ln919">  return GetWatermark&lt;Policy&gt;();</a>
<a name="ln920">}</a>
<a name="ln921"> </a>
<a name="ln922">MicrosTime PeerMessageQueue::HybridTimeLeaseExpirationWatermark() {</a>
<a name="ln923">  struct Policy {</a>
<a name="ln924">    typedef MicrosTime result_type;</a>
<a name="ln925">    // Workaround for a gcc bug. That does not understand that Comparator is actually being used.</a>
<a name="ln926">    __attribute__((unused)) typedef std::less&lt;result_type&gt; Comparator;</a>
<a name="ln927"> </a>
<a name="ln928">    static result_type NotEnoughPeersValue() {</a>
<a name="ln929">      return HybridTime::kMin.GetPhysicalValueMicros();</a>
<a name="ln930">    }</a>
<a name="ln931"> </a>
<a name="ln932">    static result_type InfiniteWatermarkForLocalPeer() {</a>
<a name="ln933">      return HybridTime::kMax.GetPhysicalValueMicros();</a>
<a name="ln934">    }</a>
<a name="ln935"> </a>
<a name="ln936">    static result_type ExtractValue(const TrackedPeer&amp; peer) {</a>
<a name="ln937">      return peer.leader_ht_lease_expiration.last_received;</a>
<a name="ln938">    }</a>
<a name="ln939"> </a>
<a name="ln940">    static const char* Name() {</a>
<a name="ln941">      return &quot;Hybrid time leader lease expiration&quot;;</a>
<a name="ln942">    }</a>
<a name="ln943">  };</a>
<a name="ln944"> </a>
<a name="ln945">  return GetWatermark&lt;Policy&gt;();</a>
<a name="ln946">}</a>
<a name="ln947"> </a>
<a name="ln948">uint64_t PeerMessageQueue::NumSSTFilesWatermark() {</a>
<a name="ln949">  struct Policy {</a>
<a name="ln950">    typedef uint64_t result_type;</a>
<a name="ln951">    // Workaround for a gcc bug. That does not understand that Comparator is actually being used.</a>
<a name="ln952">    __attribute__((unused)) typedef std::greater&lt;result_type&gt; Comparator;</a>
<a name="ln953"> </a>
<a name="ln954">    static result_type NotEnoughPeersValue() {</a>
<a name="ln955">      return 0;</a>
<a name="ln956">    }</a>
<a name="ln957"> </a>
<a name="ln958">    static result_type ExtractValue(const TrackedPeer&amp; peer) {</a>
<a name="ln959">      return peer.num_sst_files;</a>
<a name="ln960">    }</a>
<a name="ln961"> </a>
<a name="ln962">    static const char* Name() {</a>
<a name="ln963">      return &quot;Num SST files&quot;;</a>
<a name="ln964">    }</a>
<a name="ln965">  };</a>
<a name="ln966"> </a>
<a name="ln967">  auto watermark = GetWatermark&lt;Policy&gt;();</a>
<a name="ln968">  return std::max(watermark, local_peer_-&gt;num_sst_files);</a>
<a name="ln969">}</a>
<a name="ln970"> </a>
<a name="ln971">OpIdPB PeerMessageQueue::OpIdWatermark() {</a>
<a name="ln972">  struct Policy {</a>
<a name="ln973">    typedef OpIdPB result_type;</a>
<a name="ln974"> </a>
<a name="ln975">    static result_type NotEnoughPeersValue() {</a>
<a name="ln976">      return MinimumOpId();</a>
<a name="ln977">    }</a>
<a name="ln978"> </a>
<a name="ln979">    static result_type ExtractValue(const TrackedPeer&amp; peer) {</a>
<a name="ln980">      return peer.last_received;</a>
<a name="ln981">    }</a>
<a name="ln982"> </a>
<a name="ln983">    struct Comparator {</a>
<a name="ln984">      bool operator()(const OpIdPB&amp; lhs, const OpIdPB&amp; rhs) {</a>
<a name="ln985">        return lhs.index() &lt; rhs.index();</a>
<a name="ln986">      }</a>
<a name="ln987">    };</a>
<a name="ln988"> </a>
<a name="ln989">    static const char* Name() {</a>
<a name="ln990">      return &quot;OpId&quot;;</a>
<a name="ln991">    }</a>
<a name="ln992">  };</a>
<a name="ln993"> </a>
<a name="ln994">  return GetWatermark&lt;Policy&gt;();</a>
<a name="ln995">}</a>
<a name="ln996"> </a>
<a name="ln997">void PeerMessageQueue::NotifyPeerIsResponsiveDespiteError(const std::string&amp; peer_uuid) {</a>
<a name="ln998">  LockGuard l(queue_lock_);</a>
<a name="ln999">  TrackedPeer* peer = FindPtrOrNull(peers_map_, peer_uuid);</a>
<a name="ln1000">  if (!peer) return;</a>
<a name="ln1001">  peer-&gt;last_successful_communication_time = MonoTime::Now();</a>
<a name="ln1002">}</a>
<a name="ln1003"> </a>
<a name="ln1004">bool PeerMessageQueue::ResponseFromPeer(const std::string&amp; peer_uuid,</a>
<a name="ln1005">                                        const ConsensusResponsePB&amp; response) {</a>
<a name="ln1006">  DCHECK(response.IsInitialized()) &lt;&lt; &quot;Error: Uninitialized: &quot;</a>
<a name="ln1007">      &lt;&lt; response.InitializationErrorString() &lt;&lt; &quot;. Response: &quot; &lt;&lt; response.ShortDebugString();</a>
<a name="ln1008"> </a>
<a name="ln1009">  MajorityReplicatedData majority_replicated;</a>
<a name="ln1010">  Mode mode_copy;</a>
<a name="ln1011">  bool result = false;</a>
<a name="ln1012">  {</a>
<a name="ln1013">    LockGuard scoped_lock(queue_lock_);</a>
<a name="ln1014">    DCHECK_NE(State::kQueueConstructed, queue_state_.state);</a>
<a name="ln1015"> </a>
<a name="ln1016">    TrackedPeer* peer = FindPtrOrNull(peers_map_, peer_uuid);</a>
<a name="ln1017">    if (PREDICT_FALSE(queue_state_.state != State::kQueueOpen || peer == nullptr)) {</a>
<a name="ln1018">      LOG_WITH_PREFIX_UNLOCKED(WARNING) &lt;&lt; &quot;Queue is closed or peer was untracked, disregarding &quot;</a>
<a name="ln1019">          &quot;peer response. Response: &quot; &lt;&lt; response.ShortDebugString();</a>
<a name="ln1020">      return false;</a>
<a name="ln1021">    }</a>
<a name="ln1022"> </a>
<a name="ln1023">    // Remotely bootstrap the peer if the tablet is not found or deleted.</a>
<a name="ln1024">    if (response.has_error()) {</a>
<a name="ln1025">      // We only let special types of errors through to this point from the peer.</a>
<a name="ln1026">      CHECK_EQ(tserver::TabletServerErrorPB::TABLET_NOT_FOUND, response.error().code())</a>
<a name="ln1027">          &lt;&lt; response.ShortDebugString();</a>
<a name="ln1028"> </a>
<a name="ln1029">      peer-&gt;needs_remote_bootstrap = true;</a>
<a name="ln1030">      // Since we received a response from the peer, we know it is alive. So we need to update</a>
<a name="ln1031">      // peer-&gt;last_successful_communication_time, otherwise, we will remove this peer from the</a>
<a name="ln1032">      // configuration if the remote bootstrap is not completed within</a>
<a name="ln1033">      // FLAGS_follower_unavailable_considered_failed_sec seconds.</a>
<a name="ln1034">      peer-&gt;last_successful_communication_time = MonoTime::Now();</a>
<a name="ln1035">      YB_LOG_WITH_PREFIX_UNLOCKED_EVERY_N_SECS(INFO, 30)</a>
<a name="ln1036">          &lt;&lt; &quot;Marked peer as needing remote bootstrap: &quot; &lt;&lt; peer-&gt;ToString();</a>
<a name="ln1037">      return true;</a>
<a name="ln1038">    }</a>
<a name="ln1039"> </a>
<a name="ln1040">    if (queue_state_.active_config) {</a>
<a name="ln1041">      RaftPeerPB peer_pb;</a>
<a name="ln1042">      if (!GetRaftConfigMember(*queue_state_.active_config, peer_uuid, &amp;peer_pb).ok()) {</a>
<a name="ln1043">        LOG(FATAL) &lt;&lt; &quot;Peer &quot; &lt;&lt; peer_uuid &lt;&lt; &quot; not in active config&quot;;</a>
<a name="ln1044">      }</a>
<a name="ln1045">      peer-&gt;member_type = peer_pb.member_type();</a>
<a name="ln1046">    } else {</a>
<a name="ln1047">      peer-&gt;member_type = RaftPeerPB::UNKNOWN_MEMBER_TYPE;</a>
<a name="ln1048">    }</a>
<a name="ln1049"> </a>
<a name="ln1050">    // Application level errors should be handled elsewhere</a>
<a name="ln1051">    DCHECK(!response.has_error());</a>
<a name="ln1052"> </a>
<a name="ln1053">    // Take a snapshot of the current peer status.</a>
<a name="ln1054">    TrackedPeer previous = *peer;</a>
<a name="ln1055"> </a>
<a name="ln1056">    // Update the peer status based on the response.</a>
<a name="ln1057">    peer-&gt;is_new = false;</a>
<a name="ln1058">    peer-&gt;last_successful_communication_time = MonoTime::Now();</a>
<a name="ln1059"> </a>
<a name="ln1060">    // Reset so that next transmission is not considered a re-transmission.</a>
<a name="ln1061">    peer-&gt;last_num_messages_sent = -1;</a>
<a name="ln1062">    peer-&gt;current_retransmissions = -1;</a>
<a name="ln1063"> </a>
<a name="ln1064">    if (response.has_status()) {</a>
<a name="ln1065">      const auto&amp; status = response.status();</a>
<a name="ln1066">      // Sanity checks.  Some of these can be eventually removed, but they are handy for now.</a>
<a name="ln1067">      DCHECK(status.IsInitialized()) &lt;&lt; &quot;Error: Uninitialized: &quot;</a>
<a name="ln1068">                                                &lt;&lt; response.InitializationErrorString()</a>
<a name="ln1069">                                                &lt;&lt; &quot;. Response: &quot; &lt;&lt; response.ShortDebugString();</a>
<a name="ln1070">      // The status must always have a last received op id and a last committed index.</a>
<a name="ln1071">      DCHECK(status.has_last_received());</a>
<a name="ln1072">      DCHECK(status.has_last_received_current_leader());</a>
<a name="ln1073">      DCHECK(status.has_last_committed_idx());</a>
<a name="ln1074"> </a>
<a name="ln1075">      peer-&gt;last_known_committed_idx = status.last_committed_idx();</a>
<a name="ln1076"> </a>
<a name="ln1077">      // If the reported last-received op for the replica is in our local log, then resume sending</a>
<a name="ln1078">      // entries from that point onward. Otherwise, resume after the last op they received from us.</a>
<a name="ln1079">      // If we've never successfully sent them anything, start after the last-committed op in their</a>
<a name="ln1080">      // log, which is guaranteed by the Raft protocol to be a valid op.</a>
<a name="ln1081"> </a>
<a name="ln1082">      bool peer_has_prefix_of_log = IsOpInLog(yb::OpId::FromPB(status.last_received()));</a>
<a name="ln1083">      if (peer_has_prefix_of_log) {</a>
<a name="ln1084">        // If the latest thing in their log is in our log, we are in sync.</a>
<a name="ln1085">        peer-&gt;last_received = status.last_received();</a>
<a name="ln1086">        peer-&gt;next_index = peer-&gt;last_received.index() + 1;</a>
<a name="ln1087"> </a>
<a name="ln1088">      } else if (!OpIdEquals(status.last_received_current_leader(), MinimumOpId())) {</a>
<a name="ln1089">        // Their log may have diverged from ours, however we are in the process of replicating our</a>
<a name="ln1090">        // ops to them, so continue doing so. Eventually, we will cause the divergent entry in their</a>
<a name="ln1091">        // log to be overwritten.</a>
<a name="ln1092">        peer-&gt;last_received = status.last_received_current_leader();</a>
<a name="ln1093">        peer-&gt;next_index = peer-&gt;last_received.index() + 1;</a>
<a name="ln1094">      } else {</a>
<a name="ln1095">        // The peer is divergent and they have not (successfully) received anything from us yet.</a>
<a name="ln1096">        // Start sending from their last committed index.  This logic differs from the Raft spec</a>
<a name="ln1097">        // slightly because instead of stepping back one-by-one from the end until we no longer have</a>
<a name="ln1098">        // an LMP error, we jump back to the last committed op indicated by the peer with the hope</a>
<a name="ln1099">        // that doing so will result in a faster catch-up process.</a>
<a name="ln1100">        DCHECK_GE(peer-&gt;last_known_committed_idx, 0);</a>
<a name="ln1101">        peer-&gt;next_index = peer-&gt;last_known_committed_idx + 1;</a>
<a name="ln1102">      }</a>
<a name="ln1103"> </a>
<a name="ln1104">      if (PREDICT_FALSE(status.has_error())) {</a>
<a name="ln1105">        peer-&gt;is_last_exchange_successful = false;</a>
<a name="ln1106">        switch (status.error().code()) {</a>
<a name="ln1107">          case ConsensusErrorPB::PRECEDING_ENTRY_DIDNT_MATCH: {</a>
<a name="ln1108">            DCHECK(status.has_last_received());</a>
<a name="ln1109">            if (previous.is_new) {</a>
<a name="ln1110">              // That's currently how we can detect that we able to connect to a peer.</a>
<a name="ln1111">              LOG_WITH_PREFIX_UNLOCKED(INFO) &lt;&lt; &quot;Connected to new peer: &quot; &lt;&lt; peer-&gt;ToString();</a>
<a name="ln1112">            } else {</a>
<a name="ln1113">              LOG_WITH_PREFIX_UNLOCKED(INFO) &lt;&lt; &quot;Got LMP mismatch error from peer: &quot;</a>
<a name="ln1114">                                             &lt;&lt; peer-&gt;ToString();</a>
<a name="ln1115">            }</a>
<a name="ln1116">            return true;</a>
<a name="ln1117">          }</a>
<a name="ln1118">          case ConsensusErrorPB::INVALID_TERM: {</a>
<a name="ln1119">            CHECK(response.has_responder_term());</a>
<a name="ln1120">            LOG_WITH_PREFIX_UNLOCKED(INFO) &lt;&lt; &quot;Peer responded invalid term: &quot; &lt;&lt; peer-&gt;ToString()</a>
<a name="ln1121">                                           &lt;&lt; &quot;. Peer's new term: &quot; &lt;&lt; response.responder_term();</a>
<a name="ln1122">            NotifyObserversOfTermChange(response.responder_term());</a>
<a name="ln1123">            return false;</a>
<a name="ln1124">          }</a>
<a name="ln1125">          default: {</a>
<a name="ln1126">            LOG_WITH_PREFIX_UNLOCKED(FATAL) &lt;&lt; &quot;Unexpected consensus error. Code: &quot;</a>
<a name="ln1127">                &lt;&lt; ConsensusErrorPB::Code_Name(status.error().code()) &lt;&lt; &quot;. Response: &quot;</a>
<a name="ln1128">                &lt;&lt; response.ShortDebugString();</a>
<a name="ln1129">          }</a>
<a name="ln1130">        }</a>
<a name="ln1131">      }</a>
<a name="ln1132">    }</a>
<a name="ln1133"> </a>
<a name="ln1134">    peer-&gt;is_last_exchange_successful = true;</a>
<a name="ln1135">    peer-&gt;num_sst_files = response.num_sst_files();</a>
<a name="ln1136"> </a>
<a name="ln1137">    if (response.has_responder_term()) {</a>
<a name="ln1138">      // The peer must have responded with a term that is greater than or equal to the last known</a>
<a name="ln1139">      // term for that peer.</a>
<a name="ln1140">      peer-&gt;CheckMonotonicTerms(response.responder_term());</a>
<a name="ln1141"> </a>
<a name="ln1142">      // If the responder didn't send an error back that must mean that it has a term that is the</a>
<a name="ln1143">      // same or lower than ours.</a>
<a name="ln1144">      CHECK_LE(response.responder_term(), queue_state_.current_term);</a>
<a name="ln1145">    }</a>
<a name="ln1146"> </a>
<a name="ln1147">    if (PREDICT_FALSE(VLOG_IS_ON(2))) {</a>
<a name="ln1148">      VLOG_WITH_PREFIX_UNLOCKED(2) &lt;&lt; &quot;Received Response from Peer (&quot; &lt;&lt; peer-&gt;ToString() &lt;&lt; &quot;). &quot;</a>
<a name="ln1149">          &lt;&lt; &quot;Response: &quot; &lt;&lt; response.ShortDebugString();</a>
<a name="ln1150">    }</a>
<a name="ln1151"> </a>
<a name="ln1152">    // If our log has the next request for the peer or if the peer's committed index is lower than</a>
<a name="ln1153">    // our own, set 'more_pending' to true.</a>
<a name="ln1154">    result = log_cache_.HasOpBeenWritten(peer-&gt;next_index) ||</a>
<a name="ln1155">        (peer-&gt;last_known_committed_idx &lt; queue_state_.committed_op_id.index());</a>
<a name="ln1156"> </a>
<a name="ln1157">    mode_copy = queue_state_.mode;</a>
<a name="ln1158">    if (mode_copy == Mode::LEADER) {</a>
<a name="ln1159">      auto new_majority_replicated_opid = OpIdWatermark();</a>
<a name="ln1160">      if (!OpIdEquals(new_majority_replicated_opid, MinimumOpId())) {</a>
<a name="ln1161">        if (new_majority_replicated_opid.index() == MaximumOpId().index()) {</a>
<a name="ln1162">          queue_state_.majority_replicated_op_id = local_peer_-&gt;last_received;</a>
<a name="ln1163">        } else {</a>
<a name="ln1164">          queue_state_.majority_replicated_op_id = new_majority_replicated_opid;</a>
<a name="ln1165">        }</a>
<a name="ln1166">      }</a>
<a name="ln1167"> </a>
<a name="ln1168">      peer-&gt;leader_lease_expiration.OnReplyFromFollower();</a>
<a name="ln1169">      peer-&gt;leader_ht_lease_expiration.OnReplyFromFollower();</a>
<a name="ln1170"> </a>
<a name="ln1171">      majority_replicated.op_id = queue_state_.majority_replicated_op_id;</a>
<a name="ln1172">      majority_replicated.leader_lease_expiration = LeaderLeaseExpirationWatermark();</a>
<a name="ln1173">      majority_replicated.ht_lease_expiration = HybridTimeLeaseExpirationWatermark();</a>
<a name="ln1174">      majority_replicated.num_sst_files = NumSSTFilesWatermark();</a>
<a name="ln1175">    }</a>
<a name="ln1176"> </a>
<a name="ln1177">    UpdateAllReplicatedOpId(&amp;queue_state_.all_replicated_op_id);</a>
<a name="ln1178"> </a>
<a name="ln1179">    auto evict_index = GetCDCConsumerOpIdToEvict().index;</a>
<a name="ln1180"> </a>
<a name="ln1181">    int32_t lagging_follower_threshold = FLAGS_consensus_lagging_follower_threshold;</a>
<a name="ln1182">    if (lagging_follower_threshold &gt; 0) {</a>
<a name="ln1183">      UpdateAllNonLaggingReplicatedOpId(lagging_follower_threshold);</a>
<a name="ln1184">      evict_index = std::min(evict_index, queue_state_.all_nonlagging_replicated_op_id.index());</a>
<a name="ln1185">    } else {</a>
<a name="ln1186">      evict_index = std::min(evict_index, queue_state_.all_replicated_op_id.index());</a>
<a name="ln1187">    }</a>
<a name="ln1188"> </a>
<a name="ln1189">    log_cache_.EvictThroughOp(evict_index);</a>
<a name="ln1190"> </a>
<a name="ln1191">    UpdateMetrics();</a>
<a name="ln1192">  }</a>
<a name="ln1193"> </a>
<a name="ln1194">  if (mode_copy == Mode::LEADER) {</a>
<a name="ln1195">    NotifyObserversOfMajorityReplOpChange(majority_replicated);</a>
<a name="ln1196">  }</a>
<a name="ln1197"> </a>
<a name="ln1198">  return result;</a>
<a name="ln1199">}</a>
<a name="ln1200"> </a>
<a name="ln1201">PeerMessageQueue::TrackedPeer PeerMessageQueue::GetTrackedPeerForTests(string uuid) {</a>
<a name="ln1202">  LockGuard scoped_lock(queue_lock_);</a>
<a name="ln1203">  TrackedPeer* tracked = FindOrDie(peers_map_, uuid);</a>
<a name="ln1204">  return *tracked;</a>
<a name="ln1205">}</a>
<a name="ln1206"> </a>
<a name="ln1207">OpIdPB PeerMessageQueue::GetAllReplicatedIndexForTests() const {</a>
<a name="ln1208">  LockGuard lock(queue_lock_);</a>
<a name="ln1209">  return queue_state_.all_replicated_op_id;</a>
<a name="ln1210">}</a>
<a name="ln1211"> </a>
<a name="ln1212">OpIdPB PeerMessageQueue::GetCommittedIndexForTests() const {</a>
<a name="ln1213">  LockGuard lock(queue_lock_);</a>
<a name="ln1214">  return queue_state_.committed_op_id;</a>
<a name="ln1215">}</a>
<a name="ln1216"> </a>
<a name="ln1217">OpIdPB PeerMessageQueue::GetMajorityReplicatedOpIdForTests() const {</a>
<a name="ln1218">  LockGuard lock(queue_lock_);</a>
<a name="ln1219">  return queue_state_.majority_replicated_op_id;</a>
<a name="ln1220">}</a>
<a name="ln1221"> </a>
<a name="ln1222">OpIdPB PeerMessageQueue::TEST_GetLastAppended() const {</a>
<a name="ln1223">  LockGuard lock(queue_lock_);</a>
<a name="ln1224">  return queue_state_.last_appended;</a>
<a name="ln1225">}</a>
<a name="ln1226"> </a>
<a name="ln1227">void PeerMessageQueue::UpdateMetrics() {</a>
<a name="ln1228">  // Since operations have consecutive indices we can update the metrics based on simple index math.</a>
<a name="ln1229">  metrics_.num_majority_done_ops-&gt;set_value(</a>
<a name="ln1230">      queue_state_.committed_op_id.index() -</a>
<a name="ln1231">      queue_state_.all_replicated_op_id.index());</a>
<a name="ln1232">  metrics_.num_in_progress_ops-&gt;set_value(</a>
<a name="ln1233">      queue_state_.last_appended.index() -</a>
<a name="ln1234">      queue_state_.committed_op_id.index());</a>
<a name="ln1235">}</a>
<a name="ln1236"> </a>
<a name="ln1237">void PeerMessageQueue::DumpToHtml(std::ostream&amp; out) const {</a>
<a name="ln1238">  using std::endl;</a>
<a name="ln1239"> </a>
<a name="ln1240">  LockGuard lock(queue_lock_);</a>
<a name="ln1241">  out &lt;&lt; &quot;&lt;h3&gt;Watermarks&lt;/h3&gt;&quot; &lt;&lt; endl;</a>
<a name="ln1242">  out &lt;&lt; &quot;&lt;table&gt;&quot; &lt;&lt; endl;;</a>
<a name="ln1243">  out &lt;&lt; &quot;  &lt;tr&gt;&lt;th&gt;Peer&lt;/th&gt;&lt;th&gt;Watermark&lt;/th&gt;&lt;/tr&gt;&quot; &lt;&lt; endl;</a>
<a name="ln1244">  for (const PeersMap::value_type&amp; entry : peers_map_) {</a>
<a name="ln1245">    out &lt;&lt; Substitute(&quot;  &lt;tr&gt;&lt;td&gt;$0&lt;/td&gt;&lt;td&gt;$1&lt;/td&gt;&lt;/tr&gt;&quot;,</a>
<a name="ln1246">                      EscapeForHtmlToString(entry.first),</a>
<a name="ln1247">                      EscapeForHtmlToString(entry.second-&gt;ToString())) &lt;&lt; endl;</a>
<a name="ln1248">  }</a>
<a name="ln1249">  out &lt;&lt; &quot;&lt;/table&gt;&quot; &lt;&lt; endl;</a>
<a name="ln1250"> </a>
<a name="ln1251">  log_cache_.DumpToHtml(out);</a>
<a name="ln1252">}</a>
<a name="ln1253"> </a>
<a name="ln1254">void PeerMessageQueue::ClearUnlocked() {</a>
<a name="ln1255">  STLDeleteValues(&amp;peers_map_);</a>
<a name="ln1256">  queue_state_.state = State::kQueueClosed;</a>
<a name="ln1257">}</a>
<a name="ln1258"> </a>
<a name="ln1259">void PeerMessageQueue::Close() {</a>
<a name="ln1260">  if (installed_num_sst_files_changed_listener_) {</a>
<a name="ln1261">    context_-&gt;ListenNumSSTFilesChanged(std::function&lt;void()&gt;());</a>
<a name="ln1262">    installed_num_sst_files_changed_listener_ = false;</a>
<a name="ln1263">  }</a>
<a name="ln1264">  raft_pool_observers_token_-&gt;Shutdown();</a>
<a name="ln1265">  LockGuard lock(queue_lock_);</a>
<a name="ln1266">  ClearUnlocked();</a>
<a name="ln1267">}</a>
<a name="ln1268"> </a>
<a name="ln1269">string PeerMessageQueue::ToString() const {</a>
<a name="ln1270">  // Even though metrics are thread-safe obtain the lock so that we get a &quot;consistent&quot; snapshot of</a>
<a name="ln1271">  // the metrics.</a>
<a name="ln1272">  LockGuard lock(queue_lock_);</a>
<a name="ln1273">  return ToStringUnlocked();</a>
<a name="ln1274">}</a>
<a name="ln1275"> </a>
<a name="ln1276">string PeerMessageQueue::ToStringUnlocked() const {</a>
<a name="ln1277">  return Substitute(&quot;Consensus queue metrics:&quot;</a>
<a name="ln1278">                    &quot;Only Majority Done Ops: $0, In Progress Ops: $1, Cache: $2&quot;,</a>
<a name="ln1279">                    metrics_.num_majority_done_ops-&gt;value(), metrics_.num_in_progress_ops-&gt;value(),</a>
<a name="ln1280">                    log_cache_.StatsString());</a>
<a name="ln1281">}</a>
<a name="ln1282"> </a>
<a name="ln1283">void PeerMessageQueue::RegisterObserver(PeerMessageQueueObserver* observer) {</a>
<a name="ln1284">  LockGuard lock(queue_lock_);</a>
<a name="ln1285">  auto iter = std::find(observers_.begin(), observers_.end(), observer);</a>
<a name="ln1286">  if (iter == observers_.end()) {</a>
<a name="ln1287">    observers_.push_back(observer);</a>
<a name="ln1288">  }</a>
<a name="ln1289">}</a>
<a name="ln1290"> </a>
<a name="ln1291">Status PeerMessageQueue::UnRegisterObserver(PeerMessageQueueObserver* observer) {</a>
<a name="ln1292">  LockGuard lock(queue_lock_);</a>
<a name="ln1293">  auto iter = std::find(observers_.begin(), observers_.end(), observer);</a>
<a name="ln1294">  if (iter == observers_.end()) {</a>
<a name="ln1295">    return STATUS(NotFound, &quot;Can't find observer.&quot;);</a>
<a name="ln1296">  }</a>
<a name="ln1297">  observers_.erase(iter);</a>
<a name="ln1298">  return Status::OK();</a>
<a name="ln1299">}</a>
<a name="ln1300"> </a>
<a name="ln1301">const char* PeerMessageQueue::ModeToStr(Mode mode) {</a>
<a name="ln1302">  switch (mode) {</a>
<a name="ln1303">    case Mode::LEADER: return &quot;LEADER&quot;;</a>
<a name="ln1304">    case Mode::NON_LEADER: return &quot;NON_LEADER&quot;;</a>
<a name="ln1305">  }</a>
<a name="ln1306">  FATAL_INVALID_ENUM_VALUE(PeerMessageQueue::Mode, mode);</a>
<a name="ln1307">}</a>
<a name="ln1308"> </a>
<a name="ln1309">const char* PeerMessageQueue::StateToStr(State state) {</a>
<a name="ln1310">  switch (state) {</a>
<a name="ln1311">    case State::kQueueConstructed:</a>
<a name="ln1312">      return &quot;QUEUE_CONSTRUCTED&quot;;</a>
<a name="ln1313">    case State::kQueueOpen:</a>
<a name="ln1314">      return &quot;QUEUE_OPEN&quot;;</a>
<a name="ln1315">    case State::kQueueClosed:</a>
<a name="ln1316">      return &quot;QUEUE_CLOSED&quot;;</a>
<a name="ln1317"> </a>
<a name="ln1318">  }</a>
<a name="ln1319">  FATAL_INVALID_ENUM_VALUE(PeerMessageQueue::State, state);</a>
<a name="ln1320">}</a>
<a name="ln1321"> </a>
<a name="ln1322">bool PeerMessageQueue::IsOpInLog(const yb::OpId&amp; desired_op) const {</a>
<a name="ln1323">  auto result = log_cache_.LookupOpId(desired_op.index);</a>
<a name="ln1324">  if (PREDICT_TRUE(result.ok())) {</a>
<a name="ln1325">    return desired_op == *result;</a>
<a name="ln1326">  }</a>
<a name="ln1327">  if (PREDICT_TRUE(result.status().IsNotFound() || result.status().IsIncomplete())) {</a>
<a name="ln1328">    return false;</a>
<a name="ln1329">  }</a>
<a name="ln1330">  LOG_WITH_PREFIX_UNLOCKED(FATAL) &lt;&lt; &quot;Error while reading the log: &quot; &lt;&lt; result.status();</a>
<a name="ln1331">  return false; // Unreachable; here to squelch GCC warning.</a>
<a name="ln1332">}</a>
<a name="ln1333"> </a>
<a name="ln1334">void PeerMessageQueue::NotifyObserversOfMajorityReplOpChange(</a>
<a name="ln1335">    const MajorityReplicatedData&amp; majority_replicated_data) {</a>
<a name="ln1336">  if (!majority_replicated_data.op_id.IsInitialized()) {</a>
<a name="ln1337">    LOG_WITH_PREFIX_UNLOCKED(DFATAL)</a>
<a name="ln1338">        &lt;&lt; &quot;Invalid majority replicated: &quot; &lt;&lt; majority_replicated_data.ToString();</a>
<a name="ln1339">    return;</a>
<a name="ln1340">  }</a>
<a name="ln1341">  WARN_NOT_OK(raft_pool_observers_token_-&gt;SubmitClosure(</a>
<a name="ln1342">      Bind(&amp;PeerMessageQueue::NotifyObserversOfMajorityReplOpChangeTask,</a>
<a name="ln1343">           Unretained(this),</a>
<a name="ln1344">           majority_replicated_data)),</a>
<a name="ln1345">      LogPrefixUnlocked() + &quot;Unable to notify RaftConsensus of &quot;</a>
<a name="ln1346">                           &quot;majority replicated op change.&quot;);</a>
<a name="ln1347">}</a>
<a name="ln1348"> </a>
<a name="ln1349">template &lt;class Func&gt;</a>
<a name="ln1350">void PeerMessageQueue::NotifyObservers(const char* title, Func&amp;&amp; func) {</a>
<a name="ln1351">  WARN_NOT_OK(</a>
<a name="ln1352">      raft_pool_observers_token_-&gt;SubmitFunc(</a>
<a name="ln1353">          [this, func = std::move(func)] {</a>
<a name="ln1354">        MAYBE_INJECT_RANDOM_LATENCY(FLAGS_consensus_inject_latency_ms_in_notifications);</a>
<a name="ln1355">        std::vector&lt;PeerMessageQueueObserver*&gt; copy;</a>
<a name="ln1356">        {</a>
<a name="ln1357">          LockGuard lock(queue_lock_);</a>
<a name="ln1358">          copy = observers_;</a>
<a name="ln1359">        }</a>
<a name="ln1360"> </a>
<a name="ln1361">        for (PeerMessageQueueObserver* observer : copy) {</a>
<a name="ln1362">          func(observer);</a>
<a name="ln1363">        }</a>
<a name="ln1364">      }),</a>
<a name="ln1365">      Format(&quot;$0Unable to notify observers for $1.&quot;, LogPrefixUnlocked(), title));</a>
<a name="ln1366">}</a>
<a name="ln1367"> </a>
<a name="ln1368">void PeerMessageQueue::NotifyObserversOfTermChange(int64_t term) {</a>
<a name="ln1369">  NotifyObservers(&quot;term change&quot;, [term](PeerMessageQueueObserver* observer) {</a>
<a name="ln1370">    observer-&gt;NotifyTermChange(term);</a>
<a name="ln1371">  });</a>
<a name="ln1372">}</a>
<a name="ln1373"> </a>
<a name="ln1374">void PeerMessageQueue::NotifyObserversOfMajorityReplOpChangeTask(</a>
<a name="ln1375">    const MajorityReplicatedData&amp; majority_replicated_data) {</a>
<a name="ln1376">  std::vector&lt;PeerMessageQueueObserver*&gt; copy;</a>
<a name="ln1377">  {</a>
<a name="ln1378">    LockGuard lock(queue_lock_);</a>
<a name="ln1379">    copy = observers_;</a>
<a name="ln1380">  }</a>
<a name="ln1381"> </a>
<a name="ln1382">  // TODO move commit index advancement here so that the queue is not dependent on consensus at all,</a>
<a name="ln1383">  // but that requires a bit more work.</a>
<a name="ln1384">  OpIdPB new_committed_index;</a>
<a name="ln1385">  for (PeerMessageQueueObserver* observer : copy) {</a>
<a name="ln1386">    observer-&gt;UpdateMajorityReplicated(majority_replicated_data, &amp;new_committed_index);</a>
<a name="ln1387">  }</a>
<a name="ln1388"> </a>
<a name="ln1389">  {</a>
<a name="ln1390">    LockGuard lock(queue_lock_);</a>
<a name="ln1391">    if (new_committed_index.IsInitialized() &amp;&amp;</a>
<a name="ln1392">        new_committed_index.index() &gt; queue_state_.committed_op_id.index()) {</a>
<a name="ln1393">      queue_state_.committed_op_id.CopyFrom(new_committed_index);</a>
<a name="ln1394">    }</a>
<a name="ln1395">  }</a>
<a name="ln1396">}</a>
<a name="ln1397"> </a>
<a name="ln1398">void PeerMessageQueue::NotifyObserversOfFailedFollower(const string&amp; uuid,</a>
<a name="ln1399">                                                       const string&amp; reason) {</a>
<a name="ln1400">  int64_t current_term;</a>
<a name="ln1401">  {</a>
<a name="ln1402">    LockGuard lock(queue_lock_);</a>
<a name="ln1403">    current_term = queue_state_.current_term;</a>
<a name="ln1404">  }</a>
<a name="ln1405">  NotifyObserversOfFailedFollower(uuid, current_term, reason);</a>
<a name="ln1406">}</a>
<a name="ln1407"> </a>
<a name="ln1408">void PeerMessageQueue::NotifyObserversOfFailedFollower(const string&amp; uuid,</a>
<a name="ln1409">                                                       int64_t term,</a>
<a name="ln1410">                                                       const string&amp; reason) {</a>
<a name="ln1411">  NotifyObservers(&quot;failed follower&quot;, [uuid, term, reason](PeerMessageQueueObserver* observer) {</a>
<a name="ln1412">    observer-&gt;NotifyFailedFollower(uuid, term, reason);</a>
<a name="ln1413">  });</a>
<a name="ln1414">}</a>
<a name="ln1415"> </a>
<a name="ln1416">bool PeerMessageQueue::PeerAcceptedOurLease(const std::string&amp; uuid) const {</a>
<a name="ln1417">  std::lock_guard&lt;simple_spinlock&gt; lock(queue_lock_);</a>
<a name="ln1418">  TrackedPeer* peer = FindPtrOrNull(peers_map_, uuid);</a>
<a name="ln1419">  if (peer == nullptr) {</a>
<a name="ln1420">    return false;</a>
<a name="ln1421">  }</a>
<a name="ln1422"> </a>
<a name="ln1423">  return peer-&gt;leader_lease_expiration.last_received != CoarseTimePoint();</a>
<a name="ln1424">}</a>
<a name="ln1425"> </a>
<a name="ln1426">bool PeerMessageQueue::CanPeerBecomeLeader(const std::string&amp; peer_uuid) const {</a>
<a name="ln1427">  std::lock_guard&lt;simple_spinlock&gt; lock(queue_lock_);</a>
<a name="ln1428">  TrackedPeer* peer = FindPtrOrNull(peers_map_, peer_uuid);</a>
<a name="ln1429">  if (peer == nullptr) {</a>
<a name="ln1430">    LOG(ERROR) &lt;&lt; &quot;Invalid peer UUID: &quot; &lt;&lt; peer_uuid;</a>
<a name="ln1431">    return false;</a>
<a name="ln1432">  }</a>
<a name="ln1433">  const bool peer_can_be_leader =</a>
<a name="ln1434">      !OpIdLessThan(peer-&gt;last_received, queue_state_.majority_replicated_op_id);</a>
<a name="ln1435">  if (!peer_can_be_leader) {</a>
<a name="ln1436">    LOG(INFO) &lt;&lt; Substitute(</a>
<a name="ln1437">        &quot;Peer $0 cannot become Leader as it is not caught up: Majority OpId $1, Peer OpId $2&quot;,</a>
<a name="ln1438">        peer_uuid, OpIdToString(queue_state_.majority_replicated_op_id),</a>
<a name="ln1439">        OpIdToString(peer-&gt;last_received));</a>
<a name="ln1440">  }</a>
<a name="ln1441">  return peer_can_be_leader;</a>
<a name="ln1442">}</a>
<a name="ln1443"> </a>
<a name="ln1444">string PeerMessageQueue::GetUpToDatePeer() const {</a>
<a name="ln1445">  OpIdPB highest_op_id = MinimumOpId();</a>
<a name="ln1446">  std::vector&lt;std::string&gt; candidates;</a>
<a name="ln1447"> </a>
<a name="ln1448">  {</a>
<a name="ln1449">    std::lock_guard&lt;simple_spinlock&gt; lock(queue_lock_);</a>
<a name="ln1450">    for (const PeersMap::value_type&amp; entry : peers_map_) {</a>
<a name="ln1451">      if (local_peer_uuid_ == entry.first) {</a>
<a name="ln1452">        continue;</a>
<a name="ln1453">      }</a>
<a name="ln1454">      if (OpIdBiggerThan(highest_op_id, entry.second-&gt;last_received)) {</a>
<a name="ln1455">        continue;</a>
<a name="ln1456">      } else if (OpIdEquals(highest_op_id, entry.second-&gt;last_received)) {</a>
<a name="ln1457">        candidates.push_back(entry.first);</a>
<a name="ln1458">      } else {</a>
<a name="ln1459">        candidates = {entry.first};</a>
<a name="ln1460">        highest_op_id = entry.second-&gt;last_received;</a>
<a name="ln1461">      }</a>
<a name="ln1462">    }</a>
<a name="ln1463">  }</a>
<a name="ln1464"> </a>
<a name="ln1465">  if (candidates.empty()) {</a>
<a name="ln1466">    return string();</a>
<a name="ln1467">  }</a>
<a name="ln1468">  size_t index = 0;</a>
<a name="ln1469">  if (candidates.size() &gt; 1) {</a>
<a name="ln1470">    // choose randomly among candidates at the same opid</a>
<a name="ln1471">    index = RandomUniformInt&lt;size_t&gt;(0, candidates.size() - 1);</a>
<a name="ln1472">  }</a>
<a name="ln1473">  return candidates[index];</a>
<a name="ln1474">}</a>
<a name="ln1475"> </a>
<a name="ln1476">PeerMessageQueue::~PeerMessageQueue() {</a>
<a name="ln1477">  Close();</a>
<a name="ln1478">}</a>
<a name="ln1479"> </a>
<a name="ln1480">string PeerMessageQueue::LogPrefixUnlocked() const {</a>
<a name="ln1481">  // TODO: we should probably use an atomic here. We'll just annotate away the TSAN error for now,</a>
<a name="ln1482">  // since the worst case is a slightly out-of-date log message, and not very likely.</a>
<a name="ln1483">  Mode mode = ANNOTATE_UNPROTECTED_READ(queue_state_.mode);</a>
<a name="ln1484">  return Substitute(&quot;T $0 P $1 [$2]: &quot;,</a>
<a name="ln1485">                    tablet_id_,</a>
<a name="ln1486">                    local_peer_uuid_,</a>
<a name="ln1487">                    ModeToStr(mode));</a>
<a name="ln1488">}</a>
<a name="ln1489"> </a>
<a name="ln1490">string PeerMessageQueue::QueueState::ToString() const {</a>
<a name="ln1491">  return Substitute(&quot;All replicated op: $0, Majority replicated op: $1, &quot;</a>
<a name="ln1492">      &quot;Committed index: $2, Last appended: $3, Current term: $4, Majority size: $5, &quot;</a>
<a name="ln1493">      &quot;State: $6, Mode: $7$8&quot;,</a>
<a name="ln1494">      /* 0 */ OpIdToString(all_replicated_op_id),</a>
<a name="ln1495">      /* 1 */ OpIdToString(majority_replicated_op_id),</a>
<a name="ln1496">      /* 2 */ OpIdToString(committed_op_id),</a>
<a name="ln1497">      /* 3 */ OpIdToString(last_appended),</a>
<a name="ln1498">      /* 4 */ current_term,</a>
<a name="ln1499">      /* 5 */ majority_size_,</a>
<a name="ln1500">      /* 6 */ StateToStr(state),</a>
<a name="ln1501">      /* 7 */ ModeToStr(mode),</a>
<a name="ln1502">      /* 8 */ active_config ? &quot;, active raft config: &quot; + active_config-&gt;ShortDebugString() : &quot;&quot;);</a>
<a name="ln1503">}</a>
<a name="ln1504"> </a>
<a name="ln1505">size_t PeerMessageQueue::LogCacheSize() {</a>
<a name="ln1506">  return log_cache_.BytesUsed();</a>
<a name="ln1507">}</a>
<a name="ln1508"> </a>
<a name="ln1509">size_t PeerMessageQueue::EvictLogCache(size_t bytes_to_evict) {</a>
<a name="ln1510">  return log_cache_.EvictThroughOp(std::numeric_limits&lt;int64_t&gt;::max(), bytes_to_evict);</a>
<a name="ln1511">}</a>
<a name="ln1512"> </a>
<a name="ln1513">Status PeerMessageQueue::FlushLogIndex() {</a>
<a name="ln1514">  return log_cache_.FlushIndex();</a>
<a name="ln1515">}</a>
<a name="ln1516"> </a>
<a name="ln1517">Status PeerMessageQueue::CopyLogTo(const std::string&amp; dest_dir) {</a>
<a name="ln1518">  return log_cache_.CopyLogTo(dest_dir);</a>
<a name="ln1519">}</a>
<a name="ln1520"> </a>
<a name="ln1521">void PeerMessageQueue::TrackOperationsMemory(const OpIds&amp; op_ids) {</a>
<a name="ln1522">  log_cache_.TrackOperationsMemory(op_ids);</a>
<a name="ln1523">}</a>
<a name="ln1524"> </a>
<a name="ln1525">}  // namespace consensus</a>
<a name="ln1526">}  // namespace yb</a>

</code></pre>
<div class="balloon" rel="212"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="213"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="234"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="239"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="273"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="345"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="424"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="601"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="606"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="610"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="612"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="808"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="860"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="886"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1006"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1051"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1067"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1071"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1072"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1073"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1108"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1119"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>
<div class="balloon" rel="1147"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v561/" target="_blank">V561</a> It's probably better to assign value to 'result' variable than to declare it anew. Previous declaration: consensus_queue.cc, line 1011.</p></div>
<div class="balloon" rel="1148"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v561/" target="_blank">V561</a> It's probably better to assign value to 'result' variable than to declare it anew. Previous declaration: consensus_queue.cc, line 1011.</p></div>
<div class="balloon" rel="1148"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v521/" target="_blank">V521</a> Such expressions using the ',' operator are dangerous. Make sure the expression is correct.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
